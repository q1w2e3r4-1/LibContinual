Label: podnet_cnn_cifar100_5steps
orders : None
{'model': 'podnet', 'convnet': 'rebuffi', 'dropout': 0.0, 'herding': None, 'memory_size': 2000, 'temperature': 1, 'fixed_memory': True, 'dataset': 'cifar100', 'increment': 10, 'batch_size': 128, 'workers': 0, 'threads': 1, 'validation': 0.0, 'random_classes': False, 'max_task': None, 'onehot': False, 'initial_increment': None, 'sampler': None, 'data_path': '/data/douillard/', 'lr': 0.1, 'weight_decay': 0.0005, 'scheduling': 'cosine', 'lr_decay': 0.1, 'optimizer': 'sgd', 'epochs': 160, 'device': [0], 'label': 'podnet_cnn_cifar100_5steps', 'autolabel': False, 'seed': [1], 'seed_range': None, 'options': None, 'save_model': 'last', 'dump_predictions': False, 'logging': 'info', 'resume': None, 'resume_first': False, 'recompute_meta': False, 'no_benchmark': False, 'detect_anomaly': False, 'dummy': 1, 'includes': ['headers/dummy.yaml'], 'data_root': 'D:/data/douillard/cifar100/cifar100', 'save_path': '.', 'initial-increment': 50, 'backbone': {'name': 'resnet18'}, 'classifier': {'name': 'PODNet'}, 'eval_type': 'cnn', 'classifier_config': {'type': 'cosine', 'proxy_per_class': 10, 'distance': 'neg_stable_cosine_distance'}, 'postprocessor_config': {'type': 'learned_scaling', 'initial_value': 1.0}, 'pod_flat': {'scheduled_factor': 1.0}, 'pod_spatial': {'scheduled_factor': 3.0, 'collapse_channels': 'spatial'}, 'nca': {'margin': 0.6, 'scale': 1.0, 'exclude_pos_denominator': True}, 'groupwise_factors': {'old_weights': 0.0}, 'finetuning_config': {'sampling': 'undersampling', 'tuning': 'classifier', 'lr': 0.05, 'epochs': 20, 'scaling': None}, 'proxy_per_class': 1, 'weight_generation': {'type': 'imprinted', 'multi_class_diff': 'kmeans'}, 'dataset_transforms': {'color_jitter': True}}
Launching run 1/1
Set seed 1
CUDA algos are determinists but very slow!
Files already downloaded and verified
Files already downloaded and verified
Dataset iCIFAR100: class ordering: [87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39].
Downsampling type stride
Using 10 proxies per class.
Model will be save at this rythm: last.
================Task 0 Start!================
Testing on False unseen tasks (max class = 10).
Before task
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 0 Training!================
The training samples number: 5000
Train on 0->10.
train task
nb 5000.
Train [1/10] | Epoch [1/160] |	nca: 88.84441983699799, loss: 88.84441983699799 
Train [1/10] | Epoch [2/160] |	nca: 79.11060011386871, loss: 79.11060011386871 
Train [1/10] | Epoch [3/160] |	nca: 69.87183785438538, loss: 69.87183785438538 
Train [1/10] | Epoch [4/160] |	nca: 67.760573387146, loss: 67.760573387146 
Train [1/10] | Epoch [5/160] |	nca: 61.4876629114151, loss: 61.4876629114151 
Train [1/10] | Epoch [6/160] |	nca: 57.765395641326904, loss: 57.765395641326904 
Train [1/10] | Epoch [7/160] |	nca: 58.55780065059662, loss: 58.55780065059662 
Train [1/10] | Epoch [8/160] |	nca: 61.118607878685, loss: 61.118607878685 
Train [1/10] | Epoch [9/160] |	nca: 52.641666889190674, loss: 52.641666889190674 
Train [1/10] | Epoch [10/160] |	nca: 50.011925518512726, loss: 50.011925518512726 
Train [1/10] | Epoch [11/160] |	nca: 46.124371945858, loss: 46.124371945858 
Train [1/10] | Epoch [12/160] |	nca: 47.98937165737152, loss: 47.98937165737152 
Train [1/10] | Epoch [13/160] |	nca: 41.13694751262665, loss: 41.13694751262665 
Train [1/10] | Epoch [14/160] |	nca: 38.33891588449478, loss: 38.33891588449478 
Train [1/10] | Epoch [15/160] |	nca: 41.61185312271118, loss: 41.61185312271118 
Train [1/10] | Epoch [16/160] |	nca: 37.48698478937149, loss: 37.48698478937149 
Train [1/10] | Epoch [17/160] |	nca: 36.17705136537552, loss: 36.17705136537552 
Train [1/10] | Epoch [18/160] |	nca: 31.558313488960266, loss: 31.558313488960266 
Train [1/10] | Epoch [19/160] |	nca: 31.039835035800934, loss: 31.039835035800934 
Train [1/10] | Epoch [20/160] |	nca: 29.14112424850464, loss: 29.14112424850464 
Train [1/10] | Epoch [21/160] |	nca: 28.146292254328728, loss: 28.146292254328728 
Train [1/10] | Epoch [22/160] |	nca: 27.267662465572357, loss: 27.267662465572357 
Train [1/10] | Epoch [23/160] |	nca: 29.614355206489563, loss: 29.614355206489563 
Train [1/10] | Epoch [24/160] |	nca: 25.7166149020195, loss: 25.7166149020195 
Train [1/10] | Epoch [25/160] |	nca: 24.665851354599, loss: 24.665851354599 
Train [1/10] | Epoch [26/160] |	nca: 31.460562586784363, loss: 31.460562586784363 
Train [1/10] | Epoch [27/160] |	nca: 25.70610323548317, loss: 25.70610323548317 
Train [1/10] | Epoch [28/160] |	nca: 27.466257512569427, loss: 27.466257512569427 
Train [1/10] | Epoch [29/160] |	nca: 26.034245878458023, loss: 26.034245878458023 
Train [1/10] | Epoch [30/160] |	nca: 22.61686474084854, loss: 22.61686474084854 
Train [1/10] | Epoch [31/160] |	nca: 24.434981286525726, loss: 24.434981286525726 
Train [1/10] | Epoch [32/160] |	nca: 24.49695262312889, loss: 24.49695262312889 
Train [1/10] | Epoch [33/160] |	nca: 24.216795057058334, loss: 24.216795057058334 
Train [1/10] | Epoch [34/160] |	nca: 21.524989813566208, loss: 21.524989813566208 
Train [1/10] | Epoch [35/160] |	nca: 22.25376459956169, loss: 22.25376459956169 
Train [1/10] | Epoch [36/160] |	nca: 25.10152617096901, loss: 25.10152617096901 
Train [1/10] | Epoch [37/160] |	nca: 20.73759739100933, loss: 20.73759739100933 
Train [1/10] | Epoch [38/160] |	nca: 19.360168516635895, loss: 19.360168516635895 
Train [1/10] | Epoch [39/160] |	nca: 19.298235774040222, loss: 19.298235774040222 
Train [1/10] | Epoch [40/160] |	nca: 21.336131006479263, loss: 21.336131006479263 
Train [1/10] | Epoch [41/160] |	nca: 20.30236107110977, loss: 20.30236107110977 
Train [1/10] | Epoch [42/160] |	nca: 19.6372711956501, loss: 19.6372711956501 
Train [1/10] | Epoch [43/160] |	nca: 23.869147300720215, loss: 23.869147300720215 
Train [1/10] | Epoch [44/160] |	nca: 18.047589749097824, loss: 18.047589749097824 
Train [1/10] | Epoch [45/160] |	nca: 16.986017525196075, loss: 16.986017525196075 
Train [1/10] | Epoch [46/160] |	nca: 18.702930718660355, loss: 18.702930718660355 
Train [1/10] | Epoch [47/160] |	nca: 20.02269470691681, loss: 20.02269470691681 
Train [1/10] | Epoch [48/160] |	nca: 16.908311873674393, loss: 16.908311873674393 
Train [1/10] | Epoch [49/160] |	nca: 16.292940318584442, loss: 16.292940318584442 
Train [1/10] | Epoch [50/160] |	nca: 17.29039904475212, loss: 17.29039904475212 
Train [1/10] | Epoch [51/160] |	nca: 16.196531489491463, loss: 16.196531489491463 
Train [1/10] | Epoch [52/160] |	nca: 17.626958400011063, loss: 17.626958400011063 
Train [1/10] | Epoch [53/160] |	nca: 14.887350410223007, loss: 14.887350410223007 
Train [1/10] | Epoch [54/160] |	nca: 13.493476524949074, loss: 13.493476524949074 
Train [1/10] | Epoch [55/160] |	nca: 15.662740111351013, loss: 15.662740111351013 
Train [1/10] | Epoch [56/160] |	nca: 19.79817247390747, loss: 19.79817247390747 
Train [1/10] | Epoch [57/160] |	nca: 17.4656832665205, loss: 17.4656832665205 
Train [1/10] | Epoch [58/160] |	nca: 14.333144053816795, loss: 14.333144053816795 
Train [1/10] | Epoch [59/160] |	nca: 13.881128057837486, loss: 13.881128057837486 
Train [1/10] | Epoch [60/160] |	nca: 12.178027212619781, loss: 12.178027212619781 
Train [1/10] | Epoch [61/160] |	nca: 15.482374995946884, loss: 15.482374995946884 
Train [1/10] | Epoch [62/160] |	nca: 21.452505439519882, loss: 21.452505439519882 
Train [1/10] | Epoch [63/160] |	nca: 16.14898830652237, loss: 16.14898830652237 
Train [1/10] | Epoch [64/160] |	nca: 18.0999355353415, loss: 18.0999355353415 
Train [1/10] | Epoch [65/160] |	nca: 12.255662888288498, loss: 12.255662888288498 
Train [1/10] | Epoch [66/160] |	nca: 11.21840363740921, loss: 11.21840363740921 
Train [1/10] | Epoch [67/160] |	nca: 11.587950974702835, loss: 11.587950974702835 
Train [1/10] | Epoch [68/160] |	nca: 14.211926087737083, loss: 14.211926087737083 
Train [1/10] | Epoch [69/160] |	nca: 10.715613439679146, loss: 10.715613439679146 
Train [1/10] | Epoch [70/160] |	nca: 10.682947255671024, loss: 10.682947255671024 
Train [1/10] | Epoch [71/160] |	nca: 9.17995135486126, loss: 9.17995135486126 
Train [1/10] | Epoch [72/160] |	nca: 14.190697431564331, loss: 14.190697431564331 
Train [1/10] | Epoch [73/160] |	nca: 14.255453154444695, loss: 14.255453154444695 
Train [1/10] | Epoch [74/160] |	nca: 10.786579564213753, loss: 10.786579564213753 
Train [1/10] | Epoch [75/160] |	nca: 10.620489716529846, loss: 10.620489716529846 
Train [1/10] | Epoch [76/160] |	nca: 8.217870600521564, loss: 8.217870600521564 
Train [1/10] | Epoch [77/160] |	nca: 8.797773614525795, loss: 8.797773614525795 
Train [1/10] | Epoch [78/160] |	nca: 15.660394340753555, loss: 15.660394340753555 
Train [1/10] | Epoch [79/160] |	nca: 13.180777668952942, loss: 13.180777668952942 
Train [1/10] | Epoch [80/160] |	nca: 12.27100694179535, loss: 12.27100694179535 
Train [1/10] | Epoch [81/160] |	nca: 10.306177034974098, loss: 10.306177034974098 
Train [1/10] | Epoch [82/160] |	nca: 9.393114902079105, loss: 9.393114902079105 
Train [1/10] | Epoch [83/160] |	nca: 8.107420355081558, loss: 8.107420355081558 
Train [1/10] | Epoch [84/160] |	nca: 11.96583865582943, loss: 11.96583865582943 
Train [1/10] | Epoch [85/160] |	nca: 9.675739236176014, loss: 9.675739236176014 
Train [1/10] | Epoch [86/160] |	nca: 7.106740206480026, loss: 7.106740206480026 
Train [1/10] | Epoch [87/160] |	nca: 8.70975286513567, loss: 8.70975286513567 
Train [1/10] | Epoch [88/160] |	nca: 6.708696834743023, loss: 6.708696834743023 
Train [1/10] | Epoch [89/160] |	nca: 5.330506805330515, loss: 5.330506805330515 
Train [1/10] | Epoch [90/160] |	nca: 15.562799111008644, loss: 15.562799111008644 
Train [1/10] | Epoch [91/160] |	nca: 10.72421245276928, loss: 10.72421245276928 
Train [1/10] | Epoch [92/160] |	nca: 11.199054040014744, loss: 11.199054040014744 
Train [1/10] | Epoch [93/160] |	nca: 6.844364307820797, loss: 6.844364307820797 
Train [1/10] | Epoch [94/160] |	nca: 5.671864660456777, loss: 5.671864660456777 
Train [1/10] | Epoch [95/160] |	nca: 5.9802578911185265, loss: 5.9802578911185265 
Train [1/10] | Epoch [96/160] |	nca: 9.053905107080936, loss: 9.053905107080936 
Train [1/10] | Epoch [97/160] |	nca: 8.747503161430359, loss: 8.747503161430359 
Train [1/10] | Epoch [98/160] |	nca: 5.682395348325372, loss: 5.682395348325372 
Train [1/10] | Epoch [99/160] |	nca: 4.490729711949825, loss: 4.490729711949825 
Train [1/10] | Epoch [100/160] |	nca: 8.596702877432108, loss: 8.596702877432108 
Train [1/10] | Epoch [101/160] |	nca: 10.59942802786827, loss: 10.59942802786827 
Train [1/10] | Epoch [102/160] |	nca: 7.602950654923916, loss: 7.602950654923916 
Train [1/10] | Epoch [103/160] |	nca: 6.941958054900169, loss: 6.941958054900169 
Train [1/10] | Epoch [104/160] |	nca: 6.013751566410065, loss: 6.013751566410065 
Train [1/10] | Epoch [105/160] |	nca: 3.92404193431139, loss: 3.92404193431139 
Train [1/10] | Epoch [106/160] |	nca: 4.092467879876494, loss: 4.092467879876494 
Train [1/10] | Epoch [107/160] |	nca: 7.322939682751894, loss: 7.322939682751894 
Train [1/10] | Epoch [108/160] |	nca: 3.9237627387046814, loss: 3.9237627387046814 
Train [1/10] | Epoch [109/160] |	nca: 2.9092899411916733, loss: 2.9092899411916733 
Train [1/10] | Epoch [110/160] |	nca: 2.9806635566055775, loss: 2.9806635566055775 
Train [1/10] | Epoch [111/160] |	nca: 2.622420061379671, loss: 2.622420061379671 
Train [1/10] | Epoch [112/160] |	nca: 2.217816775664687, loss: 2.217816775664687 
Train [1/10] | Epoch [113/160] |	nca: 2.1876702290028334, loss: 2.1876702290028334 
Train [1/10] | Epoch [114/160] |	nca: 2.1230416540056467, loss: 2.1230416540056467 
Train [1/10] | Epoch [115/160] |	nca: 3.001470061019063, loss: 3.001470061019063 
Train [1/10] | Epoch [116/160] |	nca: 1.8772341357544065, loss: 1.8772341357544065 
Train [1/10] | Epoch [117/160] |	nca: 1.6524647790938616, loss: 1.6524647790938616 
Train [1/10] | Epoch [118/160] |	nca: 5.20774245634675, loss: 5.20774245634675 
Train [1/10] | Epoch [119/160] |	nca: 3.857597967609763, loss: 3.857597967609763 
Train [1/10] | Epoch [120/160] |	nca: 2.7219928223639727, loss: 2.7219928223639727 
Train [1/10] | Epoch [121/160] |	nca: 1.9818655289709568, loss: 1.9818655289709568 
Train [1/10] | Epoch [122/160] |	nca: 1.9441731479018927, loss: 1.9441731479018927 
Train [1/10] | Epoch [123/160] |	nca: 4.081394325941801, loss: 4.081394325941801 
Train [1/10] | Epoch [124/160] |	nca: 3.762441474944353, loss: 3.762441474944353 
Train [1/10] | Epoch [125/160] |	nca: 1.8112479783594608, loss: 1.8112479783594608 
Train [1/10] | Epoch [126/160] |	nca: 1.8238635435700417, loss: 1.8238635435700417 
Train [1/10] | Epoch [127/160] |	nca: 2.0173300434835255, loss: 2.0173300434835255 
Train [1/10] | Epoch [128/160] |	nca: 1.2823276352137327, loss: 1.2823276352137327 
Train [1/10] | Epoch [129/160] |	nca: 1.7218201365321875, loss: 1.7218201365321875 
Train [1/10] | Epoch [130/160] |	nca: 1.3576721157878637, loss: 1.3576721157878637 
Train [1/10] | Epoch [131/160] |	nca: 1.6389580825343728, loss: 1.6389580825343728 
Train [1/10] | Epoch [132/160] |	nca: 3.2880026176571846, loss: 3.2880026176571846 
Train [1/10] | Epoch [133/160] |	nca: 3.3953201845288277, loss: 3.3953201845288277 
Train [1/10] | Epoch [134/160] |	nca: 1.8788081416860223, loss: 1.8788081416860223 
Train [1/10] | Epoch [135/160] |	nca: 2.046871729195118, loss: 2.046871729195118 
Train [1/10] | Epoch [136/160] |	nca: 1.856322773732245, loss: 1.856322773732245 
Train [1/10] | Epoch [137/160] |	nca: 1.17637487500906, loss: 1.17637487500906 
Train [1/10] | Epoch [138/160] |	nca: 1.012266760226339, loss: 1.012266760226339 
Train [1/10] | Epoch [139/160] |	nca: 1.5749897547066212, loss: 1.5749897547066212 
Train [1/10] | Epoch [140/160] |	nca: 1.100706983357668, loss: 1.100706983357668 
Train [1/10] | Epoch [141/160] |	nca: 1.0929383039474487, loss: 1.0929383039474487 
Train [1/10] | Epoch [142/160] |	nca: 2.0995299136266112, loss: 2.0995299136266112 
Train [1/10] | Epoch [143/160] |	nca: 1.1189644378609955, loss: 1.1189644378609955 
Train [1/10] | Epoch [144/160] |	nca: 0.8651203024201095, loss: 0.8651203024201095 
Train [1/10] | Epoch [145/160] |	nca: 0.697887783870101, loss: 0.697887783870101 
Train [1/10] | Epoch [146/160] |	nca: 1.347928721923381, loss: 1.347928721923381 
Train [1/10] | Epoch [147/160] |	nca: 0.8967813467606902, loss: 0.8967813467606902 
Train [1/10] | Epoch [148/160] |	nca: 1.2267691539600492, loss: 1.2267691539600492 
Train [1/10] | Epoch [149/160] |	nca: 1.0294316057115793, loss: 1.0294316057115793 
Train [1/10] | Epoch [150/160] |	nca: 0.8092709833290428, loss: 0.8092709833290428 
Train [1/10] | Epoch [151/160] |	nca: 0.755003969417885, loss: 0.755003969417885 
Train [1/10] | Epoch [152/160] |	nca: 0.7986320955678821, loss: 0.7986320955678821 
Train [1/10] | Epoch [153/160] |	nca: 0.7164351996034384, loss: 0.7164351996034384 
Train [1/10] | Epoch [154/160] |	nca: 0.6697168624959886, loss: 0.6697168624959886 
Train [1/10] | Epoch [155/160] |	nca: 0.9029221888631582, loss: 0.9029221888631582 
Train [1/10] | Epoch [156/160] |	nca: 0.6803017952479422, loss: 0.6803017952479422 
Train [1/10] | Epoch [157/160] |	nca: 0.7366912122815847, loss: 0.7366912122815847 
Train [1/10] | Epoch [158/160] |	nca: 0.8101147077977657, loss: 0.8101147077977657 
Train [1/10] | Epoch [159/160] |	nca: 0.6266393573023379, loss: 0.6266393573023379 
Train [1/10] | Epoch [160/160] |	nca: 0.5611117458902299, loss: 0.5611117458902299 
after task
Building & updating memory.
after task
Eval on 0->10.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.916.
Current acc: {'total': 0.916, '00-09': 0.916}.
Avg inc acc top5: 0.996.
Current acc top5: {'total': 0.996}.
Forgetting: 0.0.
Cord metric: 0.92.
================Task 1 Start!================
Testing on False unseen tasks (max class = 20).
Set memory of size: 200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 1 Training!================
The training samples number: 5200
Train on 10->20.
train task
nb 5200.
Train [2/10] | Epoch [1/160] |	nca: 53.1803075671196, flat: 10.831761576235294, pod: 49.00676304101944, loss: 113.01883339881897 
Train [2/10] | Epoch [2/160] |	nca: 38.54024738073349, flat: 7.965770870447159, pod: 40.47199660539627, loss: 86.97801446914673 
Train [2/10] | Epoch [3/160] |	nca: 34.53479486703873, flat: 7.873882085084915, pod: 38.693058013916016, loss: 81.1017347574234 
Train [2/10] | Epoch [4/160] |	nca: 32.26461058855057, flat: 8.182074710726738, pod: 39.53561228513718, loss: 79.98229777812958 
Train [2/10] | Epoch [5/160] |	nca: 30.199222445487976, flat: 8.288762509822845, pod: 39.42194873094559, loss: 77.90993368625641 
Train [2/10] | Epoch [6/160] |	nca: 28.244422554969788, flat: 8.001119166612625, pod: 38.597612500190735, loss: 74.84315383434296 
Train [2/10] | Epoch [7/160] |	nca: 27.800767213106155, flat: 8.226141899824142, pod: 38.350551068782806, loss: 74.37746059894562 
Train [2/10] | Epoch [8/160] |	nca: 26.636409163475037, flat: 8.403113543987274, pod: 38.51271587610245, loss: 73.5522391796112 
Train [2/10] | Epoch [9/160] |	nca: 25.162962049245834, flat: 8.355438753962517, pod: 38.18856394290924, loss: 71.70696449279785 
Train [2/10] | Epoch [10/160] |	nca: 23.938359409570694, flat: 8.136564895510674, pod: 37.14654803276062, loss: 69.22147274017334 
Train [2/10] | Epoch [11/160] |	nca: 23.03831347823143, flat: 8.263782441616058, pod: 37.596012234687805, loss: 68.89810764789581 
Train [2/10] | Epoch [12/160] |	nca: 22.614782571792603, flat: 8.278211697936058, pod: 37.20484644174576, loss: 68.09784007072449 
Train [2/10] | Epoch [13/160] |	nca: 21.256848126649857, flat: 8.36401928961277, pod: 37.59422701597214, loss: 67.21509444713593 
Train [2/10] | Epoch [14/160] |	nca: 20.399477303028107, flat: 8.203046098351479, pod: 37.052861750125885, loss: 65.6553852558136 
Train [2/10] | Epoch [15/160] |	nca: 21.575133591890335, flat: 8.546861320734024, pod: 37.57928657531738, loss: 67.70128190517426 
Train [2/10] | Epoch [16/160] |	nca: 20.66126537322998, flat: 8.433486506342888, pod: 37.34601002931595, loss: 66.44076192378998 
Train [2/10] | Epoch [17/160] |	nca: 18.639484345912933, flat: 8.438356935977936, pod: 37.01089406013489, loss: 64.08873569965363 
Train [2/10] | Epoch [18/160] |	nca: 18.321478098630905, flat: 8.234966948628426, pod: 36.426277339458466, loss: 62.9827219247818 
Train [2/10] | Epoch [19/160] |	nca: 18.955341935157776, flat: 8.30617207288742, pod: 36.793027341365814, loss: 64.05454134941101 
Train [2/10] | Epoch [20/160] |	nca: 18.540781468153, flat: 8.182326912879944, pod: 37.01102691888809, loss: 63.734134912490845 
Train [2/10] | Epoch [21/160] |	nca: 17.82673344016075, flat: 8.311381354928017, pod: 36.481576800346375, loss: 62.61969196796417 
Train [2/10] | Epoch [22/160] |	nca: 17.14566159248352, flat: 8.309697791934013, pod: 37.01939249038696, loss: 62.4747519493103 
Train [2/10] | Epoch [23/160] |	nca: 17.829312801361084, flat: 8.67448903620243, pod: 37.96159780025482, loss: 64.46539998054504 
Train [2/10] | Epoch [24/160] |	nca: 16.23275938630104, flat: 8.218460246920586, pod: 36.26207286119461, loss: 60.7132922410965 
Train [2/10] | Epoch [25/160] |	nca: 16.043468356132507, flat: 8.338031083345413, pod: 36.636547565460205, loss: 61.0180469751358 
Train [2/10] | Epoch [26/160] |	nca: 16.743018448352814, flat: 8.556379303336143, pod: 37.481331169605255, loss: 62.780728340148926 
Train [2/10] | Epoch [27/160] |	nca: 15.21702167391777, flat: 8.223295345902443, pod: 35.77941453456879, loss: 59.21973133087158 
Train [2/10] | Epoch [28/160] |	nca: 15.324515610933304, flat: 8.206759959459305, pod: 35.71237391233444, loss: 59.24364912509918 
Train [2/10] | Epoch [29/160] |	nca: 15.026245012879372, flat: 8.258257880806923, pod: 35.77609133720398, loss: 59.06059396266937 
Train [2/10] | Epoch [30/160] |	nca: 14.88687151670456, flat: 8.155710726976395, pod: 35.512183010578156, loss: 58.554765462875366 
Train [2/10] | Epoch [31/160] |	nca: 14.898163080215454, flat: 8.353125765919685, pod: 35.98576033115387, loss: 59.237048983573914 
Train [2/10] | Epoch [32/160] |	nca: 16.05575506389141, flat: 8.26088048517704, pod: 35.90843105316162, loss: 60.22506630420685 
Train [2/10] | Epoch [33/160] |	nca: 13.124508067965508, flat: 8.164648920297623, pod: 36.15939736366272, loss: 57.44855439662933 
Train [2/10] | Epoch [34/160] |	nca: 13.623621001839638, flat: 8.140870466828346, pod: 35.44167101383209, loss: 57.20616281032562 
Train [2/10] | Epoch [35/160] |	nca: 12.683138236403465, flat: 7.936888962984085, pod: 34.07749664783478, loss: 54.697524428367615 
Train [2/10] | Epoch [36/160] |	nca: 13.313115492463112, flat: 8.034969910979271, pod: 35.0462760925293, loss: 56.3943612575531 
Train [2/10] | Epoch [37/160] |	nca: 13.422682225704193, flat: 8.305210724473, pod: 35.91373324394226, loss: 57.64162635803223 
Train [2/10] | Epoch [38/160] |	nca: 14.039330080151558, flat: 8.169956997036934, pod: 35.37662208080292, loss: 57.585909366607666 
Train [2/10] | Epoch [39/160] |	nca: 13.235639989376068, flat: 8.05014668405056, pod: 35.09444856643677, loss: 56.380234599113464 
Train [2/10] | Epoch [40/160] |	nca: 12.471435204148293, flat: 8.196192145347595, pod: 35.04222106933594, loss: 55.709848403930664 
Train [2/10] | Epoch [41/160] |	nca: 12.620610922574997, flat: 7.9936167150735855, pod: 34.91371214389801, loss: 55.527939677238464 
Train [2/10] | Epoch [42/160] |	nca: 12.527895480394363, flat: 8.287284135818481, pod: 35.32405602931976, loss: 56.13923633098602 
Train [2/10] | Epoch [43/160] |	nca: 13.233005672693253, flat: 8.03876842558384, pod: 35.23940551280975, loss: 56.51117956638336 
Train [2/10] | Epoch [44/160] |	nca: 13.254984587430954, flat: 8.450146958231926, pod: 36.097336769104004, loss: 57.80246841907501 
Train [2/10] | Epoch [45/160] |	nca: 12.624224528670311, flat: 8.281745821237564, pod: 35.39846450090408, loss: 56.30443477630615 
Train [2/10] | Epoch [46/160] |	nca: 11.975444465875626, flat: 8.375563144683838, pod: 35.25090134143829, loss: 55.601908922195435 
Train [2/10] | Epoch [47/160] |	nca: 11.221414119005203, flat: 7.837565526366234, pod: 34.00851386785507, loss: 53.06749391555786 
Train [2/10] | Epoch [48/160] |	nca: 10.615358352661133, flat: 7.821471258997917, pod: 33.58873361349106, loss: 52.02556324005127 
Train [2/10] | Epoch [49/160] |	nca: 11.096948340535164, flat: 8.053916096687317, pod: 34.144936978816986, loss: 53.295801281929016 
Train [2/10] | Epoch [50/160] |	nca: 11.721548423171043, flat: 8.224699169397354, pod: 34.69744873046875, loss: 54.6436961889267 
Train [2/10] | Epoch [51/160] |	nca: 10.436226263642311, flat: 8.128109991550446, pod: 34.32605290412903, loss: 52.89038920402527 
Train [2/10] | Epoch [52/160] |	nca: 10.972901418805122, flat: 8.035086765885353, pod: 34.25908446311951, loss: 53.267072439193726 
Train [2/10] | Epoch [53/160] |	nca: 9.961771935224533, flat: 7.8380855321884155, pod: 34.10635370016098, loss: 51.906211256980896 
Train [2/10] | Epoch [54/160] |	nca: 10.939962849020958, flat: 7.854085355997086, pod: 33.44249540567398, loss: 52.23654329776764 
Train [2/10] | Epoch [55/160] |	nca: 9.199629828333855, flat: 7.590988919138908, pod: 32.596274852752686, loss: 49.38689339160919 
Train [2/10] | Epoch [56/160] |	nca: 9.757126405835152, flat: 7.761863499879837, pod: 32.77257055044174, loss: 50.291560649871826 
Train [2/10] | Epoch [57/160] |	nca: 9.901143938302994, flat: 7.685535207390785, pod: 32.10211056470871, loss: 49.68878948688507 
Train [2/10] | Epoch [58/160] |	nca: 9.2884416654706, flat: 7.637851789593697, pod: 32.752628564834595, loss: 49.67892229557037 
Train [2/10] | Epoch [59/160] |	nca: 9.469914346933365, flat: 7.795221269130707, pod: 33.38584053516388, loss: 50.650975823402405 
Train [2/10] | Epoch [60/160] |	nca: 8.91068384051323, flat: 7.571899935603142, pod: 32.70652395486832, loss: 49.18910753726959 
Train [2/10] | Epoch [61/160] |	nca: 10.380798563361168, flat: 7.890178442001343, pod: 33.88465362787247, loss: 52.155630588531494 
Train [2/10] | Epoch [62/160] |	nca: 9.050983779132366, flat: 7.576329082250595, pod: 32.29424452781677, loss: 48.92155706882477 
Train [2/10] | Epoch [63/160] |	nca: 8.819420218467712, flat: 7.620288819074631, pod: 32.52677124738693, loss: 48.96648037433624 
Train [2/10] | Epoch [64/160] |	nca: 9.092872381210327, flat: 7.429470509290695, pod: 32.353047609329224, loss: 48.87539052963257 
Train [2/10] | Epoch [65/160] |	nca: 8.84471731632948, flat: 7.591203838586807, pod: 32.21832048892975, loss: 48.65424132347107 
Train [2/10] | Epoch [66/160] |	nca: 8.799134075641632, flat: 7.613512888550758, pod: 31.948223531246185, loss: 48.360870718955994 
Train [2/10] | Epoch [67/160] |	nca: 9.054718062281609, flat: 7.722307413816452, pod: 32.61272048950195, loss: 49.38974595069885 
Train [2/10] | Epoch [68/160] |	nca: 8.3243950009346, flat: 7.516322121024132, pod: 31.4372421503067, loss: 47.27795934677124 
Train [2/10] | Epoch [69/160] |	nca: 8.53178359568119, flat: 7.513476014137268, pod: 31.46239799261093, loss: 47.507657289505005 
Train [2/10] | Epoch [70/160] |	nca: 7.343572057783604, flat: 7.367592975497246, pod: 30.656177818775177, loss: 45.36734312772751 
Train [2/10] | Epoch [71/160] |	nca: 7.81770870834589, flat: 7.352066591382027, pod: 30.867328464984894, loss: 46.03710389137268 
Train [2/10] | Epoch [72/160] |	nca: 10.001009181141853, flat: 7.8141273111104965, pod: 32.93395984172821, loss: 50.749096155166626 
Train [2/10] | Epoch [73/160] |	nca: 9.003186643123627, flat: 7.660061746835709, pod: 32.55941951274872, loss: 49.222668051719666 
Train [2/10] | Epoch [74/160] |	nca: 7.760841570794582, flat: 7.379398003220558, pod: 31.368741512298584, loss: 46.50898087024689 
Train [2/10] | Epoch [75/160] |	nca: 6.390331514179707, flat: 7.143125042319298, pod: 30.067838430404663, loss: 43.60129529237747 
Train [2/10] | Epoch [76/160] |	nca: 7.243853472173214, flat: 7.128695398569107, pod: 29.92161500453949, loss: 44.29416382312775 
Train [2/10] | Epoch [77/160] |	nca: 6.947729855775833, flat: 7.218182191252708, pod: 30.100691199302673, loss: 44.26660358905792 
Train [2/10] | Epoch [78/160] |	nca: 7.331827759742737, flat: 7.0739856362342834, pod: 30.216419398784637, loss: 44.62223303318024 
Train [2/10] | Epoch [79/160] |	nca: 7.797644928097725, flat: 7.155723720788956, pod: 30.364736557006836, loss: 45.31810522079468 
Train [2/10] | Epoch [80/160] |	nca: 6.819819688796997, flat: 6.996194586157799, pod: 29.378389954566956, loss: 43.19440424442291 
Train [2/10] | Epoch [81/160] |	nca: 6.851695969700813, flat: 7.081292167305946, pod: 29.782094359397888, loss: 43.715082347393036 
Train [2/10] | Epoch [82/160] |	nca: 6.770205624401569, flat: 7.1818061619997025, pod: 29.57790905237198, loss: 43.5299209356308 
Train [2/10] | Epoch [83/160] |	nca: 6.3874706998467445, flat: 6.92057004570961, pod: 29.03444814682007, loss: 42.34248864650726 
Train [2/10] | Epoch [84/160] |	nca: 6.181533589959145, flat: 6.914877638220787, pod: 28.82257640361786, loss: 41.918987452983856 
Train [2/10] | Epoch [85/160] |	nca: 5.633309155702591, flat: 6.636305421590805, pod: 28.228784799575806, loss: 40.49839919805527 
Train [2/10] | Epoch [86/160] |	nca: 5.688617564737797, flat: 6.641980886459351, pod: 27.969234347343445, loss: 40.29983294010162 
Train [2/10] | Epoch [87/160] |	nca: 6.435007907450199, flat: 6.806892082095146, pod: 28.743301510810852, loss: 41.985201478004456 
Train [2/10] | Epoch [88/160] |	nca: 6.571753941476345, flat: 6.7180145829916, pod: 28.336415946483612, loss: 41.62618452310562 
Train [2/10] | Epoch [89/160] |	nca: 5.931692041456699, flat: 6.6669565588235855, pod: 27.472398459911346, loss: 40.07104694843292 
Train [2/10] | Epoch [90/160] |	nca: 5.823345519602299, flat: 6.633481189608574, pod: 27.673619031906128, loss: 40.13044571876526 
Train [2/10] | Epoch [91/160] |	nca: 5.543634377419949, flat: 6.512427717447281, pod: 27.689548015594482, loss: 39.74561011791229 
Train [2/10] | Epoch [92/160] |	nca: 5.619208209216595, flat: 6.58112308382988, pod: 27.381402909755707, loss: 39.581734240055084 
Train [2/10] | Epoch [93/160] |	nca: 5.476626705378294, flat: 6.5624697506427765, pod: 27.556347966194153, loss: 39.595444321632385 
Train [2/10] | Epoch [94/160] |	nca: 6.099405333399773, flat: 6.6635867059230804, pod: 27.707430720329285, loss: 40.470423102378845 
Train [2/10] | Epoch [95/160] |	nca: 5.517389249056578, flat: 6.537497252225876, pod: 27.069342017173767, loss: 39.124228715896606 
Train [2/10] | Epoch [96/160] |	nca: 5.878325156867504, flat: 6.540554627776146, pod: 27.24757480621338, loss: 39.66645449399948 
Train [2/10] | Epoch [97/160] |	nca: 4.993204966187477, flat: 6.403246909379959, pod: 26.518275678157806, loss: 37.91472774744034 
Train [2/10] | Epoch [98/160] |	nca: 5.281986862421036, flat: 6.404392406344414, pod: 26.655311942100525, loss: 38.341691076755524 
Train [2/10] | Epoch [99/160] |	nca: 5.091595873236656, flat: 6.389503076672554, pod: 26.217895567417145, loss: 37.69899445772171 
Train [2/10] | Epoch [100/160] |	nca: 5.067117132246494, flat: 6.280989468097687, pod: 26.133501946926117, loss: 37.481608510017395 
Train [2/10] | Epoch [101/160] |	nca: 4.7478901743888855, flat: 6.192020118236542, pod: 25.59594827890396, loss: 36.53585869073868 
Train [2/10] | Epoch [102/160] |	nca: 4.636456001549959, flat: 6.233414605259895, pod: 25.73233550786972, loss: 36.60220617055893 
Train [2/10] | Epoch [103/160] |	nca: 4.7817616909742355, flat: 6.132700219750404, pod: 25.72842788696289, loss: 36.64288991689682 
Train [2/10] | Epoch [104/160] |	nca: 4.518760766834021, flat: 6.065089449286461, pod: 25.073657631874084, loss: 35.657507836818695 
Train [2/10] | Epoch [105/160] |	nca: 4.529688876122236, flat: 5.905148699879646, pod: 24.39940631389618, loss: 34.83424389362335 
Train [2/10] | Epoch [106/160] |	nca: 4.2419805862009525, flat: 5.915841534733772, pod: 24.532314002513885, loss: 34.69013613462448 
Train [2/10] | Epoch [107/160] |	nca: 4.080918990075588, flat: 5.961267173290253, pod: 24.45272648334503, loss: 34.494912564754486 
Train [2/10] | Epoch [108/160] |	nca: 4.208880644291639, flat: 6.05927748978138, pod: 24.852793335914612, loss: 35.120951533317566 
Train [2/10] | Epoch [109/160] |	nca: 4.132330507040024, flat: 6.015501976013184, pod: 24.52153778076172, loss: 34.66937017440796 
Train [2/10] | Epoch [110/160] |	nca: 4.013129390776157, flat: 5.882064506411552, pod: 24.303352296352386, loss: 34.198546171188354 
Train [2/10] | Epoch [111/160] |	nca: 3.873217973858118, flat: 5.911953419446945, pod: 24.23758739233017, loss: 34.02275878190994 
Train [2/10] | Epoch [112/160] |	nca: 4.0332496501505375, flat: 5.764928117394447, pod: 23.395193994045258, loss: 33.193371653556824 
Train [2/10] | Epoch [113/160] |	nca: 3.6154905632138252, flat: 5.731919914484024, pod: 23.460694551467896, loss: 32.80810505151749 
Train [2/10] | Epoch [114/160] |	nca: 3.6293598636984825, flat: 5.660986848175526, pod: 23.22046250104904, loss: 32.51080930233002 
Train [2/10] | Epoch [115/160] |	nca: 3.810896098613739, flat: 5.707611635327339, pod: 23.058927476406097, loss: 32.57743513584137 
Train [2/10] | Epoch [116/160] |	nca: 3.6734786070883274, flat: 5.701657757163048, pod: 22.885308027267456, loss: 32.2604444026947 
Train [2/10] | Epoch [117/160] |	nca: 3.5033698566257954, flat: 5.638737812638283, pod: 22.840790450572968, loss: 31.982897996902466 
Train [2/10] | Epoch [118/160] |	nca: 3.409811142832041, flat: 5.590160824358463, pod: 22.676501274108887, loss: 31.676473200321198 
Train [2/10] | Epoch [119/160] |	nca: 3.4400727190077305, flat: 5.636719472706318, pod: 22.91839700937271, loss: 31.995189249515533 
Train [2/10] | Epoch [120/160] |	nca: 3.2708866633474827, flat: 5.5372233390808105, pod: 22.220272481441498, loss: 31.02838236093521 
Train [2/10] | Epoch [121/160] |	nca: 3.166633538901806, flat: 5.460034042596817, pod: 21.860076129436493, loss: 30.48674374818802 
Train [2/10] | Epoch [122/160] |	nca: 3.0686263740062714, flat: 5.392798766493797, pod: 21.899969458580017, loss: 30.361394584178925 
Train [2/10] | Epoch [123/160] |	nca: 3.2213617004454136, flat: 5.325134374201298, pod: 21.86657491326332, loss: 30.413071155548096 
Train [2/10] | Epoch [124/160] |	nca: 3.199924934655428, flat: 5.365173302590847, pod: 21.68146413564682, loss: 30.24656230211258 
Train [2/10] | Epoch [125/160] |	nca: 3.1035279259085655, flat: 5.317521147429943, pod: 21.34472021460533, loss: 29.765769302845 
Train [2/10] | Epoch [126/160] |	nca: 2.8862989358603954, flat: 5.3042126297950745, pod: 21.52332380414009, loss: 29.71383535861969 
Train [2/10] | Epoch [127/160] |	nca: 3.2250255085527897, flat: 5.3113764971494675, pod: 21.713967114686966, loss: 30.25036907196045 
Train [2/10] | Epoch [128/160] |	nca: 3.1917780227959156, flat: 5.3499384969472885, pod: 21.587358862161636, loss: 30.129075586795807 
Train [2/10] | Epoch [129/160] |	nca: 2.8051357865333557, flat: 5.1653662994503975, pod: 20.96395045518875, loss: 28.93445259332657 
Train [2/10] | Epoch [130/160] |	nca: 2.9442954398691654, flat: 5.172253094613552, pod: 20.827972322702408, loss: 28.94452053308487 
Train [2/10] | Epoch [131/160] |	nca: 2.826933916658163, flat: 5.21929931640625, pod: 20.82971352338791, loss: 28.875946819782257 
Train [2/10] | Epoch [132/160] |	nca: 2.9064455181360245, flat: 5.198635645210743, pod: 20.73691689968109, loss: 28.841998040676117 
Train [2/10] | Epoch [133/160] |	nca: 2.786828178912401, flat: 5.135219141840935, pod: 20.723736196756363, loss: 28.64578354358673 
Train [2/10] | Epoch [134/160] |	nca: 2.73565362021327, flat: 5.044114947319031, pod: 20.370691895484924, loss: 28.150460362434387 
Train [2/10] | Epoch [135/160] |	nca: 2.7523148432374, flat: 5.048721306025982, pod: 20.27351114153862, loss: 28.074547231197357 
Train [2/10] | Epoch [136/160] |	nca: 2.9407930318266153, flat: 5.176699593663216, pod: 20.479808449745178, loss: 28.597301125526428 
Train [2/10] | Epoch [137/160] |	nca: 2.9758306331932545, flat: 5.0734462440013885, pod: 20.087672978639603, loss: 28.136950075626373 
Train [2/10] | Epoch [138/160] |	nca: 2.8018003180623055, flat: 5.017367236316204, pod: 20.101484537124634, loss: 27.920651972293854 
Train [2/10] | Epoch [139/160] |	nca: 2.757649064064026, flat: 5.052065245807171, pod: 20.087659686803818, loss: 27.897373974323273 
Train [2/10] | Epoch [140/160] |	nca: 2.7239715419709682, flat: 5.061465747654438, pod: 20.081323593854904, loss: 27.866760790348053 
Train [2/10] | Epoch [141/160] |	nca: 2.550269193947315, flat: 5.060857079923153, pod: 19.79318529367447, loss: 27.40431171655655 
Train [2/10] | Epoch [142/160] |	nca: 2.641094420105219, flat: 4.989808179438114, pod: 20.02635207772255, loss: 27.65725475549698 
Train [2/10] | Epoch [143/160] |	nca: 2.645761463791132, flat: 4.9092927277088165, pod: 19.369851231575012, loss: 26.924905478954315 
Train [2/10] | Epoch [144/160] |	nca: 2.722356889396906, flat: 4.99125662446022, pod: 19.822963178157806, loss: 27.536576747894287 
Train [2/10] | Epoch [145/160] |	nca: 2.6597689986228943, flat: 4.962021708488464, pod: 19.700696617364883, loss: 27.3224875330925 
Train [2/10] | Epoch [146/160] |	nca: 2.573039073497057, flat: 4.963855937123299, pod: 19.929273307323456, loss: 27.46616816520691 
Train [2/10] | Epoch [147/160] |	nca: 2.657449100166559, flat: 4.991179898381233, pod: 19.5939798951149, loss: 27.242608785629272 
Train [2/10] | Epoch [148/160] |	nca: 2.5754854045808315, flat: 4.977657027542591, pod: 19.473188430070877, loss: 27.02633100748062 
Train [2/10] | Epoch [149/160] |	nca: 2.321644924581051, flat: 4.9342211708426476, pod: 19.560107111930847, loss: 26.815973043441772 
Train [2/10] | Epoch [150/160] |	nca: 2.554793357849121, flat: 4.90730844438076, pod: 19.3928542137146, loss: 26.85495615005493 
Train [2/10] | Epoch [151/160] |	nca: 2.350319929420948, flat: 4.993057042360306, pod: 19.762924671173096, loss: 27.10630190372467 
Train [2/10] | Epoch [152/160] |	nca: 2.396031953394413, flat: 4.889802120625973, pod: 19.218315422534943, loss: 26.50414925813675 
Train [2/10] | Epoch [153/160] |	nca: 2.447309445589781, flat: 4.905352793633938, pod: 19.366947531700134, loss: 26.71960961818695 
Train [2/10] | Epoch [154/160] |	nca: 2.4135543070733547, flat: 4.896128371357918, pod: 19.088030487298965, loss: 26.39771330356598 
Train [2/10] | Epoch [155/160] |	nca: 2.5022499207407236, flat: 4.942152798175812, pod: 19.577854484319687, loss: 27.022257447242737 
Train [2/10] | Epoch [156/160] |	nca: 2.407292854040861, flat: 4.828383669257164, pod: 19.13958778977394, loss: 26.375264286994934 
Train [2/10] | Epoch [157/160] |	nca: 2.3339820727705956, flat: 4.869930386543274, pod: 19.192045241594315, loss: 26.395957827568054 
Train [2/10] | Epoch [158/160] |	nca: 2.6258391104638577, flat: 4.862203076481819, pod: 19.281774312257767, loss: 26.769816517829895 
Train [2/10] | Epoch [159/160] |	nca: 2.46198258921504, flat: 4.846652537584305, pod: 18.986647695302963, loss: 26.29528295993805 
Train [2/10] | Epoch [160/160] |	nca: 2.5758136101067066, flat: 4.8492696210742, pod: 19.145424962043762, loss: 26.570508241653442 
Fine-tuning
Building & updating memory.
Train [2/10] | Epoch [161/180] |	nca: 0.6794980987906456, flat: 0.5554018914699554, pod: 2.45025634765625, loss: 3.6851563453674316 
Train [2/10] | Epoch [162/180] |	nca: 0.3552587926387787, flat: 0.5121386051177979, pod: 2.373186230659485, loss: 3.240583658218384 
Train [2/10] | Epoch [163/180] |	nca: 0.442531481385231, flat: 0.6597204655408859, pod: 2.7026434540748596, loss: 3.8048954010009766 
Train [2/10] | Epoch [164/180] |	nca: 0.36569860577583313, flat: 0.5611939430236816, pod: 2.4023667573928833, loss: 3.3292592763900757 
Train [2/10] | Epoch [165/180] |	nca: 0.389606274664402, flat: 0.534113273024559, pod: 2.2906545996665955, loss: 3.2143741846084595 
Train [2/10] | Epoch [166/180] |	nca: 0.4887569025158882, flat: 0.5860776230692863, pod: 2.42340812087059, loss: 3.498242735862732 
Train [2/10] | Epoch [167/180] |	nca: 0.8961621038615704, flat: 0.599449411034584, pod: 2.6168482303619385, loss: 4.112459719181061 
Train [2/10] | Epoch [168/180] |	nca: 0.2856386713683605, flat: 0.5514555796980858, pod: 2.350899338722229, loss: 3.187993586063385 
Train [2/10] | Epoch [169/180] |	nca: 0.27011069655418396, flat: 0.6162796020507812, pod: 2.537334978580475, loss: 3.4237253069877625 
Train [2/10] | Epoch [170/180] |	nca: 0.35077522695064545, flat: 0.5660620629787445, pod: 2.5929582715034485, loss: 3.509795606136322 
Train [2/10] | Epoch [171/180] |	nca: 0.30266424641013145, flat: 0.5460993722081184, pod: 2.397459626197815, loss: 3.246223211288452 
Train [2/10] | Epoch [172/180] |	nca: 0.4776792526245117, flat: 0.5898340046405792, pod: 2.4100260138511658, loss: 3.4775392413139343 
Train [2/10] | Epoch [173/180] |	nca: 0.27572981268167496, flat: 0.5464224517345428, pod: 2.4096293449401855, loss: 3.2317816615104675 
Train [2/10] | Epoch [174/180] |	nca: 0.3767436221241951, flat: 0.5796039626002312, pod: 2.3996843695640564, loss: 3.356031894683838 
Train [2/10] | Epoch [175/180] |	nca: 0.3445286825299263, flat: 0.5817755460739136, pod: 2.3356288075447083, loss: 3.2619330286979675 
Train [2/10] | Epoch [176/180] |	nca: 0.2472487986087799, flat: 0.5435468852519989, pod: 2.322139322757721, loss: 3.1129350066184998 
Train [2/10] | Epoch [177/180] |	nca: 0.3307829387485981, flat: 0.5937660783529282, pod: 2.538499593734741, loss: 3.463048577308655 
Train [2/10] | Epoch [178/180] |	nca: 0.22654196247458458, flat: 0.5818067491054535, pod: 2.3771820664405823, loss: 3.185530722141266 
Train [2/10] | Epoch [179/180] |	nca: 0.2776435390114784, flat: 0.547806590795517, pod: 2.3424375653266907, loss: 3.1678876876831055 
Train [2/10] | Epoch [180/180] |	nca: 0.1993228755891323, flat: 0.5684139728546143, pod: 2.3817583322525024, loss: 3.1494951844215393 
after task
Building & updating memory.
after task
Eval on 0->20.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.839.
Current acc: {'total': 0.762, '00-09': 0.778, '10-19': 0.746}.
Avg inc acc top5: 0.98.
Current acc top5: {'total': 0.964}.
Forgetting: -0.20266666666666666.
Cord metric: 0.80.
Old accuracy: 0.78, mean: 0.78.
New accuracy: 0.75, mean: 0.75.
================Task 2 Start!================
Testing on False unseen tasks (max class = 30).
Set memory of size: 400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 2 Training!================
The training samples number: 5400
Train on 20->30.
train task
nb 5400.
Train [3/10] | Epoch [1/160] |	nca: 66.96912741661072, flat: 8.985580842942, pod: 51.72009488940239, loss: 127.67480230331421 
Train [3/10] | Epoch [2/160] |	nca: 53.614773631095886, flat: 8.307385817170143, pod: 52.512645840644836, loss: 114.43480610847473 
Train [3/10] | Epoch [3/160] |	nca: 44.21412140130997, flat: 7.046560034155846, pod: 45.35907119512558, loss: 96.61975252628326 
Train [3/10] | Epoch [4/160] |	nca: 40.852663576602936, flat: 6.764025345444679, pod: 43.688316345214844, loss: 91.30500543117523 
Train [3/10] | Epoch [5/160] |	nca: 39.447390019893646, flat: 6.950003921985626, pod: 44.527898252010345, loss: 90.92529273033142 
Train [3/10] | Epoch [6/160] |	nca: 37.36644172668457, flat: 7.113659918308258, pod: 44.26836323738098, loss: 88.748464345932 
Train [3/10] | Epoch [7/160] |	nca: 35.44415855407715, flat: 7.280624732375145, pod: 44.132173240184784, loss: 86.85695660114288 
Train [3/10] | Epoch [8/160] |	nca: 33.508680284023285, flat: 7.062284201383591, pod: 43.196783900260925, loss: 83.7677481174469 
Train [3/10] | Epoch [9/160] |	nca: 32.59004807472229, flat: 7.181999921798706, pod: 43.17010223865509, loss: 82.94215047359467 
Train [3/10] | Epoch [10/160] |	nca: 32.29379716515541, flat: 7.374527350068092, pod: 43.62104117870331, loss: 83.2893658876419 
Train [3/10] | Epoch [11/160] |	nca: 29.87664633989334, flat: 7.05819796025753, pod: 41.89477616548538, loss: 78.82962000370026 
Train [3/10] | Epoch [12/160] |	nca: 29.534473717212677, flat: 7.287796884775162, pod: 42.23477095365524, loss: 79.05704152584076 
Train [3/10] | Epoch [13/160] |	nca: 28.369641661643982, flat: 7.089745804667473, pod: 41.101413905620575, loss: 76.56080162525177 
Train [3/10] | Epoch [14/160] |	nca: 28.39134556055069, flat: 7.176376864314079, pod: 42.088689506053925, loss: 77.6564120054245 
Train [3/10] | Epoch [15/160] |	nca: 29.997325837612152, flat: 7.741200968623161, pod: 44.451706647872925, loss: 82.19023370742798 
Train [3/10] | Epoch [16/160] |	nca: 27.36365219950676, flat: 7.559928521513939, pod: 43.347226321697235, loss: 78.2708078622818 
Train [3/10] | Epoch [17/160] |	nca: 25.74504691362381, flat: 7.393644779920578, pod: 42.43027824163437, loss: 75.56896984577179 
Train [3/10] | Epoch [18/160] |	nca: 24.808323740959167, flat: 7.349654912948608, pod: 42.05036926269531, loss: 74.20834803581238 
Train [3/10] | Epoch [19/160] |	nca: 25.20333844423294, flat: 7.376301258802414, pod: 42.92058652639389, loss: 75.50022649765015 
Train [3/10] | Epoch [20/160] |	nca: 24.02767613530159, flat: 7.110241159796715, pod: 41.10639441013336, loss: 72.2443116903305 
Train [3/10] | Epoch [21/160] |	nca: 24.33314597606659, flat: 7.3286824226379395, pod: 41.706565141677856, loss: 73.36839365959167 
Train [3/10] | Epoch [22/160] |	nca: 25.60079339146614, flat: 7.804719313979149, pod: 43.831744968891144, loss: 77.2372578382492 
Train [3/10] | Epoch [23/160] |	nca: 23.652216643095016, flat: 7.231061235070229, pod: 41.28271013498306, loss: 72.16598796844482 
Train [3/10] | Epoch [24/160] |	nca: 21.624000638723373, flat: 7.458012238144875, pod: 41.35161578655243, loss: 70.43362855911255 
Train [3/10] | Epoch [25/160] |	nca: 21.869257539510727, flat: 7.3620737344026566, pod: 40.97480088472366, loss: 70.20613217353821 
Train [3/10] | Epoch [26/160] |	nca: 20.900999426841736, flat: 7.352429643273354, pod: 40.95299816131592, loss: 69.20642697811127 
Train [3/10] | Epoch [27/160] |	nca: 23.053509175777435, flat: 7.780257746577263, pod: 43.17746567726135, loss: 74.01123237609863 
Train [3/10] | Epoch [28/160] |	nca: 23.870175182819366, flat: 7.960419729351997, pod: 43.539450109004974, loss: 75.37004482746124 
Train [3/10] | Epoch [29/160] |	nca: 23.718569457530975, flat: 7.898186504840851, pod: 43.94912266731262, loss: 75.56587886810303 
Train [3/10] | Epoch [30/160] |	nca: 20.63248547911644, flat: 7.541916906833649, pod: 41.74612104892731, loss: 69.92052364349365 
Train [3/10] | Epoch [31/160] |	nca: 22.06628453731537, flat: 7.742204636335373, pod: 42.59913069009781, loss: 72.40761983394623 
Train [3/10] | Epoch [32/160] |	nca: 22.71561023592949, flat: 7.7573543936014175, pod: 42.91568875312805, loss: 73.38865327835083 
Train [3/10] | Epoch [33/160] |	nca: 19.843319952487946, flat: 7.8013346046209335, pod: 42.230481028556824, loss: 69.87513506412506 
Train [3/10] | Epoch [34/160] |	nca: 19.49928605556488, flat: 7.45356260240078, pod: 41.11139142513275, loss: 68.06424009799957 
Train [3/10] | Epoch [35/160] |	nca: 20.012747675180435, flat: 7.625791907310486, pod: 41.72860783338547, loss: 69.36714744567871 
Train [3/10] | Epoch [36/160] |	nca: 20.194876611232758, flat: 7.746764615178108, pod: 42.20256394147873, loss: 70.14420545101166 
Train [3/10] | Epoch [37/160] |	nca: 19.65303072333336, flat: 7.684677317738533, pod: 42.76475012302399, loss: 70.10245835781097 
Train [3/10] | Epoch [38/160] |	nca: 18.553598672151566, flat: 7.504549860954285, pod: 41.50181567668915, loss: 67.55996417999268 
Train [3/10] | Epoch [39/160] |	nca: 18.144391804933548, flat: 7.4851361364126205, pod: 40.7720742225647, loss: 66.4016021490097 
Train [3/10] | Epoch [40/160] |	nca: 16.85409653186798, flat: 7.341073349118233, pod: 39.88566970825195, loss: 64.08083963394165 
Train [3/10] | Epoch [41/160] |	nca: 15.28859955072403, flat: 7.073365569114685, pod: 38.77203017473221, loss: 61.13399529457092 
Train [3/10] | Epoch [42/160] |	nca: 14.8557757884264, flat: 7.085222035646439, pod: 38.84826719760895, loss: 60.78926479816437 
Train [3/10] | Epoch [43/160] |	nca: 15.781310856342316, flat: 7.179153293371201, pod: 38.83219140768051, loss: 61.79265558719635 
Train [3/10] | Epoch [44/160] |	nca: 18.171364903450012, flat: 7.562843158841133, pod: 41.287672996520996, loss: 67.02188062667847 
Train [3/10] | Epoch [45/160] |	nca: 16.9003646671772, flat: 7.666938289999962, pod: 41.26197302341461, loss: 65.82927584648132 
Train [3/10] | Epoch [46/160] |	nca: 17.187350407242775, flat: 7.464365646243095, pod: 40.78308844566345, loss: 65.43480432033539 
Train [3/10] | Epoch [47/160] |	nca: 17.84327483177185, flat: 7.718998998403549, pod: 41.31139862537384, loss: 66.87367272377014 
Train [3/10] | Epoch [48/160] |	nca: 17.47922819852829, flat: 7.645748645067215, pod: 41.176569163799286, loss: 66.3015456199646 
Train [3/10] | Epoch [49/160] |	nca: 14.902504950761795, flat: 7.2350208312273026, pod: 39.053610265254974, loss: 61.19113636016846 
Train [3/10] | Epoch [50/160] |	nca: 16.315799057483673, flat: 7.343490183353424, pod: 39.510373532772064, loss: 63.169663310050964 
Train [3/10] | Epoch [51/160] |	nca: 16.265401802957058, flat: 7.59384822845459, pod: 41.01335233449936, loss: 64.87260210514069 
Train [3/10] | Epoch [52/160] |	nca: 12.718506917357445, flat: 7.034183591604233, pod: 37.801370680332184, loss: 57.55406105518341 
Train [3/10] | Epoch [53/160] |	nca: 14.096028596162796, flat: 7.068983256816864, pod: 38.49665957689285, loss: 59.6616712808609 
Train [3/10] | Epoch [54/160] |	nca: 16.62126660346985, flat: 7.5877595245838165, pod: 40.823618829250336, loss: 65.03264498710632 
Train [3/10] | Epoch [55/160] |	nca: 15.41177824139595, flat: 7.400960102677345, pod: 39.86405724287033, loss: 62.67679584026337 
Train [3/10] | Epoch [56/160] |	nca: 14.847841516137123, flat: 7.247885510325432, pod: 38.81101697683334, loss: 60.90674424171448 
Train [3/10] | Epoch [57/160] |	nca: 12.909201934933662, flat: 7.087088122963905, pod: 38.5977498292923, loss: 58.59403967857361 
Train [3/10] | Epoch [58/160] |	nca: 11.946033909916878, flat: 6.977209165692329, pod: 37.64949256181717, loss: 56.57273519039154 
Train [3/10] | Epoch [59/160] |	nca: 12.932914420962334, flat: 6.9060473293066025, pod: 37.01308423280716, loss: 56.85204565525055 
Train [3/10] | Epoch [60/160] |	nca: 13.165988355875015, flat: 6.983344376087189, pod: 37.537926495075226, loss: 57.68725919723511 
Train [3/10] | Epoch [61/160] |	nca: 12.262477114796638, flat: 6.883643358945847, pod: 37.2207527756691, loss: 56.36687362194061 
Train [3/10] | Epoch [62/160] |	nca: 12.896146669983864, flat: 7.0243339985609055, pod: 37.585332691669464, loss: 57.50581336021423 
Train [3/10] | Epoch [63/160] |	nca: 10.672295689582825, flat: 6.835943281650543, pod: 36.812259793281555, loss: 54.32049870491028 
Train [3/10] | Epoch [64/160] |	nca: 11.066335275769234, flat: 6.798868477344513, pod: 36.3444020152092, loss: 54.20960605144501 
Train [3/10] | Epoch [65/160] |	nca: 12.811684235930443, flat: 7.214203879237175, pod: 38.1860237121582, loss: 58.2119117975235 
Train [3/10] | Epoch [66/160] |	nca: 11.885763481259346, flat: 7.092332676053047, pod: 37.34117376804352, loss: 56.31927001476288 
Train [3/10] | Epoch [67/160] |	nca: 11.695390239357948, flat: 6.928789123892784, pod: 37.035313963890076, loss: 55.65949356555939 
Train [3/10] | Epoch [68/160] |	nca: 11.740722730755806, flat: 7.01091967523098, pod: 36.66519618034363, loss: 55.41683828830719 
Train [3/10] | Epoch [69/160] |	nca: 12.696024358272552, flat: 7.023070156574249, pod: 37.346573293209076, loss: 57.06566774845123 
Train [3/10] | Epoch [70/160] |	nca: 12.219536393880844, flat: 7.1082222908735275, pod: 37.2645645737648, loss: 56.59232318401337 
Train [3/10] | Epoch [71/160] |	nca: 11.397350385785103, flat: 6.867251068353653, pod: 36.37127232551575, loss: 54.635873675346375 
Train [3/10] | Epoch [72/160] |	nca: 9.814878463745117, flat: 6.590371564030647, pod: 34.981588423252106, loss: 51.38683831691742 
Train [3/10] | Epoch [73/160] |	nca: 10.214270740747452, flat: 6.630411610007286, pod: 35.185505628585815, loss: 52.0301878452301 
Train [3/10] | Epoch [74/160] |	nca: 10.326420113444328, flat: 6.831231132149696, pod: 35.595685720443726, loss: 52.753336787223816 
Train [3/10] | Epoch [75/160] |	nca: 10.224166676402092, flat: 6.615660861134529, pod: 35.16074788570404, loss: 52.00057566165924 
Train [3/10] | Epoch [76/160] |	nca: 9.588531166315079, flat: 6.669031277298927, pod: 35.23786985874176, loss: 51.49543225765228 
Train [3/10] | Epoch [77/160] |	nca: 9.743066996335983, flat: 6.628956645727158, pod: 35.45870614051819, loss: 51.830729603767395 
Train [3/10] | Epoch [78/160] |	nca: 8.664209589362144, flat: 6.417961001396179, pod: 33.601772248744965, loss: 48.68394327163696 
Train [3/10] | Epoch [79/160] |	nca: 9.224459268152714, flat: 6.517390325665474, pod: 34.23007822036743, loss: 49.97192740440369 
Train [3/10] | Epoch [80/160] |	nca: 11.356905072927475, flat: 6.868416264653206, pod: 36.55752056837082, loss: 54.78284180164337 
Train [3/10] | Epoch [81/160] |	nca: 9.144991382956505, flat: 6.458878010511398, pod: 34.31849718093872, loss: 49.92236626148224 
Train [3/10] | Epoch [82/160] |	nca: 9.910913273692131, flat: 6.598856553435326, pod: 34.37332093715668, loss: 50.8830908536911 
Train [3/10] | Epoch [83/160] |	nca: 10.031594678759575, flat: 6.4522507935762405, pod: 34.36197119951248, loss: 50.84581685066223 
Train [3/10] | Epoch [84/160] |	nca: 9.302077636122704, flat: 6.399009540677071, pod: 33.80176442861557, loss: 49.502851486206055 
Train [3/10] | Epoch [85/160] |	nca: 9.945603743195534, flat: 6.521319687366486, pod: 34.01788657903671, loss: 50.4848096370697 
Train [3/10] | Epoch [86/160] |	nca: 9.371937170624733, flat: 6.497991114854813, pod: 33.902022659778595, loss: 49.77195084095001 
Train [3/10] | Epoch [87/160] |	nca: 7.862705886363983, flat: 6.38581919670105, pod: 33.242940843105316, loss: 47.49146592617035 
Train [3/10] | Epoch [88/160] |	nca: 7.202654346823692, flat: 6.142084926366806, pod: 32.04499167203903, loss: 45.38973122835159 
Train [3/10] | Epoch [89/160] |	nca: 6.517619393765926, flat: 5.854953408241272, pod: 30.754277884960175, loss: 43.1268504858017 
Train [3/10] | Epoch [90/160] |	nca: 6.8563187494874, flat: 6.002145141363144, pod: 31.865324437618256, loss: 44.72378820180893 
Train [3/10] | Epoch [91/160] |	nca: 7.524069137871265, flat: 6.094013229012489, pod: 32.0576029419899, loss: 45.67568552494049 
Train [3/10] | Epoch [92/160] |	nca: 7.585108056664467, flat: 6.207164950668812, pod: 32.419429063797, loss: 46.21170175075531 
Train [3/10] | Epoch [93/160] |	nca: 6.714070439338684, flat: 5.924824573099613, pod: 31.108201801776886, loss: 43.74709689617157 
Train [3/10] | Epoch [94/160] |	nca: 5.672445505857468, flat: 5.6905845031142235, pod: 29.519644558429718, loss: 40.882674753665924 
Train [3/10] | Epoch [95/160] |	nca: 5.982626728713512, flat: 5.643189944326878, pod: 29.95583063364029, loss: 41.58164739608765 
Train [3/10] | Epoch [96/160] |	nca: 6.395899601280689, flat: 5.769601725041866, pod: 30.993552684783936, loss: 43.15905398130417 
Train [3/10] | Epoch [97/160] |	nca: 8.565557301044464, flat: 5.990498587489128, pod: 31.23401564359665, loss: 45.79007184505463 
Train [3/10] | Epoch [98/160] |	nca: 6.868958778679371, flat: 5.82617761939764, pod: 30.324443638324738, loss: 43.01957994699478 
Train [3/10] | Epoch [99/160] |	nca: 6.83886294066906, flat: 5.761766545474529, pod: 30.08242392539978, loss: 42.683053851127625 
Train [3/10] | Epoch [100/160] |	nca: 5.858997158706188, flat: 5.699932433664799, pod: 29.253845512866974, loss: 40.81277519464493 
Train [3/10] | Epoch [101/160] |	nca: 5.7253133431077, flat: 5.574290998280048, pod: 28.960902154445648, loss: 40.26050662994385 
Train [3/10] | Epoch [102/160] |	nca: 6.131221704185009, flat: 5.643104240298271, pod: 29.43451064825058, loss: 41.20883685350418 
Train [3/10] | Epoch [103/160] |	nca: 6.182704463601112, flat: 5.715349309146404, pod: 29.846863090991974, loss: 41.744916558265686 
Train [3/10] | Epoch [104/160] |	nca: 5.525371864438057, flat: 5.533377222716808, pod: 29.01881980895996, loss: 40.07756865024567 
Train [3/10] | Epoch [105/160] |	nca: 5.418223895132542, flat: 5.443892635405064, pod: 28.307634592056274, loss: 39.16975140571594 
Train [3/10] | Epoch [106/160] |	nca: 5.576123923063278, flat: 5.509868212044239, pod: 28.056111752986908, loss: 39.14210402965546 
Train [3/10] | Epoch [107/160] |	nca: 4.575097691267729, flat: 5.270919643342495, pod: 27.23261535167694, loss: 37.07863247394562 
Train [3/10] | Epoch [108/160] |	nca: 4.373415119946003, flat: 5.240339905023575, pod: 27.213968753814697, loss: 36.82772374153137 
Train [3/10] | Epoch [109/160] |	nca: 4.431662227958441, flat: 5.106410555541515, pod: 26.524239659309387, loss: 36.06231254339218 
Train [3/10] | Epoch [110/160] |	nca: 4.6597176641225815, flat: 5.177508227527142, pod: 26.593296468257904, loss: 36.43052250146866 
Train [3/10] | Epoch [111/160] |	nca: 4.779386304318905, flat: 5.236495330929756, pod: 27.266687512397766, loss: 37.28256916999817 
Train [3/10] | Epoch [112/160] |	nca: 4.490132983773947, flat: 5.016665510833263, pod: 26.24772608280182, loss: 35.754524528980255 
Train [3/10] | Epoch [113/160] |	nca: 4.899966541677713, flat: 5.131626769900322, pod: 26.679798305034637, loss: 36.7113915681839 
Train [3/10] | Epoch [114/160] |	nca: 4.250997144728899, flat: 5.074718542397022, pod: 26.320079684257507, loss: 35.64579540491104 
Train [3/10] | Epoch [115/160] |	nca: 4.589838929474354, flat: 5.084494233131409, pod: 26.18502789735794, loss: 35.8593612909317 
Train [3/10] | Epoch [116/160] |	nca: 4.752279169857502, flat: 5.060051679611206, pod: 25.944399416446686, loss: 35.75673007965088 
Train [3/10] | Epoch [117/160] |	nca: 5.439140602946281, flat: 5.403042271733284, pod: 27.5267795920372, loss: 38.3689626455307 
Train [3/10] | Epoch [118/160] |	nca: 5.135427951812744, flat: 5.267308838665485, pod: 27.071058690547943, loss: 37.473795652389526 
Train [3/10] | Epoch [119/160] |	nca: 4.1342863738536835, flat: 5.000715836882591, pod: 25.314733564853668, loss: 34.44973587989807 
Train [3/10] | Epoch [120/160] |	nca: 4.009984277188778, flat: 4.96893035620451, pod: 25.174157083034515, loss: 34.15307170152664 
Train [3/10] | Epoch [121/160] |	nca: 4.046591706573963, flat: 4.931162849068642, pod: 25.54629933834076, loss: 34.52405375242233 
Train [3/10] | Epoch [122/160] |	nca: 3.955520808696747, flat: 4.845104373991489, pod: 24.862503111362457, loss: 33.663128316402435 
Train [3/10] | Epoch [123/160] |	nca: 3.7959718219935894, flat: 4.7513357847929, pod: 24.378994464874268, loss: 32.92630207538605 
Train [3/10] | Epoch [124/160] |	nca: 3.933432463556528, flat: 4.799440801143646, pod: 25.158553540706635, loss: 33.89142709970474 
Train [3/10] | Epoch [125/160] |	nca: 3.547220952808857, flat: 4.749612361192703, pod: 24.441770553588867, loss: 32.73860400915146 
Train [3/10] | Epoch [126/160] |	nca: 3.52468628808856, flat: 4.75007713586092, pod: 24.084197521209717, loss: 32.35896110534668 
Train [3/10] | Epoch [127/160] |	nca: 3.7491893470287323, flat: 4.703401006758213, pod: 24.03098702430725, loss: 32.483577251434326 
Train [3/10] | Epoch [128/160] |	nca: 3.359036196023226, flat: 4.767194427549839, pod: 23.94014608860016, loss: 32.06637662649155 
Train [3/10] | Epoch [129/160] |	nca: 3.2761198841035366, flat: 4.605075351893902, pod: 23.40983134508133, loss: 31.29102659225464 
Train [3/10] | Epoch [130/160] |	nca: 3.337238058447838, flat: 4.6062628626823425, pod: 23.590860605239868, loss: 31.53436177968979 
Train [3/10] | Epoch [131/160] |	nca: 3.359837017953396, flat: 4.59196475148201, pod: 23.25657284259796, loss: 31.208374619483948 
Train [3/10] | Epoch [132/160] |	nca: 3.8012039847671986, flat: 4.65923660248518, pod: 23.789130210876465, loss: 32.24957072734833 
Train [3/10] | Epoch [133/160] |	nca: 3.593410935252905, flat: 4.6456731259822845, pod: 23.770661413669586, loss: 32.00974524021149 
Train [3/10] | Epoch [134/160] |	nca: 3.6428438052535057, flat: 4.654081620275974, pod: 23.384884536266327, loss: 31.681809961795807 
Train [3/10] | Epoch [135/160] |	nca: 3.3218127228319645, flat: 4.594555780291557, pod: 23.281929075717926, loss: 31.19829750061035 
Train [3/10] | Epoch [136/160] |	nca: 3.395084585994482, flat: 4.594972521066666, pod: 23.460655510425568, loss: 31.45071280002594 
Train [3/10] | Epoch [137/160] |	nca: 3.3452266417443752, flat: 4.531411334872246, pod: 22.978027045726776, loss: 30.854665219783783 
Train [3/10] | Epoch [138/160] |	nca: 3.342278979718685, flat: 4.594337694346905, pod: 23.17855527997017, loss: 31.115172028541565 
Train [3/10] | Epoch [139/160] |	nca: 3.1930655166506767, flat: 4.495790436863899, pod: 22.44037652015686, loss: 30.12923228740692 
Train [3/10] | Epoch [140/160] |	nca: 3.2493064403533936, flat: 4.549619443714619, pod: 22.894497871398926, loss: 30.693423807621002 
Train [3/10] | Epoch [141/160] |	nca: 3.2306001111865044, flat: 4.532133959233761, pod: 22.796701341867447, loss: 30.559435486793518 
Train [3/10] | Epoch [142/160] |	nca: 3.2329116947948933, flat: 4.521553210914135, pod: 22.513660073280334, loss: 30.26812493801117 
Train [3/10] | Epoch [143/160] |	nca: 3.080961186438799, flat: 4.453894354403019, pod: 22.448769867420197, loss: 29.983625411987305 
Train [3/10] | Epoch [144/160] |	nca: 2.998875707387924, flat: 4.500969484448433, pod: 22.483930617570877, loss: 29.983775734901428 
Train [3/10] | Epoch [145/160] |	nca: 3.1080708168447018, flat: 4.442045629024506, pod: 22.493618577718735, loss: 30.043735146522522 
Train [3/10] | Epoch [146/160] |	nca: 2.892028506845236, flat: 4.413723647594452, pod: 22.275803923606873, loss: 29.58155608177185 
Train [3/10] | Epoch [147/160] |	nca: 2.9757359735667706, flat: 4.458066798746586, pod: 22.23119741678238, loss: 29.66500025987625 
Train [3/10] | Epoch [148/160] |	nca: 2.8627905510365963, flat: 4.444242373108864, pod: 22.435036838054657, loss: 29.742069721221924 
Train [3/10] | Epoch [149/160] |	nca: 2.8931791074573994, flat: 4.387638606131077, pod: 22.316864043474197, loss: 29.59768158197403 
Train [3/10] | Epoch [150/160] |	nca: 3.0611014366149902, flat: 4.382109560072422, pod: 21.825425535440445, loss: 29.26863658428192 
Train [3/10] | Epoch [151/160] |	nca: 2.767682161182165, flat: 4.426162675023079, pod: 22.125353395938873, loss: 29.319198071956635 
Train [3/10] | Epoch [152/160] |	nca: 2.9230204075574875, flat: 4.375029072165489, pod: 21.808855712413788, loss: 29.106905043125153 
Train [3/10] | Epoch [153/160] |	nca: 2.9023341685533524, flat: 4.358740620315075, pod: 21.937386870384216, loss: 29.198461771011353 
Train [3/10] | Epoch [154/160] |	nca: 2.880448281764984, flat: 4.339924640953541, pod: 21.672041296958923, loss: 28.892414212226868 
Train [3/10] | Epoch [155/160] |	nca: 2.8445073142647743, flat: 4.34843610227108, pod: 21.885858803987503, loss: 29.078802227973938 
Train [3/10] | Epoch [156/160] |	nca: 2.867188524454832, flat: 4.372406668961048, pod: 22.13926264643669, loss: 29.378857791423798 
Train [3/10] | Epoch [157/160] |	nca: 2.689178988337517, flat: 4.370908685028553, pod: 22.215871512889862, loss: 29.275959253311157 
Train [3/10] | Epoch [158/160] |	nca: 2.8713174611330032, flat: 4.37155244499445, pod: 21.876703709363937, loss: 29.119573652744293 
Train [3/10] | Epoch [159/160] |	nca: 2.98757828399539, flat: 4.357236452400684, pod: 21.69064763188362, loss: 29.035462379455566 
Train [3/10] | Epoch [160/160] |	nca: 2.929161299020052, flat: 4.35184583067894, pod: 21.859802156686783, loss: 29.140809178352356 
Fine-tuning
Building & updating memory.
Train [3/10] | Epoch [161/180] |	nca: 1.2040951251983643, flat: 0.5369248315691948, pod: 2.9354917407035828, loss: 4.676511704921722 
Train [3/10] | Epoch [162/180] |	nca: 0.6603148095309734, flat: 0.529258981347084, pod: 2.842944920063019, loss: 4.032518684864044 
Train [3/10] | Epoch [163/180] |	nca: 0.47910545766353607, flat: 0.53872399777174, pod: 2.8991904854774475, loss: 3.917019844055176 
Train [3/10] | Epoch [164/180] |	nca: 0.5536194145679474, flat: 0.5346141755580902, pod: 2.9256736636161804, loss: 4.013907313346863 
Train [3/10] | Epoch [165/180] |	nca: 0.4471830129623413, flat: 0.5336538478732109, pod: 2.967995345592499, loss: 3.9488322138786316 
Train [3/10] | Epoch [166/180] |	nca: 0.35940124467015266, flat: 0.5330428704619408, pod: 2.829485595226288, loss: 3.7219297289848328 
Train [3/10] | Epoch [167/180] |	nca: 0.3872842416167259, flat: 0.5321272686123848, pod: 2.818736493587494, loss: 3.7381480932235718 
Train [3/10] | Epoch [168/180] |	nca: 0.3912477344274521, flat: 0.5346325635910034, pod: 2.835434675216675, loss: 3.7613149285316467 
Train [3/10] | Epoch [169/180] |	nca: 0.3645034171640873, flat: 0.5415407195687294, pod: 2.8871496319770813, loss: 3.7931936979293823 
Train [3/10] | Epoch [170/180] |	nca: 0.28840194270014763, flat: 0.5277570560574532, pod: 2.7522971630096436, loss: 3.5684561729431152 
Train [3/10] | Epoch [171/180] |	nca: 0.2824881598353386, flat: 0.5501382201910019, pod: 2.940203607082367, loss: 3.7728299498558044 
Train [3/10] | Epoch [172/180] |	nca: 0.3690488077700138, flat: 0.5503972172737122, pod: 2.9396310448646545, loss: 3.8590771555900574 
Train [3/10] | Epoch [173/180] |	nca: 0.27557504177093506, flat: 0.5346118435263634, pod: 2.867950201034546, loss: 3.6781370639801025 
Train [3/10] | Epoch [174/180] |	nca: 0.2724450007081032, flat: 0.5353136286139488, pod: 2.8716921210289, loss: 3.679450750350952 
Train [3/10] | Epoch [175/180] |	nca: 0.2862156890332699, flat: 0.5347858667373657, pod: 2.801091432571411, loss: 3.6220930218696594 
Train [3/10] | Epoch [176/180] |	nca: 0.28936317190527916, flat: 0.5380825772881508, pod: 2.850502133369446, loss: 3.6779478788375854 
Train [3/10] | Epoch [177/180] |	nca: 0.2976484186947346, flat: 0.5409877747297287, pod: 2.837998926639557, loss: 3.6766351461410522 
Train [3/10] | Epoch [178/180] |	nca: 0.29549214616417885, flat: 0.5272349044680595, pod: 2.7882876992225647, loss: 3.6110147833824158 
Train [3/10] | Epoch [179/180] |	nca: 0.2548951804637909, flat: 0.5443153753876686, pod: 2.9053483605384827, loss: 3.7045589685440063 
Train [3/10] | Epoch [180/180] |	nca: 0.29861148074269295, flat: 0.5356278046965599, pod: 2.831478774547577, loss: 3.6657180190086365 
after task
Building & updating memory.
after task
Eval on 0->30.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.7756666666666666.
Current acc: {'total': 0.649, '00-09': 0.694, '10-19': 0.515, '20-29': 0.739}.
Avg inc acc top5: 0.956.
Current acc top5: {'total': 0.908}.
Forgetting: -0.07149999999999998.
Cord metric: 0.72.
Old accuracy: 0.60, mean: 0.69.
New accuracy: 0.74, mean: 0.74.
================Task 3 Start!================
Testing on False unseen tasks (max class = 40).
Set memory of size: 600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 3 Training!================
The training samples number: 5600
Train on 30->40.
train task
nb 5600.
Train [4/10] | Epoch [1/160] |	nca: 66.2195748090744, flat: 6.735244732350111, pod: 52.89123275876045, loss: 125.84605121612549 
Train [4/10] | Epoch [2/160] |	nca: 48.59511536359787, flat: 6.281094506382942, pod: 49.721948981285095, loss: 104.59815907478333 
Train [4/10] | Epoch [3/160] |	nca: 41.89303141832352, flat: 5.608618147671223, pod: 45.67718720436096, loss: 93.17883658409119 
Train [4/10] | Epoch [4/160] |	nca: 37.37845480442047, flat: 5.4076389372348785, pod: 44.32069629430771, loss: 87.10678994655609 
Train [4/10] | Epoch [5/160] |	nca: 36.954344630241394, flat: 5.864111609756947, pod: 45.454803347587585, loss: 88.27325963973999 
Train [4/10] | Epoch [6/160] |	nca: 35.39848268032074, flat: 5.7898431569337845, pod: 45.08298933506012, loss: 86.27131474018097 
Train [4/10] | Epoch [7/160] |	nca: 33.67863380908966, flat: 5.822800658643246, pod: 44.78456920385361, loss: 84.28600347042084 
Train [4/10] | Epoch [8/160] |	nca: 31.964237868785858, flat: 5.940648853778839, pod: 45.100451946258545, loss: 83.00533866882324 
Train [4/10] | Epoch [9/160] |	nca: 30.019622772932053, flat: 5.871383585035801, pod: 43.688206255435944, loss: 79.5792121887207 
Train [4/10] | Epoch [10/160] |	nca: 29.813116937875748, flat: 5.93453149497509, pod: 43.76065444946289, loss: 79.5083030462265 
Train [4/10] | Epoch [11/160] |	nca: 28.905674815177917, flat: 5.84964757412672, pod: 43.2317196726799, loss: 77.98704195022583 
Train [4/10] | Epoch [12/160] |	nca: 26.846100389957428, flat: 5.885140150785446, pod: 43.26820504665375, loss: 75.99944579601288 
Train [4/10] | Epoch [13/160] |	nca: 27.42061221599579, flat: 6.0583270490169525, pod: 43.70306396484375, loss: 77.18200349807739 
Train [4/10] | Epoch [14/160] |	nca: 25.652601331472397, flat: 5.95979630947113, pod: 42.38526803255081, loss: 73.99766564369202 
Train [4/10] | Epoch [15/160] |	nca: 25.814503997564316, flat: 5.945272624492645, pod: 42.57701253890991, loss: 74.33678948879242 
Train [4/10] | Epoch [16/160] |	nca: 24.955496788024902, flat: 5.9734931737184525, pod: 43.101346373558044, loss: 74.03033590316772 
Train [4/10] | Epoch [17/160] |	nca: 24.227305859327316, flat: 5.915491819381714, pod: 42.489255487918854, loss: 72.63205373287201 
Train [4/10] | Epoch [18/160] |	nca: 25.18982031941414, flat: 6.30105385184288, pod: 44.32429152727127, loss: 75.81516575813293 
Train [4/10] | Epoch [19/160] |	nca: 22.87588921189308, flat: 6.030194155871868, pod: 42.81281358003616, loss: 71.7188971042633 
Train [4/10] | Epoch [20/160] |	nca: 21.933082073926926, flat: 6.062346264719963, pod: 43.255887031555176, loss: 71.25131559371948 
Train [4/10] | Epoch [21/160] |	nca: 22.768828004598618, flat: 6.150353774428368, pod: 43.65253812074661, loss: 72.57171988487244 
Train [4/10] | Epoch [22/160] |	nca: 21.078342348337173, flat: 6.1314829885959625, pod: 42.57960319519043, loss: 69.7894287109375 
Train [4/10] | Epoch [23/160] |	nca: 20.792012184858322, flat: 6.010582886636257, pod: 41.75676780939102, loss: 68.55936276912689 
Train [4/10] | Epoch [24/160] |	nca: 20.383736550807953, flat: 6.02967469394207, pod: 41.21750086545944, loss: 67.63091230392456 
Train [4/10] | Epoch [25/160] |	nca: 20.168419271707535, flat: 6.046106830239296, pod: 41.98811435699463, loss: 68.2026401758194 
Train [4/10] | Epoch [26/160] |	nca: 21.07919865846634, flat: 6.40669672191143, pod: 43.922014594078064, loss: 71.40790963172913 
Train [4/10] | Epoch [27/160] |	nca: 20.068423599004745, flat: 6.058983393013477, pod: 42.30733495950699, loss: 68.43474209308624 
Train [4/10] | Epoch [28/160] |	nca: 18.69728171825409, flat: 6.090776294469833, pod: 41.76503258943558, loss: 66.55309092998505 
Train [4/10] | Epoch [29/160] |	nca: 19.584878891706467, flat: 6.262425273656845, pod: 43.00631695985794, loss: 68.85362076759338 
Train [4/10] | Epoch [30/160] |	nca: 19.395167648792267, flat: 6.12818306684494, pod: 41.37332093715668, loss: 66.89667201042175 
Train [4/10] | Epoch [31/160] |	nca: 18.978619933128357, flat: 6.076082058250904, pod: 41.25373578071594, loss: 66.30843794345856 
Train [4/10] | Epoch [32/160] |	nca: 19.697359636425972, flat: 6.1341879069805145, pod: 42.73768067359924, loss: 68.56922793388367 
Train [4/10] | Epoch [33/160] |	nca: 17.193032428622246, flat: 6.141085214912891, pod: 41.30265134572983, loss: 64.63676929473877 
Train [4/10] | Epoch [34/160] |	nca: 16.361339792609215, flat: 5.998935878276825, pod: 40.417010605335236, loss: 62.77728629112244 
Train [4/10] | Epoch [35/160] |	nca: 17.26904806494713, flat: 6.199917212128639, pod: 42.02885144948959, loss: 65.49781668186188 
Train [4/10] | Epoch [36/160] |	nca: 17.870774149894714, flat: 6.2932659685611725, pod: 42.58806133270264, loss: 66.75210225582123 
Train [4/10] | Epoch [37/160] |	nca: 16.824779212474823, flat: 6.108737230300903, pod: 41.12891036272049, loss: 64.0624270439148 
Train [4/10] | Epoch [38/160] |	nca: 15.591451093554497, flat: 6.067818209528923, pod: 41.25783985853195, loss: 62.91710901260376 
Train [4/10] | Epoch [39/160] |	nca: 17.142791241407394, flat: 6.136416241526604, pod: 41.94351553916931, loss: 65.22272288799286 
Train [4/10] | Epoch [40/160] |	nca: 16.64951990544796, flat: 6.166198015213013, pod: 41.88358372449875, loss: 64.69930160045624 
Train [4/10] | Epoch [41/160] |	nca: 15.874202489852905, flat: 6.210640877485275, pod: 41.80934029817581, loss: 63.89418339729309 
Train [4/10] | Epoch [42/160] |	nca: 16.3896723985672, flat: 6.205394044518471, pod: 41.94499087333679, loss: 64.5400573015213 
Train [4/10] | Epoch [43/160] |	nca: 15.04340834915638, flat: 6.0122373551130295, pod: 40.644151866436005, loss: 61.69979763031006 
Train [4/10] | Epoch [44/160] |	nca: 15.318267896771431, flat: 6.092057153582573, pod: 39.914946019649506, loss: 61.325270891189575 
Train [4/10] | Epoch [45/160] |	nca: 13.422124400734901, flat: 5.880854159593582, pod: 39.52345538139343, loss: 58.826433539390564 
Train [4/10] | Epoch [46/160] |	nca: 14.474959999322891, flat: 5.8993697836995125, pod: 39.29409855604172, loss: 59.66842806339264 
Train [4/10] | Epoch [47/160] |	nca: 14.7714564204216, flat: 6.096624322235584, pod: 41.20246082544327, loss: 62.07054150104523 
Train [4/10] | Epoch [48/160] |	nca: 14.76670390367508, flat: 6.040744058787823, pod: 40.724093198776245, loss: 61.53154146671295 
Train [4/10] | Epoch [49/160] |	nca: 15.083880633115768, flat: 5.937322527170181, pod: 40.09740960597992, loss: 61.11861276626587 
Train [4/10] | Epoch [50/160] |	nca: 12.184970542788506, flat: 5.827760830521584, pod: 39.49494141340256, loss: 57.50767278671265 
Train [4/10] | Epoch [51/160] |	nca: 13.557066574692726, flat: 5.928327903151512, pod: 39.3722106218338, loss: 58.85760509967804 
Train [4/10] | Epoch [52/160] |	nca: 13.057357251644135, flat: 5.88092153519392, pod: 39.207420110702515, loss: 58.14569890499115 
Train [4/10] | Epoch [53/160] |	nca: 13.078811466693878, flat: 5.753479138016701, pod: 38.46094787120819, loss: 57.293238282203674 
Train [4/10] | Epoch [54/160] |	nca: 11.801880106329918, flat: 5.713248692452908, pod: 37.69252014160156, loss: 55.20764899253845 
Train [4/10] | Epoch [55/160] |	nca: 12.257336527109146, flat: 5.589225731790066, pod: 37.36888134479523, loss: 55.21544361114502 
Train [4/10] | Epoch [56/160] |	nca: 13.470922097563744, flat: 5.866470590233803, pod: 39.213073670864105, loss: 58.550466418266296 
Train [4/10] | Epoch [57/160] |	nca: 12.34276993572712, flat: 5.728684514760971, pod: 38.40434008836746, loss: 56.475794553756714 
Train [4/10] | Epoch [58/160] |	nca: 12.25224120914936, flat: 5.791841201484203, pod: 39.00730073451996, loss: 57.05138325691223 
Train [4/10] | Epoch [59/160] |	nca: 12.964137375354767, flat: 5.942262679338455, pod: 39.352837324142456, loss: 58.25923752784729 
Train [4/10] | Epoch [60/160] |	nca: 11.932462871074677, flat: 5.74688084423542, pod: 38.38282006978989, loss: 56.062164068222046 
Train [4/10] | Epoch [61/160] |	nca: 10.621219873428345, flat: 5.639096662402153, pod: 37.10559445619583, loss: 53.36591100692749 
Train [4/10] | Epoch [62/160] |	nca: 11.240366578102112, flat: 5.611189603805542, pod: 37.62716859579086, loss: 54.47872447967529 
Train [4/10] | Epoch [63/160] |	nca: 11.43490320444107, flat: 5.670926071703434, pod: 37.749936163425446, loss: 54.85576546192169 
Train [4/10] | Epoch [64/160] |	nca: 10.955030307173729, flat: 5.599860265851021, pod: 36.87514466047287, loss: 53.4300354719162 
Train [4/10] | Epoch [65/160] |	nca: 10.899599626660347, flat: 5.554837338626385, pod: 36.657810032367706, loss: 53.112247586250305 
Train [4/10] | Epoch [66/160] |	nca: 11.039916723966599, flat: 5.687706150114536, pod: 37.21703773736954, loss: 53.94466054439545 
Train [4/10] | Epoch [67/160] |	nca: 10.805506199598312, flat: 5.657706588506699, pod: 37.275471448898315, loss: 53.73868441581726 
Train [4/10] | Epoch [68/160] |	nca: 9.977584481239319, flat: 5.488582104444504, pod: 35.99493944644928, loss: 51.461106181144714 
Train [4/10] | Epoch [69/160] |	nca: 8.939802385866642, flat: 5.40932884067297, pod: 36.09735023975372, loss: 50.446481585502625 
Train [4/10] | Epoch [70/160] |	nca: 10.316251903772354, flat: 5.477295927703381, pod: 36.53904312849045, loss: 52.33259057998657 
Train [4/10] | Epoch [71/160] |	nca: 9.701160609722137, flat: 5.362899251282215, pod: 35.386020958423615, loss: 50.45008063316345 
Train [4/10] | Epoch [72/160] |	nca: 9.583898842334747, flat: 5.458847902715206, pod: 35.40842658281326, loss: 50.45117366313934 
Train [4/10] | Epoch [73/160] |	nca: 9.144775122404099, flat: 5.3109211921691895, pod: 34.22665911912918, loss: 48.682355642318726 
Train [4/10] | Epoch [74/160] |	nca: 9.380900755524635, flat: 5.3078606724739075, pod: 35.13560074567795, loss: 49.82436192035675 
Train [4/10] | Epoch [75/160] |	nca: 8.689725436270237, flat: 5.3110790848731995, pod: 34.6727277636528, loss: 48.673532128334045 
Train [4/10] | Epoch [76/160] |	nca: 8.729209214448929, flat: 5.249382451176643, pod: 35.106793105602264, loss: 49.085384786129 
Train [4/10] | Epoch [77/160] |	nca: 8.779953591525555, flat: 5.256415136158466, pod: 34.06609886884689, loss: 48.10246753692627 
Train [4/10] | Epoch [78/160] |	nca: 8.790301710367203, flat: 5.137007459998131, pod: 33.889790177345276, loss: 47.81709963083267 
Train [4/10] | Epoch [79/160] |	nca: 8.532601118087769, flat: 5.237292900681496, pod: 34.28867268562317, loss: 48.05856674909592 
Train [4/10] | Epoch [80/160] |	nca: 8.865708500146866, flat: 5.186280854046345, pod: 34.164646208286285, loss: 48.21663582324982 
Train [4/10] | Epoch [81/160] |	nca: 7.502220809459686, flat: 5.163686960935593, pod: 33.000814378261566, loss: 45.66672205924988 
Train [4/10] | Epoch [82/160] |	nca: 8.495716482400894, flat: 5.031709469854832, pod: 32.55944889783859, loss: 46.08687472343445 
Train [4/10] | Epoch [83/160] |	nca: 7.715154804289341, flat: 5.119741544127464, pod: 33.21284705400467, loss: 46.04774332046509 
Train [4/10] | Epoch [84/160] |	nca: 7.341016225516796, flat: 4.87386604398489, pod: 32.23135703802109, loss: 44.44623929262161 
Train [4/10] | Epoch [85/160] |	nca: 6.9153862074017525, flat: 4.866403661668301, pod: 31.886637806892395, loss: 43.668427526950836 
Train [4/10] | Epoch [86/160] |	nca: 7.1173422411084175, flat: 4.8361140340566635, pod: 31.500844836235046, loss: 43.45430105924606 
Train [4/10] | Epoch [87/160] |	nca: 7.190691024065018, flat: 4.884395904839039, pod: 31.731123983860016, loss: 43.806211054325104 
Train [4/10] | Epoch [88/160] |	nca: 6.719356559216976, flat: 4.945259064435959, pod: 32.44489097595215, loss: 44.10950630903244 
Train [4/10] | Epoch [89/160] |	nca: 6.861995965242386, flat: 4.869459770619869, pod: 31.58222270011902, loss: 43.31367802619934 
Train [4/10] | Epoch [90/160] |	nca: 6.153327241539955, flat: 4.696926176548004, pod: 30.969656825065613, loss: 41.81991010904312 
Train [4/10] | Epoch [91/160] |	nca: 5.822156630456448, flat: 4.611111856997013, pod: 29.855453193187714, loss: 40.28872162103653 
Train [4/10] | Epoch [92/160] |	nca: 6.169957108795643, flat: 4.709826350212097, pod: 30.600657641887665, loss: 41.480441212654114 
Train [4/10] | Epoch [93/160] |	nca: 5.9227356016635895, flat: 4.61128768324852, pod: 31.071455419063568, loss: 41.60547894239426 
Train [4/10] | Epoch [94/160] |	nca: 5.835774891078472, flat: 4.583152964711189, pod: 30.209328055381775, loss: 40.62825608253479 
Train [4/10] | Epoch [95/160] |	nca: 6.002876028418541, flat: 4.509845979511738, pod: 29.72522270679474, loss: 40.23794466257095 
Train [4/10] | Epoch [96/160] |	nca: 6.35668458044529, flat: 4.616204537451267, pod: 29.987650454044342, loss: 40.96053957939148 
Train [4/10] | Epoch [97/160] |	nca: 6.113537847995758, flat: 4.589972846210003, pod: 29.873408913612366, loss: 40.57691979408264 
Train [4/10] | Epoch [98/160] |	nca: 5.713527388870716, flat: 4.531125567853451, pod: 29.73736447095871, loss: 39.982017278671265 
Train [4/10] | Epoch [99/160] |	nca: 4.84895271807909, flat: 4.340149015188217, pod: 29.121876657009125, loss: 38.31097847223282 
Train [4/10] | Epoch [100/160] |	nca: 4.927798822522163, flat: 4.302726440131664, pod: 28.663313806056976, loss: 37.89383912086487 
Train [4/10] | Epoch [101/160] |	nca: 5.116040378808975, flat: 4.344847224652767, pod: 28.08656221628189, loss: 37.547449827194214 
Train [4/10] | Epoch [102/160] |	nca: 4.894538730382919, flat: 4.31532634049654, pod: 28.008498549461365, loss: 37.218363642692566 
Train [4/10] | Epoch [103/160] |	nca: 5.121006228029728, flat: 4.2947458773851395, pod: 28.400990188121796, loss: 37.81674236059189 
Train [4/10] | Epoch [104/160] |	nca: 5.209670953452587, flat: 4.262549936771393, pod: 28.306872963905334, loss: 37.77909380197525 
Train [4/10] | Epoch [105/160] |	nca: 5.34497981518507, flat: 4.295126520097256, pod: 28.211070716381073, loss: 37.85117733478546 
Train [4/10] | Epoch [106/160] |	nca: 5.131999731063843, flat: 4.23490946739912, pod: 27.899198830127716, loss: 37.26610815525055 
Train [4/10] | Epoch [107/160] |	nca: 4.647735245525837, flat: 4.145605206489563, pod: 27.124390602111816, loss: 35.91773098707199 
Train [4/10] | Epoch [108/160] |	nca: 4.800458192825317, flat: 4.144474148750305, pod: 27.37067484855652, loss: 36.315607130527496 
Train [4/10] | Epoch [109/160] |	nca: 4.460028380155563, flat: 4.047175824642181, pod: 27.024811506271362, loss: 35.53201550245285 
Train [4/10] | Epoch [110/160] |	nca: 4.551199119538069, flat: 4.036797381937504, pod: 26.216440320014954, loss: 34.80443686246872 
Train [4/10] | Epoch [111/160] |	nca: 3.9958504736423492, flat: 3.9286133646965027, pod: 25.592841029167175, loss: 33.517304837703705 
Train [4/10] | Epoch [112/160] |	nca: 4.161515757441521, flat: 3.982627972960472, pod: 25.97851252555847, loss: 34.12265634536743 
Train [4/10] | Epoch [113/160] |	nca: 3.9428998194634914, flat: 3.939922735095024, pod: 25.95538830757141, loss: 33.83821088075638 
Train [4/10] | Epoch [114/160] |	nca: 4.1041449457407, flat: 3.8652067109942436, pod: 25.48608499765396, loss: 33.455436646938324 
Train [4/10] | Epoch [115/160] |	nca: 4.126770559698343, flat: 3.9330548495054245, pod: 26.032324135303497, loss: 34.09214961528778 
Train [4/10] | Epoch [116/160] |	nca: 3.7774896323680878, flat: 3.8756631165742874, pod: 25.290050148963928, loss: 32.943202912807465 
Train [4/10] | Epoch [117/160] |	nca: 4.030125670135021, flat: 3.8676592633128166, pod: 25.33623331785202, loss: 33.23401814699173 
Train [4/10] | Epoch [118/160] |	nca: 3.5585317946970463, flat: 3.7704224810004234, pod: 24.877859264612198, loss: 32.2068133354187 
Train [4/10] | Epoch [119/160] |	nca: 3.5298346281051636, flat: 3.786283940076828, pod: 24.558440625667572, loss: 31.87455916404724 
Train [4/10] | Epoch [120/160] |	nca: 3.6242571771144867, flat: 3.7546435594558716, pod: 24.872791290283203, loss: 32.25169241428375 
Train [4/10] | Epoch [121/160] |	nca: 3.459782689809799, flat: 3.7009025290608406, pod: 24.709247678518295, loss: 31.869932889938354 
Train [4/10] | Epoch [122/160] |	nca: 3.4663594737648964, flat: 3.652098923921585, pod: 24.491532653570175, loss: 31.6099910736084 
Train [4/10] | Epoch [123/160] |	nca: 3.532219685614109, flat: 3.638384647667408, pod: 24.01047646999359, loss: 31.181080639362335 
Train [4/10] | Epoch [124/160] |	nca: 3.29282858222723, flat: 3.6545718237757683, pod: 24.02595990896225, loss: 30.973360300064087 
Train [4/10] | Epoch [125/160] |	nca: 3.2116717137396336, flat: 3.6243269219994545, pod: 23.559026211500168, loss: 30.395024836063385 
Train [4/10] | Epoch [126/160] |	nca: 3.384137850254774, flat: 3.5854624658823013, pod: 23.598585188388824, loss: 30.56818550825119 
Train [4/10] | Epoch [127/160] |	nca: 3.2215434722602367, flat: 3.5731923952698708, pod: 23.179494351148605, loss: 29.97423005104065 
Train [4/10] | Epoch [128/160] |	nca: 3.3101937659084797, flat: 3.5087321549654007, pod: 22.635426819324493, loss: 29.454352736473083 
Train [4/10] | Epoch [129/160] |	nca: 3.218753106892109, flat: 3.5595594719052315, pod: 23.208622068166733, loss: 29.986934661865234 
Train [4/10] | Epoch [130/160] |	nca: 3.170135647058487, flat: 3.556624263525009, pod: 22.842779636383057, loss: 29.569539606571198 
Train [4/10] | Epoch [131/160] |	nca: 3.121861845254898, flat: 3.5322634428739548, pod: 22.878144174814224, loss: 29.532269597053528 
Train [4/10] | Epoch [132/160] |	nca: 3.341747835278511, flat: 3.4885324016213417, pod: 23.069179326295853, loss: 29.89945960044861 
Train [4/10] | Epoch [133/160] |	nca: 3.2096929103136063, flat: 3.5144579336047173, pod: 22.969404995441437, loss: 29.693555772304535 
Train [4/10] | Epoch [134/160] |	nca: 3.032091248780489, flat: 3.4326193034648895, pod: 21.93104836344719, loss: 28.395758986473083 
Train [4/10] | Epoch [135/160] |	nca: 3.0681051835417747, flat: 3.480412282049656, pod: 22.39393201470375, loss: 28.94244933128357 
Train [4/10] | Epoch [136/160] |	nca: 3.1268696263432503, flat: 3.475991629064083, pod: 22.44334590435028, loss: 29.046206891536713 
Train [4/10] | Epoch [137/160] |	nca: 2.960803434252739, flat: 3.421450987458229, pod: 22.49698930978775, loss: 28.87924361228943 
Train [4/10] | Epoch [138/160] |	nca: 3.1159390844404697, flat: 3.4570948779582977, pod: 22.843013525009155, loss: 29.4160475730896 
Train [4/10] | Epoch [139/160] |	nca: 2.8789418004453182, flat: 3.422706998884678, pod: 22.19415944814682, loss: 28.495808243751526 
Train [4/10] | Epoch [140/160] |	nca: 2.9035593904554844, flat: 3.404033273458481, pod: 21.67505332827568, loss: 27.982646226882935 
Train [4/10] | Epoch [141/160] |	nca: 3.007003091275692, flat: 3.3939692303538322, pod: 21.896269649267197, loss: 28.297241747379303 
Train [4/10] | Epoch [142/160] |	nca: 2.951477821916342, flat: 3.3956866785883904, pod: 21.92640995979309, loss: 28.273574590682983 
Train [4/10] | Epoch [143/160] |	nca: 2.827203270047903, flat: 3.330303445458412, pod: 21.411355316638947, loss: 27.56886178255081 
Train [4/10] | Epoch [144/160] |	nca: 2.9510635137557983, flat: 3.323840007185936, pod: 21.25227177143097, loss: 27.527175545692444 
Train [4/10] | Epoch [145/160] |	nca: 2.9316298216581345, flat: 3.3700191751122475, pod: 21.850399762392044, loss: 28.15204882621765 
Train [4/10] | Epoch [146/160] |	nca: 2.8822626657783985, flat: 3.329920306801796, pod: 21.444954693317413, loss: 27.657137751579285 
Train [4/10] | Epoch [147/160] |	nca: 2.845884829759598, flat: 3.3584811463952065, pod: 21.453342348337173, loss: 27.657708406448364 
Train [4/10] | Epoch [148/160] |	nca: 2.919799443334341, flat: 3.339069150388241, pod: 21.160244554281235, loss: 27.419113278388977 
Train [4/10] | Epoch [149/160] |	nca: 2.927876513451338, flat: 3.3299676552414894, pod: 21.27229991555214, loss: 27.530144155025482 
Train [4/10] | Epoch [150/160] |	nca: 2.9416156224906445, flat: 3.356361612677574, pod: 21.486826181411743, loss: 27.784803569316864 
Train [4/10] | Epoch [151/160] |	nca: 2.726894911378622, flat: 3.315644606947899, pod: 20.902017205953598, loss: 26.944556415081024 
Train [4/10] | Epoch [152/160] |	nca: 2.8229056149721146, flat: 3.3335108309984207, pod: 21.47288766503334, loss: 27.62930428981781 
Train [4/10] | Epoch [153/160] |	nca: 2.725069008767605, flat: 3.311008244752884, pod: 21.128964751958847, loss: 27.165041983127594 
Train [4/10] | Epoch [154/160] |	nca: 2.633937418460846, flat: 3.30009513348341, pod: 21.00867834687233, loss: 26.9427108168602 
Train [4/10] | Epoch [155/160] |	nca: 2.7897249050438404, flat: 3.305074080824852, pod: 21.007812291383743, loss: 27.102611243724823 
Train [4/10] | Epoch [156/160] |	nca: 2.730822306126356, flat: 3.3120280355215073, pod: 21.16510158777237, loss: 27.20795178413391 
Train [4/10] | Epoch [157/160] |	nca: 2.7134210765361786, flat: 3.3066824078559875, pod: 20.789242297410965, loss: 26.80934590101242 
Train [4/10] | Epoch [158/160] |	nca: 2.829013381153345, flat: 3.2708576768636703, pod: 20.80865052342415, loss: 26.90852153301239 
Train [4/10] | Epoch [159/160] |	nca: 2.6497521474957466, flat: 3.2705305367708206, pod: 20.765575021505356, loss: 26.685857474803925 
Train [4/10] | Epoch [160/160] |	nca: 2.5980793982744217, flat: 3.2780780643224716, pod: 20.763824820518494, loss: 26.639982283115387 
Fine-tuning
Building & updating memory.
Train [4/10] | Epoch [161/180] |	nca: 1.4355053901672363, flat: 0.5058441981673241, pod: 3.76646888256073, loss: 5.707818448543549 
Train [4/10] | Epoch [162/180] |	nca: 0.6513125225901604, flat: 0.49284714460372925, pod: 3.7740193605422974, loss: 4.918178975582123 
Train [4/10] | Epoch [163/180] |	nca: 0.8624025881290436, flat: 0.4955032914876938, pod: 3.666203200817108, loss: 5.024109125137329 
Train [4/10] | Epoch [164/180] |	nca: 0.6613368839025497, flat: 0.5117339342832565, pod: 3.882081061601639, loss: 5.055151879787445 
Train [4/10] | Epoch [165/180] |	nca: 0.662680447101593, flat: 0.5088576152920723, pod: 3.9261998534202576, loss: 5.097737967967987 
Train [4/10] | Epoch [166/180] |	nca: 0.6483858115971088, flat: 0.5074349567294121, pod: 3.890327751636505, loss: 5.0461485385894775 
Train [4/10] | Epoch [167/180] |	nca: 0.48239341378211975, flat: 0.48604484647512436, pod: 3.7152178585529327, loss: 4.68365615606308 
Train [4/10] | Epoch [168/180] |	nca: 0.5364612340927124, flat: 0.4967368245124817, pod: 3.728608101606369, loss: 4.761806130409241 
Train [4/10] | Epoch [169/180] |	nca: 0.6216286048293114, flat: 0.5010920614004135, pod: 3.885226249694824, loss: 5.007946968078613 
Train [4/10] | Epoch [170/180] |	nca: 0.46910347416996956, flat: 0.5039948672056198, pod: 3.8157046735286713, loss: 4.788803040981293 
Train [4/10] | Epoch [171/180] |	nca: 0.41939814761281013, flat: 0.5140439793467522, pod: 3.8119364380836487, loss: 4.745378613471985 
Train [4/10] | Epoch [172/180] |	nca: 0.4583777152001858, flat: 0.4911884665489197, pod: 3.8734110891819, loss: 4.822977244853973 
Train [4/10] | Epoch [173/180] |	nca: 0.5033806413412094, flat: 0.49241218343377113, pod: 3.789236903190613, loss: 4.785029768943787 
Train [4/10] | Epoch [174/180] |	nca: 0.4188772961497307, flat: 0.5010285750031471, pod: 3.7970967292785645, loss: 4.71700257062912 
Train [4/10] | Epoch [175/180] |	nca: 0.4244469478726387, flat: 0.4973674938082695, pod: 3.784911036491394, loss: 4.706725537776947 
Train [4/10] | Epoch [176/180] |	nca: 0.4398805685341358, flat: 0.5036925598978996, pod: 3.8244826197624207, loss: 4.76805579662323 
Train [4/10] | Epoch [177/180] |	nca: 0.42950771376490593, flat: 0.5016418695449829, pod: 3.8572500348091125, loss: 4.788399577140808 
Train [4/10] | Epoch [178/180] |	nca: 0.4204403646290302, flat: 0.5064635276794434, pod: 3.8363707065582275, loss: 4.763274669647217 
Train [4/10] | Epoch [179/180] |	nca: 0.4575198069214821, flat: 0.5108914524316788, pod: 3.9010149240493774, loss: 4.869426131248474 
Train [4/10] | Epoch [180/180] |	nca: 0.4334833472967148, flat: 0.5032822117209435, pod: 3.8069528341293335, loss: 4.743718385696411 
after task
Building & updating memory.
after task
Eval on 0->40.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.71675.
Current acc: {'total': 0.54, '00-09': 0.632, '10-19': 0.42, '20-29': 0.395, '30-39': 0.713}.
Avg inc acc top5: 0.92975.
Current acc top5: {'total': 0.851}.
Forgetting: 0.04820000000000002.
Cord metric: 0.65.
Old accuracy: 0.48, mean: 0.62.
New accuracy: 0.71, mean: 0.73.
================Task 4 Start!================
Testing on False unseen tasks (max class = 50).
Set memory of size: 800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 4 Training!================
The training samples number: 5800
Train on 40->50.
train task
nb 5800.
Train [5/10] | Epoch [1/160] |	nca: 68.7990128993988, flat: 8.686564601957798, pod: 59.72531497478485, loss: 137.2108919620514 
Train [5/10] | Epoch [2/160] |	nca: 50.80996596813202, flat: 8.13229888677597, pod: 60.28700304031372, loss: 119.22926831245422 
Train [5/10] | Epoch [3/160] |	nca: 42.23021847009659, flat: 6.794816300272942, pod: 53.25101828575134, loss: 102.27605390548706 
Train [5/10] | Epoch [4/160] |	nca: 38.57216411828995, flat: 6.450336053967476, pod: 50.007312297821045, loss: 95.02981269359589 
Train [5/10] | Epoch [5/160] |	nca: 37.20709818601608, flat: 6.578487694263458, pod: 49.1441068649292, loss: 92.92969310283661 
Train [5/10] | Epoch [6/160] |	nca: 33.802700221538544, flat: 6.388428673148155, pod: 47.31633311510086, loss: 87.50746190547943 
Train [5/10] | Epoch [7/160] |	nca: 33.03763762116432, flat: 6.4857485592365265, pod: 47.45283252000809, loss: 86.97621893882751 
Train [5/10] | Epoch [8/160] |	nca: 30.958924919366837, flat: 6.474560558795929, pod: 48.482991218566895, loss: 85.91647684574127 
Train [5/10] | Epoch [9/160] |	nca: 28.74460458755493, flat: 6.393666990101337, pod: 46.654471933841705, loss: 81.79274368286133 
Train [5/10] | Epoch [10/160] |	nca: 28.198719799518585, flat: 6.3034971952438354, pod: 45.39572662115097, loss: 79.89794325828552 
Train [5/10] | Epoch [11/160] |	nca: 27.94904527068138, flat: 6.375191107392311, pod: 46.257283329963684, loss: 80.58151984214783 
Train [5/10] | Epoch [12/160] |	nca: 27.787608116865158, flat: 6.710847422480583, pod: 48.17779338359833, loss: 82.67624855041504 
Train [5/10] | Epoch [13/160] |	nca: 26.29220086336136, flat: 6.56113962829113, pod: 46.62290781736374, loss: 79.47624862194061 
Train [5/10] | Epoch [14/160] |	nca: 26.324955821037292, flat: 6.583421468734741, pod: 46.94430893659592, loss: 79.8526861667633 
Train [5/10] | Epoch [15/160] |	nca: 25.62482041120529, flat: 6.638697445392609, pod: 46.59264123439789, loss: 78.85615849494934 
Train [5/10] | Epoch [16/160] |	nca: 22.85712230205536, flat: 6.113096743822098, pod: 43.42032730579376, loss: 72.39054656028748 
Train [5/10] | Epoch [17/160] |	nca: 24.954123109579086, flat: 6.63079571723938, pod: 46.4509996175766, loss: 78.0359183549881 
Train [5/10] | Epoch [18/160] |	nca: 23.732699543237686, flat: 6.688891813158989, pod: 46.02505153417587, loss: 76.44664251804352 
Train [5/10] | Epoch [19/160] |	nca: 22.146310418844223, flat: 6.681728094816208, pod: 45.75768339633942, loss: 74.5857218503952 
Train [5/10] | Epoch [20/160] |	nca: 22.960291862487793, flat: 6.684968516230583, pod: 45.995975494384766, loss: 75.64123558998108 
Train [5/10] | Epoch [21/160] |	nca: 21.7695472240448, flat: 6.439557135105133, pod: 45.88913333415985, loss: 74.09823846817017 
Train [5/10] | Epoch [22/160] |	nca: 23.384923577308655, flat: 6.8565313667058945, pod: 46.34757572412491, loss: 76.58903050422668 
Train [5/10] | Epoch [23/160] |	nca: 21.141831308603287, flat: 6.571182414889336, pod: 44.79293775558472, loss: 72.50595128536224 
Train [5/10] | Epoch [24/160] |	nca: 19.761398434638977, flat: 6.430960699915886, pod: 43.42545831203461, loss: 69.6178172826767 
Train [5/10] | Epoch [25/160] |	nca: 19.47533592581749, flat: 6.455504387617111, pod: 43.59788578748703, loss: 69.52872669696808 
Train [5/10] | Epoch [26/160] |	nca: 20.744122445583344, flat: 6.616012021899223, pod: 44.85744857788086, loss: 72.21758329868317 
Train [5/10] | Epoch [27/160] |	nca: 21.791926980018616, flat: 6.88779479265213, pod: 46.69429177045822, loss: 75.37401294708252 
Train [5/10] | Epoch [28/160] |	nca: 18.737889975309372, flat: 6.374042719602585, pod: 43.04016178846359, loss: 68.15209436416626 
Train [5/10] | Epoch [29/160] |	nca: 19.393577605485916, flat: 6.616357624530792, pod: 44.35510700941086, loss: 70.36504173278809 
Train [5/10] | Epoch [30/160] |	nca: 20.87552371621132, flat: 6.722265988588333, pod: 45.43326497077942, loss: 73.031054854393 
Train [5/10] | Epoch [31/160] |	nca: 17.821505337953568, flat: 6.408591940999031, pod: 43.08540028333664, loss: 67.31549775600433 
Train [5/10] | Epoch [32/160] |	nca: 18.42814089357853, flat: 6.57468481361866, pod: 43.62226152420044, loss: 68.62508702278137 
Train [5/10] | Epoch [33/160] |	nca: 18.136159285902977, flat: 6.465743616223335, pod: 43.76543462276459, loss: 68.36733758449554 
Train [5/10] | Epoch [34/160] |	nca: 17.28548139333725, flat: 6.287420436739922, pod: 43.24159532785416, loss: 66.81449735164642 
Train [5/10] | Epoch [35/160] |	nca: 18.27905896306038, flat: 6.503776550292969, pod: 43.48774069547653, loss: 68.27057659626007 
Train [5/10] | Epoch [36/160] |	nca: 17.058910474181175, flat: 6.476332664489746, pod: 43.23333293199539, loss: 66.76857602596283 
Train [5/10] | Epoch [37/160] |	nca: 15.717386603355408, flat: 6.280697271227837, pod: 42.098921716213226, loss: 64.09700584411621 
Train [5/10] | Epoch [38/160] |	nca: 16.99243250489235, flat: 6.401396334171295, pod: 43.28763896226883, loss: 66.68146789073944 
Train [5/10] | Epoch [39/160] |	nca: 17.040043637156487, flat: 6.403603196144104, pod: 43.12603920698166, loss: 66.56968605518341 
Train [5/10] | Epoch [40/160] |	nca: 16.32518234848976, flat: 6.424803555011749, pod: 43.38404154777527, loss: 66.13402736186981 
Train [5/10] | Epoch [41/160] |	nca: 16.08683681488037, flat: 6.405969798564911, pod: 43.18199700117111, loss: 65.6748036146164 
Train [5/10] | Epoch [42/160] |	nca: 15.83142726123333, flat: 6.409438103437424, pod: 42.269387900829315, loss: 64.51025307178497 
Train [5/10] | Epoch [43/160] |	nca: 17.352004796266556, flat: 6.571103885769844, pod: 44.22126942873001, loss: 68.14437782764435 
Train [5/10] | Epoch [44/160] |	nca: 15.928288012742996, flat: 6.4954743683338165, pod: 42.579329669475555, loss: 65.0030916929245 
Train [5/10] | Epoch [45/160] |	nca: 16.435282289981842, flat: 6.662695273756981, pod: 43.5562539100647, loss: 66.65423166751862 
Train [5/10] | Epoch [46/160] |	nca: 15.409334003925323, flat: 6.541664719581604, pod: 43.2752228975296, loss: 65.22622156143188 
Train [5/10] | Epoch [47/160] |	nca: 14.167885079979897, flat: 6.31219208240509, pod: 41.25177562236786, loss: 61.731852769851685 
Train [5/10] | Epoch [48/160] |	nca: 14.299147605895996, flat: 6.168909817934036, pod: 40.609797060489655, loss: 61.07785451412201 
Train [5/10] | Epoch [49/160] |	nca: 14.628683239221573, flat: 6.362664945423603, pod: 41.38764423131943, loss: 62.37899208068848 
Train [5/10] | Epoch [50/160] |	nca: 12.803741410374641, flat: 6.062296472489834, pod: 40.011404514312744, loss: 58.877442359924316 
Train [5/10] | Epoch [51/160] |	nca: 13.757604122161865, flat: 6.2107329070568085, pod: 41.063132524490356, loss: 61.03147006034851 
Train [5/10] | Epoch [52/160] |	nca: 15.022080019116402, flat: 6.230907201766968, pod: 41.08260923624039, loss: 62.335596323013306 
Train [5/10] | Epoch [53/160] |	nca: 13.34286031126976, flat: 6.162221483886242, pod: 40.28595721721649, loss: 59.79103910923004 
Train [5/10] | Epoch [54/160] |	nca: 13.885168001055717, flat: 6.251910947263241, pod: 41.510893523693085, loss: 61.64797246456146 
Train [5/10] | Epoch [55/160] |	nca: 13.474360227584839, flat: 6.229430973529816, pod: 40.8601348400116, loss: 60.563926458358765 
Train [5/10] | Epoch [56/160] |	nca: 13.133280649781227, flat: 6.144735611975193, pod: 40.767781376838684, loss: 60.04579734802246 
Train [5/10] | Epoch [57/160] |	nca: 12.377217814326286, flat: 6.070200018584728, pod: 40.275752782821655, loss: 58.7231707572937 
Train [5/10] | Epoch [58/160] |	nca: 13.455561414361, flat: 6.323763303458691, pod: 41.08392804861069, loss: 60.863253116607666 
Train [5/10] | Epoch [59/160] |	nca: 13.314497575163841, flat: 6.109602078795433, pod: 40.60843914747238, loss: 60.03253936767578 
Train [5/10] | Epoch [60/160] |	nca: 12.267549082636833, flat: 6.1256193444132805, pod: 40.57019227743149, loss: 58.96336126327515 
Train [5/10] | Epoch [61/160] |	nca: 12.46356125175953, flat: 6.159018158912659, pod: 40.838360369205475, loss: 59.46093940734863 
Train [5/10] | Epoch [62/160] |	nca: 13.660214468836784, flat: 6.242223538458347, pod: 40.83364278078079, loss: 60.73608112335205 
Train [5/10] | Epoch [63/160] |	nca: 11.819092601537704, flat: 6.01580823212862, pod: 40.40294140577316, loss: 58.237842321395874 
Train [5/10] | Epoch [64/160] |	nca: 11.122715815901756, flat: 5.854115195572376, pod: 38.86954045295715, loss: 55.84637129306793 
Train [5/10] | Epoch [65/160] |	nca: 10.960867822170258, flat: 5.85944714397192, pod: 38.41514605283737, loss: 55.23546087741852 
Train [5/10] | Epoch [66/160] |	nca: 10.918146565556526, flat: 5.85513511300087, pod: 38.264577090740204, loss: 55.037858843803406 
Train [5/10] | Epoch [67/160] |	nca: 11.554814651608467, flat: 5.949827276170254, pod: 40.04395979642868, loss: 57.54860198497772 
Train [5/10] | Epoch [68/160] |	nca: 11.495010361075401, flat: 5.923323795199394, pod: 38.77281957864761, loss: 56.19115388393402 
Train [5/10] | Epoch [69/160] |	nca: 10.749681532382965, flat: 5.7711296528577805, pod: 37.72629243135452, loss: 54.247103452682495 
Train [5/10] | Epoch [70/160] |	nca: 10.147936090826988, flat: 5.796605251729488, pod: 38.41891425848007, loss: 54.3634557723999 
Train [5/10] | Epoch [71/160] |	nca: 10.355679661035538, flat: 5.825380459427834, pod: 38.14576369524002, loss: 54.32682383060455 
Train [5/10] | Epoch [72/160] |	nca: 10.112464740872383, flat: 5.760930389165878, pod: 37.68626058101654, loss: 53.55965518951416 
Train [5/10] | Epoch [73/160] |	nca: 10.435285702347755, flat: 5.878409817814827, pod: 38.64255100488663, loss: 54.95624613761902 
Train [5/10] | Epoch [74/160] |	nca: 9.838642910122871, flat: 5.640799008309841, pod: 36.57153910398483, loss: 52.05098068714142 
Train [5/10] | Epoch [75/160] |	nca: 8.848114788532257, flat: 5.536981776356697, pod: 36.21561276912689, loss: 50.600709676742554 
Train [5/10] | Epoch [76/160] |	nca: 9.421244144439697, flat: 5.633016146719456, pod: 37.332423746585846, loss: 52.38668406009674 
Train [5/10] | Epoch [77/160] |	nca: 10.070614606142044, flat: 5.652283489704132, pod: 37.01994204521179, loss: 52.74283981323242 
Train [5/10] | Epoch [78/160] |	nca: 10.1680076867342, flat: 5.564421959221363, pod: 37.286740481853485, loss: 53.01916968822479 
Train [5/10] | Epoch [79/160] |	nca: 8.37840823084116, flat: 5.354859337210655, pod: 35.427608251571655, loss: 49.16087567806244 
Train [5/10] | Epoch [80/160] |	nca: 10.275686025619507, flat: 5.669512823224068, pod: 36.6432541012764, loss: 52.58845293521881 
Train [5/10] | Epoch [81/160] |	nca: 9.298559442162514, flat: 5.62376494705677, pod: 37.10902959108353, loss: 52.03135406970978 
Train [5/10] | Epoch [82/160] |	nca: 8.017647698521614, flat: 5.272816374897957, pod: 35.34966719150543, loss: 48.640131056308746 
Train [5/10] | Epoch [83/160] |	nca: 8.122720398008823, flat: 5.222138278186321, pod: 35.34261006116867, loss: 48.68746906518936 
Train [5/10] | Epoch [84/160] |	nca: 8.542383790016174, flat: 5.3358727395534515, pod: 35.52930527925491, loss: 49.40756183862686 
Train [5/10] | Epoch [85/160] |	nca: 7.872829370200634, flat: 5.157657913863659, pod: 33.98234283924103, loss: 47.01283037662506 
Train [5/10] | Epoch [86/160] |	nca: 7.043590843677521, flat: 5.128321431577206, pod: 33.71801406145096, loss: 45.88992637395859 
Train [5/10] | Epoch [87/160] |	nca: 6.980998806655407, flat: 5.040962629020214, pod: 32.93492341041565, loss: 44.956885159015656 
Train [5/10] | Epoch [88/160] |	nca: 7.159666568040848, flat: 5.012176848948002, pod: 32.866294264793396, loss: 45.03813773393631 
Train [5/10] | Epoch [89/160] |	nca: 7.1184092015028, flat: 4.996294513344765, pod: 32.62984752655029, loss: 44.74455118179321 
Train [5/10] | Epoch [90/160] |	nca: 6.984595894813538, flat: 4.91541013866663, pod: 32.90332770347595, loss: 44.80333375930786 
Train [5/10] | Epoch [91/160] |	nca: 7.293208345770836, flat: 5.075459435582161, pod: 33.14365994930267, loss: 45.51232773065567 
Train [5/10] | Epoch [92/160] |	nca: 7.986555680632591, flat: 5.132898889482021, pod: 32.83955615758896, loss: 45.95901072025299 
Train [5/10] | Epoch [93/160] |	nca: 6.91051672399044, flat: 4.865911640226841, pod: 32.19425195455551, loss: 43.970680236816406 
Train [5/10] | Epoch [94/160] |	nca: 7.2614928632974625, flat: 4.8553765788674355, pod: 31.910887002944946, loss: 44.02775651216507 
Train [5/10] | Epoch [95/160] |	nca: 6.481452189385891, flat: 4.839998960494995, pod: 31.844955384731293, loss: 43.16640627384186 
Train [5/10] | Epoch [96/160] |	nca: 7.019329808652401, flat: 4.782030962407589, pod: 31.556604325771332, loss: 43.35796517133713 
Train [5/10] | Epoch [97/160] |	nca: 6.001633487641811, flat: 4.704868778586388, pod: 31.450990319252014, loss: 42.15749263763428 
Train [5/10] | Epoch [98/160] |	nca: 6.357040144503117, flat: 4.693420864641666, pod: 30.69515097141266, loss: 41.745612144470215 
Train [5/10] | Epoch [99/160] |	nca: 5.783063389360905, flat: 4.586489215493202, pod: 30.42262452840805, loss: 40.79217708110809 
Train [5/10] | Epoch [100/160] |	nca: 5.618263456970453, flat: 4.528250470757484, pod: 30.0373517870903, loss: 40.183865904808044 
Train [5/10] | Epoch [101/160] |	nca: 5.428644604980946, flat: 4.486822120845318, pod: 29.246344923973083, loss: 39.16181176900864 
Train [5/10] | Epoch [102/160] |	nca: 5.280404143035412, flat: 4.451125733554363, pod: 28.983172953128815, loss: 38.71470272541046 
Train [5/10] | Epoch [103/160] |	nca: 5.1396841034293175, flat: 4.3325245305895805, pod: 29.009481728076935, loss: 38.48169016838074 
Train [5/10] | Epoch [104/160] |	nca: 5.7206516191363335, flat: 4.440210729837418, pod: 29.546216011047363, loss: 39.70707857608795 
Train [5/10] | Epoch [105/160] |	nca: 6.363415837287903, flat: 4.512613095343113, pod: 29.70729696750641, loss: 40.58332586288452 
Train [5/10] | Epoch [106/160] |	nca: 5.328815393149853, flat: 4.315926559269428, pod: 28.587682485580444, loss: 38.232424199581146 
Train [5/10] | Epoch [107/160] |	nca: 5.102996662259102, flat: 4.394237712025642, pod: 28.7211776971817, loss: 38.21841204166412 
Train [5/10] | Epoch [108/160] |	nca: 4.813928417861462, flat: 4.229121893644333, pod: 27.509730339050293, loss: 36.552780508995056 
Train [5/10] | Epoch [109/160] |	nca: 4.9617878049612045, flat: 4.215451590716839, pod: 27.36060732603073, loss: 36.53784668445587 
Train [5/10] | Epoch [110/160] |	nca: 4.974420711398125, flat: 4.252864353358746, pod: 28.14065384864807, loss: 37.36793893575668 
Train [5/10] | Epoch [111/160] |	nca: 4.4384824968874454, flat: 4.101257003843784, pod: 27.560277223587036, loss: 36.10001677274704 
Train [5/10] | Epoch [112/160] |	nca: 4.449700158089399, flat: 4.065073549747467, pod: 26.715199887752533, loss: 35.22997349500656 
Train [5/10] | Epoch [113/160] |	nca: 4.427491873502731, flat: 3.9814219549298286, pod: 26.87085258960724, loss: 35.279766261577606 
Train [5/10] | Epoch [114/160] |	nca: 4.5230053551495075, flat: 4.053361877799034, pod: 27.040850698947906, loss: 35.617217898368835 
Train [5/10] | Epoch [115/160] |	nca: 4.056171905249357, flat: 3.9663559943437576, pod: 26.30540096759796, loss: 34.327928721904755 
Train [5/10] | Epoch [116/160] |	nca: 3.9321447648108006, flat: 3.8363117948174477, pod: 25.273213654756546, loss: 33.041670083999634 
Train [5/10] | Epoch [117/160] |	nca: 4.366038095206022, flat: 3.9754746705293655, pod: 26.182643115520477, loss: 34.5241556763649 
Train [5/10] | Epoch [118/160] |	nca: 4.12479742243886, flat: 3.9338787123560905, pod: 25.49047163128853, loss: 33.54914790391922 
Train [5/10] | Epoch [119/160] |	nca: 4.134506486356258, flat: 3.8645069003105164, pod: 25.789542019367218, loss: 33.788555562496185 
Train [5/10] | Epoch [120/160] |	nca: 4.0369460470974445, flat: 3.8895347490906715, pod: 25.15697741508484, loss: 33.0834584236145 
Train [5/10] | Epoch [121/160] |	nca: 4.255820374935865, flat: 3.8349901661276817, pod: 25.277012169361115, loss: 33.36782270669937 
Train [5/10] | Epoch [122/160] |	nca: 4.376008290797472, flat: 3.8794507905840874, pod: 25.405484557151794, loss: 33.66094362735748 
Train [5/10] | Epoch [123/160] |	nca: 4.102548971772194, flat: 3.7571209594607353, pod: 24.9212064743042, loss: 32.78087645769119 
Train [5/10] | Epoch [124/160] |	nca: 3.8464762195944786, flat: 3.754195384681225, pod: 24.540450632572174, loss: 32.14112198352814 
Train [5/10] | Epoch [125/160] |	nca: 3.8958175219595432, flat: 3.8200715854763985, pod: 25.425027430057526, loss: 33.14091646671295 
Train [5/10] | Epoch [126/160] |	nca: 3.8064636513590813, flat: 3.7245126962661743, pod: 24.53792703151703, loss: 32.068903267383575 
Train [5/10] | Epoch [127/160] |	nca: 3.7403025813400745, flat: 3.8181322067976, pod: 25.127842873334885, loss: 32.68627750873566 
Train [5/10] | Epoch [128/160] |	nca: 3.8298569321632385, flat: 3.668590672314167, pod: 24.433060467243195, loss: 31.93150818347931 
Train [5/10] | Epoch [129/160] |	nca: 3.763573072850704, flat: 3.766387350857258, pod: 24.34765475988388, loss: 31.877615213394165 
Train [5/10] | Epoch [130/160] |	nca: 3.718313828110695, flat: 3.65825741738081, pod: 24.27616247534752, loss: 31.65273380279541 
Train [5/10] | Epoch [131/160] |	nca: 3.647884715348482, flat: 3.6602686271071434, pod: 23.921276837587357, loss: 31.229429960250854 
Train [5/10] | Epoch [132/160] |	nca: 3.448101334273815, flat: 3.690165415406227, pod: 23.94872683286667, loss: 31.08699381351471 
Train [5/10] | Epoch [133/160] |	nca: 3.456141121685505, flat: 3.6180310398340225, pod: 23.764297753572464, loss: 30.838469862937927 
Train [5/10] | Epoch [134/160] |	nca: 3.3543610759079456, flat: 3.5401273742318153, pod: 22.964133977890015, loss: 29.858622312545776 
Train [5/10] | Epoch [135/160] |	nca: 3.2815034575760365, flat: 3.5732593536376953, pod: 22.98950007557869, loss: 29.844262719154358 
Train [5/10] | Epoch [136/160] |	nca: 3.3670548163354397, flat: 3.56809563934803, pod: 23.4610755443573, loss: 30.396226048469543 
Train [5/10] | Epoch [137/160] |	nca: 3.3299748077988625, flat: 3.4726279377937317, pod: 22.27577441930771, loss: 29.078377187252045 
Train [5/10] | Epoch [138/160] |	nca: 3.294738221913576, flat: 3.503856912255287, pod: 22.61237460374832, loss: 29.41096967458725 
Train [5/10] | Epoch [139/160] |	nca: 3.2359863854944706, flat: 3.4828400015830994, pod: 22.55110514163971, loss: 29.269931375980377 
Train [5/10] | Epoch [140/160] |	nca: 3.0986426435410976, flat: 3.476656824350357, pod: 22.566730618476868, loss: 29.142029941082 
Train [5/10] | Epoch [141/160] |	nca: 3.3075767047703266, flat: 3.460778534412384, pod: 22.191697746515274, loss: 28.9600527882576 
Train [5/10] | Epoch [142/160] |	nca: 3.049469470977783, flat: 3.4270038679242134, pod: 22.315501272678375, loss: 28.791974663734436 
Train [5/10] | Epoch [143/160] |	nca: 3.1734013333916664, flat: 3.4212085008621216, pod: 22.188214361667633, loss: 28.782824218273163 
Train [5/10] | Epoch [144/160] |	nca: 3.1082161590456963, flat: 3.464614361524582, pod: 22.462136059999466, loss: 29.034966707229614 
Train [5/10] | Epoch [145/160] |	nca: 3.1204673126339912, flat: 3.4460784941911697, pod: 21.930264115333557, loss: 28.49680995941162 
Train [5/10] | Epoch [146/160] |	nca: 3.1550284400582314, flat: 3.4403000101447105, pod: 21.954559594392776, loss: 28.54988783597946 
Train [5/10] | Epoch [147/160] |	nca: 2.991803076118231, flat: 3.398530051112175, pod: 21.78541424870491, loss: 28.175747215747833 
Train [5/10] | Epoch [148/160] |	nca: 3.137698817998171, flat: 3.419075347483158, pod: 22.011452794075012, loss: 28.5682270526886 
Train [5/10] | Epoch [149/160] |	nca: 3.0896734930574894, flat: 3.382081262767315, pod: 21.652209132909775, loss: 28.123963832855225 
Train [5/10] | Epoch [150/160] |	nca: 3.137523587793112, flat: 3.3886066898703575, pod: 21.93175533413887, loss: 28.45788550376892 
Train [5/10] | Epoch [151/160] |	nca: 2.9673431031405926, flat: 3.3937320932745934, pod: 21.770111978054047, loss: 28.13118690252304 
Train [5/10] | Epoch [152/160] |	nca: 3.045676037669182, flat: 3.377198189496994, pod: 21.371902108192444, loss: 27.794776260852814 
Train [5/10] | Epoch [153/160] |	nca: 3.218927036970854, flat: 3.3879158049821854, pod: 21.433488845825195, loss: 28.040331780910492 
Train [5/10] | Epoch [154/160] |	nca: 2.9717526249587536, flat: 3.3713740557432175, pod: 21.43772715330124, loss: 27.780853748321533 
Train [5/10] | Epoch [155/160] |	nca: 2.9983992129564285, flat: 3.379355952143669, pod: 21.19494977593422, loss: 27.57270497083664 
Train [5/10] | Epoch [156/160] |	nca: 2.9443587884306908, flat: 3.4133970513939857, pod: 21.394228667020798, loss: 27.751984477043152 
Train [5/10] | Epoch [157/160] |	nca: 3.196543548256159, flat: 3.33435520529747, pod: 21.253271728754044, loss: 27.784170389175415 
Train [5/10] | Epoch [158/160] |	nca: 3.1271341778337955, flat: 3.3489074259996414, pod: 20.897638231515884, loss: 27.373679876327515 
Train [5/10] | Epoch [159/160] |	nca: 2.9271788373589516, flat: 3.3542893156409264, pod: 21.133540451526642, loss: 27.415008664131165 
Train [5/10] | Epoch [160/160] |	nca: 3.1290344148874283, flat: 3.397471286356449, pod: 21.619302690029144, loss: 28.145808577537537 
Fine-tuning
Building & updating memory.
Train [5/10] | Epoch [161/180] |	nca: 1.8251579850912094, flat: 0.7074997499585152, pod: 5.821906268596649, loss: 8.354564011096954 
Train [5/10] | Epoch [162/180] |	nca: 0.8833278939127922, flat: 0.7135571464896202, pod: 5.829431474208832, loss: 7.426316499710083 
Train [5/10] | Epoch [163/180] |	nca: 0.8322065025568008, flat: 0.7058277949690819, pod: 5.825661361217499, loss: 7.363695740699768 
Train [5/10] | Epoch [164/180] |	nca: 0.695746012032032, flat: 0.7324443608522415, pod: 6.039876401424408, loss: 7.468066871166229 
Train [5/10] | Epoch [165/180] |	nca: 0.7199569791555405, flat: 0.7317278608679771, pod: 5.984652459621429, loss: 7.4363372921943665 
Train [5/10] | Epoch [166/180] |	nca: 0.6357347369194031, flat: 0.7097876965999603, pod: 5.860545456409454, loss: 7.206067860126495 
Train [5/10] | Epoch [167/180] |	nca: 0.6031203046441078, flat: 0.7022381946444511, pod: 5.781868875026703, loss: 7.087227463722229 
Train [5/10] | Epoch [168/180] |	nca: 0.6055172234773636, flat: 0.7054900228977203, pod: 5.75994086265564, loss: 7.07094806432724 
Train [5/10] | Epoch [169/180] |	nca: 0.5755868963897228, flat: 0.7031252384185791, pod: 5.776396214962006, loss: 7.055108428001404 
Train [5/10] | Epoch [170/180] |	nca: 0.6245504394173622, flat: 0.7053684890270233, pod: 5.801997780799866, loss: 7.131916701793671 
Train [5/10] | Epoch [171/180] |	nca: 0.548035953193903, flat: 0.7008139565587044, pod: 5.763880729675293, loss: 7.012730717658997 
Train [5/10] | Epoch [172/180] |	nca: 0.5725286789238453, flat: 0.7215752154588699, pod: 5.892832696437836, loss: 7.186936616897583 
Train [5/10] | Epoch [173/180] |	nca: 0.6087041907012463, flat: 0.7228430658578873, pod: 5.955081343650818, loss: 7.286628723144531 
Train [5/10] | Epoch [174/180] |	nca: 0.5378390774130821, flat: 0.7177500948309898, pod: 5.8432594537734985, loss: 7.098848581314087 
Train [5/10] | Epoch [175/180] |	nca: 0.5853855311870575, flat: 0.7202856987714767, pod: 5.871128618717194, loss: 7.176799893379211 
Train [5/10] | Epoch [176/180] |	nca: 0.5291662290692329, flat: 0.7098852097988129, pod: 5.8182737827301025, loss: 7.05732524394989 
Train [5/10] | Epoch [177/180] |	nca: 0.5603116974234581, flat: 0.7161967307329178, pod: 5.836829721927643, loss: 7.113338232040405 
Train [5/10] | Epoch [178/180] |	nca: 0.5507120043039322, flat: 0.7165352702140808, pod: 5.910890877246857, loss: 7.1781381368637085 
Train [5/10] | Epoch [179/180] |	nca: 0.5060392208397388, flat: 0.7132592797279358, pod: 5.9086520075798035, loss: 7.127950489521027 
Train [5/10] | Epoch [180/180] |	nca: 0.5734696723520756, flat: 0.7235205844044685, pod: 5.8423988819122314, loss: 7.139389097690582 
after task
Building & updating memory.
after task
Eval on 0->50.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.6752.
Current acc: {'total': 0.509, '00-09': 0.59, '10-19': 0.423, '20-29': 0.337, '30-39': 0.418, '40-49': 0.779}.
Avg inc acc top5: 0.9086000000000001.
Current acc top5: {'total': 0.824}.
Forgetting: 0.09449999999999997.
Cord metric: 0.62.
Old accuracy: 0.44, mean: 0.58.
New accuracy: 0.78, mean: 0.74.
================Task 5 Start!================
Testing on False unseen tasks (max class = 60).
Set memory of size: 1000.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 5 Training!================
The training samples number: 6000
Train on 50->60.
train task
nb 6000.
Train [6/10] | Epoch [1/160] |	nca: 65.9250095486641, flat: 8.61526308953762, pod: 65.19828927516937, loss: 139.738560795784 
Train [6/10] | Epoch [2/160] |	nca: 48.586904883384705, flat: 8.068324699997902, pod: 63.449814677238464, loss: 120.10504364967346 
Train [6/10] | Epoch [3/160] |	nca: 41.03315049409866, flat: 7.298989042639732, pod: 57.21279335021973, loss: 105.54493355751038 
Train [6/10] | Epoch [4/160] |	nca: 34.40919154882431, flat: 6.704985961318016, pod: 53.47448492050171, loss: 94.58866250514984 
Train [6/10] | Epoch [5/160] |	nca: 30.99031963944435, flat: 6.60906570404768, pod: 51.607415556907654, loss: 89.2068008184433 
Train [6/10] | Epoch [6/160] |	nca: 30.7326640188694, flat: 6.693814270198345, pod: 52.52093696594238, loss: 89.94741499423981 
Train [6/10] | Epoch [7/160] |	nca: 29.757514387369156, flat: 6.520713776350021, pod: 50.39324206113815, loss: 86.67147040367126 
Train [6/10] | Epoch [8/160] |	nca: 26.572984993457794, flat: 6.284678861498833, pod: 48.15425890684128, loss: 81.01192259788513 
Train [6/10] | Epoch [9/160] |	nca: 27.757754892110825, flat: 6.781978935003281, pod: 51.31443101167679, loss: 85.8541647195816 
Train [6/10] | Epoch [10/160] |	nca: 26.205929458141327, flat: 6.55519911646843, pod: 49.8827178478241, loss: 82.64384639263153 
Train [6/10] | Epoch [11/160] |	nca: 25.644913971424103, flat: 6.550935573875904, pod: 50.1017050743103, loss: 82.29755520820618 
Train [6/10] | Epoch [12/160] |	nca: 23.601722568273544, flat: 6.428124740719795, pod: 48.1076483130455, loss: 78.13749551773071 
Train [6/10] | Epoch [13/160] |	nca: 22.456013917922974, flat: 6.460914827883244, pod: 47.64881521463394, loss: 76.56574392318726 
Train [6/10] | Epoch [14/160] |	nca: 23.010040313005447, flat: 6.558084487915039, pod: 49.6017102599144, loss: 79.1698350906372 
Train [6/10] | Epoch [15/160] |	nca: 20.857733219861984, flat: 6.4266970455646515, pod: 48.152614176273346, loss: 75.43704438209534 
Train [6/10] | Epoch [16/160] |	nca: 20.84088906645775, flat: 6.280988469719887, pod: 47.73181629180908, loss: 74.85369396209717 
Train [6/10] | Epoch [17/160] |	nca: 20.476719230413437, flat: 6.583654552698135, pod: 47.758179008960724, loss: 74.81855297088623 
Train [6/10] | Epoch [18/160] |	nca: 19.273238122463226, flat: 6.214508108794689, pod: 46.06098657846451, loss: 71.54873275756836 
Train [6/10] | Epoch [19/160] |	nca: 18.76890680193901, flat: 6.3324726819992065, pod: 47.381319999694824, loss: 72.48269951343536 
Train [6/10] | Epoch [20/160] |	nca: 18.562932282686234, flat: 6.276974834501743, pod: 46.120670199394226, loss: 70.96057665348053 
Train [6/10] | Epoch [21/160] |	nca: 19.43855309486389, flat: 6.571462541818619, pod: 47.24399995803833, loss: 73.25401544570923 
Train [6/10] | Epoch [22/160] |	nca: 19.773144245147705, flat: 6.474525630474091, pod: 46.85971117019653, loss: 73.10738110542297 
Train [6/10] | Epoch [23/160] |	nca: 19.114262133836746, flat: 6.5224591344594955, pod: 47.57631343603134, loss: 73.21303474903107 
Train [6/10] | Epoch [24/160] |	nca: 18.32471963763237, flat: 6.359444670379162, pod: 46.099554777145386, loss: 70.78371906280518 
Train [6/10] | Epoch [25/160] |	nca: 17.775949358940125, flat: 6.554180324077606, pod: 47.142323434352875, loss: 71.47245383262634 
Train [6/10] | Epoch [26/160] |	nca: 17.931409388780594, flat: 6.394582748413086, pod: 46.9693409204483, loss: 71.29533302783966 
Train [6/10] | Epoch [27/160] |	nca: 16.447521299123764, flat: 6.349603049457073, pod: 46.03678560256958, loss: 68.83390963077545 
Train [6/10] | Epoch [28/160] |	nca: 15.812301069498062, flat: 6.115442238748074, pod: 44.199481308460236, loss: 66.12722420692444 
Train [6/10] | Epoch [29/160] |	nca: 15.364163726568222, flat: 6.373659133911133, pod: 44.61249792575836, loss: 66.35032033920288 
Train [6/10] | Epoch [30/160] |	nca: 15.567098081111908, flat: 6.172257721424103, pod: 43.61945277452469, loss: 65.35880839824677 
Train [6/10] | Epoch [31/160] |	nca: 15.586524158716202, flat: 6.040780074894428, pod: 43.157424092292786, loss: 64.78472828865051 
Train [6/10] | Epoch [32/160] |	nca: 15.929881721735, flat: 6.263598248362541, pod: 44.25900912284851, loss: 66.45248937606812 
Train [6/10] | Epoch [33/160] |	nca: 14.27147002518177, flat: 6.226381413638592, pod: 44.15757781267166, loss: 64.65542948246002 
Train [6/10] | Epoch [34/160] |	nca: 14.864866718649864, flat: 6.269620679318905, pod: 45.596276104450226, loss: 66.73076331615448 
Train [6/10] | Epoch [35/160] |	nca: 15.212142631411552, flat: 6.235172063112259, pod: 44.97888398170471, loss: 66.42619848251343 
Train [6/10] | Epoch [36/160] |	nca: 15.406258389353752, flat: 6.188005670905113, pod: 44.44510978460312, loss: 66.03937375545502 
Train [6/10] | Epoch [37/160] |	nca: 15.857747659087181, flat: 6.447026424109936, pod: 45.1584911942482, loss: 67.46326553821564 
Train [6/10] | Epoch [38/160] |	nca: 14.512829586863518, flat: 6.273727908730507, pod: 44.20657205581665, loss: 64.99312949180603 
Train [6/10] | Epoch [39/160] |	nca: 13.744825586676598, flat: 6.027867034077644, pod: 44.249617755413055, loss: 64.02231061458588 
Train [6/10] | Epoch [40/160] |	nca: 13.391620114445686, flat: 6.022890143096447, pod: 42.954285621643066, loss: 62.36879599094391 
Train [6/10] | Epoch [41/160] |	nca: 12.539370909333229, flat: 5.971941404044628, pod: 42.12364196777344, loss: 60.63495421409607 
Train [6/10] | Epoch [42/160] |	nca: 13.396346628665924, flat: 6.103090986609459, pod: 43.06462401151657, loss: 62.564061641693115 
Train [6/10] | Epoch [43/160] |	nca: 12.775732159614563, flat: 6.014723286032677, pod: 42.38560551404953, loss: 61.176061153411865 
Train [6/10] | Epoch [44/160] |	nca: 13.005469217896461, flat: 5.961570121347904, pod: 42.0558420419693, loss: 61.022881388664246 
Train [6/10] | Epoch [45/160] |	nca: 12.528382897377014, flat: 5.853782996535301, pod: 41.983420610427856, loss: 60.3655868768692 
Train [6/10] | Epoch [46/160] |	nca: 11.72163513302803, flat: 5.795161157846451, pod: 41.256105184555054, loss: 58.77290153503418 
Train [6/10] | Epoch [47/160] |	nca: 11.671756133437157, flat: 5.903427630662918, pod: 42.57623654603958, loss: 60.15142011642456 
Train [6/10] | Epoch [48/160] |	nca: 11.67852632701397, flat: 5.856599472463131, pod: 42.40877145528793, loss: 59.94389748573303 
Train [6/10] | Epoch [49/160] |	nca: 12.416470512747765, flat: 5.935213923454285, pod: 42.72398829460144, loss: 61.07567262649536 
Train [6/10] | Epoch [50/160] |	nca: 12.47337606549263, flat: 6.024353697896004, pod: 42.57904785871506, loss: 61.076777935028076 
Train [6/10] | Epoch [51/160] |	nca: 13.180717766284943, flat: 6.108868047595024, pod: 43.13121676445007, loss: 62.4208025932312 
Train [6/10] | Epoch [52/160] |	nca: 11.9253548681736, flat: 5.922373786568642, pod: 42.22076493501663, loss: 60.068493366241455 
Train [6/10] | Epoch [53/160] |	nca: 11.652398869395256, flat: 5.8747976794838905, pod: 41.914386212825775, loss: 59.441582918167114 
Train [6/10] | Epoch [54/160] |	nca: 10.690172016620636, flat: 5.790088951587677, pod: 41.2227663397789, loss: 57.7030268907547 
Train [6/10] | Epoch [55/160] |	nca: 11.643047161400318, flat: 5.744355253875256, pod: 41.91583460569382, loss: 59.303237080574036 
Train [6/10] | Epoch [56/160] |	nca: 10.5097825974226, flat: 5.643274240195751, pod: 40.68727004528046, loss: 56.84032714366913 
Train [6/10] | Epoch [57/160] |	nca: 10.306404933333397, flat: 5.537701912224293, pod: 39.65645903348923, loss: 55.50056612491608 
Train [6/10] | Epoch [58/160] |	nca: 9.692161947488785, flat: 5.395703874528408, pod: 38.68339681625366, loss: 53.77126258611679 
Train [6/10] | Epoch [59/160] |	nca: 10.227111652493477, flat: 5.421410955488682, pod: 39.005706787109375, loss: 54.654229164123535 
Train [6/10] | Epoch [60/160] |	nca: 11.587818622589111, flat: 5.82926332205534, pod: 42.33231168985367, loss: 59.749393701553345 
Train [6/10] | Epoch [61/160] |	nca: 10.017441302537918, flat: 5.635081358253956, pod: 39.91654163599014, loss: 55.569064021110535 
Train [6/10] | Epoch [62/160] |	nca: 9.345451928675175, flat: 5.259140565991402, pod: 38.05646300315857, loss: 52.6610546708107 
Train [6/10] | Epoch [63/160] |	nca: 9.474311970174313, flat: 5.411208458244801, pod: 38.78667742013931, loss: 53.67219817638397 
Train [6/10] | Epoch [64/160] |	nca: 10.199888445436954, flat: 5.5158721357584, pod: 39.014660120010376, loss: 54.73042023181915 
Train [6/10] | Epoch [65/160] |	nca: 10.81687182188034, flat: 5.689234606921673, pod: 40.52222400903702, loss: 57.02833080291748 
Train [6/10] | Epoch [66/160] |	nca: 9.306963816285133, flat: 5.345634877681732, pod: 38.136361598968506, loss: 52.78896015882492 
Train [6/10] | Epoch [67/160] |	nca: 9.623765721917152, flat: 5.4183347672224045, pod: 38.3930242061615, loss: 53.4351247549057 
Train [6/10] | Epoch [68/160] |	nca: 8.740860134363174, flat: 5.159736581146717, pod: 36.10187530517578, loss: 50.00247186422348 
Train [6/10] | Epoch [69/160] |	nca: 8.377776175737381, flat: 5.190880678594112, pod: 37.30238056182861, loss: 50.87103748321533 
Train [6/10] | Epoch [70/160] |	nca: 7.449452117085457, flat: 4.831965513527393, pod: 36.11872053146362, loss: 48.400138199329376 
Train [6/10] | Epoch [71/160] |	nca: 7.96303303539753, flat: 4.929930165410042, pod: 35.287354826927185, loss: 48.180317878723145 
Train [6/10] | Epoch [72/160] |	nca: 8.778845556080341, flat: 5.1996292397379875, pod: 37.10227686166763, loss: 51.08075153827667 
Train [6/10] | Epoch [73/160] |	nca: 9.212210483849049, flat: 5.212134316563606, pod: 37.179049134254456, loss: 51.60339432954788 
Train [6/10] | Epoch [74/160] |	nca: 9.132996268570423, flat: 5.075646907091141, pod: 36.88928407430649, loss: 51.097927272319794 
Train [6/10] | Epoch [75/160] |	nca: 9.021937429904938, flat: 5.276786983013153, pod: 37.87838971614838, loss: 52.17711400985718 
Train [6/10] | Epoch [76/160] |	nca: 7.829292319715023, flat: 5.009718827903271, pod: 35.88983565568924, loss: 48.72884690761566 
Train [6/10] | Epoch [77/160] |	nca: 8.242483258247375, flat: 5.059845462441444, pod: 36.93561226129532, loss: 50.23794078826904 
Train [6/10] | Epoch [78/160] |	nca: 7.131330564618111, flat: 4.794096060097218, pod: 35.43536067008972, loss: 47.36078745126724 
Train [6/10] | Epoch [79/160] |	nca: 7.7973973751068115, flat: 4.870831795036793, pod: 35.32827651500702, loss: 47.99650591611862 
Train [6/10] | Epoch [80/160] |	nca: 7.526112794876099, flat: 4.911458343267441, pod: 36.0697095990181, loss: 48.50728088617325 
Train [6/10] | Epoch [81/160] |	nca: 8.008082240819931, flat: 4.872152470052242, pod: 35.228715002536774, loss: 48.10895001888275 
Train [6/10] | Epoch [82/160] |	nca: 7.413500666618347, flat: 4.848993614315987, pod: 34.916608929634094, loss: 47.17910325527191 
Train [6/10] | Epoch [83/160] |	nca: 7.975860632956028, flat: 5.02777174115181, pod: 37.10885375738144, loss: 50.11248582601547 
Train [6/10] | Epoch [84/160] |	nca: 7.875153765082359, flat: 4.870974764227867, pod: 35.09175223112106, loss: 47.837881326675415 
Train [6/10] | Epoch [85/160] |	nca: 7.083548910915852, flat: 4.760297365486622, pod: 34.38443565368652, loss: 46.228282153606415 
Train [6/10] | Epoch [86/160] |	nca: 6.13499902933836, flat: 4.590476356446743, pod: 33.63673222064972, loss: 44.36220771074295 
Train [6/10] | Epoch [87/160] |	nca: 5.923875622451305, flat: 4.450152203440666, pod: 32.640997529029846, loss: 43.015025198459625 
Train [6/10] | Epoch [88/160] |	nca: 6.391959086060524, flat: 4.560013182461262, pod: 33.371586203575134, loss: 44.32355850934982 
Train [6/10] | Epoch [89/160] |	nca: 6.59017788618803, flat: 4.6028525829315186, pod: 33.954574942588806, loss: 45.14760512113571 
Train [6/10] | Epoch [90/160] |	nca: 6.55087660998106, flat: 4.544934570789337, pod: 33.24825620651245, loss: 44.344066977500916 
Train [6/10] | Epoch [91/160] |	nca: 5.988653756678104, flat: 4.500231921672821, pod: 33.50184065103531, loss: 43.99072629213333 
Train [6/10] | Epoch [92/160] |	nca: 5.402212381362915, flat: 4.259703062474728, pod: 31.858271598815918, loss: 41.52018713951111 
Train [6/10] | Epoch [93/160] |	nca: 5.8530972599983215, flat: 4.337099842727184, pod: 32.55128216743469, loss: 42.741479337215424 
Train [6/10] | Epoch [94/160] |	nca: 5.964586794376373, flat: 4.387704864144325, pod: 31.899943709373474, loss: 42.2522354722023 
Train [6/10] | Epoch [95/160] |	nca: 5.909839108586311, flat: 4.303345628082752, pod: 32.04842150211334, loss: 42.261606216430664 
Train [6/10] | Epoch [96/160] |	nca: 5.431889936327934, flat: 4.280782796442509, pod: 31.634038746356964, loss: 41.34671139717102 
Train [6/10] | Epoch [97/160] |	nca: 4.999931752681732, flat: 4.070849724113941, pod: 30.862555742263794, loss: 39.93333721160889 
Train [6/10] | Epoch [98/160] |	nca: 5.298966161906719, flat: 4.199815422296524, pod: 30.912433743476868, loss: 40.41121530532837 
Train [6/10] | Epoch [99/160] |	nca: 4.92965592071414, flat: 4.065724611282349, pod: 29.995563209056854, loss: 38.990943908691406 
Train [6/10] | Epoch [100/160] |	nca: 4.980167869478464, flat: 4.011445000767708, pod: 30.098933517932892, loss: 39.09054654836655 
Train [6/10] | Epoch [101/160] |	nca: 5.016009282320738, flat: 3.971320502460003, pod: 30.03841072320938, loss: 39.02574020624161 
Train [6/10] | Epoch [102/160] |	nca: 4.63115806132555, flat: 3.9884891733527184, pod: 28.983362019062042, loss: 37.603009045124054 
Train [6/10] | Epoch [103/160] |	nca: 4.7311395183205605, flat: 3.9119224324822426, pod: 29.658745408058167, loss: 38.30180740356445 
Train [6/10] | Epoch [104/160] |	nca: 4.533258430659771, flat: 3.844978876411915, pod: 28.9967480301857, loss: 37.374985456466675 
Train [6/10] | Epoch [105/160] |	nca: 4.583876878023148, flat: 3.8779197111725807, pod: 29.07968258857727, loss: 37.54147917032242 
Train [6/10] | Epoch [106/160] |	nca: 4.8864777982234955, flat: 3.8752327784895897, pod: 29.191994726657867, loss: 37.95370548963547 
Train [6/10] | Epoch [107/160] |	nca: 4.6826221495866776, flat: 3.8526535481214523, pod: 28.94680678844452, loss: 37.48208236694336 
Train [6/10] | Epoch [108/160] |	nca: 4.222324028611183, flat: 3.760353200137615, pod: 27.93374937772751, loss: 35.91642665863037 
Train [6/10] | Epoch [109/160] |	nca: 4.5563609302043915, flat: 3.7555107921361923, pod: 28.883647084236145, loss: 37.1955189704895 
Train [6/10] | Epoch [110/160] |	nca: 4.119386289268732, flat: 3.6909023821353912, pod: 27.06838023662567, loss: 34.878669023513794 
Train [6/10] | Epoch [111/160] |	nca: 4.050019294023514, flat: 3.657012201845646, pod: 27.954598367214203, loss: 35.66162997484207 
Train [6/10] | Epoch [112/160] |	nca: 4.155921194702387, flat: 3.621427074074745, pod: 27.51712054014206, loss: 35.29446876049042 
Train [6/10] | Epoch [113/160] |	nca: 3.885101515799761, flat: 3.567370004951954, pod: 27.24534684419632, loss: 34.697818338871 
Train [6/10] | Epoch [114/160] |	nca: 4.312703020870686, flat: 3.593492105603218, pod: 27.317057222127914, loss: 35.22325223684311 
Train [6/10] | Epoch [115/160] |	nca: 4.097398664802313, flat: 3.614737570285797, pod: 27.438759922981262, loss: 35.15089625120163 
Train [6/10] | Epoch [116/160] |	nca: 4.313231486827135, flat: 3.5756932869553566, pod: 26.782545119524002, loss: 34.67146980762482 
Train [6/10] | Epoch [117/160] |	nca: 3.9805003851652145, flat: 3.558282881975174, pod: 27.032878547906876, loss: 34.57166141271591 
Train [6/10] | Epoch [118/160] |	nca: 4.0523029789328575, flat: 3.5101069509983063, pod: 26.412232726812363, loss: 33.97464257478714 
Train [6/10] | Epoch [119/160] |	nca: 3.739193882793188, flat: 3.482137233018875, pod: 26.2128826379776, loss: 33.43421387672424 
Train [6/10] | Epoch [120/160] |	nca: 3.578903157263994, flat: 3.403596229851246, pod: 25.930524975061417, loss: 32.91302448511124 
Train [6/10] | Epoch [121/160] |	nca: 3.5018316246569157, flat: 3.3513529747724533, pod: 25.506200820207596, loss: 32.35938549041748 
Train [6/10] | Epoch [122/160] |	nca: 3.794478576630354, flat: 3.4376648291945457, pod: 26.542956620454788, loss: 33.775100231170654 
Train [6/10] | Epoch [123/160] |	nca: 3.481754168868065, flat: 3.3249318972229958, pod: 25.122990369796753, loss: 31.929676294326782 
Train [6/10] | Epoch [124/160] |	nca: 3.62772623449564, flat: 3.3146895691752434, pod: 25.134945541620255, loss: 32.07736140489578 
Train [6/10] | Epoch [125/160] |	nca: 3.5059018172323704, flat: 3.3375686332583427, pod: 25.654449969530106, loss: 32.4979202747345 
Train [6/10] | Epoch [126/160] |	nca: 3.2987074814736843, flat: 3.2484970279037952, pod: 24.753080397844315, loss: 31.300284922122955 
Train [6/10] | Epoch [127/160] |	nca: 3.4469641633331776, flat: 3.226119615137577, pod: 24.88480696082115, loss: 31.55789053440094 
Train [6/10] | Epoch [128/160] |	nca: 3.321389924734831, flat: 3.189418762922287, pod: 24.160794019699097, loss: 30.671602606773376 
Train [6/10] | Epoch [129/160] |	nca: 3.4960268139839172, flat: 3.2490639984607697, pod: 24.092609494924545, loss: 30.837700366973877 
Train [6/10] | Epoch [130/160] |	nca: 3.482927840203047, flat: 3.215261362493038, pod: 24.389816015958786, loss: 31.088005363941193 
Train [6/10] | Epoch [131/160] |	nca: 3.40115075558424, flat: 3.1526019982993603, pod: 23.53204071521759, loss: 30.085793554782867 
Train [6/10] | Epoch [132/160] |	nca: 3.1351571269333363, flat: 3.203301824629307, pod: 24.272609412670135, loss: 30.611068308353424 
Train [6/10] | Epoch [133/160] |	nca: 3.118223875761032, flat: 3.076952740550041, pod: 23.196733117103577, loss: 29.391909897327423 
Train [6/10] | Epoch [134/160] |	nca: 3.2920259349048138, flat: 3.1469903625547886, pod: 23.84608817100525, loss: 30.285104393959045 
Train [6/10] | Epoch [135/160] |	nca: 3.154690057039261, flat: 3.087688721716404, pod: 22.874228209257126, loss: 29.116606950759888 
Train [6/10] | Epoch [136/160] |	nca: 3.138029232621193, flat: 3.118738252669573, pod: 23.453146874904633, loss: 29.70991426706314 
Train [6/10] | Epoch [137/160] |	nca: 3.0876916274428368, flat: 3.092996645718813, pod: 23.275727927684784, loss: 29.456415951251984 
Train [6/10] | Epoch [138/160] |	nca: 3.0651955120265484, flat: 3.014359001070261, pod: 22.204739212989807, loss: 28.284293830394745 
Train [6/10] | Epoch [139/160] |	nca: 3.201104611158371, flat: 3.0605147294700146, pod: 22.964862197637558, loss: 29.22648137807846 
Train [6/10] | Epoch [140/160] |	nca: 3.0234017074108124, flat: 3.066633801907301, pod: 22.644042998552322, loss: 28.734078586101532 
Train [6/10] | Epoch [141/160] |	nca: 3.214782878756523, flat: 3.0493854954838753, pod: 22.601476222276688, loss: 28.86564463376999 
Train [6/10] | Epoch [142/160] |	nca: 3.199091676622629, flat: 3.058238457888365, pod: 22.66285800933838, loss: 28.920188426971436 
Train [6/10] | Epoch [143/160] |	nca: 3.080024264752865, flat: 3.003472253680229, pod: 22.053243845701218, loss: 28.136740148067474 
Train [6/10] | Epoch [144/160] |	nca: 3.043869849294424, flat: 3.0182254761457443, pod: 22.333713829517365, loss: 28.395809054374695 
Train [6/10] | Epoch [145/160] |	nca: 2.962398000061512, flat: 2.988955393433571, pod: 21.813118040561676, loss: 27.764471471309662 
Train [6/10] | Epoch [146/160] |	nca: 2.962255995720625, flat: 2.970215395092964, pod: 22.140045046806335, loss: 28.072516351938248 
Train [6/10] | Epoch [147/160] |	nca: 3.0191229954361916, flat: 2.98233912140131, pod: 22.13780841231346, loss: 28.13927036523819 
Train [6/10] | Epoch [148/160] |	nca: 2.9052527993917465, flat: 2.9389223903417587, pod: 21.67642816901207, loss: 27.520603269338608 
Train [6/10] | Epoch [149/160] |	nca: 2.986084897071123, flat: 2.9264724999666214, pod: 21.56677007675171, loss: 27.47932732105255 
Train [6/10] | Epoch [150/160] |	nca: 2.969922587275505, flat: 2.9651686660945415, pod: 22.086054176092148, loss: 28.021145313978195 
Train [6/10] | Epoch [151/160] |	nca: 3.012545369565487, flat: 2.933020293712616, pod: 21.68472546339035, loss: 27.630291044712067 
Train [6/10] | Epoch [152/160] |	nca: 2.9537489525973797, flat: 2.9515821523964405, pod: 21.45630782842636, loss: 27.361638963222504 
Train [6/10] | Epoch [153/160] |	nca: 2.8960789516568184, flat: 2.9044793359935284, pod: 21.200087189674377, loss: 27.000645458698273 
Train [6/10] | Epoch [154/160] |	nca: 2.96628437936306, flat: 2.944762110710144, pod: 21.491911619901657, loss: 27.402958154678345 
Train [6/10] | Epoch [155/160] |	nca: 2.9610570147633553, flat: 2.9423633962869644, pod: 21.52709636092186, loss: 27.430516719818115 
Train [6/10] | Epoch [156/160] |	nca: 3.043416555970907, flat: 2.931247338652611, pod: 21.18676871061325, loss: 27.161432445049286 
Train [6/10] | Epoch [157/160] |	nca: 2.8796696960926056, flat: 2.9313057996332645, pod: 21.430220127105713, loss: 27.241195857524872 
Train [6/10] | Epoch [158/160] |	nca: 2.8761134147644043, flat: 2.8961065001785755, pod: 21.237998574972153, loss: 27.010218411684036 
Train [6/10] | Epoch [159/160] |	nca: 2.8341530822217464, flat: 2.897672086954117, pod: 20.96441099047661, loss: 26.696236193180084 
Train [6/10] | Epoch [160/160] |	nca: 2.9696679152548313, flat: 2.9264495708048344, pod: 21.157766193151474, loss: 27.053883641958237 
Fine-tuning
Building & updating memory.
Train [6/10] | Epoch [161/180] |	nca: 1.8909209296107292, flat: 0.7548419907689095, pod: 7.885643661022186, loss: 10.53140664100647 
Train [6/10] | Epoch [162/180] |	nca: 1.0587801560759544, flat: 0.7686195820569992, pod: 7.897117257118225, loss: 9.724516987800598 
Train [6/10] | Epoch [163/180] |	nca: 0.909393735229969, flat: 0.7535528913140297, pod: 7.910381972789764, loss: 9.573328614234924 
Train [6/10] | Epoch [164/180] |	nca: 0.8815869316458702, flat: 0.7632891684770584, pod: 7.8340758085250854, loss: 9.478951930999756 
Train [6/10] | Epoch [165/180] |	nca: 0.7883434072136879, flat: 0.7558553516864777, pod: 7.786904156208038, loss: 9.331102788448334 
Train [6/10] | Epoch [166/180] |	nca: 0.7557355985045433, flat: 0.7783345803618431, pod: 7.938046932220459, loss: 9.472117066383362 
Train [6/10] | Epoch [167/180] |	nca: 0.7357362806797028, flat: 0.7751912176609039, pod: 8.017882168293, loss: 9.52880984544754 
Train [6/10] | Epoch [168/180] |	nca: 0.7644374296069145, flat: 0.7799334861338139, pod: 8.045047640800476, loss: 9.589418530464172 
Train [6/10] | Epoch [169/180] |	nca: 0.864740289747715, flat: 0.7964599803090096, pod: 8.12827479839325, loss: 9.789474904537201 
Train [6/10] | Epoch [170/180] |	nca: 0.6730904132127762, flat: 0.7481403201818466, pod: 7.842397391796112, loss: 9.263628125190735 
Train [6/10] | Epoch [171/180] |	nca: 0.7078015953302383, flat: 0.7700703218579292, pod: 7.840467572212219, loss: 9.318339586257935 
Train [6/10] | Epoch [172/180] |	nca: 0.7736536711454391, flat: 0.7795492336153984, pod: 7.932618260383606, loss: 9.48582124710083 
Train [6/10] | Epoch [173/180] |	nca: 0.7170145511627197, flat: 0.7804759182035923, pod: 8.011780381202698, loss: 9.509270966053009 
Train [6/10] | Epoch [174/180] |	nca: 0.7180085331201553, flat: 0.7587862499058247, pod: 7.865191459655762, loss: 9.341986358165741 
Train [6/10] | Epoch [175/180] |	nca: 0.6857464760541916, flat: 0.8000374138355255, pod: 8.155770540237427, loss: 9.641554415225983 
Train [6/10] | Epoch [176/180] |	nca: 0.6308549791574478, flat: 0.7503313794732094, pod: 7.752617835998535, loss: 9.133804261684418 
Train [6/10] | Epoch [177/180] |	nca: 0.6795085892081261, flat: 0.7705240920186043, pod: 7.967508852481842, loss: 9.41754138469696 
Train [6/10] | Epoch [178/180] |	nca: 0.6383371166884899, flat: 0.7693781964480877, pod: 7.9220563769340515, loss: 9.329771757125854 
Train [6/10] | Epoch [179/180] |	nca: 0.642202116549015, flat: 0.7929751053452492, pod: 8.101708054542542, loss: 9.53688532114029 
Train [6/10] | Epoch [180/180] |	nca: 0.6611092165112495, flat: 0.7707873955368996, pod: 7.90798145532608, loss: 9.33987808227539 
after task
Building & updating memory.
after task
Eval on 0->60.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.6468333333333333.
Current acc: {'total': 0.505, '00-09': 0.603, '10-19': 0.38, '20-29': 0.308, '30-39': 0.334, '40-49': 0.591, '50-59': 0.812}.
Avg inc acc top5: 0.8906666666666667.
Current acc top5: {'total': 0.801}.
Forgetting: 0.12357142857142857.
Cord metric: 0.60.
Old accuracy: 0.44, mean: 0.55.
New accuracy: 0.81, mean: 0.76.
================Task 6 Start!================
Testing on False unseen tasks (max class = 70).
Set memory of size: 1200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 6 Training!================
The training samples number: 6200
Train on 60->70.
train task
nb 6200.
Train [7/10] | Epoch [1/160] |	nca: 95.78076672554016, flat: 10.080134931951761, pod: 75.0422437787056, loss: 180.90314531326294 
Train [7/10] | Epoch [2/160] |	nca: 68.43545317649841, flat: 7.991179376840591, pod: 67.40655779838562, loss: 143.83319091796875 
Train [7/10] | Epoch [3/160] |	nca: 60.882867991924286, flat: 7.32932436466217, pod: 61.812156319618225, loss: 130.02434945106506 
Train [7/10] | Epoch [4/160] |	nca: 55.879483699798584, flat: 7.133214056491852, pod: 59.16835582256317, loss: 122.18105340003967 
Train [7/10] | Epoch [5/160] |	nca: 50.63571858406067, flat: 6.900641694664955, pod: 56.91592347621918, loss: 114.45228505134583 
Train [7/10] | Epoch [6/160] |	nca: 48.513766050338745, flat: 6.8595238626003265, pod: 55.688761472702026, loss: 111.06205105781555 
Train [7/10] | Epoch [7/160] |	nca: 46.458082497119904, flat: 6.755674168467522, pod: 54.89282488822937, loss: 108.10658156871796 
Train [7/10] | Epoch [8/160] |	nca: 44.88444375991821, flat: 6.792129784822464, pod: 55.400543332099915, loss: 107.07711625099182 
Train [7/10] | Epoch [9/160] |	nca: 42.6826388835907, flat: 6.9055981040000916, pod: 55.30832135677338, loss: 104.89655876159668 
Train [7/10] | Epoch [10/160] |	nca: 43.05356341600418, flat: 7.248056381940842, pod: 55.950926661491394, loss: 106.25254607200623 
Train [7/10] | Epoch [11/160] |	nca: 39.67547047138214, flat: 6.7675697803497314, pod: 52.11553168296814, loss: 98.55857241153717 
Train [7/10] | Epoch [12/160] |	nca: 40.073480010032654, flat: 6.987634986639023, pod: 53.42736303806305, loss: 100.48847699165344 
Train [7/10] | Epoch [13/160] |	nca: 38.09542864561081, flat: 7.052826076745987, pod: 53.56219434738159, loss: 98.71044945716858 
Train [7/10] | Epoch [14/160] |	nca: 37.95536094903946, flat: 6.939269885420799, pod: 52.83067810535431, loss: 97.72530949115753 
Train [7/10] | Epoch [15/160] |	nca: 37.689919114112854, flat: 6.9924981743097305, pod: 53.54670262336731, loss: 98.22911930084229 
Train [7/10] | Epoch [16/160] |	nca: 35.37905007600784, flat: 6.8851339519023895, pod: 53.112743854522705, loss: 95.37692737579346 
Train [7/10] | Epoch [17/160] |	nca: 35.29860383272171, flat: 7.078523680567741, pod: 53.58201307058334, loss: 95.9591406583786 
Train [7/10] | Epoch [18/160] |	nca: 33.21958649158478, flat: 6.849459066987038, pod: 52.29523414373398, loss: 92.36427927017212 
Train [7/10] | Epoch [19/160] |	nca: 33.92970460653305, flat: 6.858475401997566, pod: 52.2417973279953, loss: 93.02997696399689 
Train [7/10] | Epoch [20/160] |	nca: 32.069064259529114, flat: 6.877564907073975, pod: 52.55505120754242, loss: 91.50168001651764 
Train [7/10] | Epoch [21/160] |	nca: 33.07833734154701, flat: 7.008792452514172, pod: 52.54263234138489, loss: 92.62976229190826 
Train [7/10] | Epoch [22/160] |	nca: 31.260052859783173, flat: 6.875171259045601, pod: 51.86387491226196, loss: 89.99909913539886 
Train [7/10] | Epoch [23/160] |	nca: 31.115303248167038, flat: 7.038306072354317, pod: 52.464633107185364, loss: 90.61824238300323 
Train [7/10] | Epoch [24/160] |	nca: 31.331643968820572, flat: 7.080646753311157, pod: 52.67463558912277, loss: 91.08692586421967 
Train [7/10] | Epoch [25/160] |	nca: 29.842219710350037, flat: 7.068691581487656, pod: 52.27231973409653, loss: 89.18323111534119 
Train [7/10] | Epoch [26/160] |	nca: 29.02993404865265, flat: 6.9770359098911285, pod: 51.12714660167694, loss: 87.13411605358124 
Train [7/10] | Epoch [27/160] |	nca: 29.046492964029312, flat: 6.962396547198296, pod: 51.51987582445145, loss: 87.52876508235931 
Train [7/10] | Epoch [28/160] |	nca: 28.447948813438416, flat: 7.14437261223793, pod: 52.4644433259964, loss: 88.05676436424255 
Train [7/10] | Epoch [29/160] |	nca: 27.757253885269165, flat: 6.86486154794693, pod: 50.99301278591156, loss: 85.6151282787323 
Train [7/10] | Epoch [30/160] |	nca: 27.6016403734684, flat: 6.918156787753105, pod: 50.40374577045441, loss: 84.92354309558868 
Train [7/10] | Epoch [31/160] |	nca: 28.777205914258957, flat: 7.210046201944351, pod: 51.84329068660736, loss: 87.83054280281067 
Train [7/10] | Epoch [32/160] |	nca: 27.224557787179947, flat: 6.946251466870308, pod: 51.677097141742706, loss: 85.84790658950806 
Train [7/10] | Epoch [33/160] |	nca: 26.50226992368698, flat: 7.089077576994896, pod: 51.74180269241333, loss: 85.33314979076385 
Train [7/10] | Epoch [34/160] |	nca: 26.84232449531555, flat: 7.070919513702393, pod: 52.1098809838295, loss: 86.02312552928925 
Train [7/10] | Epoch [35/160] |	nca: 24.18810585141182, flat: 6.966698944568634, pod: 50.31435614824295, loss: 81.46916091442108 
Train [7/10] | Epoch [36/160] |	nca: 26.752857953310013, flat: 7.022186733782291, pod: 50.79929846525192, loss: 84.574343085289 
Train [7/10] | Epoch [37/160] |	nca: 24.926309317350388, flat: 7.041675001382828, pod: 50.97618740797043, loss: 82.94417178630829 
Train [7/10] | Epoch [38/160] |	nca: 24.812073588371277, flat: 7.0749755799770355, pod: 51.89654803276062, loss: 83.78359758853912 
Train [7/10] | Epoch [39/160] |	nca: 24.11685535311699, flat: 6.692402362823486, pod: 49.00603771209717, loss: 79.81529557704926 
Train [7/10] | Epoch [40/160] |	nca: 22.9444423019886, flat: 6.971119478344917, pod: 50.11258375644684, loss: 80.02814543247223 
Train [7/10] | Epoch [41/160] |	nca: 24.37707805633545, flat: 6.975888207554817, pod: 51.29579538106918, loss: 82.64876127243042 
Train [7/10] | Epoch [42/160] |	nca: 22.010444164276123, flat: 6.951680019497871, pod: 50.798404574394226, loss: 79.76052844524384 
Train [7/10] | Epoch [43/160] |	nca: 22.04296115040779, flat: 6.998606249690056, pod: 49.9346849322319, loss: 78.97625255584717 
Train [7/10] | Epoch [44/160] |	nca: 22.170649528503418, flat: 6.90921351313591, pod: 49.441689252853394, loss: 78.52155184745789 
Train [7/10] | Epoch [45/160] |	nca: 23.012677162885666, flat: 6.983627960085869, pod: 50.47879076004028, loss: 80.47509562969208 
Train [7/10] | Epoch [46/160] |	nca: 22.527661681175232, flat: 6.9685138911008835, pod: 50.39585506916046, loss: 79.89203011989594 
Train [7/10] | Epoch [47/160] |	nca: 22.216472029685974, flat: 6.914971485733986, pod: 50.16891407966614, loss: 79.30035734176636 
Train [7/10] | Epoch [48/160] |	nca: 22.004636824131012, flat: 6.995890200138092, pod: 49.81582963466644, loss: 78.81635689735413 
Train [7/10] | Epoch [49/160] |	nca: 22.015613049268723, flat: 6.80962160974741, pod: 50.33250427246094, loss: 79.15773844718933 
Train [7/10] | Epoch [50/160] |	nca: 20.706323325634003, flat: 6.7728157341480255, pod: 49.37291777133942, loss: 76.85205686092377 
Train [7/10] | Epoch [51/160] |	nca: 19.718154668807983, flat: 6.676105335354805, pod: 47.8508215546608, loss: 74.24508142471313 
Train [7/10] | Epoch [52/160] |	nca: 20.909490257501602, flat: 6.783936619758606, pod: 48.76624482870102, loss: 76.45967185497284 
Train [7/10] | Epoch [53/160] |	nca: 20.803617238998413, flat: 6.798744969069958, pod: 49.19564402103424, loss: 76.79800593852997 
Train [7/10] | Epoch [54/160] |	nca: 19.824673682451248, flat: 6.807022333145142, pod: 47.93240064382553, loss: 74.5640971660614 
Train [7/10] | Epoch [55/160] |	nca: 19.274837255477905, flat: 6.687164664268494, pod: 47.297591745853424, loss: 73.25959384441376 
Train [7/10] | Epoch [56/160] |	nca: 18.394628286361694, flat: 6.720322169363499, pod: 47.40217697620392, loss: 72.51712703704834 
Train [7/10] | Epoch [57/160] |	nca: 18.721261382102966, flat: 6.65508546680212, pod: 47.50459188222885, loss: 72.88093912601471 
Train [7/10] | Epoch [58/160] |	nca: 18.57782392203808, flat: 6.4334025382995605, pod: 45.97396594285965, loss: 70.98519229888916 
Train [7/10] | Epoch [59/160] |	nca: 18.255128860473633, flat: 6.454727485775948, pod: 47.18863666057587, loss: 71.89849293231964 
Train [7/10] | Epoch [60/160] |	nca: 19.191585779190063, flat: 6.652494803071022, pod: 47.241265296936035, loss: 73.0853453874588 
Train [7/10] | Epoch [61/160] |	nca: 17.593864858150482, flat: 6.389131546020508, pod: 46.30358159542084, loss: 70.28657865524292 
Train [7/10] | Epoch [62/160] |	nca: 17.296691834926605, flat: 6.474392384290695, pod: 46.21336501836777, loss: 69.98444926738739 
Train [7/10] | Epoch [63/160] |	nca: 15.322035908699036, flat: 6.227794259786606, pod: 44.505897760391235, loss: 66.05572819709778 
Train [7/10] | Epoch [64/160] |	nca: 15.63213025033474, flat: 6.308929450809956, pod: 45.37487405538559, loss: 67.3159339427948 
Train [7/10] | Epoch [65/160] |	nca: 17.040762901306152, flat: 6.227339006960392, pod: 44.69108760356903, loss: 67.9591896533966 
Train [7/10] | Epoch [66/160] |	nca: 17.314348250627518, flat: 6.654992058873177, pod: 46.44752675294876, loss: 70.41686713695526 
Train [7/10] | Epoch [67/160] |	nca: 17.61460116505623, flat: 6.452762991189957, pod: 45.670620143413544, loss: 69.73798418045044 
Train [7/10] | Epoch [68/160] |	nca: 16.309333950281143, flat: 6.4241088181734085, pod: 46.05603963136673, loss: 68.78948223590851 
Train [7/10] | Epoch [69/160] |	nca: 15.596019193530083, flat: 6.225967325270176, pod: 44.497302770614624, loss: 66.31928932666779 
Train [7/10] | Epoch [70/160] |	nca: 16.367690101265907, flat: 6.178988441824913, pod: 44.02256923913956, loss: 66.56924796104431 
Train [7/10] | Epoch [71/160] |	nca: 16.834079816937447, flat: 6.449703216552734, pod: 45.630503714084625, loss: 68.91428709030151 
Train [7/10] | Epoch [72/160] |	nca: 14.525931283831596, flat: 6.087540954351425, pod: 43.08040904998779, loss: 63.69388151168823 
Train [7/10] | Epoch [73/160] |	nca: 14.722175389528275, flat: 6.248073935508728, pod: 44.186956107616425, loss: 65.15720510482788 
Train [7/10] | Epoch [74/160] |	nca: 13.468978509306908, flat: 6.218620486557484, pod: 42.82546079158783, loss: 62.51305937767029 
Train [7/10] | Epoch [75/160] |	nca: 13.676934078335762, flat: 5.982957147061825, pod: 42.74694466590881, loss: 62.40683603286743 
Train [7/10] | Epoch [76/160] |	nca: 14.236729249358177, flat: 6.058903336524963, pod: 42.74400943517685, loss: 63.039641976356506 
Train [7/10] | Epoch [77/160] |	nca: 13.780979260802269, flat: 6.201660104095936, pod: 43.5345761179924, loss: 63.517215609550476 
Train [7/10] | Epoch [78/160] |	nca: 13.69476069509983, flat: 5.958156928420067, pod: 41.77540338039398, loss: 61.4283207654953 
Train [7/10] | Epoch [79/160] |	nca: 13.517265856266022, flat: 5.97976403683424, pod: 42.071628510951996, loss: 61.56865870952606 
Train [7/10] | Epoch [80/160] |	nca: 13.788395449519157, flat: 6.038252994418144, pod: 42.35722029209137, loss: 62.18386900424957 
Train [7/10] | Epoch [81/160] |	nca: 12.766446307301521, flat: 5.965456202626228, pod: 41.857781767845154, loss: 60.58968472480774 
Train [7/10] | Epoch [82/160] |	nca: 11.642079517245293, flat: 5.787508524954319, pod: 41.691559970378876, loss: 59.121147871017456 
Train [7/10] | Epoch [83/160] |	nca: 11.198164895176888, flat: 5.551783204078674, pod: 39.73897933959961, loss: 56.488927245140076 
Train [7/10] | Epoch [84/160] |	nca: 11.530730038881302, flat: 5.644441165030003, pod: 39.0963973402977, loss: 56.271568298339844 
Train [7/10] | Epoch [85/160] |	nca: 12.07886290550232, flat: 5.724582381546497, pod: 39.97281062602997, loss: 57.77625596523285 
Train [7/10] | Epoch [86/160] |	nca: 10.293390534818172, flat: 5.531331814825535, pod: 39.544905960559845, loss: 55.36962831020355 
Train [7/10] | Epoch [87/160] |	nca: 10.488860666751862, flat: 5.586435168981552, pod: 39.41519242525101, loss: 55.49048900604248 
Train [7/10] | Epoch [88/160] |	nca: 10.24917882680893, flat: 5.480162866413593, pod: 38.58679312467575, loss: 54.31613481044769 
Train [7/10] | Epoch [89/160] |	nca: 10.866313695907593, flat: 5.493445724248886, pod: 38.610495805740356, loss: 54.97025549411774 
Train [7/10] | Epoch [90/160] |	nca: 10.608414977788925, flat: 5.471979334950447, pod: 38.126071989536285, loss: 54.20646619796753 
Train [7/10] | Epoch [91/160] |	nca: 10.519635140895844, flat: 5.405414596199989, pod: 38.59162765741348, loss: 54.51667761802673 
Train [7/10] | Epoch [92/160] |	nca: 10.164795383810997, flat: 5.309583246707916, pod: 38.10801964998245, loss: 53.58239793777466 
Train [7/10] | Epoch [93/160] |	nca: 10.162337601184845, flat: 5.304865472018719, pod: 37.203974425792694, loss: 52.67117738723755 
Train [7/10] | Epoch [94/160] |	nca: 9.44278298318386, flat: 5.251936547458172, pod: 37.21461361646652, loss: 51.90933358669281 
Train [7/10] | Epoch [95/160] |	nca: 9.519921131432056, flat: 5.228927880525589, pod: 36.949661552906036, loss: 51.69851052761078 
Train [7/10] | Epoch [96/160] |	nca: 9.622373096644878, flat: 5.237761177122593, pod: 36.55360436439514, loss: 51.413739025592804 
Train [7/10] | Epoch [97/160] |	nca: 8.776518851518631, flat: 5.15362074226141, pod: 36.353940546512604, loss: 50.284080386161804 
Train [7/10] | Epoch [98/160] |	nca: 8.758624322712421, flat: 5.10007631778717, pod: 36.075582563877106, loss: 49.93428325653076 
Train [7/10] | Epoch [99/160] |	nca: 9.36970167607069, flat: 5.0862438306212425, pod: 35.51560401916504, loss: 49.97154897451401 
Train [7/10] | Epoch [100/160] |	nca: 8.765075579285622, flat: 5.106031507253647, pod: 35.75172698497772, loss: 49.62283390760422 
Train [7/10] | Epoch [101/160] |	nca: 8.49725891649723, flat: 4.992668621242046, pod: 35.122416496276855, loss: 48.61234438419342 
Train [7/10] | Epoch [102/160] |	nca: 7.931763246655464, flat: 4.841514773666859, pod: 34.201735854148865, loss: 46.975013732910156 
Train [7/10] | Epoch [103/160] |	nca: 7.3411578088998795, flat: 4.850507445633411, pod: 34.322922110557556, loss: 46.514587342739105 
Train [7/10] | Epoch [104/160] |	nca: 7.057502508163452, flat: 4.721104487776756, pod: 33.24201285839081, loss: 45.02061969041824 
Train [7/10] | Epoch [105/160] |	nca: 6.9940472692251205, flat: 4.7759855017066, pod: 33.41522663831711, loss: 45.18525940179825 
Train [7/10] | Epoch [106/160] |	nca: 7.306140795350075, flat: 4.691575393080711, pod: 33.148496091365814, loss: 45.14621251821518 
Train [7/10] | Epoch [107/160] |	nca: 7.1207714304327965, flat: 4.722685985267162, pod: 32.80123960971832, loss: 44.6446972489357 
Train [7/10] | Epoch [108/160] |	nca: 7.058957532048225, flat: 4.637564927339554, pod: 32.790468990802765, loss: 44.486991465091705 
Train [7/10] | Epoch [109/160] |	nca: 7.2403686717152596, flat: 4.649854376912117, pod: 33.44105786085129, loss: 45.33128064870834 
Train [7/10] | Epoch [110/160] |	nca: 6.7304849699139595, flat: 4.584628276526928, pod: 31.887441098690033, loss: 43.202554285526276 
Train [7/10] | Epoch [111/160] |	nca: 6.370471626520157, flat: 4.470467627048492, pod: 32.03777277469635, loss: 42.87871217727661 
Train [7/10] | Epoch [112/160] |	nca: 6.68914595246315, flat: 4.5084691643714905, pod: 32.0875580906868, loss: 43.285173177719116 
Train [7/10] | Epoch [113/160] |	nca: 6.1434933841228485, flat: 4.3657915741205215, pod: 30.884525179862976, loss: 41.39381003379822 
Train [7/10] | Epoch [114/160] |	nca: 5.955235667526722, flat: 4.350496731698513, pod: 30.212341487407684, loss: 40.51807403564453 
Train [7/10] | Epoch [115/160] |	nca: 5.640340842306614, flat: 4.270467638969421, pod: 29.879586696624756, loss: 39.79039531946182 
Train [7/10] | Epoch [116/160] |	nca: 5.569185145199299, flat: 4.265350796282291, pod: 30.767431259155273, loss: 40.601967215538025 
Train [7/10] | Epoch [117/160] |	nca: 5.344404362142086, flat: 4.255218997597694, pod: 29.793723464012146, loss: 39.39334684610367 
Train [7/10] | Epoch [118/160] |	nca: 5.645366258919239, flat: 4.178165175020695, pod: 29.980321943759918, loss: 39.803853273391724 
Train [7/10] | Epoch [119/160] |	nca: 5.567628398537636, flat: 4.210179276764393, pod: 29.144706904888153, loss: 38.922514617443085 
Train [7/10] | Epoch [120/160] |	nca: 5.252884663641453, flat: 4.188187576830387, pod: 29.567433536052704, loss: 39.00850588083267 
Train [7/10] | Epoch [121/160] |	nca: 5.196049742400646, flat: 4.0980569794774055, pod: 28.592892825603485, loss: 37.88699960708618 
Train [7/10] | Epoch [122/160] |	nca: 5.5049800500273705, flat: 4.144039511680603, pod: 29.51997661590576, loss: 39.16899609565735 
Train [7/10] | Epoch [123/160] |	nca: 5.056032821536064, flat: 4.149386547505856, pod: 29.144572913646698, loss: 38.34999215602875 
Train [7/10] | Epoch [124/160] |	nca: 5.223200283944607, flat: 4.069573111832142, pod: 28.951397836208344, loss: 38.244171142578125 
Train [7/10] | Epoch [125/160] |	nca: 4.996303521096706, flat: 4.055210940539837, pod: 28.784043788909912, loss: 37.83555817604065 
Train [7/10] | Epoch [126/160] |	nca: 5.073264606297016, flat: 4.008919030427933, pod: 28.49972540140152, loss: 37.581909120082855 
Train [7/10] | Epoch [127/160] |	nca: 5.097734019160271, flat: 4.020645931363106, pod: 28.51665484905243, loss: 37.63503473997116 
Train [7/10] | Epoch [128/160] |	nca: 4.9705884382128716, flat: 3.92684618383646, pod: 28.037145882844925, loss: 36.93458038568497 
Train [7/10] | Epoch [129/160] |	nca: 4.910381734371185, flat: 3.96891513466835, pod: 27.923790454864502, loss: 36.803087174892426 
Train [7/10] | Epoch [130/160] |	nca: 4.760051898658276, flat: 3.9153377413749695, pod: 27.652423560619354, loss: 36.327812910079956 
Train [7/10] | Epoch [131/160] |	nca: 4.751674450933933, flat: 3.869092807173729, pod: 26.746321946382523, loss: 35.3670893907547 
Train [7/10] | Epoch [132/160] |	nca: 4.623187649995089, flat: 3.8745676279067993, pod: 26.45972028374672, loss: 34.9574756026268 
Train [7/10] | Epoch [133/160] |	nca: 4.674933947622776, flat: 3.8590727373957634, pod: 26.833874255418777, loss: 35.36788088083267 
Train [7/10] | Epoch [134/160] |	nca: 4.873804934322834, flat: 3.7930740639567375, pod: 26.527605444192886, loss: 35.19448435306549 
Train [7/10] | Epoch [135/160] |	nca: 4.455457512289286, flat: 3.825268305838108, pod: 26.822283774614334, loss: 35.10300958156586 
Train [7/10] | Epoch [136/160] |	nca: 4.580520648509264, flat: 3.804351791739464, pod: 26.377406924962997, loss: 34.76227909326553 
Train [7/10] | Epoch [137/160] |	nca: 4.2352840304374695, flat: 3.7991034239530563, pod: 26.277469992637634, loss: 34.31185728311539 
Train [7/10] | Epoch [138/160] |	nca: 4.28978269174695, flat: 3.7402595430612564, pod: 25.88148584961891, loss: 33.911528050899506 
Train [7/10] | Epoch [139/160] |	nca: 4.170668330043554, flat: 3.7295394390821457, pod: 25.453044682741165, loss: 33.3532520532608 
Train [7/10] | Epoch [140/160] |	nca: 4.276308622211218, flat: 3.7693348973989487, pod: 26.093813449144363, loss: 34.13945668935776 
Train [7/10] | Epoch [141/160] |	nca: 4.334411457180977, flat: 3.7340931817889214, pod: 25.165733516216278, loss: 33.23423832654953 
Train [7/10] | Epoch [142/160] |	nca: 4.204075932502747, flat: 3.6657031923532486, pod: 25.433925569057465, loss: 33.3037046790123 
Train [7/10] | Epoch [143/160] |	nca: 4.211720138788223, flat: 3.675889551639557, pod: 25.406784802675247, loss: 33.29439431428909 
Train [7/10] | Epoch [144/160] |	nca: 4.049172509461641, flat: 3.700059562921524, pod: 25.22597888112068, loss: 32.975210785865784 
Train [7/10] | Epoch [145/160] |	nca: 4.274114556610584, flat: 3.673648089170456, pod: 25.445550084114075, loss: 33.39331245422363 
Train [7/10] | Epoch [146/160] |	nca: 4.277362518012524, flat: 3.6417821422219276, pod: 24.81300923228264, loss: 32.7321537733078 
Train [7/10] | Epoch [147/160] |	nca: 4.1459319069981575, flat: 3.6814510747790337, pod: 24.944387406110764, loss: 32.77177029848099 
Train [7/10] | Epoch [148/160] |	nca: 4.1107034757733345, flat: 3.676172837615013, pod: 24.85551282763481, loss: 32.64238911867142 
Train [7/10] | Epoch [149/160] |	nca: 4.1219762079417706, flat: 3.655752308666706, pod: 25.225137621164322, loss: 33.002866327762604 
Train [7/10] | Epoch [150/160] |	nca: 3.924777239561081, flat: 3.6006239727139473, pod: 24.490239799022675, loss: 32.01564121246338 
Train [7/10] | Epoch [151/160] |	nca: 3.9897963628172874, flat: 3.6190981566905975, pod: 24.3769850730896, loss: 31.98587954044342 
Train [7/10] | Epoch [152/160] |	nca: 3.9931987449526787, flat: 3.5954222828149796, pod: 24.13403758406639, loss: 31.722658395767212 
Train [7/10] | Epoch [153/160] |	nca: 4.130584929138422, flat: 3.6118042543530464, pod: 24.641623586416245, loss: 32.38401257991791 
Train [7/10] | Epoch [154/160] |	nca: 4.050460938364267, flat: 3.615946188569069, pod: 24.437089532613754, loss: 32.10349667072296 
Train [7/10] | Epoch [155/160] |	nca: 3.995188158005476, flat: 3.610087275505066, pod: 24.62548765540123, loss: 32.2307630777359 
Train [7/10] | Epoch [156/160] |	nca: 3.906315967440605, flat: 3.587678402662277, pod: 24.136483877897263, loss: 31.630478262901306 
Train [7/10] | Epoch [157/160] |	nca: 4.044462889432907, flat: 3.589633122086525, pod: 24.212727904319763, loss: 31.846823930740356 
Train [7/10] | Epoch [158/160] |	nca: 4.112839128822088, flat: 3.619894616305828, pod: 24.32097166776657, loss: 32.053705394268036 
Train [7/10] | Epoch [159/160] |	nca: 3.9899849332869053, flat: 3.6049612686038017, pod: 24.07831245660782, loss: 31.67325860261917 
Train [7/10] | Epoch [160/160] |	nca: 3.9226436726748943, flat: 3.5745880007743835, pod: 23.826414972543716, loss: 31.32364672422409 
Fine-tuning
Building & updating memory.
Train [7/10] | Epoch [161/180] |	nca: 2.301620975136757, flat: 0.8405331820249557, pod: 7.582745254039764, loss: 10.724899470806122 
Train [7/10] | Epoch [162/180] |	nca: 1.2761629521846771, flat: 0.8354538306593895, pod: 7.5870025753974915, loss: 9.698619365692139 
Train [7/10] | Epoch [163/180] |	nca: 1.1564622446894646, flat: 0.8435394540429115, pod: 7.631978332996368, loss: 9.631979942321777 
Train [7/10] | Epoch [164/180] |	nca: 1.1349661722779274, flat: 0.8501627668738365, pod: 7.6150805950164795, loss: 9.600209414958954 
Train [7/10] | Epoch [165/180] |	nca: 1.0212669372558594, flat: 0.8462435826659203, pod: 7.596216559410095, loss: 9.463727116584778 
Train [7/10] | Epoch [166/180] |	nca: 0.888101801276207, flat: 0.8379174098372459, pod: 7.578126430511475, loss: 9.304145753383636 
Train [7/10] | Epoch [167/180] |	nca: 0.9163112863898277, flat: 0.8232301324605942, pod: 7.447165131568909, loss: 9.18670654296875 
Train [7/10] | Epoch [168/180] |	nca: 0.8570929951965809, flat: 0.8578182756900787, pod: 7.683153748512268, loss: 9.398064970970154 
Train [7/10] | Epoch [169/180] |	nca: 0.9393484592437744, flat: 0.8287506699562073, pod: 7.582654356956482, loss: 9.350753545761108 
Train [7/10] | Epoch [170/180] |	nca: 0.8243719600141048, flat: 0.8382218331098557, pod: 7.548807621002197, loss: 9.211401462554932 
Train [7/10] | Epoch [171/180] |	nca: 0.8665541335940361, flat: 0.8389930613338947, pod: 7.574362874031067, loss: 9.279910027980804 
Train [7/10] | Epoch [172/180] |	nca: 0.8781458958983421, flat: 0.8303228989243507, pod: 7.505155026912689, loss: 9.213623821735382 
Train [7/10] | Epoch [173/180] |	nca: 0.8677051812410355, flat: 0.8391346633434296, pod: 7.535829842090607, loss: 9.242669701576233 
Train [7/10] | Epoch [174/180] |	nca: 0.8110772743821144, flat: 0.8307827860116959, pod: 7.600929856300354, loss: 9.24278974533081 
Train [7/10] | Epoch [175/180] |	nca: 0.7982668802142143, flat: 0.8373073115944862, pod: 7.683991491794586, loss: 9.31956571340561 
Train [7/10] | Epoch [176/180] |	nca: 0.7769141048192978, flat: 0.8433022499084473, pod: 7.594534873962402, loss: 9.214751243591309 
Train [7/10] | Epoch [177/180] |	nca: 0.7678894735872746, flat: 0.842681460082531, pod: 7.640629231929779, loss: 9.251200199127197 
Train [7/10] | Epoch [178/180] |	nca: 0.8392084874212742, flat: 0.8454528525471687, pod: 7.666509985923767, loss: 9.351171255111694 
Train [7/10] | Epoch [179/180] |	nca: 0.8136606812477112, flat: 0.8407957665622234, pod: 7.722519218921661, loss: 9.376975655555725 
Train [7/10] | Epoch [180/180] |	nca: 0.7962253801524639, flat: 0.8313605114817619, pod: 7.4787997007369995, loss: 9.106385588645935 
after task
Building & updating memory.
after task
Eval on 0->70.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.6208571428571429.
Current acc: {'total': 0.465, '00-09': 0.57, '10-19': 0.335, '20-29': 0.291, '30-39': 0.309, '40-49': 0.512, '50-59': 0.572, '60-69': 0.667}.
Avg inc acc top5: 0.8730000000000001.
Current acc top5: {'total': 0.767}.
Forgetting: 0.181125.
Cord metric: 0.57.
Old accuracy: 0.43, mean: 0.53.
New accuracy: 0.67, mean: 0.74.
================Task 7 Start!================
Testing on False unseen tasks (max class = 80).
Set memory of size: 1400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 7 Training!================
The training samples number: 6400
Train on 70->80.
train task
nb 6400.
Train [8/10] | Epoch [1/160] |	nca: 85.75242400169373, flat: 10.438133491203189, pod: 75.91480445861816, loss: 172.10536360740662 
Train [8/10] | Epoch [2/160] |	nca: 59.58098518848419, flat: 7.909670069813728, pod: 67.31666505336761, loss: 134.80732035636902 
Train [8/10] | Epoch [3/160] |	nca: 48.39233261346817, flat: 7.044827535748482, pod: 62.256571531295776, loss: 117.6937325000763 
Train [8/10] | Epoch [4/160] |	nca: 45.54748177528381, flat: 7.008778043091297, pod: 60.22779154777527, loss: 112.78405237197876 
Train [8/10] | Epoch [5/160] |	nca: 40.81041085720062, flat: 6.740036964416504, pod: 58.43834340572357, loss: 105.98879110813141 
Train [8/10] | Epoch [6/160] |	nca: 37.60008263587952, flat: 6.598138079047203, pod: 56.31545603275299, loss: 100.51367712020874 
Train [8/10] | Epoch [7/160] |	nca: 35.503243148326874, flat: 6.609416499733925, pod: 56.25641143321991, loss: 98.36907076835632 
Train [8/10] | Epoch [8/160] |	nca: 34.39100608229637, flat: 6.696339346468449, pod: 55.107409834861755, loss: 96.19475483894348 
Train [8/10] | Epoch [9/160] |	nca: 33.37179896235466, flat: 6.835253082215786, pod: 56.33436822891235, loss: 96.54142022132874 
Train [8/10] | Epoch [10/160] |	nca: 32.566566199064255, flat: 6.758134603500366, pod: 55.83488154411316, loss: 95.1595823764801 
Train [8/10] | Epoch [11/160] |	nca: 31.422058254480362, flat: 6.648560531437397, pod: 53.46485936641693, loss: 91.53547847270966 
Train [8/10] | Epoch [12/160] |	nca: 28.712612062692642, flat: 6.459063731133938, pod: 53.2855549454689, loss: 88.45723068714142 
Train [8/10] | Epoch [13/160] |	nca: 29.243670970201492, flat: 6.565234534442425, pod: 54.28146696090698, loss: 90.09037256240845 
Train [8/10] | Epoch [14/160] |	nca: 28.354372888803482, flat: 6.689415492117405, pod: 53.77165311574936, loss: 88.81544101238251 
Train [8/10] | Epoch [15/160] |	nca: 29.129948019981384, flat: 6.87258530408144, pod: 55.81213438510895, loss: 91.81466770172119 
Train [8/10] | Epoch [16/160] |	nca: 28.03369438648224, flat: 6.9548472464084625, pod: 55.754663825035095, loss: 90.7432050704956 
Train [8/10] | Epoch [17/160] |	nca: 27.271659016609192, flat: 6.782815098762512, pod: 54.0666885972023, loss: 88.12116277217865 
Train [8/10] | Epoch [18/160] |	nca: 25.669455468654633, flat: 6.4653123915195465, pod: 52.08429527282715, loss: 84.21906316280365 
Train [8/10] | Epoch [19/160] |	nca: 25.61878913640976, flat: 6.4980665892362595, pod: 52.57187443971634, loss: 84.68873012065887 
Train [8/10] | Epoch [20/160] |	nca: 24.534606009721756, flat: 6.600384451448917, pod: 52.360607624053955, loss: 83.49559795856476 
Train [8/10] | Epoch [21/160] |	nca: 25.67247435450554, flat: 6.588323198258877, pod: 53.09907650947571, loss: 85.35987401008606 
Train [8/10] | Epoch [22/160] |	nca: 23.982169091701508, flat: 6.709466405212879, pod: 53.23702281713486, loss: 83.9286584854126 
Train [8/10] | Epoch [23/160] |	nca: 23.138601809740067, flat: 6.488072730600834, pod: 51.40983474254608, loss: 81.03650951385498 
Train [8/10] | Epoch [24/160] |	nca: 23.003774642944336, flat: 6.65875831246376, pod: 51.49091309309006, loss: 81.15344572067261 
Train [8/10] | Epoch [25/160] |	nca: 23.715923577547073, flat: 6.645283192396164, pod: 52.05931681394577, loss: 82.42052376270294 
Train [8/10] | Epoch [26/160] |	nca: 21.683378785848618, flat: 6.4869629964232445, pod: 51.06958889961243, loss: 79.2399308681488 
Train [8/10] | Epoch [27/160] |	nca: 24.124739468097687, flat: 6.644718132913113, pod: 52.87755620479584, loss: 83.6470137834549 
Train [8/10] | Epoch [28/160] |	nca: 22.594579860568047, flat: 6.603761002421379, pod: 51.83869695663452, loss: 81.03703761100769 
Train [8/10] | Epoch [29/160] |	nca: 22.442984998226166, flat: 6.576383575797081, pod: 51.390237629413605, loss: 80.4096063375473 
Train [8/10] | Epoch [30/160] |	nca: 21.839286148548126, flat: 6.620500735938549, pod: 52.21707558631897, loss: 80.6768627166748 
Train [8/10] | Epoch [31/160] |	nca: 21.216412633657455, flat: 6.451020203530788, pod: 49.783915638923645, loss: 77.45134818553925 
Train [8/10] | Epoch [32/160] |	nca: 20.633289009332657, flat: 6.4953927770257, pod: 50.09888154268265, loss: 77.2275630235672 
Train [8/10] | Epoch [33/160] |	nca: 21.409483015537262, flat: 6.6838691756129265, pod: 52.180472016334534, loss: 80.2738242149353 
Train [8/10] | Epoch [34/160] |	nca: 21.528487861156464, flat: 6.638288140296936, pod: 51.5759602189064, loss: 79.7427362203598 
Train [8/10] | Epoch [35/160] |	nca: 19.395140573382378, flat: 6.463449761271477, pod: 50.79212313890457, loss: 76.65071380138397 
Train [8/10] | Epoch [36/160] |	nca: 19.555172979831696, flat: 6.3637634962797165, pod: 50.18026226758957, loss: 76.09919917583466 
Train [8/10] | Epoch [37/160] |	nca: 21.21831402182579, flat: 6.816306345164776, pod: 52.06052124500275, loss: 80.09514129161835 
Train [8/10] | Epoch [38/160] |	nca: 19.327754944562912, flat: 6.470245756208897, pod: 49.89945590496063, loss: 75.69745683670044 
Train [8/10] | Epoch [39/160] |	nca: 18.310215145349503, flat: 6.398956201970577, pod: 48.90476620197296, loss: 73.61393773555756 
Train [8/10] | Epoch [40/160] |	nca: 17.44361351430416, flat: 6.2401392087340355, pod: 48.22035974264145, loss: 71.90411245822906 
Train [8/10] | Epoch [41/160] |	nca: 18.107314884662628, flat: 6.368179731070995, pod: 48.649340093135834, loss: 73.12483513355255 
Train [8/10] | Epoch [42/160] |	nca: 18.625284790992737, flat: 6.544567242264748, pod: 49.88782024383545, loss: 75.05767214298248 
Train [8/10] | Epoch [43/160] |	nca: 16.84249198436737, flat: 6.179520733654499, pod: 48.402049005031586, loss: 71.42406129837036 
Train [8/10] | Epoch [44/160] |	nca: 17.940906509757042, flat: 6.413425989449024, pod: 48.21254914999008, loss: 72.56688165664673 
Train [8/10] | Epoch [45/160] |	nca: 18.77674935758114, flat: 6.485292658209801, pod: 50.111292243003845, loss: 75.37333393096924 
Train [8/10] | Epoch [46/160] |	nca: 18.37735489010811, flat: 6.471775613725185, pod: 50.7297825217247, loss: 75.57891297340393 
Train [8/10] | Epoch [47/160] |	nca: 17.584527775645256, flat: 6.42356313765049, pod: 48.85225975513458, loss: 72.86035084724426 
Train [8/10] | Epoch [48/160] |	nca: 17.73560670018196, flat: 6.624685153365135, pod: 50.59723061323166, loss: 74.95752227306366 
Train [8/10] | Epoch [49/160] |	nca: 17.66694101691246, flat: 6.43259970843792, pod: 49.39136290550232, loss: 73.49090373516083 
Train [8/10] | Epoch [50/160] |	nca: 16.88706335425377, flat: 6.4113407507538795, pod: 50.13197320699692, loss: 73.43037736415863 
Train [8/10] | Epoch [51/160] |	nca: 17.240353867411613, flat: 6.368847407400608, pod: 48.973453104496, loss: 72.58265423774719 
Train [8/10] | Epoch [52/160] |	nca: 16.795070946216583, flat: 6.387066647410393, pod: 49.23741960525513, loss: 72.41955733299255 
Train [8/10] | Epoch [53/160] |	nca: 16.948142766952515, flat: 6.268441401422024, pod: 49.081412613391876, loss: 72.29799675941467 
Train [8/10] | Epoch [54/160] |	nca: 15.95639944076538, flat: 6.172050438821316, pod: 47.270669877529144, loss: 69.39912009239197 
Train [8/10] | Epoch [55/160] |	nca: 14.210866019129753, flat: 5.875303693115711, pod: 45.508731842041016, loss: 65.59490168094635 
Train [8/10] | Epoch [56/160] |	nca: 13.606944799423218, flat: 5.837169624865055, pod: 45.30417722463608, loss: 64.74829149246216 
Train [8/10] | Epoch [57/160] |	nca: 15.234152674674988, flat: 6.06410750746727, pod: 47.724196434020996, loss: 69.02245676517487 
Train [8/10] | Epoch [58/160] |	nca: 14.085940599441528, flat: 5.883223548531532, pod: 45.88830977678299, loss: 65.85747385025024 
Train [8/10] | Epoch [59/160] |	nca: 13.283292815089226, flat: 5.7145824283361435, pod: 44.54082465171814, loss: 63.53869915008545 
Train [8/10] | Epoch [60/160] |	nca: 12.440723672509193, flat: 5.693233095109463, pod: 44.97975021600723, loss: 63.11370635032654 
Train [8/10] | Epoch [61/160] |	nca: 14.437749356031418, flat: 5.860941134393215, pod: 45.82882755994797, loss: 66.1275178194046 
Train [8/10] | Epoch [62/160] |	nca: 14.953823387622833, flat: 6.205099068582058, pod: 47.53074276447296, loss: 68.68966519832611 
Train [8/10] | Epoch [63/160] |	nca: 13.558328285813332, flat: 5.978653073310852, pod: 46.02978587150574, loss: 65.56676697731018 
Train [8/10] | Epoch [64/160] |	nca: 13.372832521796227, flat: 5.831280015408993, pod: 44.96998172998428, loss: 64.1740939617157 
Train [8/10] | Epoch [65/160] |	nca: 13.757418513298035, flat: 5.848836049437523, pod: 44.989942371845245, loss: 64.59619700908661 
Train [8/10] | Epoch [66/160] |	nca: 12.5149345099926, flat: 5.749218858778477, pod: 44.557398200035095, loss: 62.82155156135559 
Train [8/10] | Epoch [67/160] |	nca: 12.997696831822395, flat: 5.609513506293297, pod: 43.14235174655914, loss: 61.74956178665161 
Train [8/10] | Epoch [68/160] |	nca: 12.426696307957172, flat: 5.677922174334526, pod: 43.81678092479706, loss: 61.921398758888245 
Train [8/10] | Epoch [69/160] |	nca: 11.774818167090416, flat: 5.532321579754353, pod: 43.541079103946686, loss: 60.8482186794281 
Train [8/10] | Epoch [70/160] |	nca: 12.07268263399601, flat: 5.654812939465046, pod: 42.97942852973938, loss: 60.706924080848694 
Train [8/10] | Epoch [71/160] |	nca: 12.474960781633854, flat: 5.677608497440815, pod: 44.02686947584152, loss: 62.179439067840576 
Train [8/10] | Epoch [72/160] |	nca: 11.361479714512825, flat: 5.523536384105682, pod: 42.54151999950409, loss: 59.426535964012146 
Train [8/10] | Epoch [73/160] |	nca: 13.26541630923748, flat: 5.704429611563683, pod: 43.98946666717529, loss: 62.959312438964844 
Train [8/10] | Epoch [74/160] |	nca: 11.606830894947052, flat: 5.506565757095814, pod: 43.191797375679016, loss: 60.30519413948059 
Train [8/10] | Epoch [75/160] |	nca: 10.79031252861023, flat: 5.34674558788538, pod: 41.73807865381241, loss: 57.875136852264404 
Train [8/10] | Epoch [76/160] |	nca: 12.327183112502098, flat: 5.599883571267128, pod: 42.96581327915192, loss: 60.89288002252579 
Train [8/10] | Epoch [77/160] |	nca: 11.040535815060139, flat: 5.505671039223671, pod: 42.1651645898819, loss: 58.711371541023254 
Train [8/10] | Epoch [78/160] |	nca: 10.067658871412277, flat: 5.315802998840809, pod: 41.84849590063095, loss: 57.2319575548172 
Train [8/10] | Epoch [79/160] |	nca: 10.148476302623749, flat: 5.205352336168289, pod: 41.741793274879456, loss: 57.095622301101685 
Train [8/10] | Epoch [80/160] |	nca: 10.801999002695084, flat: 5.347089275717735, pod: 40.76789844036102, loss: 56.91698682308197 
Train [8/10] | Epoch [81/160] |	nca: 10.231617033481598, flat: 5.27998960763216, pod: 41.03330856561661, loss: 56.544915080070496 
Train [8/10] | Epoch [82/160] |	nca: 11.056793056428432, flat: 5.3252281323075294, pod: 41.66505080461502, loss: 58.047072529792786 
Train [8/10] | Epoch [83/160] |	nca: 10.156176447868347, flat: 5.2744419276714325, pod: 40.839368522167206, loss: 56.269986391067505 
Train [8/10] | Epoch [84/160] |	nca: 10.01213563978672, flat: 5.133863806724548, pod: 39.70470875501633, loss: 54.8507080078125 
Train [8/10] | Epoch [85/160] |	nca: 9.923590794205666, flat: 5.1545994728803635, pod: 40.03473490476608, loss: 55.11292505264282 
Train [8/10] | Epoch [86/160] |	nca: 9.812355801463127, flat: 5.208014011383057, pod: 41.669699132442474, loss: 56.69006907939911 
Train [8/10] | Epoch [87/160] |	nca: 9.427839316427708, flat: 5.113115549087524, pod: 39.30180108547211, loss: 53.84275585412979 
Train [8/10] | Epoch [88/160] |	nca: 9.396917447447777, flat: 5.163982979953289, pod: 39.726066172122955, loss: 54.28696650266647 
Train [8/10] | Epoch [89/160] |	nca: 8.51211229711771, flat: 4.901726834475994, pod: 38.524593353271484, loss: 51.938432455062866 
Train [8/10] | Epoch [90/160] |	nca: 8.065785892307758, flat: 4.772894188761711, pod: 37.51899689435959, loss: 50.35767686367035 
Train [8/10] | Epoch [91/160] |	nca: 8.685414217412472, flat: 4.930832996964455, pod: 38.82272392511368, loss: 52.438971400260925 
Train [8/10] | Epoch [92/160] |	nca: 8.011231578886509, flat: 4.747634805738926, pod: 37.54740643501282, loss: 50.306272983551025 
Train [8/10] | Epoch [93/160] |	nca: 7.75193215161562, flat: 4.684148952364922, pod: 37.685731112957, loss: 50.12181180715561 
Train [8/10] | Epoch [94/160] |	nca: 7.647475458681583, flat: 4.633926130831242, pod: 37.22801464796066, loss: 49.50941652059555 
Train [8/10] | Epoch [95/160] |	nca: 7.334143832325935, flat: 4.651792906224728, pod: 37.991039752960205, loss: 49.97697651386261 
Train [8/10] | Epoch [96/160] |	nca: 7.210863888263702, flat: 4.463811002671719, pod: 36.635112047195435, loss: 48.3097870349884 
Train [8/10] | Epoch [97/160] |	nca: 7.352338939905167, flat: 4.46780988574028, pod: 35.8398574590683, loss: 47.660006046295166 
Train [8/10] | Epoch [98/160] |	nca: 6.8302305191755295, flat: 4.386483825743198, pod: 34.90921467542648, loss: 46.125929057598114 
Train [8/10] | Epoch [99/160] |	nca: 6.6627572774887085, flat: 4.3976761773228645, pod: 35.25256389379501, loss: 46.31299716234207 
Train [8/10] | Epoch [100/160] |	nca: 7.548743732273579, flat: 4.386199675500393, pod: 35.21728616952896, loss: 47.15222930908203 
Train [8/10] | Epoch [101/160] |	nca: 6.464487731456757, flat: 4.288392387330532, pod: 33.74207681417465, loss: 44.494956851005554 
Train [8/10] | Epoch [102/160] |	nca: 6.750232979655266, flat: 4.185824118554592, pod: 33.590402007102966, loss: 44.52645927667618 
Train [8/10] | Epoch [103/160] |	nca: 6.3078512623906136, flat: 4.1662894412875175, pod: 34.20226973295212, loss: 44.67641007900238 
Train [8/10] | Epoch [104/160] |	nca: 5.965519580990076, flat: 4.1638883501291275, pod: 34.15920931100845, loss: 44.28861737251282 
Train [8/10] | Epoch [105/160] |	nca: 6.69133947789669, flat: 4.266952954232693, pod: 35.28225439786911, loss: 46.24054658412933 
Train [8/10] | Epoch [106/160] |	nca: 6.272812023758888, flat: 4.042906433343887, pod: 32.98125344514847, loss: 43.29697209596634 
Train [8/10] | Epoch [107/160] |	nca: 6.055620156228542, flat: 4.155823461711407, pod: 33.61306893825531, loss: 43.82451260089874 
Train [8/10] | Epoch [108/160] |	nca: 5.9704888463020325, flat: 4.031138777732849, pod: 32.741150081157684, loss: 42.74277776479721 
Train [8/10] | Epoch [109/160] |	nca: 5.610690377652645, flat: 3.926614873111248, pod: 32.04679197072983, loss: 41.584097266197205 
Train [8/10] | Epoch [110/160] |	nca: 5.241620764136314, flat: 3.8858151733875275, pod: 31.736154854297638, loss: 40.86359089612961 
Train [8/10] | Epoch [111/160] |	nca: 5.2806369215250015, flat: 3.7558808997273445, pod: 31.166528820991516, loss: 40.2030468583107 
Train [8/10] | Epoch [112/160] |	nca: 5.1559572741389275, flat: 3.8253209814429283, pod: 31.47815638780594, loss: 40.45943486690521 
Train [8/10] | Epoch [113/160] |	nca: 5.008514739573002, flat: 3.7427005618810654, pod: 31.158495485782623, loss: 39.90971088409424 
Train [8/10] | Epoch [114/160] |	nca: 5.057838752865791, flat: 3.701279990375042, pod: 31.486374855041504, loss: 40.2454931139946 
Train [8/10] | Epoch [115/160] |	nca: 5.138848960399628, flat: 3.723297856748104, pod: 30.510660648345947, loss: 39.37280756235123 
Train [8/10] | Epoch [116/160] |	nca: 4.8564245998859406, flat: 3.7306396514177322, pod: 30.000473976135254, loss: 38.5875381231308 
Train [8/10] | Epoch [117/160] |	nca: 4.833375722169876, flat: 3.6332017332315445, pod: 29.501027464866638, loss: 37.967604994773865 
Train [8/10] | Epoch [118/160] |	nca: 4.977653451263905, flat: 3.6376724913716316, pod: 30.528161644935608, loss: 39.14348745346069 
Train [8/10] | Epoch [119/160] |	nca: 4.861072618514299, flat: 3.5943437442183495, pod: 29.449411988258362, loss: 37.90482831001282 
Train [8/10] | Epoch [120/160] |	nca: 4.6127955466508865, flat: 3.541680261492729, pod: 29.292926490306854, loss: 37.44740217924118 
Train [8/10] | Epoch [121/160] |	nca: 4.493372272700071, flat: 3.475070096552372, pod: 28.30613061785698, loss: 36.27457296848297 
Train [8/10] | Epoch [122/160] |	nca: 4.326631262898445, flat: 3.407190077006817, pod: 27.88668230175972, loss: 35.62050360441208 
Train [8/10] | Epoch [123/160] |	nca: 4.200835034251213, flat: 3.432130705565214, pod: 28.345169007778168, loss: 35.978134751319885 
Train [8/10] | Epoch [124/160] |	nca: 4.309324324131012, flat: 3.388358771800995, pod: 28.266995131969452, loss: 35.96467822790146 
Train [8/10] | Epoch [125/160] |	nca: 4.251791164278984, flat: 3.3601536601781845, pod: 27.430317282676697, loss: 35.04226219654083 
Train [8/10] | Epoch [126/160] |	nca: 4.330707684159279, flat: 3.374551586806774, pod: 27.540681660175323, loss: 35.24594086408615 
Train [8/10] | Epoch [127/160] |	nca: 4.220406252890825, flat: 3.386877439916134, pod: 27.89097785949707, loss: 35.49826169013977 
Train [8/10] | Epoch [128/160] |	nca: 4.176109239459038, flat: 3.3156819567084312, pod: 27.74001654982567, loss: 35.2318075299263 
Train [8/10] | Epoch [129/160] |	nca: 4.074939701706171, flat: 3.2278960421681404, pod: 26.70221558213234, loss: 34.00505143404007 
Train [8/10] | Epoch [130/160] |	nca: 4.1337380185723305, flat: 3.2763286754488945, pod: 27.250567376613617, loss: 34.660633981227875 
Train [8/10] | Epoch [131/160] |	nca: 4.090674482285976, flat: 3.2842444628477097, pod: 27.551032096147537, loss: 34.925950825214386 
Train [8/10] | Epoch [132/160] |	nca: 3.9943072088062763, flat: 3.2624476961791515, pod: 26.966601580381393, loss: 34.2233567237854 
Train [8/10] | Epoch [133/160] |	nca: 4.031788654625416, flat: 3.2574246153235435, pod: 27.257992327213287, loss: 34.54720574617386 
Train [8/10] | Epoch [134/160] |	nca: 3.897496897727251, flat: 3.1848439648747444, pod: 25.998665690422058, loss: 33.081006705760956 
Train [8/10] | Epoch [135/160] |	nca: 3.9927714206278324, flat: 3.1784229166805744, pod: 26.120713114738464, loss: 33.291907370090485 
Train [8/10] | Epoch [136/160] |	nca: 3.925910022109747, flat: 3.155746664851904, pod: 26.060649424791336, loss: 33.14230579137802 
Train [8/10] | Epoch [137/160] |	nca: 4.121041480451822, flat: 3.1962897293269634, pod: 25.939509391784668, loss: 33.25684070587158 
Train [8/10] | Epoch [138/160] |	nca: 3.7540853321552277, flat: 3.1810027211904526, pod: 25.85840752720833, loss: 32.79349571466446 
Train [8/10] | Epoch [139/160] |	nca: 3.7119719088077545, flat: 3.0994021482765675, pod: 25.659663796424866, loss: 32.4710379242897 
Train [8/10] | Epoch [140/160] |	nca: 4.120256416499615, flat: 3.1026157289743423, pod: 25.563288003206253, loss: 32.7861602306366 
Train [8/10] | Epoch [141/160] |	nca: 3.729829750955105, flat: 3.067350372672081, pod: 24.830711364746094, loss: 31.6278914809227 
Train [8/10] | Epoch [142/160] |	nca: 3.8461485728621483, flat: 3.0977841578423977, pod: 25.383092373609543, loss: 32.327025055885315 
Train [8/10] | Epoch [143/160] |	nca: 3.579331297427416, flat: 3.048431597650051, pod: 24.73263716697693, loss: 31.360400021076202 
Train [8/10] | Epoch [144/160] |	nca: 3.698427479714155, flat: 3.045403338968754, pod: 24.80438607931137, loss: 31.54821687936783 
Train [8/10] | Epoch [145/160] |	nca: 3.709052488207817, flat: 3.0303245186805725, pod: 24.584011733531952, loss: 31.323388755321503 
Train [8/10] | Epoch [146/160] |	nca: 3.633109100162983, flat: 2.9940408170223236, pod: 24.11530375480652, loss: 30.74245375394821 
Train [8/10] | Epoch [147/160] |	nca: 3.6897046007215977, flat: 3.0025141201913357, pod: 24.395040333271027, loss: 31.08725917339325 
Train [8/10] | Epoch [148/160] |	nca: 3.6465737372636795, flat: 3.058297496289015, pod: 24.82637831568718, loss: 31.531249701976776 
Train [8/10] | Epoch [149/160] |	nca: 3.5370850153267384, flat: 2.9995978325605392, pod: 24.101698517799377, loss: 30.63838142156601 
Train [8/10] | Epoch [150/160] |	nca: 3.82216577231884, flat: 3.0030400045216084, pod: 24.252318531274796, loss: 31.077524304389954 
Train [8/10] | Epoch [151/160] |	nca: 3.5633234456181526, flat: 3.019551295787096, pod: 24.206673234701157, loss: 30.789547979831696 
Train [8/10] | Epoch [152/160] |	nca: 3.621997456997633, flat: 2.985684409737587, pod: 24.13513535261154, loss: 30.74281734228134 
Train [8/10] | Epoch [153/160] |	nca: 3.5665048584342003, flat: 2.988331850618124, pod: 23.978677183389664, loss: 30.53351390361786 
Train [8/10] | Epoch [154/160] |	nca: 3.5914919897913933, flat: 2.974886767566204, pod: 23.75521144270897, loss: 30.321590185165405 
Train [8/10] | Epoch [155/160] |	nca: 3.5262776724994183, flat: 2.9602484554052353, pod: 23.850706428289413, loss: 30.337232649326324 
Train [8/10] | Epoch [156/160] |	nca: 3.608897175639868, flat: 2.9644142389297485, pod: 23.886749655008316, loss: 30.460061073303223 
Train [8/10] | Epoch [157/160] |	nca: 3.6064548678696156, flat: 2.994205616414547, pod: 23.87958425283432, loss: 30.480244636535645 
Train [8/10] | Epoch [158/160] |	nca: 3.5987549535930157, flat: 2.9669570364058018, pod: 23.488418519496918, loss: 30.054130494594574 
Train [8/10] | Epoch [159/160] |	nca: 3.4523416571319103, flat: 2.993107106536627, pod: 24.06253120303154, loss: 30.507979929447174 
Train [8/10] | Epoch [160/160] |	nca: 3.624965138733387, flat: 2.9743762761354446, pod: 23.80991691350937, loss: 30.409258365631104 
Fine-tuning
Building & updating memory.
Train [8/10] | Epoch [161/180] |	nca: 1.992579735815525, flat: 0.7341594286262989, pod: 7.033936053514481, loss: 9.760675251483917 
Train [8/10] | Epoch [162/180] |	nca: 1.2984224408864975, flat: 0.7467524036765099, pod: 7.410665720701218, loss: 9.455840587615967 
Train [8/10] | Epoch [163/180] |	nca: 1.15265042334795, flat: 0.7274783551692963, pod: 7.0426278710365295, loss: 8.922756671905518 
Train [8/10] | Epoch [164/180] |	nca: 1.0428376346826553, flat: 0.7355743534862995, pod: 7.048704266548157, loss: 8.827116310596466 
Train [8/10] | Epoch [165/180] |	nca: 1.0531341210007668, flat: 0.7475571371614933, pod: 7.3073550164699554, loss: 9.108046233654022 
Train [8/10] | Epoch [166/180] |	nca: 1.069186631590128, flat: 0.7333483695983887, pod: 7.209835082292557, loss: 9.01237016916275 
Train [8/10] | Epoch [167/180] |	nca: 1.04176764190197, flat: 0.7249663211405277, pod: 7.128666639328003, loss: 8.895400702953339 
Train [8/10] | Epoch [168/180] |	nca: 1.0025122538208961, flat: 0.746497917920351, pod: 7.228117525577545, loss: 8.977127730846405 
Train [8/10] | Epoch [169/180] |	nca: 0.9787959307432175, flat: 0.7341171614825726, pod: 7.024727821350098, loss: 8.737640917301178 
Train [8/10] | Epoch [170/180] |	nca: 1.033392071723938, flat: 0.7199962437152863, pod: 7.061943024396896, loss: 8.815331280231476 
Train [8/10] | Epoch [171/180] |	nca: 0.9538286030292511, flat: 0.7346802689135075, pod: 7.023369491100311, loss: 8.711878299713135 
Train [8/10] | Epoch [172/180] |	nca: 0.9380556717514992, flat: 0.7336219511926174, pod: 7.093550115823746, loss: 8.765227794647217 
Train [8/10] | Epoch [173/180] |	nca: 0.9055479168891907, flat: 0.742506992071867, pod: 7.323844939470291, loss: 8.9718998670578 
Train [8/10] | Epoch [174/180] |	nca: 0.8934245370328426, flat: 0.7218543775379658, pod: 7.006395667791367, loss: 8.621674656867981 
Train [8/10] | Epoch [175/180] |	nca: 0.940664991736412, flat: 0.75190120190382, pod: 7.3636404275894165, loss: 9.056206583976746 
Train [8/10] | Epoch [176/180] |	nca: 0.8482782803475857, flat: 0.7405288629233837, pod: 7.1678972244262695, loss: 8.75670439004898 
Train [8/10] | Epoch [177/180] |	nca: 0.8386155068874359, flat: 0.7289055250585079, pod: 7.044576734304428, loss: 8.612097799777985 
Train [8/10] | Epoch [178/180] |	nca: 0.7947003282606602, flat: 0.7262162268161774, pod: 6.932748943567276, loss: 8.453665375709534 
Train [8/10] | Epoch [179/180] |	nca: 0.849949549883604, flat: 0.7368610836565495, pod: 7.197808712720871, loss: 8.784619331359863 
Train [8/10] | Epoch [180/180] |	nca: 0.8583574555814266, flat: 0.7468383051455021, pod: 7.257700681686401, loss: 8.86289632320404 
after task
Building & updating memory.
after task
Eval on 0->80.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.597625.
Current acc: {'total': 0.435, '00-09': 0.558, '10-19': 0.348, '20-29': 0.274, '30-39': 0.279, '40-49': 0.411, '50-59': 0.441, '60-69': 0.4, '70-79': 0.772}.
Avg inc acc top5: 0.856875.
Current acc top5: {'total': 0.744}.
Forgetting: 0.2098888888888889.
Cord metric: 0.55.
Old accuracy: 0.39, mean: 0.51.
New accuracy: 0.77, mean: 0.75.
================Task 8 Start!================
Testing on False unseen tasks (max class = 90).
Set memory of size: 1600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 8 Training!================
The training samples number: 6600
Train on 80->90.
train task
nb 6600.
Train [9/10] | Epoch [1/160] |	nca: 92.17880547046661, flat: 12.325877636671066, pod: 88.1222396492958, loss: 192.62692141532898 
Train [9/10] | Epoch [2/160] |	nca: 65.03813546895981, flat: 9.0491873472929, pod: 73.86513185501099, loss: 147.95245385169983 
Train [9/10] | Epoch [3/160] |	nca: 53.27086466550827, flat: 8.061856091022491, pod: 67.51521027088165, loss: 128.84793186187744 
Train [9/10] | Epoch [4/160] |	nca: 48.79022437334061, flat: 7.885011792182922, pod: 65.14644956588745, loss: 121.82168579101562 
Train [9/10] | Epoch [5/160] |	nca: 44.316742062568665, flat: 7.610640496015549, pod: 62.36583364009857, loss: 114.29321718215942 
Train [9/10] | Epoch [6/160] |	nca: 44.34907877445221, flat: 7.603890389204025, pod: 63.257919907569885, loss: 115.21088969707489 
Train [9/10] | Epoch [7/160] |	nca: 40.76228964328766, flat: 7.379950195550919, pod: 60.86777091026306, loss: 109.01001119613647 
Train [9/10] | Epoch [8/160] |	nca: 37.404725790023804, flat: 7.329028584063053, pod: 59.221803307533264, loss: 103.9555572271347 
Train [9/10] | Epoch [9/160] |	nca: 39.10930514335632, flat: 7.569215774536133, pod: 62.00137257575989, loss: 108.67989373207092 
Train [9/10] | Epoch [10/160] |	nca: 36.991259038448334, flat: 7.491489484906197, pod: 60.66040623188019, loss: 105.1431554555893 
Train [9/10] | Epoch [11/160] |	nca: 36.001717776060104, flat: 7.475924596190453, pod: 60.17790472507477, loss: 103.65554666519165 
Train [9/10] | Epoch [12/160] |	nca: 33.60594713687897, flat: 7.258315712213516, pod: 59.917123317718506, loss: 100.7813857793808 
Train [9/10] | Epoch [13/160] |	nca: 32.11245658993721, flat: 7.534238547086716, pod: 61.2323043346405, loss: 100.87899935245514 
Train [9/10] | Epoch [14/160] |	nca: 32.53718417882919, flat: 7.26048531383276, pod: 59.3219290971756, loss: 99.11959862709045 
Train [9/10] | Epoch [15/160] |	nca: 33.14325648546219, flat: 7.414720833301544, pod: 59.257657289505005, loss: 99.81563448905945 
Train [9/10] | Epoch [16/160] |	nca: 29.54911482334137, flat: 7.145570941269398, pod: 57.52346467971802, loss: 94.21815037727356 
Train [9/10] | Epoch [17/160] |	nca: 30.56769961118698, flat: 7.095314033329487, pod: 56.931671261787415, loss: 94.59468519687653 
Train [9/10] | Epoch [18/160] |	nca: 31.036472469568253, flat: 7.511796876788139, pod: 59.19494700431824, loss: 97.74321675300598 
Train [9/10] | Epoch [19/160] |	nca: 29.494217485189438, flat: 7.128141306340694, pod: 57.11869430541992, loss: 93.74105274677277 
Train [9/10] | Epoch [20/160] |	nca: 28.777398467063904, flat: 6.984039254486561, pod: 56.146496415138245, loss: 91.90793430805206 
Train [9/10] | Epoch [21/160] |	nca: 27.687487304210663, flat: 7.145247779786587, pod: 56.3812158703804, loss: 91.21395111083984 
Train [9/10] | Epoch [22/160] |	nca: 27.910467952489853, flat: 7.250815063714981, pod: 57.663825273513794, loss: 92.82510805130005 
Train [9/10] | Epoch [23/160] |	nca: 28.570137679576874, flat: 7.218378469347954, pod: 56.94287192821503, loss: 92.73138809204102 
Train [9/10] | Epoch [24/160] |	nca: 28.104231119155884, flat: 7.334031954407692, pod: 58.97757613658905, loss: 94.4158388376236 
Train [9/10] | Epoch [25/160] |	nca: 27.324783265590668, flat: 7.234741427004337, pod: 57.19576048851013, loss: 91.75528478622437 
Train [9/10] | Epoch [26/160] |	nca: 25.32687520980835, flat: 7.07063689827919, pod: 55.8997078537941, loss: 88.29721927642822 
Train [9/10] | Epoch [27/160] |	nca: 25.7588869035244, flat: 7.1546961814165115, pod: 56.407670378685, loss: 89.321253657341 
Train [9/10] | Epoch [28/160] |	nca: 26.341026037931442, flat: 7.231785356998444, pod: 56.38272613286972, loss: 89.95553755760193 
Train [9/10] | Epoch [29/160] |	nca: 24.991147726774216, flat: 6.90457147359848, pod: 54.055413007736206, loss: 85.95113182067871 
Train [9/10] | Epoch [30/160] |	nca: 23.819323152303696, flat: 6.797180511057377, pod: 54.88837265968323, loss: 85.50487637519836 
Train [9/10] | Epoch [31/160] |	nca: 25.297091752290726, flat: 7.268617197871208, pod: 56.16649949550629, loss: 88.73220837116241 
Train [9/10] | Epoch [32/160] |	nca: 24.81053712964058, flat: 7.175016835331917, pod: 56.98392826318741, loss: 88.96948254108429 
Train [9/10] | Epoch [33/160] |	nca: 23.902604043483734, flat: 6.887262172996998, pod: 53.54507768154144, loss: 84.33494412899017 
Train [9/10] | Epoch [34/160] |	nca: 24.014406114816666, flat: 6.990010000765324, pod: 55.07076370716095, loss: 86.07517969608307 
Train [9/10] | Epoch [35/160] |	nca: 23.260145753622055, flat: 6.86537428945303, pod: 53.79959458112717, loss: 83.92511427402496 
Train [9/10] | Epoch [36/160] |	nca: 24.674756944179535, flat: 6.96575789898634, pod: 54.31863850355148, loss: 85.95915365219116 
Train [9/10] | Epoch [37/160] |	nca: 23.039299964904785, flat: 7.120917364954948, pod: 56.03749752044678, loss: 86.19771444797516 
Train [9/10] | Epoch [38/160] |	nca: 21.51314666867256, flat: 6.775573290884495, pod: 53.19177132844925, loss: 81.48049068450928 
Train [9/10] | Epoch [39/160] |	nca: 22.636354982852936, flat: 7.019455142319202, pod: 54.94439160823822, loss: 84.60020172595978 
Train [9/10] | Epoch [40/160] |	nca: 23.35455948114395, flat: 7.047890700399876, pod: 54.94064259529114, loss: 85.34309267997742 
Train [9/10] | Epoch [41/160] |	nca: 23.206174463033676, flat: 7.107353247702122, pod: 55.26958471536636, loss: 85.5831127166748 
Train [9/10] | Epoch [42/160] |	nca: 23.624403834342957, flat: 6.998761720955372, pod: 53.95548301935196, loss: 84.57864797115326 
Train [9/10] | Epoch [43/160] |	nca: 21.252319872379303, flat: 6.949140332639217, pod: 53.43619054555893, loss: 81.63765072822571 
Train [9/10] | Epoch [44/160] |	nca: 20.382671624422073, flat: 6.837770141661167, pod: 54.26766687631607, loss: 81.48810839653015 
Train [9/10] | Epoch [45/160] |	nca: 20.399344712495804, flat: 6.731308721005917, pod: 52.75481814146042, loss: 79.88547170162201 
Train [9/10] | Epoch [46/160] |	nca: 20.369366824626923, flat: 6.883008897304535, pod: 54.061032235622406, loss: 81.31340801715851 
Train [9/10] | Epoch [47/160] |	nca: 21.59816011786461, flat: 6.856611683964729, pod: 53.47769612073898, loss: 81.93246817588806 
Train [9/10] | Epoch [48/160] |	nca: 20.80062821507454, flat: 6.815568149089813, pod: 52.42859214544296, loss: 80.04478812217712 
Train [9/10] | Epoch [49/160] |	nca: 19.928652092814445, flat: 6.673872292041779, pod: 52.638938188552856, loss: 79.24146282672882 
Train [9/10] | Epoch [50/160] |	nca: 21.1013602912426, flat: 6.721253611147404, pod: 52.50454330444336, loss: 80.32715678215027 
Train [9/10] | Epoch [51/160] |	nca: 22.502266973257065, flat: 7.243264600634575, pod: 55.21883499622345, loss: 84.96436631679535 
Train [9/10] | Epoch [52/160] |	nca: 20.025468438863754, flat: 6.743225835263729, pod: 52.929486989974976, loss: 79.69818103313446 
Train [9/10] | Epoch [53/160] |	nca: 18.978354930877686, flat: 6.724269725382328, pod: 51.67644441127777, loss: 77.37906897068024 
Train [9/10] | Epoch [54/160] |	nca: 19.108131557703018, flat: 6.71964355558157, pod: 52.831439316272736, loss: 78.65921449661255 
Train [9/10] | Epoch [55/160] |	nca: 19.535958155989647, flat: 6.846694231033325, pod: 52.9505033493042, loss: 79.33315575122833 
Train [9/10] | Epoch [56/160] |	nca: 18.486000150442123, flat: 6.612444669008255, pod: 52.36894941329956, loss: 77.46739447116852 
Train [9/10] | Epoch [57/160] |	nca: 18.25762164592743, flat: 6.617617703974247, pod: 50.89127117395401, loss: 75.76651084423065 
Train [9/10] | Epoch [58/160] |	nca: 16.54964131116867, flat: 6.3065396547317505, pod: 50.21837532520294, loss: 73.07455635070801 
Train [9/10] | Epoch [59/160] |	nca: 16.93313828110695, flat: 6.499223046004772, pod: 50.209735095500946, loss: 73.64209687709808 
Train [9/10] | Epoch [60/160] |	nca: 17.097287893295288, flat: 6.323864072561264, pod: 48.95184475183487, loss: 72.37299644947052 
Train [9/10] | Epoch [61/160] |	nca: 17.11906324326992, flat: 6.223496824502945, pod: 48.727441012859344, loss: 72.07000088691711 
Train [9/10] | Epoch [62/160] |	nca: 17.213265478610992, flat: 6.440580748021603, pod: 50.53214621543884, loss: 74.18599247932434 
Train [9/10] | Epoch [63/160] |	nca: 17.539817556738853, flat: 6.487351574003696, pod: 49.76982647180557, loss: 73.79699563980103 
Train [9/10] | Epoch [64/160] |	nca: 17.711471274495125, flat: 6.382767468690872, pod: 49.50096297264099, loss: 73.59520173072815 
Train [9/10] | Epoch [65/160] |	nca: 17.049197301268578, flat: 6.399545066058636, pod: 49.41695511341095, loss: 72.86569726467133 
Train [9/10] | Epoch [66/160] |	nca: 16.20953457057476, flat: 6.312943905591965, pod: 49.82339936494827, loss: 72.3458776473999 
Train [9/10] | Epoch [67/160] |	nca: 15.174032419919968, flat: 6.079279042780399, pod: 47.860323548316956, loss: 69.1136349439621 
Train [9/10] | Epoch [68/160] |	nca: 16.69368752837181, flat: 6.406009018421173, pod: 49.259314119815826, loss: 72.35901069641113 
Train [9/10] | Epoch [69/160] |	nca: 15.689627602696419, flat: 6.171145372092724, pod: 48.35572266578674, loss: 70.2164956331253 
Train [9/10] | Epoch [70/160] |	nca: 16.018277809023857, flat: 6.299107417464256, pod: 48.8752555847168, loss: 71.19264078140259 
Train [9/10] | Epoch [71/160] |	nca: 14.795569732785225, flat: 6.155722558498383, pod: 48.0855912566185, loss: 69.03688359260559 
Train [9/10] | Epoch [72/160] |	nca: 14.627675145864487, flat: 6.0244380235672, pod: 47.41070640087128, loss: 68.06281960010529 
Train [9/10] | Epoch [73/160] |	nca: 13.837737634778023, flat: 5.986456759274006, pod: 46.63693517446518, loss: 66.46112954616547 
Train [9/10] | Epoch [74/160] |	nca: 13.931036427617073, flat: 5.974777415394783, pod: 47.48648685216904, loss: 67.39230072498322 
Train [9/10] | Epoch [75/160] |	nca: 14.070458889007568, flat: 5.862468741834164, pod: 45.846017599105835, loss: 65.77894508838654 
Train [9/10] | Epoch [76/160] |	nca: 13.358922004699707, flat: 5.884924590587616, pod: 46.93140113353729, loss: 66.1752473115921 
Train [9/10] | Epoch [77/160] |	nca: 13.616788178682327, flat: 6.0233738496899605, pod: 46.81611555814743, loss: 66.45627748966217 
Train [9/10] | Epoch [78/160] |	nca: 13.59997221827507, flat: 5.935864470899105, pod: 45.999539494514465, loss: 65.53537607192993 
Train [9/10] | Epoch [79/160] |	nca: 13.848404884338379, flat: 5.979511506855488, pod: 45.81166833639145, loss: 65.63958466053009 
Train [9/10] | Epoch [80/160] |	nca: 14.271029025316238, flat: 5.974016234278679, pod: 46.10917812585831, loss: 66.35422325134277 
Train [9/10] | Epoch [81/160] |	nca: 13.436491191387177, flat: 5.688824541866779, pod: 46.41169708967209, loss: 65.53701269626617 
Train [9/10] | Epoch [82/160] |	nca: 12.968230962753296, flat: 5.733197003602982, pod: 44.881656527519226, loss: 63.58308398723602 
Train [9/10] | Epoch [83/160] |	nca: 11.516714677214622, flat: 5.679452270269394, pod: 44.395640194416046, loss: 61.59180700778961 
Train [9/10] | Epoch [84/160] |	nca: 10.967195317149162, flat: 5.449183568358421, pod: 43.27493792772293, loss: 59.6913161277771 
Train [9/10] | Epoch [85/160] |	nca: 12.740165695548058, flat: 5.668439142405987, pod: 45.109729170799255, loss: 63.518333435058594 
Train [9/10] | Epoch [86/160] |	nca: 10.21722686290741, flat: 5.4859544187784195, pod: 43.70704734325409, loss: 59.41022861003876 
Train [9/10] | Epoch [87/160] |	nca: 10.796695783734322, flat: 5.186196535825729, pod: 41.07163441181183, loss: 57.05452686548233 
Train [9/10] | Epoch [88/160] |	nca: 11.600460559129715, flat: 5.38490118086338, pod: 43.02533209323883, loss: 60.01069355010986 
Train [9/10] | Epoch [89/160] |	nca: 10.80558742582798, flat: 5.561242289841175, pod: 43.379473984241486, loss: 59.7463036775589 
Train [9/10] | Epoch [90/160] |	nca: 11.749127946794033, flat: 5.513463869690895, pod: 43.04533839225769, loss: 60.30793011188507 
Train [9/10] | Epoch [91/160] |	nca: 11.5167738199234, flat: 5.358067102730274, pod: 41.85023558139801, loss: 58.72507631778717 
Train [9/10] | Epoch [92/160] |	nca: 10.06573698669672, flat: 5.19163254648447, pod: 40.39494305849075, loss: 55.65231239795685 
Train [9/10] | Epoch [93/160] |	nca: 9.011496625840664, flat: 4.935865521430969, pod: 38.94755905866623, loss: 52.89492094516754 
Train [9/10] | Epoch [94/160] |	nca: 9.368061311542988, flat: 4.943849757313728, pod: 39.302320659160614, loss: 53.614231526851654 
Train [9/10] | Epoch [95/160] |	nca: 9.00202789902687, flat: 4.978976368904114, pod: 38.64678394794464, loss: 52.62778830528259 
Train [9/10] | Epoch [96/160] |	nca: 10.131018064916134, flat: 5.049799777567387, pod: 40.70688050985336, loss: 55.88769835233688 
Train [9/10] | Epoch [97/160] |	nca: 9.301122441887856, flat: 4.9439355209469795, pod: 39.50815725326538, loss: 53.753214716911316 
Train [9/10] | Epoch [98/160] |	nca: 8.773082360625267, flat: 4.894504874944687, pod: 38.91687470674515, loss: 52.58446156978607 
Train [9/10] | Epoch [99/160] |	nca: 9.057708896696568, flat: 4.862519308924675, pod: 39.07812172174454, loss: 52.99834996461868 
Train [9/10] | Epoch [100/160] |	nca: 9.058002553880215, flat: 4.951157733798027, pod: 39.72373825311661, loss: 53.7328987121582 
Train [9/10] | Epoch [101/160] |	nca: 8.526714950799942, flat: 4.749226115643978, pod: 38.15933281183243, loss: 51.43527388572693 
Train [9/10] | Epoch [102/160] |	nca: 8.830245114862919, flat: 4.78834181278944, pod: 38.18439322710037, loss: 51.8029802441597 
Train [9/10] | Epoch [103/160] |	nca: 8.262121245265007, flat: 4.67912520468235, pod: 37.72602051496506, loss: 50.66726702451706 
Train [9/10] | Epoch [104/160] |	nca: 8.835853025317192, flat: 4.727450460195541, pod: 37.52436900138855, loss: 51.087671995162964 
Train [9/10] | Epoch [105/160] |	nca: 7.703292146325111, flat: 4.602240547537804, pod: 37.70066446065903, loss: 50.00619715452194 
Train [9/10] | Epoch [106/160] |	nca: 7.737449482083321, flat: 4.586495280265808, pod: 37.398557245731354, loss: 49.7225016951561 
Train [9/10] | Epoch [107/160] |	nca: 7.474282123148441, flat: 4.628941439092159, pod: 37.1601305603981, loss: 49.2633541226387 
Train [9/10] | Epoch [108/160] |	nca: 7.458640240132809, flat: 4.445443086326122, pod: 36.111850798130035, loss: 48.015934348106384 
Train [9/10] | Epoch [109/160] |	nca: 7.3421570956707, flat: 4.482046388089657, pod: 36.31488162279129, loss: 48.13908529281616 
Train [9/10] | Epoch [110/160] |	nca: 7.340304732322693, flat: 4.571740992367268, pod: 37.83506774902344, loss: 49.7471137046814 
Train [9/10] | Epoch [111/160] |	nca: 7.2169379144907, flat: 4.400756232440472, pod: 36.246114790439606, loss: 47.8638089299202 
Train [9/10] | Epoch [112/160] |	nca: 6.884937770664692, flat: 4.338031142950058, pod: 34.634480237960815, loss: 45.85744923353195 
Train [9/10] | Epoch [113/160] |	nca: 7.0239871591329575, flat: 4.357253357768059, pod: 36.15261501073837, loss: 47.53385543823242 
Train [9/10] | Epoch [114/160] |	nca: 6.575615085661411, flat: 4.251962535083294, pod: 34.55030357837677, loss: 45.37788128852844 
Train [9/10] | Epoch [115/160] |	nca: 6.388091295957565, flat: 4.136196114122868, pod: 33.616169810295105, loss: 44.1404572725296 
Train [9/10] | Epoch [116/160] |	nca: 6.89326485991478, flat: 4.19071252644062, pod: 34.67526465654373, loss: 45.759241819381714 
Train [9/10] | Epoch [117/160] |	nca: 6.434554561972618, flat: 4.184426948428154, pod: 33.98412603139877, loss: 44.60310739278793 
Train [9/10] | Epoch [118/160] |	nca: 6.164566397666931, flat: 4.106389917433262, pod: 33.24519616365433, loss: 43.51615256071091 
Train [9/10] | Epoch [119/160] |	nca: 6.002534873783588, flat: 4.046925097703934, pod: 33.27830684185028, loss: 43.32776689529419 
Train [9/10] | Epoch [120/160] |	nca: 5.397201806306839, flat: 3.9002315253019333, pod: 31.655231475830078, loss: 40.952664852142334 
Train [9/10] | Epoch [121/160] |	nca: 5.412931464612484, flat: 3.7720051631331444, pod: 30.450203716754913, loss: 39.63514047861099 
Train [9/10] | Epoch [122/160] |	nca: 5.494930163025856, flat: 3.9074597507715225, pod: 32.5321951508522, loss: 41.93458515405655 
Train [9/10] | Epoch [123/160] |	nca: 5.778924226760864, flat: 3.8723499923944473, pod: 31.281473338603973, loss: 40.932747542858124 
Train [9/10] | Epoch [124/160] |	nca: 5.195415236055851, flat: 3.893427826464176, pod: 31.51113361120224, loss: 40.599976778030396 
Train [9/10] | Epoch [125/160] |	nca: 5.2578329890966415, flat: 3.7507853880524635, pod: 31.137195259332657, loss: 40.14581388235092 
Train [9/10] | Epoch [126/160] |	nca: 5.322177961468697, flat: 3.7596695497632027, pod: 31.31855797767639, loss: 40.400405526161194 
Train [9/10] | Epoch [127/160] |	nca: 5.118687447160482, flat: 3.743565134704113, pod: 30.42352169752121, loss: 39.28577446937561 
Train [9/10] | Epoch [128/160] |	nca: 5.19662880897522, flat: 3.703370176255703, pod: 30.083459973335266, loss: 38.98345899581909 
Train [9/10] | Epoch [129/160] |	nca: 5.252791240811348, flat: 3.6799064949154854, pod: 30.363855451345444, loss: 39.29655313491821 
Train [9/10] | Epoch [130/160] |	nca: 4.860856808722019, flat: 3.6333878934383392, pod: 29.482862323522568, loss: 37.97710698843002 
Train [9/10] | Epoch [131/160] |	nca: 4.84283097833395, flat: 3.6441431120038033, pod: 30.089495301246643, loss: 38.57646942138672 
Train [9/10] | Epoch [132/160] |	nca: 4.691482022404671, flat: 3.5756675079464912, pod: 29.485464245080948, loss: 37.752613842487335 
Train [9/10] | Epoch [133/160] |	nca: 4.846688538789749, flat: 3.5590536035597324, pod: 28.876162201166153, loss: 37.281904458999634 
Train [9/10] | Epoch [134/160] |	nca: 4.856367625296116, flat: 3.566125325858593, pod: 29.797342032194138, loss: 38.21983480453491 
Train [9/10] | Epoch [135/160] |	nca: 4.492465682327747, flat: 3.5248804055154324, pod: 28.91023537516594, loss: 36.92758160829544 
Train [9/10] | Epoch [136/160] |	nca: 4.586460489779711, flat: 3.5272552147507668, pod: 28.89063334465027, loss: 37.00434881448746 
Train [9/10] | Epoch [137/160] |	nca: 4.587874263525009, flat: 3.4933063574135303, pod: 28.432054489850998, loss: 36.513235211372375 
Train [9/10] | Epoch [138/160] |	nca: 4.540499486029148, flat: 3.5313875898718834, pod: 29.179582834243774, loss: 37.251469910144806 
Train [9/10] | Epoch [139/160] |	nca: 4.633237540721893, flat: 3.4898891896009445, pod: 28.581040114164352, loss: 36.704166889190674 
Train [9/10] | Epoch [140/160] |	nca: 4.501130994409323, flat: 3.5153834745287895, pod: 28.982674151659012, loss: 36.99918854236603 
Train [9/10] | Epoch [141/160] |	nca: 4.321768093854189, flat: 3.4251555055379868, pod: 27.95613932609558, loss: 35.703062891960144 
Train [9/10] | Epoch [142/160] |	nca: 4.488460458815098, flat: 3.448901392519474, pod: 28.17368048429489, loss: 36.11104243993759 
Train [9/10] | Epoch [143/160] |	nca: 4.409101892262697, flat: 3.4455372095108032, pod: 27.62286004424095, loss: 35.477499067783356 
Train [9/10] | Epoch [144/160] |	nca: 4.188402038067579, flat: 3.3363610729575157, pod: 27.205970764160156, loss: 34.73073375225067 
Train [9/10] | Epoch [145/160] |	nca: 4.317348763346672, flat: 3.332275662571192, pod: 26.775132805109024, loss: 34.42475712299347 
Train [9/10] | Epoch [146/160] |	nca: 4.2992653995752335, flat: 3.331761457026005, pod: 26.686745792627335, loss: 34.31777262687683 
Train [9/10] | Epoch [147/160] |	nca: 4.051787652075291, flat: 3.2858299612998962, pod: 25.74243986606598, loss: 33.0800576210022 
Train [9/10] | Epoch [148/160] |	nca: 4.288178980350494, flat: 3.3157543875277042, pod: 26.710070997476578, loss: 34.31400430202484 
Train [9/10] | Epoch [149/160] |	nca: 4.250159405171871, flat: 3.2956585846841335, pod: 26.521628886461258, loss: 34.067446649074554 
Train [9/10] | Epoch [150/160] |	nca: 4.349217627197504, flat: 3.3108771592378616, pod: 26.54363352060318, loss: 34.20372837781906 
Train [9/10] | Epoch [151/160] |	nca: 4.082104556262493, flat: 3.32952194288373, pod: 27.05170851945877, loss: 34.46333521604538 
Train [9/10] | Epoch [152/160] |	nca: 3.975158426910639, flat: 3.3452162854373455, pod: 26.59372168779373, loss: 33.91409623622894 
Train [9/10] | Epoch [153/160] |	nca: 4.2488942332565784, flat: 3.312897589057684, pod: 26.394067496061325, loss: 33.95585948228836 
Train [9/10] | Epoch [154/160] |	nca: 4.2456167079508305, flat: 3.370732396841049, pod: 27.393222749233246, loss: 35.00957179069519 
Train [9/10] | Epoch [155/160] |	nca: 4.187796335667372, flat: 3.245361503213644, pod: 25.634154230356216, loss: 33.06731194257736 
Train [9/10] | Epoch [156/160] |	nca: 4.333187088370323, flat: 3.275474913418293, pod: 26.065848916769028, loss: 33.6745108962059 
Train [9/10] | Epoch [157/160] |	nca: 4.181449584662914, flat: 3.2693159878253937, pod: 26.052438110113144, loss: 33.50320369005203 
Train [9/10] | Epoch [158/160] |	nca: 4.105443503707647, flat: 3.22930071875453, pod: 25.606872111558914, loss: 32.9416161775589 
Train [9/10] | Epoch [159/160] |	nca: 4.115558590739965, flat: 3.2902982980012894, pod: 26.16953843832016, loss: 33.57539522647858 
Train [9/10] | Epoch [160/160] |	nca: 4.223003599792719, flat: 3.300460960716009, pod: 26.26554447412491, loss: 33.789009153842926 
Fine-tuning
Building & updating memory.
Train [9/10] | Epoch [161/180] |	nca: 3.766324922442436, flat: 1.3901880607008934, pod: 14.79178673028946, loss: 19.948299527168274 
Train [9/10] | Epoch [162/180] |	nca: 3.2555658519268036, flat: 1.354114055633545, pod: 14.725998878479004, loss: 19.33567863702774 
Train [9/10] | Epoch [163/180] |	nca: 3.078147880733013, flat: 1.3258637562394142, pod: 14.407775402069092, loss: 18.811787247657776 
Train [9/10] | Epoch [164/180] |	nca: 2.7724071592092514, flat: 1.3318255245685577, pod: 14.68064969778061, loss: 18.784882187843323 
Train [9/10] | Epoch [165/180] |	nca: 2.77796433866024, flat: 1.3605494871735573, pod: 14.70235151052475, loss: 18.84086525440216 
Train [9/10] | Epoch [166/180] |	nca: 2.5426176115870476, flat: 1.419848844408989, pod: 15.253334283828735, loss: 19.21580058336258 
Train [9/10] | Epoch [167/180] |	nca: 2.3424745574593544, flat: 1.3005742728710175, pod: 14.409529209136963, loss: 18.05257797241211 
Train [9/10] | Epoch [168/180] |	nca: 2.0661947056651115, flat: 1.2857864573597908, pod: 14.189614832401276, loss: 17.541596114635468 
Train [9/10] | Epoch [169/180] |	nca: 2.169566832482815, flat: 1.3674524500966072, pod: 14.647365689277649, loss: 18.184385180473328 
Train [9/10] | Epoch [170/180] |	nca: 2.9869705736637115, flat: 1.3323582038283348, pod: 14.660958588123322, loss: 18.980287551879883 
Train [9/10] | Epoch [171/180] |	nca: 2.4303997233510017, flat: 1.3972505629062653, pod: 14.667638957500458, loss: 18.495289087295532 
Train [9/10] | Epoch [172/180] |	nca: 3.0076811462640762, flat: 1.350060485303402, pod: 14.732345283031464, loss: 19.090086936950684 
Train [9/10] | Epoch [173/180] |	nca: 3.1401068568229675, flat: 1.3536605462431908, pod: 14.820933163166046, loss: 19.314700722694397 
Train [9/10] | Epoch [174/180] |	nca: 3.341410920023918, flat: 1.3590901494026184, pod: 14.695048332214355, loss: 19.395549297332764 
Train [9/10] | Epoch [175/180] |	nca: 2.8357203602790833, flat: 1.3190546408295631, pod: 14.539756178855896, loss: 18.694531202316284 
Train [9/10] | Epoch [176/180] |	nca: 1.957664042711258, flat: 1.2976190224289894, pod: 14.298858165740967, loss: 17.554141223430634 
Train [9/10] | Epoch [177/180] |	nca: 1.6822933331131935, flat: 1.3501203507184982, pod: 14.29389375448227, loss: 17.3263076543808 
Train [9/10] | Epoch [178/180] |	nca: 1.8147196993231773, flat: 1.3733517825603485, pod: 14.879823565483093, loss: 18.06789517402649 
Train [9/10] | Epoch [179/180] |	nca: 2.0407251492142677, flat: 1.3255115300416946, pod: 14.695913791656494, loss: 18.062150359153748 
Train [9/10] | Epoch [180/180] |	nca: 2.4493387788534164, flat: 1.5104983150959015, pod: 15.120535016059875, loss: 19.080371856689453 
after task
Building & updating memory.
after task
Eval on 0->90.
eval task
podnet_cnn_cifar100_5steps
Avg inc acc: 0.578.
Current acc: {'total': 0.421, '00-09': 0.564, '10-19': 0.359, '20-29': 0.24, '30-39': 0.26, '40-49': 0.405, '50-59': 0.441, '60-69': 0.337, '70-79': 0.453, '80-89': 0.727}.
Avg inc acc top5: 0.8418888888888889.
Current acc top5: {'total': 0.722}.
Forgetting: 0.2358.
Cord metric: 0.53.
Old accuracy: 0.38, mean: 0.49.
New accuracy: 0.73, mean: 0.74.
================Task 9 Start!================
Testing on False unseen tasks (max class = 100).
Set memory of size: 1800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 9 Training!================
The training samples number: 6800
Train on 90->100.
train task
nb 6800.
Train [10/10] | Epoch [1/160] |	nca: 117.840580701828, flat: 14.019520238041878, pod: 92.37349671125412, loss: 224.2335982322693 
Train [10/10] | Epoch [2/160] |	nca: 88.56689596176147, flat: 11.050469487905502, pod: 83.17596518993378, loss: 182.79333114624023 
Train [10/10] | Epoch [3/160] |	nca: 75.11783540248871, flat: 9.831750482320786, pod: 74.7198748588562, loss: 159.66946077346802 
Train [10/10] | Epoch [4/160] |	nca: 66.77091240882874, flat: 9.067401990294456, pod: 71.08088660240173, loss: 146.9192008972168 
Train [10/10] | Epoch [5/160] |	nca: 65.12304443120956, flat: 9.257014259696007, pod: 69.59884691238403, loss: 143.97890543937683 
Train [10/10] | Epoch [6/160] |	nca: 64.80250316858292, flat: 9.369651094079018, pod: 73.4979956150055, loss: 147.67014932632446 
Train [10/10] | Epoch [7/160] |	nca: 58.8476527929306, flat: 8.911243543028831, pod: 67.62382483482361, loss: 135.38272094726562 
Train [10/10] | Epoch [8/160] |	nca: 55.879335045814514, flat: 8.939966067671776, pod: 66.35875105857849, loss: 131.17805290222168 
Train [10/10] | Epoch [9/160] |	nca: 55.3994197845459, flat: 9.171444922685623, pod: 67.5922691822052, loss: 132.1631326675415 
Train [10/10] | Epoch [10/160] |	nca: 52.334092915058136, flat: 9.11956612765789, pod: 68.00859868526459, loss: 129.46225762367249 
Train [10/10] | Epoch [11/160] |	nca: 52.37880003452301, flat: 8.97946086525917, pod: 67.02668952941895, loss: 128.38495004177094 
Train [10/10] | Epoch [12/160] |	nca: 51.10124760866165, flat: 9.076348006725311, pod: 66.77216935157776, loss: 126.94976592063904 
Train [10/10] | Epoch [13/160] |	nca: 49.879413187503815, flat: 8.930987268686295, pod: 66.24787652492523, loss: 125.05827760696411 
Train [10/10] | Epoch [14/160] |	nca: 50.23677623271942, flat: 9.243943646550179, pod: 67.14183902740479, loss: 126.62255930900574 
Train [10/10] | Epoch [15/160] |	nca: 50.79909998178482, flat: 9.215724915266037, pod: 66.86825633049011, loss: 126.88308215141296 
Train [10/10] | Epoch [16/160] |	nca: 47.733938694000244, flat: 8.96600253880024, pod: 66.80931842327118, loss: 123.50926005840302 
Train [10/10] | Epoch [17/160] |	nca: 48.63948738574982, flat: 9.455314889550209, pod: 67.6609718799591, loss: 125.75577521324158 
Train [10/10] | Epoch [18/160] |	nca: 46.35859161615372, flat: 8.760654374957085, pod: 63.60507011413574, loss: 118.72431552410126 
Train [10/10] | Epoch [19/160] |	nca: 46.74540734291077, flat: 9.33062332868576, pod: 68.29341697692871, loss: 124.36944794654846 
Train [10/10] | Epoch [20/160] |	nca: 45.29161596298218, flat: 9.175042599439621, pod: 65.94624602794647, loss: 120.4129045009613 
Train [10/10] | Epoch [21/160] |	nca: 44.73955720663071, flat: 9.062792718410492, pod: 66.44875466823578, loss: 120.25110363960266 
Train [10/10] | Epoch [22/160] |	nca: 41.39859849214554, flat: 8.689785942435265, pod: 63.43138289451599, loss: 113.51976752281189 
Train [10/10] | Epoch [23/160] |	nca: 41.98909908533096, flat: 8.895825073122978, pod: 65.03223741054535, loss: 115.91716158390045 
Train [10/10] | Epoch [24/160] |	nca: 45.28718185424805, flat: 9.530092105269432, pod: 67.42147171497345, loss: 122.23874461650848 
Train [10/10] | Epoch [25/160] |	nca: 39.1786045730114, flat: 8.710218608379364, pod: 63.80207622051239, loss: 111.69090008735657 
Train [10/10] | Epoch [26/160] |	nca: 40.26273328065872, flat: 9.016076132655144, pod: 63.73165786266327, loss: 113.0104672908783 
Train [10/10] | Epoch [27/160] |	nca: 41.04475700855255, flat: 9.044512659311295, pod: 64.97850513458252, loss: 115.06777513027191 
Train [10/10] | Epoch [28/160] |	nca: 39.51911836862564, flat: 8.922174289822578, pod: 64.83765888214111, loss: 113.27895152568817 
Train [10/10] | Epoch [29/160] |	nca: 39.4127112030983, flat: 8.931415721774101, pod: 63.51164758205414, loss: 111.85577487945557 
Train [10/10] | Epoch [30/160] |	nca: 39.66003715991974, flat: 9.177340105175972, pod: 64.14265584945679, loss: 112.98003339767456 
Train [10/10] | Epoch [31/160] |	nca: 40.642377853393555, flat: 9.25975689291954, pod: 64.43745398521423, loss: 114.33958899974823 
Train [10/10] | Epoch [32/160] |	nca: 37.61740693449974, flat: 8.83050137758255, pod: 63.03875195980072, loss: 109.48666048049927 
Train [10/10] | Epoch [33/160] |	nca: 36.778484642505646, flat: 8.916125848889351, pod: 63.01563537120819, loss: 108.71024560928345 
Train [10/10] | Epoch [34/160] |	nca: 36.83462756872177, flat: 8.939343586564064, pod: 63.09308695793152, loss: 108.86705780029297 
Train [10/10] | Epoch [35/160] |	nca: 32.82087469100952, flat: 8.607928544282913, pod: 61.33586072921753, loss: 102.76466429233551 
Train [10/10] | Epoch [36/160] |	nca: 35.58245661854744, flat: 8.90803299844265, pod: 62.011682748794556, loss: 106.5021721124649 
Train [10/10] | Epoch [37/160] |	nca: 39.22781324386597, flat: 9.515866950154305, pod: 66.49657225608826, loss: 115.24025273323059 
Train [10/10] | Epoch [38/160] |	nca: 34.2170290350914, flat: 9.003213346004486, pod: 62.6756237745285, loss: 105.89586699008942 
Train [10/10] | Epoch [39/160] |	nca: 34.66081631183624, flat: 8.947741255164146, pod: 62.28620672225952, loss: 105.8947639465332 
Train [10/10] | Epoch [40/160] |	nca: 34.63909071683884, flat: 8.92742446064949, pod: 63.372432827949524, loss: 106.93894791603088 
Train [10/10] | Epoch [41/160] |	nca: 36.60322245955467, flat: 9.244704842567444, pod: 64.19112598896027, loss: 110.03905272483826 
Train [10/10] | Epoch [42/160] |	nca: 37.04592788219452, flat: 9.437333047389984, pod: 65.7020593881607, loss: 112.18532049655914 
Train [10/10] | Epoch [43/160] |	nca: 36.196643590927124, flat: 9.440298646688461, pod: 65.2633501291275, loss: 110.9002935886383 
Train [10/10] | Epoch [44/160] |	nca: 32.841722279787064, flat: 8.933511018753052, pod: 62.17968416213989, loss: 103.9549173116684 
Train [10/10] | Epoch [45/160] |	nca: 32.201375275850296, flat: 8.68579876422882, pod: 61.48741936683655, loss: 102.37459421157837 
Train [10/10] | Epoch [46/160] |	nca: 34.50471565127373, flat: 8.871877282857895, pod: 63.09041750431061, loss: 106.46700990200043 
Train [10/10] | Epoch [47/160] |	nca: 29.12842059135437, flat: 8.400997832417488, pod: 58.14802306890488, loss: 95.67744183540344 
Train [10/10] | Epoch [48/160] |	nca: 32.28901278972626, flat: 9.031806603074074, pod: 61.39582598209381, loss: 102.71664535999298 
Train [10/10] | Epoch [49/160] |	nca: 31.61077257990837, flat: 9.028583943843842, pod: 62.75176644325256, loss: 103.39112317562103 
Train [10/10] | Epoch [50/160] |	nca: 29.46598955988884, flat: 8.82157650589943, pod: 60.92496705055237, loss: 99.21253299713135 
Train [10/10] | Epoch [51/160] |	nca: 26.917545974254608, flat: 8.280669033527374, pod: 57.97411274909973, loss: 93.1723279953003 
Train [10/10] | Epoch [52/160] |	nca: 29.58313038945198, flat: 8.578601762652397, pod: 60.00409811735153, loss: 98.16583013534546 
Train [10/10] | Epoch [53/160] |	nca: 31.336618036031723, flat: 9.06811261177063, pod: 61.77777063846588, loss: 102.18250131607056 
Train [10/10] | Epoch [54/160] |	nca: 30.397736757993698, flat: 8.908647015690804, pod: 60.421637177467346, loss: 99.72802078723907 
Train [10/10] | Epoch [55/160] |	nca: 27.33733969926834, flat: 8.184934556484222, pod: 57.53792119026184, loss: 93.06019592285156 
Train [10/10] | Epoch [56/160] |	nca: 32.10948610305786, flat: 9.071339935064316, pod: 61.988136768341064, loss: 103.1689624786377 
Train [10/10] | Epoch [57/160] |	nca: 30.22488048672676, flat: 8.717583641409874, pod: 60.320245027542114, loss: 99.26270961761475 
Train [10/10] | Epoch [58/160] |	nca: 28.994348645210266, flat: 8.654614314436913, pod: 58.673727095127106, loss: 96.32268989086151 
Train [10/10] | Epoch [59/160] |	nca: 28.025521099567413, flat: 8.42800658941269, pod: 59.586888790130615, loss: 96.04041635990143 
Train [10/10] | Epoch [60/160] |	nca: 31.332474917173386, flat: 8.850723162293434, pod: 60.7548588514328, loss: 100.93805694580078 
Train [10/10] | Epoch [61/160] |	nca: 30.504457861185074, flat: 8.98636831343174, pod: 61.98717439174652, loss: 101.47800052165985 
Train [10/10] | Epoch [62/160] |	nca: 26.29171860218048, flat: 8.458119928836823, pod: 59.29432201385498, loss: 94.04416024684906 
Train [10/10] | Epoch [63/160] |	nca: 23.424983024597168, flat: 7.993717297911644, pod: 55.586442828178406, loss: 87.00514340400696 
Train [10/10] | Epoch [64/160] |	nca: 26.736169010400772, flat: 8.449686288833618, pod: 57.966948330402374, loss: 93.15280342102051 
Train [10/10] | Epoch [65/160] |	nca: 27.500364273786545, flat: 8.65266378223896, pod: 58.68055301904678, loss: 94.8335816860199 
Train [10/10] | Epoch [66/160] |	nca: 27.992138236761093, flat: 8.62342657148838, pod: 60.12368220090866, loss: 96.73924720287323 
