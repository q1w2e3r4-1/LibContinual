Label: podnet_nme_cifar100_10steps
orders : None
{'model': 'podnet', 'convnet': 'rebuffi', 'dropout': 0.0, 'herding': None, 'memory_size': 2000, 'temperature': 1, 'fixed_memory': True, 'dataset': 'cifar100', 'increment': 5, 'batch_size': 128, 'workers': 0, 'threads': 1, 'validation': 0.0, 'random_classes': False, 'max_task': None, 'onehot': False, 'initial_increment': 50, 'sampler': None, 'data_path': '/data/douillard/', 'lr': 0.1, 'weight_decay': 0.0005, 'scheduling': 'cosine', 'lr_decay': 0.1, 'optimizer': 'sgd', 'epochs': 160, 'device': [0], 'label': 'podnet_nme_cifar100_10steps', 'autolabel': False, 'seed': [1], 'seed_range': None, 'options': None, 'save_model': 'last', 'dump_predictions': False, 'logging': 'info', 'resume': None, 'resume_first': False, 'recompute_meta': False, 'no_benchmark': False, 'detect_anomaly': False, 'dummy': 1, 'includes': ['headers/dummy.yaml'], 'data_root': 'D:/data/douillard/cifar100/cifar100', 'save_path': '.', 'eval_type': 'nme', 'backbone': {'name': 'resnet18'}, 'classifier': {'name': 'PODNet'}, 'classifier_config': {'type': 'cosine', 'proxy_per_class': 10, 'distance': 'neg_stable_cosine_distance'}, 'postprocessor_config': {'type': 'learned_scaling', 'initial_value': 1.0}, 'pod_flat': {'scheduled_factor': 1.0}, 'pod_spatial': {'scheduled_factor': 3.0, 'collapse_channels': 'spatial'}, 'nca': {'margin': 0.6, 'scale': 1.0, 'exclude_pos_denominator': True}, 'groupwise_factors': {'old_weights': 0.0}, 'finetuning_config': {'sampling': 'undersampling', 'tuning': 'classifier', 'lr': 0.05, 'epochs': 20, 'scaling': None}, 'proxy_per_class': 1, 'weight_generation': {'type': 'imprinted', 'multi_class_diff': 'kmeans'}, 'dataset_transforms': {'color_jitter': True}}
Launching run 1/1
Set seed 1
CUDA algos are determinists but very slow!
Files already downloaded and verified
Files already downloaded and verified
Dataset iCIFAR100: class ordering: [87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39].
Downsampling type stride
Using 10 proxies per class.
Model will be save at this rythm: last.
================Task 0 Start!================
Testing on False unseen tasks (max class = 50).
Before task
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 0 Training!================
The training samples number: 25000
Train on 0->50.
train task
nb 25000.
Train [1/11] | Epoch [1/160] |	nca: 713.351884841919, loss: 713.351884841919 
Train [1/11] | Epoch [2/160] |	nca: 628.6165583133698, loss: 628.6165583133698 
Train [1/11] | Epoch [3/160] |	nca: 578.6331541538239, loss: 578.6331541538239 
Train [1/11] | Epoch [4/160] |	nca: 530.7386615276337, loss: 530.7386615276337 
Train [1/11] | Epoch [5/160] |	nca: 479.500501871109, loss: 479.500501871109 
Train [1/11] | Epoch [6/160] |	nca: 435.3442208766937, loss: 435.3442208766937 
Train [1/11] | Epoch [7/160] |	nca: 401.26643419265747, loss: 401.26643419265747 
Train [1/11] | Epoch [8/160] |	nca: 375.8024117946625, loss: 375.8024117946625 
Train [1/11] | Epoch [9/160] |	nca: 354.27213966846466, loss: 354.27213966846466 
Train [1/11] | Epoch [10/160] |	nca: 336.8898422718048, loss: 336.8898422718048 
Train [1/11] | Epoch [11/160] |	nca: 320.44804549217224, loss: 320.44804549217224 
Train [1/11] | Epoch [12/160] |	nca: 305.83493304252625, loss: 305.83493304252625 
Train [1/11] | Epoch [13/160] |	nca: 294.6501029729843, loss: 294.6501029729843 
Train [1/11] | Epoch [14/160] |	nca: 282.2315227985382, loss: 282.2315227985382 
Train [1/11] | Epoch [15/160] |	nca: 274.926295876503, loss: 274.926295876503 
Train [1/11] | Epoch [16/160] |	nca: 266.0881495475769, loss: 266.0881495475769 
Train [1/11] | Epoch [17/160] |	nca: 259.16981571912766, loss: 259.16981571912766 
Train [1/11] | Epoch [18/160] |	nca: 254.72574758529663, loss: 254.72574758529663 
Train [1/11] | Epoch [19/160] |	nca: 248.95968079566956, loss: 248.95968079566956 
Train [1/11] | Epoch [20/160] |	nca: 243.20548540353775, loss: 243.20548540353775 
Train [1/11] | Epoch [21/160] |	nca: 239.14421570301056, loss: 239.14421570301056 
Train [1/11] | Epoch [22/160] |	nca: 231.69573068618774, loss: 231.69573068618774 
Train [1/11] | Epoch [23/160] |	nca: 230.83445185422897, loss: 230.83445185422897 
Train [1/11] | Epoch [24/160] |	nca: 224.39093899726868, loss: 224.39093899726868 
Train [1/11] | Epoch [25/160] |	nca: 223.75408631563187, loss: 223.75408631563187 
Train [1/11] | Epoch [26/160] |	nca: 220.56728547811508, loss: 220.56728547811508 
Train [1/11] | Epoch [27/160] |	nca: 217.50402510166168, loss: 217.50402510166168 
Train [1/11] | Epoch [28/160] |	nca: 214.038755774498, loss: 214.038755774498 
Train [1/11] | Epoch [29/160] |	nca: 211.85838121175766, loss: 211.85838121175766 
Train [1/11] | Epoch [30/160] |	nca: 209.0929234623909, loss: 209.0929234623909 
Train [1/11] | Epoch [31/160] |	nca: 204.9795206785202, loss: 204.9795206785202 
Train [1/11] | Epoch [32/160] |	nca: 206.8096480369568, loss: 206.8096480369568 
Train [1/11] | Epoch [33/160] |	nca: 204.11862134933472, loss: 204.11862134933472 
Train [1/11] | Epoch [34/160] |	nca: 200.40510100126266, loss: 200.40510100126266 
Train [1/11] | Epoch [35/160] |	nca: 198.49675315618515, loss: 198.49675315618515 
Train [1/11] | Epoch [36/160] |	nca: 196.67374467849731, loss: 196.67374467849731 
Train [1/11] | Epoch [37/160] |	nca: 194.41171395778656, loss: 194.41171395778656 
Train [1/11] | Epoch [38/160] |	nca: 191.68678677082062, loss: 191.68678677082062 
Train [1/11] | Epoch [39/160] |	nca: 192.71395355463028, loss: 192.71395355463028 
Train [1/11] | Epoch [40/160] |	nca: 190.81061494350433, loss: 190.81061494350433 
Train [1/11] | Epoch [41/160] |	nca: 189.1604282259941, loss: 189.1604282259941 
Train [1/11] | Epoch [42/160] |	nca: 186.20672190189362, loss: 186.20672190189362 
Train [1/11] | Epoch [43/160] |	nca: 186.92845010757446, loss: 186.92845010757446 
Train [1/11] | Epoch [44/160] |	nca: 181.49871999025345, loss: 181.49871999025345 
Train [1/11] | Epoch [45/160] |	nca: 181.77578687667847, loss: 181.77578687667847 
Train [1/11] | Epoch [46/160] |	nca: 181.2056167125702, loss: 181.2056167125702 
Train [1/11] | Epoch [47/160] |	nca: 181.16315454244614, loss: 181.16315454244614 
Train [1/11] | Epoch [48/160] |	nca: 178.53908595442772, loss: 178.53908595442772 
Train [1/11] | Epoch [49/160] |	nca: 175.36670005321503, loss: 175.36670005321503 
Train [1/11] | Epoch [50/160] |	nca: 174.0537033677101, loss: 174.0537033677101 
Train [1/11] | Epoch [51/160] |	nca: 171.19595915079117, loss: 171.19595915079117 
Train [1/11] | Epoch [52/160] |	nca: 172.69342017173767, loss: 172.69342017173767 
Train [1/11] | Epoch [53/160] |	nca: 168.82566076517105, loss: 168.82566076517105 
Train [1/11] | Epoch [54/160] |	nca: 167.9023533463478, loss: 167.9023533463478 
Train [1/11] | Epoch [55/160] |	nca: 167.24974232912064, loss: 167.24974232912064 
Train [1/11] | Epoch [56/160] |	nca: 165.85436302423477, loss: 165.85436302423477 
Train [1/11] | Epoch [57/160] |	nca: 165.5051113963127, loss: 165.5051113963127 
Train [1/11] | Epoch [58/160] |	nca: 164.60466295480728, loss: 164.60466295480728 
Train [1/11] | Epoch [59/160] |	nca: 160.6327401995659, loss: 160.6327401995659 
Train [1/11] | Epoch [60/160] |	nca: 162.23893290758133, loss: 162.23893290758133 
Train [1/11] | Epoch [61/160] |	nca: 157.18538808822632, loss: 157.18538808822632 
Train [1/11] | Epoch [62/160] |	nca: 156.47558665275574, loss: 156.47558665275574 
Train [1/11] | Epoch [63/160] |	nca: 154.64292865991592, loss: 154.64292865991592 
Train [1/11] | Epoch [64/160] |	nca: 155.6742660999298, loss: 155.6742660999298 
Train [1/11] | Epoch [65/160] |	nca: 149.62107729911804, loss: 149.62107729911804 
Train [1/11] | Epoch [66/160] |	nca: 153.21525579690933, loss: 153.21525579690933 
Train [1/11] | Epoch [67/160] |	nca: 147.12253135442734, loss: 147.12253135442734 
Train [1/11] | Epoch [68/160] |	nca: 146.77572679519653, loss: 146.77572679519653 
Train [1/11] | Epoch [69/160] |	nca: 147.21071964502335, loss: 147.21071964502335 
Train [1/11] | Epoch [70/160] |	nca: 143.65168660879135, loss: 143.65168660879135 
Train [1/11] | Epoch [71/160] |	nca: 145.1826254427433, loss: 145.1826254427433 
Train [1/11] | Epoch [72/160] |	nca: 140.94649094343185, loss: 140.94649094343185 
Train [1/11] | Epoch [73/160] |	nca: 136.1016357243061, loss: 136.1016357243061 
Train [1/11] | Epoch [74/160] |	nca: 136.10018265247345, loss: 136.10018265247345 
Train [1/11] | Epoch [75/160] |	nca: 137.39468535780907, loss: 137.39468535780907 
Train [1/11] | Epoch [76/160] |	nca: 134.91196206212044, loss: 134.91196206212044 
Train [1/11] | Epoch [77/160] |	nca: 133.55890649557114, loss: 133.55890649557114 
Train [1/11] | Epoch [78/160] |	nca: 130.7498186826706, loss: 130.7498186826706 
Train [1/11] | Epoch [79/160] |	nca: 129.03210878372192, loss: 129.03210878372192 
Train [1/11] | Epoch [80/160] |	nca: 127.07343074679375, loss: 127.07343074679375 
Train [1/11] | Epoch [81/160] |	nca: 126.50620111823082, loss: 126.50620111823082 
Train [1/11] | Epoch [82/160] |	nca: 125.5404884815216, loss: 125.5404884815216 
Train [1/11] | Epoch [83/160] |	nca: 121.37834912538528, loss: 121.37834912538528 
Train [1/11] | Epoch [84/160] |	nca: 120.21516990661621, loss: 120.21516990661621 
Train [1/11] | Epoch [85/160] |	nca: 118.00880980491638, loss: 118.00880980491638 
Train [1/11] | Epoch [86/160] |	nca: 122.26294612884521, loss: 122.26294612884521 
Train [1/11] | Epoch [87/160] |	nca: 114.48825865983963, loss: 114.48825865983963 
Train [1/11] | Epoch [88/160] |	nca: 112.44232502579689, loss: 112.44232502579689 
Train [1/11] | Epoch [89/160] |	nca: 113.65240815281868, loss: 113.65240815281868 
Train [1/11] | Epoch [90/160] |	nca: 108.59288465976715, loss: 108.59288465976715 
Train [1/11] | Epoch [91/160] |	nca: 107.31433835625648, loss: 107.31433835625648 
Train [1/11] | Epoch [92/160] |	nca: 106.03064024448395, loss: 106.03064024448395 
Train [1/11] | Epoch [93/160] |	nca: 104.8274872303009, loss: 104.8274872303009 
Train [1/11] | Epoch [94/160] |	nca: 99.3927595615387, loss: 99.3927595615387 
Train [1/11] | Epoch [95/160] |	nca: 98.01765170693398, loss: 98.01765170693398 
Train [1/11] | Epoch [96/160] |	nca: 98.72503092885017, loss: 98.72503092885017 
Train [1/11] | Epoch [97/160] |	nca: 92.91395708918571, loss: 92.91395708918571 
Train [1/11] | Epoch [98/160] |	nca: 94.99951711297035, loss: 94.99951711297035 
Train [1/11] | Epoch [99/160] |	nca: 90.99919417500496, loss: 90.99919417500496 
Train [1/11] | Epoch [100/160] |	nca: 89.08166259527206, loss: 89.08166259527206 
Train [1/11] | Epoch [101/160] |	nca: 87.35527998209, loss: 87.35527998209 
Train [1/11] | Epoch [102/160] |	nca: 84.42908239364624, loss: 84.42908239364624 
Train [1/11] | Epoch [103/160] |	nca: 81.95249280333519, loss: 81.95249280333519 
Train [1/11] | Epoch [104/160] |	nca: 78.56588837504387, loss: 78.56588837504387 
Train [1/11] | Epoch [105/160] |	nca: 77.78540995717049, loss: 77.78540995717049 
Train [1/11] | Epoch [106/160] |	nca: 77.76533743739128, loss: 77.76533743739128 
Train [1/11] | Epoch [107/160] |	nca: 73.34200575947762, loss: 73.34200575947762 
Train [1/11] | Epoch [108/160] |	nca: 67.52499675750732, loss: 67.52499675750732 
Train [1/11] | Epoch [109/160] |	nca: 67.94865590333939, loss: 67.94865590333939 
Train [1/11] | Epoch [110/160] |	nca: 68.80205161869526, loss: 68.80205161869526 
Train [1/11] | Epoch [111/160] |	nca: 63.13556386530399, loss: 63.13556386530399 
Train [1/11] | Epoch [112/160] |	nca: 63.32496574521065, loss: 63.32496574521065 
Train [1/11] | Epoch [113/160] |	nca: 57.91928431391716, loss: 57.91928431391716 
Train [1/11] | Epoch [114/160] |	nca: 58.13551875948906, loss: 58.13551875948906 
Train [1/11] | Epoch [115/160] |	nca: 55.22845076024532, loss: 55.22845076024532 
Train [1/11] | Epoch [116/160] |	nca: 51.329284861683846, loss: 51.329284861683846 
Train [1/11] | Epoch [117/160] |	nca: 46.37196624279022, loss: 46.37196624279022 
Train [1/11] | Epoch [118/160] |	nca: 45.11584118753672, loss: 45.11584118753672 
Train [1/11] | Epoch [119/160] |	nca: 44.9192823022604, loss: 44.9192823022604 
Train [1/11] | Epoch [120/160] |	nca: 41.42254064977169, loss: 41.42254064977169 
Train [1/11] | Epoch [121/160] |	nca: 37.90351743251085, loss: 37.90351743251085 
Train [1/11] | Epoch [122/160] |	nca: 37.02498168870807, loss: 37.02498168870807 
Train [1/11] | Epoch [123/160] |	nca: 37.104259222745895, loss: 37.104259222745895 
Train [1/11] | Epoch [124/160] |	nca: 32.7702416703105, loss: 32.7702416703105 
Train [1/11] | Epoch [125/160] |	nca: 30.432747825980186, loss: 30.432747825980186 
Train [1/11] | Epoch [126/160] |	nca: 28.43459513783455, loss: 28.43459513783455 
Train [1/11] | Epoch [127/160] |	nca: 26.454925294965506, loss: 26.454925294965506 
Train [1/11] | Epoch [128/160] |	nca: 24.065714728087187, loss: 24.065714728087187 
Train [1/11] | Epoch [129/160] |	nca: 23.70870105549693, loss: 23.70870105549693 
Train [1/11] | Epoch [130/160] |	nca: 21.023952335119247, loss: 21.023952335119247 
Train [1/11] | Epoch [131/160] |	nca: 19.12814335897565, loss: 19.12814335897565 
Train [1/11] | Epoch [132/160] |	nca: 17.830847334116697, loss: 17.830847334116697 
Train [1/11] | Epoch [133/160] |	nca: 16.285766765475273, loss: 16.285766765475273 
Train [1/11] | Epoch [134/160] |	nca: 14.202484237030149, loss: 14.202484237030149 
Train [1/11] | Epoch [135/160] |	nca: 13.40601178072393, loss: 13.40601178072393 
Train [1/11] | Epoch [136/160] |	nca: 12.08366908878088, loss: 12.08366908878088 
Train [1/11] | Epoch [137/160] |	nca: 11.904909536242485, loss: 11.904909536242485 
Train [1/11] | Epoch [138/160] |	nca: 10.581489497795701, loss: 10.581489497795701 
Train [1/11] | Epoch [139/160] |	nca: 9.774033959954977, loss: 9.774033959954977 
Train [1/11] | Epoch [140/160] |	nca: 9.209662212058902, loss: 9.209662212058902 
Train [1/11] | Epoch [141/160] |	nca: 8.856159476563334, loss: 8.856159476563334 
Train [1/11] | Epoch [142/160] |	nca: 7.608423316851258, loss: 7.608423316851258 
Train [1/11] | Epoch [143/160] |	nca: 7.30239122081548, loss: 7.30239122081548 
Train [1/11] | Epoch [144/160] |	nca: 7.472957908175886, loss: 7.472957908175886 
Train [1/11] | Epoch [145/160] |	nca: 6.936280506663024, loss: 6.936280506663024 
Train [1/11] | Epoch [146/160] |	nca: 6.2756683034822345, loss: 6.2756683034822345 
Train [1/11] | Epoch [147/160] |	nca: 6.389433943666518, loss: 6.389433943666518 
Train [1/11] | Epoch [148/160] |	nca: 6.155689801089466, loss: 6.155689801089466 
Train [1/11] | Epoch [149/160] |	nca: 6.098772035911679, loss: 6.098772035911679 
Train [1/11] | Epoch [150/160] |	nca: 5.655912977643311, loss: 5.655912977643311 
Train [1/11] | Epoch [151/160] |	nca: 5.426882187835872, loss: 5.426882187835872 
Train [1/11] | Epoch [152/160] |	nca: 5.37652182020247, loss: 5.37652182020247 
Train [1/11] | Epoch [153/160] |	nca: 5.289367562159896, loss: 5.289367562159896 
Train [1/11] | Epoch [154/160] |	nca: 5.042710347101092, loss: 5.042710347101092 
Train [1/11] | Epoch [155/160] |	nca: 5.120712922886014, loss: 5.120712922886014 
Train [1/11] | Epoch [156/160] |	nca: 4.793882131576538, loss: 4.793882131576538 
Train [1/11] | Epoch [157/160] |	nca: 5.144459698349237, loss: 5.144459698349237 
Train [1/11] | Epoch [158/160] |	nca: 4.835824086330831, loss: 4.835824086330831 
Train [1/11] | Epoch [159/160] |	nca: 5.0165546126663685, loss: 5.0165546126663685 
Train [1/11] | Epoch [160/160] |	nca: 4.910076605156064, loss: 4.910076605156064 
after task
Building & updating memory.
after task
Eval on 0->50.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.753.
Current acc: {'total': 0.753, '00-09': 0.789, '10-19': 0.779, '20-29': 0.706, '30-39': 0.725, '40-49': 0.768}.
Avg inc acc top5: 0.938.
Current acc top5: {'total': 0.938}.
Forgetting: 0.0.
Cord metric: 0.75.
================Task 1 Start!================
Testing on False unseen tasks (max class = 55).
Set memory of size: 1000.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 1 Training!================
The training samples number: 3500
Train on 50->55.
train task
nb 3500.
Train [2/11] | Epoch [1/160] |	nca: 44.82924032211304, flat: 35.564167246222496, pod: 135.94865834712982, loss: 216.34206581115723 
Train [2/11] | Epoch [2/160] |	nca: 27.983812153339386, flat: 31.764069259166718, pod: 122.05134892463684, loss: 181.79923009872437 
Train [2/11] | Epoch [3/160] |	nca: 17.24539852142334, flat: 24.435089349746704, pod: 104.61998677253723, loss: 146.30047512054443 
Train [2/11] | Epoch [4/160] |	nca: 12.132884591817856, flat: 20.01362681388855, pod: 95.1768536567688, loss: 127.32336473464966 
Train [2/11] | Epoch [5/160] |	nca: 8.863678932189941, flat: 16.622351348400116, pod: 84.32834076881409, loss: 109.8143720626831 
Train [2/11] | Epoch [6/160] |	nca: 7.405658334493637, flat: 14.390776693820953, pod: 78.59159827232361, loss: 100.38803291320801 
Train [2/11] | Epoch [7/160] |	nca: 6.810374230146408, flat: 13.324071943759918, pod: 76.34859204292297, loss: 96.48303818702698 
Train [2/11] | Epoch [8/160] |	nca: 5.802192375063896, flat: 11.63117441534996, pod: 70.50201177597046, loss: 87.93537878990173 
Train [2/11] | Epoch [9/160] |	nca: 5.965537644922733, flat: 11.239669293165207, pod: 69.88247275352478, loss: 87.08767938613892 
Train [2/11] | Epoch [10/160] |	nca: 5.857330001890659, flat: 11.16130405664444, pod: 69.87495017051697, loss: 86.89358401298523 
Train [2/11] | Epoch [11/160] |	nca: 5.98348693549633, flat: 11.261560082435608, pod: 70.38826584815979, loss: 87.63331317901611 
Train [2/11] | Epoch [12/160] |	nca: 5.46498166769743, flat: 10.516379624605179, pod: 67.22330355644226, loss: 83.20466470718384 
Train [2/11] | Epoch [13/160] |	nca: 4.699228465557098, flat: 9.604820132255554, pod: 65.17894554138184, loss: 79.48299384117126 
Train [2/11] | Epoch [14/160] |	nca: 4.751695096492767, flat: 9.131677478551865, pod: 62.25266122817993, loss: 76.1360342502594 
Train [2/11] | Epoch [15/160] |	nca: 4.91766357421875, flat: 9.240451842546463, pod: 63.191598653793335, loss: 77.3497142791748 
Train [2/11] | Epoch [16/160] |	nca: 4.649460077285767, flat: 9.002542942762375, pod: 61.661887407302856, loss: 75.31389021873474 
Train [2/11] | Epoch [17/160] |	nca: 4.61829636991024, flat: 8.72948107123375, pod: 61.43311023712158, loss: 74.78088784217834 
Train [2/11] | Epoch [18/160] |	nca: 4.339715786278248, flat: 8.367326974868774, pod: 59.86055827140808, loss: 72.56760096549988 
Train [2/11] | Epoch [19/160] |	nca: 4.127044893801212, flat: 8.03088566660881, pod: 59.12067234516144, loss: 71.27860307693481 
Train [2/11] | Epoch [20/160] |	nca: 4.961996078491211, flat: 8.509198099374771, pod: 60.32738971710205, loss: 73.79858422279358 
Train [2/11] | Epoch [21/160] |	nca: 4.750367805361748, flat: 8.939926862716675, pod: 62.25025153160095, loss: 75.94054627418518 
Train [2/11] | Epoch [22/160] |	nca: 4.62252039834857, flat: 8.86511817574501, pod: 61.01174807548523, loss: 74.49938702583313 
Train [2/11] | Epoch [23/160] |	nca: 3.849928766489029, flat: 8.008318975567818, pod: 57.36428081989288, loss: 69.22252821922302 
Train [2/11] | Epoch [24/160] |	nca: 4.409502819180489, flat: 7.956587493419647, pod: 57.04044449329376, loss: 69.40653467178345 
Train [2/11] | Epoch [25/160] |	nca: 4.445312492549419, flat: 8.114200234413147, pod: 59.05085277557373, loss: 71.61036539077759 
Train [2/11] | Epoch [26/160] |	nca: 3.6631936877965927, flat: 7.717409059405327, pod: 57.463252782821655, loss: 68.84385561943054 
Train [2/11] | Epoch [27/160] |	nca: 4.412364482879639, flat: 7.74285951256752, pod: 57.79615819454193, loss: 69.95138239860535 
Train [2/11] | Epoch [28/160] |	nca: 5.427196159958839, flat: 8.974733412265778, pod: 61.34350919723511, loss: 75.74543857574463 
Train [2/11] | Epoch [29/160] |	nca: 4.95044819265604, flat: 8.694983959197998, pod: 60.75427746772766, loss: 74.3997094631195 
Train [2/11] | Epoch [30/160] |	nca: 3.5941643863916397, flat: 8.053660452365875, pod: 58.15180015563965, loss: 69.79962515830994 
Train [2/11] | Epoch [31/160] |	nca: 3.188393972814083, flat: 6.963725984096527, pod: 54.451157450675964, loss: 64.60327792167664 
Train [2/11] | Epoch [32/160] |	nca: 3.5430823490023613, flat: 6.833264127373695, pod: 53.377190709114075, loss: 63.75353717803955 
Train [2/11] | Epoch [33/160] |	nca: 3.62143861502409, flat: 6.617327198386192, pod: 52.5851114988327, loss: 62.82387709617615 
Train [2/11] | Epoch [34/160] |	nca: 4.405164428055286, flat: 7.847887262701988, pod: 56.88949453830719, loss: 69.14254641532898 
Train [2/11] | Epoch [35/160] |	nca: 4.284789681434631, flat: 8.249368101358414, pod: 59.120391488075256, loss: 71.65454936027527 
Train [2/11] | Epoch [36/160] |	nca: 3.361186094582081, flat: 7.336249560117722, pod: 56.36359763145447, loss: 67.06103372573853 
Train [2/11] | Epoch [37/160] |	nca: 3.4644620567560196, flat: 6.856811940670013, pod: 53.662498235702515, loss: 63.98377227783203 
Train [2/11] | Epoch [38/160] |	nca: 3.5256822295486927, flat: 7.0851216316223145, pod: 54.54384362697601, loss: 65.15464735031128 
Train [2/11] | Epoch [39/160] |	nca: 3.6056825257837772, flat: 6.483759179711342, pod: 51.74534332752228, loss: 61.83478498458862 
Train [2/11] | Epoch [40/160] |	nca: 3.6474244073033333, flat: 6.397374168038368, pod: 51.1671245098114, loss: 61.21192288398743 
Train [2/11] | Epoch [41/160] |	nca: 3.6004317179322243, flat: 6.949960812926292, pod: 53.75486946105957, loss: 64.30526185035706 
Train [2/11] | Epoch [42/160] |	nca: 3.652185909450054, flat: 7.120202913880348, pod: 54.46415567398071, loss: 65.23654437065125 
Train [2/11] | Epoch [43/160] |	nca: 3.8280493766069412, flat: 6.688505440950394, pod: 51.98613262176514, loss: 62.502687215805054 
Train [2/11] | Epoch [44/160] |	nca: 3.2542257457971573, flat: 6.825458765029907, pod: 54.56364917755127, loss: 64.64333438873291 
Train [2/11] | Epoch [45/160] |	nca: 3.671242654323578, flat: 6.739603891968727, pod: 52.967164278030396, loss: 63.378010272979736 
Train [2/11] | Epoch [46/160] |	nca: 3.868563711643219, flat: 6.814185410737991, pod: 53.55108940601349, loss: 64.23383808135986 
Train [2/11] | Epoch [47/160] |	nca: 4.2129379361867905, flat: 6.919972836971283, pod: 53.34901976585388, loss: 64.48193049430847 
Train [2/11] | Epoch [48/160] |	nca: 3.848718583583832, flat: 6.91586671769619, pod: 53.14263737201691, loss: 63.907222270965576 
Train [2/11] | Epoch [49/160] |	nca: 3.2456875778734684, flat: 6.124087676405907, pod: 50.20693647861481, loss: 59.576712131500244 
Train [2/11] | Epoch [50/160] |	nca: 3.5211034789681435, flat: 6.5475954711437225, pod: 51.03756546974182, loss: 61.10626435279846 
Train [2/11] | Epoch [51/160] |	nca: 3.2689571529626846, flat: 6.560736835002899, pod: 52.88651645183563, loss: 62.71621036529541 
Train [2/11] | Epoch [52/160] |	nca: 3.54439976811409, flat: 6.1337848752737045, pod: 49.84415686130524, loss: 59.52234089374542 
Train [2/11] | Epoch [53/160] |	nca: 3.7047023326158524, flat: 6.589313432574272, pod: 53.00812566280365, loss: 63.302141189575195 
Train [2/11] | Epoch [54/160] |	nca: 3.3415347635746, flat: 6.240467458963394, pod: 51.08266019821167, loss: 60.66466176509857 
Train [2/11] | Epoch [55/160] |	nca: 2.904127608984709, flat: 5.635703578591347, pod: 47.678255915641785, loss: 56.21808671951294 
Train [2/11] | Epoch [56/160] |	nca: 3.229574579745531, flat: 5.535203203558922, pod: 46.826594948768616, loss: 55.59137284755707 
Train [2/11] | Epoch [57/160] |	nca: 3.2828532606363297, flat: 5.945214822888374, pod: 48.734073638916016, loss: 57.96214151382446 
Train [2/11] | Epoch [58/160] |	nca: 3.526260055601597, flat: 5.938723295927048, pod: 48.30895233154297, loss: 57.7739360332489 
Train [2/11] | Epoch [59/160] |	nca: 3.351513843983412, flat: 5.977458104491234, pod: 48.931087017059326, loss: 58.26005935668945 
Train [2/11] | Epoch [60/160] |	nca: 3.2244792357087135, flat: 5.832951799035072, pod: 48.51533031463623, loss: 57.57276153564453 
Train [2/11] | Epoch [61/160] |	nca: 3.2734152525663376, flat: 5.7066972851753235, pod: 49.76285398006439, loss: 58.74296700954437 
Train [2/11] | Epoch [62/160] |	nca: 3.4997492246329784, flat: 5.860253393650055, pod: 48.530717730522156, loss: 57.8907208442688 
Train [2/11] | Epoch [63/160] |	nca: 3.8172149881720543, flat: 6.489305600523949, pod: 50.634658455848694, loss: 60.941179037094116 
Train [2/11] | Epoch [64/160] |	nca: 3.5281860902905464, flat: 6.360492616891861, pod: 51.56209599971771, loss: 61.450775146484375 
Train [2/11] | Epoch [65/160] |	nca: 3.1236728876829147, flat: 5.9277801513671875, pod: 49.194849371910095, loss: 58.24630284309387 
Train [2/11] | Epoch [66/160] |	nca: 3.2566198632121086, flat: 5.754544213414192, pod: 48.79515898227692, loss: 57.806323289871216 
Train [2/11] | Epoch [67/160] |	nca: 2.9939960837364197, flat: 5.528910890221596, pod: 47.356178522109985, loss: 55.87908577919006 
Train [2/11] | Epoch [68/160] |	nca: 2.737660028040409, flat: 5.228479623794556, pod: 47.30372393131256, loss: 55.26986348628998 
Train [2/11] | Epoch [69/160] |	nca: 3.2630420960485935, flat: 5.362624824047089, pod: 47.1109619140625, loss: 55.73662877082825 
Train [2/11] | Epoch [70/160] |	nca: 3.3221547454595566, flat: 5.5210007429122925, pod: 46.04599142074585, loss: 54.88914680480957 
Train [2/11] | Epoch [71/160] |	nca: 3.239521011710167, flat: 5.305622726678848, pod: 45.25967454910278, loss: 53.80481815338135 
Train [2/11] | Epoch [72/160] |	nca: 3.3129310309886932, flat: 5.5339262038469315, pod: 46.734970927238464, loss: 55.581827878952026 
Train [2/11] | Epoch [73/160] |	nca: 3.3623563572764397, flat: 5.4666189551353455, pod: 45.37020397186279, loss: 54.19917953014374 
Train [2/11] | Epoch [74/160] |	nca: 2.8917733393609524, flat: 5.083453550934792, pod: 44.619138956069946, loss: 52.59436595439911 
Train [2/11] | Epoch [75/160] |	nca: 2.550966300070286, flat: 4.778037890791893, pod: 43.85163903236389, loss: 51.18064320087433 
Train [2/11] | Epoch [76/160] |	nca: 3.0595228001475334, flat: 4.748090088367462, pod: 42.542625427246094, loss: 50.35023820400238 
Train [2/11] | Epoch [77/160] |	nca: 3.250359259545803, flat: 4.834336951375008, pod: 43.897780656814575, loss: 51.98247694969177 
Train [2/11] | Epoch [78/160] |	nca: 3.1250979639589787, flat: 5.094169348478317, pod: 44.80562949180603, loss: 53.02489733695984 
Train [2/11] | Epoch [79/160] |	nca: 2.9685986042022705, flat: 4.899743437767029, pod: 43.81995642185211, loss: 51.68829834461212 
Train [2/11] | Epoch [80/160] |	nca: 3.0170126743614674, flat: 5.089440226554871, pod: 45.713648200035095, loss: 53.82010114192963 
Train [2/11] | Epoch [81/160] |	nca: 2.666931789368391, flat: 4.591417849063873, pod: 42.19899380207062, loss: 49.45734345912933 
Train [2/11] | Epoch [82/160] |	nca: 2.9125551022589207, flat: 4.464703470468521, pod: 41.5582457780838, loss: 48.93550407886505 
Train [2/11] | Epoch [83/160] |	nca: 2.6239010617136955, flat: 4.474429711699486, pod: 41.43531548976898, loss: 48.53364646434784 
Train [2/11] | Epoch [84/160] |	nca: 2.6352344416081905, flat: 4.404990315437317, pod: 41.48965811729431, loss: 48.52988278865814 
Train [2/11] | Epoch [85/160] |	nca: 3.2245039120316505, flat: 4.395926535129547, pod: 41.164629101753235, loss: 48.785059571266174 
Train [2/11] | Epoch [86/160] |	nca: 3.2299302630126476, flat: 4.7081882655620575, pod: 42.53941261768341, loss: 50.47753083705902 
Train [2/11] | Epoch [87/160] |	nca: 2.795976486057043, flat: 4.394253179430962, pod: 41.681663393974304, loss: 48.87189316749573 
Train [2/11] | Epoch [88/160] |	nca: 2.911487776786089, flat: 4.208372712135315, pod: 40.894341349601746, loss: 48.01420199871063 
Train [2/11] | Epoch [89/160] |	nca: 2.749624289572239, flat: 4.365950420498848, pod: 40.587533831596375, loss: 47.70310866832733 
Train [2/11] | Epoch [90/160] |	nca: 2.6249134317040443, flat: 4.052668862044811, pod: 39.30526793003082, loss: 45.982850193977356 
Train [2/11] | Epoch [91/160] |	nca: 2.726627118885517, flat: 3.9972702711820602, pod: 38.61531448364258, loss: 45.33921158313751 
Train [2/11] | Epoch [92/160] |	nca: 2.955079674720764, flat: 4.326910197734833, pod: 40.43762266635895, loss: 47.71961236000061 
Train [2/11] | Epoch [93/160] |	nca: 2.840609073638916, flat: 4.1625189036130905, pod: 39.97437059879303, loss: 46.97749853134155 
Train [2/11] | Epoch [94/160] |	nca: 2.819347355514765, flat: 4.206138804554939, pod: 40.417561411857605, loss: 47.443047761917114 
Train [2/11] | Epoch [95/160] |	nca: 2.6376019194722176, flat: 3.8340338617563248, pod: 37.642788767814636, loss: 44.11442458629608 
Train [2/11] | Epoch [96/160] |	nca: 2.9417878463864326, flat: 3.895038314163685, pod: 37.76340854167938, loss: 44.600234627723694 
Train [2/11] | Epoch [97/160] |	nca: 3.0210966765880585, flat: 3.9915493726730347, pod: 38.16546058654785, loss: 45.17810678482056 
Train [2/11] | Epoch [98/160] |	nca: 2.6800436824560165, flat: 3.977051243185997, pod: 37.998592376708984, loss: 44.65568768978119 
Train [2/11] | Epoch [99/160] |	nca: 2.7994788959622383, flat: 3.9762587398290634, pod: 38.957178354263306, loss: 45.7329158782959 
Train [2/11] | Epoch [100/160] |	nca: 2.8331076093018055, flat: 3.9642261937260628, pod: 38.107064723968506, loss: 44.90439856052399 
Train [2/11] | Epoch [101/160] |	nca: 2.910873908549547, flat: 4.164409026503563, pod: 40.243316769599915, loss: 47.318599581718445 
Train [2/11] | Epoch [102/160] |	nca: 2.5108976289629936, flat: 3.7247473523020744, pod: 36.719194412231445, loss: 42.95483922958374 
Train [2/11] | Epoch [103/160] |	nca: 2.6192167475819588, flat: 3.3857269808650017, pod: 34.84823942184448, loss: 40.85318303108215 
Train [2/11] | Epoch [104/160] |	nca: 2.7779125943779945, flat: 3.685138814151287, pod: 35.93325352668762, loss: 42.396305441856384 
Train [2/11] | Epoch [105/160] |	nca: 2.730513785034418, flat: 3.5753764882683754, pod: 35.379380106925964, loss: 41.68527054786682 
Train [2/11] | Epoch [106/160] |	nca: 2.8011025190353394, flat: 3.5373334661126137, pod: 35.58461391925812, loss: 41.92304992675781 
Train [2/11] | Epoch [107/160] |	nca: 2.7003917172551155, flat: 3.5291591361165047, pod: 35.05945944786072, loss: 41.28901028633118 
Train [2/11] | Epoch [108/160] |	nca: 2.6599484346807003, flat: 3.377035766839981, pod: 34.595170378685, loss: 40.63215458393097 
Train [2/11] | Epoch [109/160] |	nca: 2.546900440007448, flat: 3.3334383964538574, pod: 34.15181219577789, loss: 40.032151222229004 
Train [2/11] | Epoch [110/160] |	nca: 2.4709849804639816, flat: 3.4335649833083153, pod: 34.712451815605164, loss: 40.61700212955475 
Train [2/11] | Epoch [111/160] |	nca: 2.4648387283086777, flat: 3.088993512094021, pod: 33.243093609809875, loss: 38.79692614078522 
Train [2/11] | Epoch [112/160] |	nca: 2.5855327397584915, flat: 3.250185787677765, pod: 33.279908418655396, loss: 39.11562705039978 
Train [2/11] | Epoch [113/160] |	nca: 2.5689728260040283, flat: 3.3006021603941917, pod: 34.85103237628937, loss: 40.72060739994049 
Train [2/11] | Epoch [114/160] |	nca: 2.960842300206423, flat: 3.2731514498591423, pod: 34.31566333770752, loss: 40.549657583236694 
Train [2/11] | Epoch [115/160] |	nca: 2.6935798563063145, flat: 3.3363339975476265, pod: 33.706767320632935, loss: 39.73668098449707 
Train [2/11] | Epoch [116/160] |	nca: 2.2870655208826065, flat: 3.127891793847084, pod: 33.289759039878845, loss: 38.704716086387634 
Train [2/11] | Epoch [117/160] |	nca: 2.835290662944317, flat: 3.1448622718453407, pod: 32.60156226158142, loss: 38.58171534538269 
Train [2/11] | Epoch [118/160] |	nca: 2.630864340811968, flat: 2.9536740109324455, pod: 31.58118450641632, loss: 37.16572332382202 
Train [2/11] | Epoch [119/160] |	nca: 2.3493525572121143, flat: 3.1715990751981735, pod: 32.90479516983032, loss: 38.42574691772461 
Train [2/11] | Epoch [120/160] |	nca: 2.4828792698681355, flat: 3.0528083443641663, pod: 32.770033836364746, loss: 38.305721163749695 
Train [2/11] | Epoch [121/160] |	nca: 2.5559544190764427, flat: 2.9056888446211815, pod: 31.43998384475708, loss: 36.90162765979767 
Train [2/11] | Epoch [122/160] |	nca: 2.2778709456324577, flat: 2.9348431304097176, pod: 32.27441143989563, loss: 37.487125515937805 
Train [2/11] | Epoch [123/160] |	nca: 2.379449062049389, flat: 2.7755225226283073, pod: 30.074835419654846, loss: 35.229806900024414 
Train [2/11] | Epoch [124/160] |	nca: 2.7835340686142445, flat: 2.759418874979019, pod: 30.505143880844116, loss: 36.048096895217896 
Train [2/11] | Epoch [125/160] |	nca: 2.372105985879898, flat: 2.8623406067490578, pod: 30.146840751171112, loss: 35.38128745555878 
Train [2/11] | Epoch [126/160] |	nca: 2.5132221207022667, flat: 2.7166786417365074, pod: 29.869496941566467, loss: 35.09939765930176 
Train [2/11] | Epoch [127/160] |	nca: 2.561065725982189, flat: 2.811797119677067, pod: 30.089150071144104, loss: 35.46201288700104 
Train [2/11] | Epoch [128/160] |	nca: 2.4226195104420185, flat: 2.7259714379906654, pod: 29.554952442646027, loss: 34.70354342460632 
Train [2/11] | Epoch [129/160] |	nca: 2.2725467644631863, flat: 2.6964856013655663, pod: 29.236357748508453, loss: 34.205389976501465 
Train [2/11] | Epoch [130/160] |	nca: 2.363890152424574, flat: 2.6734791919589043, pod: 29.077700078487396, loss: 34.11506927013397 
Train [2/11] | Epoch [131/160] |	nca: 2.240604404360056, flat: 2.5819103345274925, pod: 28.831334352493286, loss: 33.65384900569916 
Train [2/11] | Epoch [132/160] |	nca: 2.415293611586094, flat: 2.539994567632675, pod: 28.32372134923935, loss: 33.27900958061218 
Train [2/11] | Epoch [133/160] |	nca: 2.371340949088335, flat: 2.523021124303341, pod: 28.04158842563629, loss: 32.93595039844513 
Train [2/11] | Epoch [134/160] |	nca: 2.370696034282446, flat: 2.5775094479322433, pod: 28.503607630729675, loss: 33.45181322097778 
Train [2/11] | Epoch [135/160] |	nca: 2.5503136068582535, flat: 2.52772169560194, pod: 28.46916800737381, loss: 33.54720330238342 
Train [2/11] | Epoch [136/160] |	nca: 2.556899167597294, flat: 2.5820476561784744, pod: 28.56555026769638, loss: 33.70449709892273 
Train [2/11] | Epoch [137/160] |	nca: 2.153839636594057, flat: 2.6250303238630295, pod: 28.090006947517395, loss: 32.86887687444687 
Train [2/11] | Epoch [138/160] |	nca: 2.450639322400093, flat: 2.579113155603409, pod: 28.717374324798584, loss: 33.7471267580986 
Train [2/11] | Epoch [139/160] |	nca: 2.2460471838712692, flat: 2.4243273213505745, pod: 26.979512155056, loss: 31.64988672733307 
Train [2/11] | Epoch [140/160] |	nca: 2.1227050069719553, flat: 2.340082958340645, pod: 26.554734110832214, loss: 31.017522037029266 
Train [2/11] | Epoch [141/160] |	nca: 2.5636026971042156, flat: 2.3866686522960663, pod: 26.79683083295822, loss: 31.747102439403534 
Train [2/11] | Epoch [142/160] |	nca: 2.264402821660042, flat: 2.4107567369937897, pod: 27.113132297992706, loss: 31.788291811943054 
Train [2/11] | Epoch [143/160] |	nca: 2.227565247565508, flat: 2.3217445611953735, pod: 26.37828880548477, loss: 30.92759871482849 
Train [2/11] | Epoch [144/160] |	nca: 2.312747623771429, flat: 2.3835888504981995, pod: 26.59939330816269, loss: 31.295729398727417 
Train [2/11] | Epoch [145/160] |	nca: 2.255413055419922, flat: 2.343266636133194, pod: 26.352295756340027, loss: 30.95097541809082 
Train [2/11] | Epoch [146/160] |	nca: 2.310799863189459, flat: 2.3350740149617195, pod: 26.122542142868042, loss: 30.768416047096252 
Train [2/11] | Epoch [147/160] |	nca: 2.3887972608208656, flat: 2.2806561663746834, pod: 25.453633964061737, loss: 30.123087644577026 
Train [2/11] | Epoch [148/160] |	nca: 2.17287490516901, flat: 2.2781101167201996, pod: 25.456265151500702, loss: 29.907250344753265 
Train [2/11] | Epoch [149/160] |	nca: 2.3116962872445583, flat: 2.2937104776501656, pod: 25.98783153295517, loss: 30.593238472938538 
Train [2/11] | Epoch [150/160] |	nca: 2.3308077827095985, flat: 2.3137307912111282, pod: 25.646630704402924, loss: 30.291169345378876 
Train [2/11] | Epoch [151/160] |	nca: 2.2312406934797764, flat: 2.203705333173275, pod: 25.369265854358673, loss: 29.804211795330048 
Train [2/11] | Epoch [152/160] |	nca: 2.2857560887932777, flat: 2.234946347773075, pod: 25.459466695785522, loss: 29.98016905784607 
Train [2/11] | Epoch [153/160] |	nca: 2.250719364732504, flat: 2.213879130780697, pod: 24.9896342754364, loss: 29.454232692718506 
Train [2/11] | Epoch [154/160] |	nca: 2.4313190691173077, flat: 2.2233533039689064, pod: 25.38720452785492, loss: 30.04187673330307 
Train [2/11] | Epoch [155/160] |	nca: 2.321077670902014, flat: 2.2474657222628593, pod: 25.087041676044464, loss: 29.655584812164307 
Train [2/11] | Epoch [156/160] |	nca: 2.2066889703273773, flat: 2.257298670709133, pod: 25.448038935661316, loss: 29.912026703357697 
Train [2/11] | Epoch [157/160] |	nca: 2.4303029384464025, flat: 2.2776389345526695, pod: 24.886868000030518, loss: 29.594810009002686 
Train [2/11] | Epoch [158/160] |	nca: 2.1766847483813763, flat: 2.2434752732515335, pod: 25.085073113441467, loss: 29.505233228206635 
Train [2/11] | Epoch [159/160] |	nca: 2.2611093297600746, flat: 2.278898276388645, pod: 25.24970716238022, loss: 29.789714872837067 
Train [2/11] | Epoch [160/160] |	nca: 2.3540625981986523, flat: 2.245868541300297, pod: 25.06341326236725, loss: 29.663344621658325 
Fine-tuning
Building & updating memory.
Train [2/11] | Epoch [161/180] |	nca: 2.010902315378189, flat: 1.5270997434854507, pod: 13.153459429740906, loss: 16.691461443901062 
Train [2/11] | Epoch [162/180] |	nca: 1.1481474712491035, flat: 1.5876197069883347, pod: 13.413826704025269, loss: 16.149593949317932 
Train [2/11] | Epoch [163/180] |	nca: 0.7852595970034599, flat: 1.542619451880455, pod: 13.016262292861938, loss: 15.344141364097595 
Train [2/11] | Epoch [164/180] |	nca: 0.5502756163477898, flat: 1.5378828942775726, pod: 13.114659190177917, loss: 15.202817678451538 
Train [2/11] | Epoch [165/180] |	nca: 0.4831102229654789, flat: 1.5166374295949936, pod: 13.047391176223755, loss: 15.047138690948486 
Train [2/11] | Epoch [166/180] |	nca: 0.40969545766711235, flat: 1.5298236161470413, pod: 13.164478063583374, loss: 15.103996992111206 
Train [2/11] | Epoch [167/180] |	nca: 0.33223109506070614, flat: 1.537545882165432, pod: 13.066663146018982, loss: 14.936440229415894 
Train [2/11] | Epoch [168/180] |	nca: 0.3505383376032114, flat: 1.5727375820279121, pod: 13.369641184806824, loss: 15.292917132377625 
Train [2/11] | Epoch [169/180] |	nca: 0.36753025837242603, flat: 1.5297977924346924, pod: 13.040289759635925, loss: 14.937617897987366 
Train [2/11] | Epoch [170/180] |	nca: 0.316649092361331, flat: 1.5577968508005142, pod: 13.298542022705078, loss: 15.172987937927246 
Train [2/11] | Epoch [171/180] |	nca: 0.2932417895644903, flat: 1.5465068519115448, pod: 13.206814885139465, loss: 15.046563386917114 
Train [2/11] | Epoch [172/180] |	nca: 0.27879450283944607, flat: 1.5384601801633835, pod: 13.064788818359375, loss: 14.882043361663818 
Train [2/11] | Epoch [173/180] |	nca: 0.31303318962454796, flat: 1.5551658123731613, pod: 13.09240972995758, loss: 14.96060860157013 
Train [2/11] | Epoch [174/180] |	nca: 0.3259091265499592, flat: 1.5761182010173798, pod: 13.273940443992615, loss: 15.175967812538147 
Train [2/11] | Epoch [175/180] |	nca: 0.2473731879144907, flat: 1.602626085281372, pod: 13.241773128509521, loss: 15.091772317886353 
Train [2/11] | Epoch [176/180] |	nca: 0.25362782925367355, flat: 1.593400426208973, pod: 13.313276052474976, loss: 15.160304188728333 
Train [2/11] | Epoch [177/180] |	nca: 0.3040892668068409, flat: 1.534830242395401, pod: 13.005146384239197, loss: 14.84406590461731 
Train [2/11] | Epoch [178/180] |	nca: 0.2524478081613779, flat: 1.557325005531311, pod: 13.158844113349915, loss: 14.968616843223572 
Train [2/11] | Epoch [179/180] |	nca: 0.2621998805552721, flat: 1.5400429666042328, pod: 13.097411751747131, loss: 14.899654507637024 
Train [2/11] | Epoch [180/180] |	nca: 0.2628834471106529, flat: 1.5235255062580109, pod: 13.080174326896667, loss: 14.866583347320557 
after task
Building & updating memory.
after task
Eval on 0->55.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.735.
Current acc: {'total': 0.717, '00-09': 0.774, '10-19': 0.728, '20-29': 0.643, '30-39': 0.702, '40-49': 0.763, '50-59': 0.668}.
Avg inc acc top5: 0.9315.
Current acc top5: {'total': 0.925}.
Forgetting: -0.073.
Cord metric: 0.73.
Old accuracy: 0.72, mean: 0.72.
New accuracy: 0.67, mean: 0.67.
================Task 2 Start!================
Testing on False unseen tasks (max class = 60).
Set memory of size: 1100.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 2 Training!================
The training samples number: 3600
Train on 55->60.
train task
nb 3600.
Train [3/11] | Epoch [1/160] |	nca: 19.663272112607956, flat: 11.829906284809113, pod: 74.4938508272171, loss: 105.98702919483185 
Train [3/11] | Epoch [2/160] |	nca: 16.77483642101288, flat: 18.476925790309906, pod: 95.01429271697998, loss: 130.2660551071167 
Train [3/11] | Epoch [3/160] |	nca: 12.001768693327904, flat: 15.44840145111084, pod: 86.3286657333374, loss: 113.77883529663086 
Train [3/11] | Epoch [4/160] |	nca: 8.096274510025978, flat: 13.037174791097641, pod: 78.97598052024841, loss: 100.10943007469177 
Train [3/11] | Epoch [5/160] |	nca: 6.8213519006967545, flat: 10.469157606363297, pod: 72.88163208961487, loss: 90.17214131355286 
Train [3/11] | Epoch [6/160] |	nca: 7.056797981262207, flat: 11.0360749065876, pod: 73.90979862213135, loss: 92.00267028808594 
Train [3/11] | Epoch [7/160] |	nca: 4.9797574654221535, flat: 8.727435290813446, pod: 65.30387854576111, loss: 79.01107096672058 
Train [3/11] | Epoch [8/160] |	nca: 5.726088881492615, flat: 8.921681433916092, pod: 66.12408590316772, loss: 80.7718563079834 
Train [3/11] | Epoch [9/160] |	nca: 5.783279985189438, flat: 9.580859988927841, pod: 69.19165658950806, loss: 84.5557963848114 
Train [3/11] | Epoch [10/160] |	nca: 5.138123691082001, flat: 8.808926522731781, pod: 67.04985332489014, loss: 80.99690341949463 
Train [3/11] | Epoch [11/160] |	nca: 7.18111164867878, flat: 10.276311576366425, pod: 71.98982548713684, loss: 89.44724822044373 
Train [3/11] | Epoch [12/160] |	nca: 4.927369490265846, flat: 9.156175822019577, pod: 66.69254088401794, loss: 80.77608680725098 
Train [3/11] | Epoch [13/160] |	nca: 4.420688025653362, flat: 8.167949721217155, pod: 62.554319858551025, loss: 75.14295768737793 
Train [3/11] | Epoch [14/160] |	nca: 3.7373404279351234, flat: 7.039230480790138, pod: 58.831892251968384, loss: 69.60846328735352 
Train [3/11] | Epoch [15/160] |	nca: 4.441131144762039, flat: 7.864814639091492, pod: 62.648077964782715, loss: 74.95402407646179 
Train [3/11] | Epoch [16/160] |	nca: 5.218450918793678, flat: 8.076578572392464, pod: 62.448646664619446, loss: 75.74367570877075 
Train [3/11] | Epoch [17/160] |	nca: 3.9382188096642494, flat: 7.657024160027504, pod: 62.431164264678955, loss: 74.02640795707703 
Train [3/11] | Epoch [18/160] |	nca: 4.590453125536442, flat: 8.648945778608322, pod: 65.38982343673706, loss: 78.62922263145447 
Train [3/11] | Epoch [19/160] |	nca: 3.7446263805031776, flat: 7.108721852302551, pod: 60.31836724281311, loss: 71.17171549797058 
Train [3/11] | Epoch [20/160] |	nca: 4.153616148978472, flat: 7.459971129894257, pod: 61.641650676727295, loss: 73.2552375793457 
Train [3/11] | Epoch [21/160] |	nca: 3.917262740433216, flat: 6.3248162269592285, pod: 56.374258160591125, loss: 66.61633706092834 
Train [3/11] | Epoch [22/160] |	nca: 4.098696738481522, flat: 6.971726179122925, pod: 57.884018301963806, loss: 68.95444130897522 
Train [3/11] | Epoch [23/160] |	nca: 4.586258802562952, flat: 8.237467035651207, pod: 63.02082312107086, loss: 75.84454917907715 
Train [3/11] | Epoch [24/160] |	nca: 3.0838177129626274, flat: 6.365212291479111, pod: 55.15952730178833, loss: 64.60855722427368 
Train [3/11] | Epoch [25/160] |	nca: 3.0037586838006973, flat: 5.743721306324005, pod: 53.13092660903931, loss: 61.87840664386749 
Train [3/11] | Epoch [26/160] |	nca: 3.677924335002899, flat: 5.937822490930557, pod: 53.14763259887695, loss: 62.763378858566284 
Train [3/11] | Epoch [27/160] |	nca: 4.297467224299908, flat: 7.165563926100731, pod: 57.37364685535431, loss: 68.83667802810669 
Train [3/11] | Epoch [28/160] |	nca: 3.9339988231658936, flat: 7.360666409134865, pod: 59.53174149990082, loss: 70.826406955719 
Train [3/11] | Epoch [29/160] |	nca: 4.313443206250668, flat: 7.501048132777214, pod: 59.52171015739441, loss: 71.33620071411133 
Train [3/11] | Epoch [30/160] |	nca: 3.6582192108035088, flat: 6.836131080985069, pod: 58.240628361701965, loss: 68.7349784374237 
Train [3/11] | Epoch [31/160] |	nca: 3.4489663913846016, flat: 6.5658528208732605, pod: 55.58945310115814, loss: 65.60427188873291 
Train [3/11] | Epoch [32/160] |	nca: 3.76886934787035, flat: 7.3247809410095215, pod: 59.3332736492157, loss: 70.42692399024963 
Train [3/11] | Epoch [33/160] |	nca: 3.732560057193041, flat: 5.939598560333252, pod: 54.35993015766144, loss: 64.03208935260773 
Train [3/11] | Epoch [34/160] |	nca: 5.913007564842701, flat: 9.072820484638214, pod: 65.66318500041962, loss: 80.64901280403137 
Train [3/11] | Epoch [35/160] |	nca: 3.3990765661001205, flat: 6.817995756864548, pod: 57.09529185295105, loss: 67.31236457824707 
Train [3/11] | Epoch [36/160] |	nca: 3.701104074716568, flat: 6.188116207718849, pod: 54.11627793312073, loss: 64.00549864768982 
Train [3/11] | Epoch [37/160] |	nca: 3.323782503604889, flat: 5.931573644280434, pod: 53.10334241390228, loss: 62.35869872570038 
Train [3/11] | Epoch [38/160] |	nca: 3.4470940083265305, flat: 6.293778017163277, pod: 54.761093974113464, loss: 64.50196599960327 
Train [3/11] | Epoch [39/160] |	nca: 3.845708914101124, flat: 6.386780455708504, pod: 55.10878086090088, loss: 65.3412697315216 
Train [3/11] | Epoch [40/160] |	nca: 4.489538550376892, flat: 6.999139696359634, pod: 58.8610143661499, loss: 70.34969305992126 
Train [3/11] | Epoch [41/160] |	nca: 4.5936150178313255, flat: 7.856641978025436, pod: 60.805936336517334, loss: 73.25619268417358 
Train [3/11] | Epoch [42/160] |	nca: 5.723810084164143, flat: 8.94472049176693, pod: 65.00536608695984, loss: 79.67389607429504 
Train [3/11] | Epoch [43/160] |	nca: 3.586502969264984, flat: 6.989758625626564, pod: 57.55795156955719, loss: 68.13421320915222 
Train [3/11] | Epoch [44/160] |	nca: 3.937788374722004, flat: 7.200170606374741, pod: 59.67636048793793, loss: 70.8143196105957 
Train [3/11] | Epoch [45/160] |	nca: 2.848434466868639, flat: 6.068332061171532, pod: 54.41246140003204, loss: 63.329227924346924 
Train [3/11] | Epoch [46/160] |	nca: 2.786862000823021, flat: 5.686692908406258, pod: 50.906453013420105, loss: 59.38000810146332 
Train [3/11] | Epoch [47/160] |	nca: 2.6849564723670483, flat: 5.339562833309174, pod: 51.413089752197266, loss: 59.43760895729065 
Train [3/11] | Epoch [48/160] |	nca: 2.5215975120663643, flat: 4.633322522044182, pod: 46.3772189617157, loss: 53.53213918209076 
Train [3/11] | Epoch [49/160] |	nca: 3.502500481903553, flat: 5.699198752641678, pod: 52.64752113819122, loss: 61.84922003746033 
Train [3/11] | Epoch [50/160] |	nca: 2.566478345543146, flat: 5.1455312967300415, pod: 48.934492111206055, loss: 56.646501898765564 
Train [3/11] | Epoch [51/160] |	nca: 3.752835266292095, flat: 4.777263432741165, pod: 46.748602986335754, loss: 55.27870166301727 
Train [3/11] | Epoch [52/160] |	nca: 7.953950941562653, flat: 9.395989805459976, pod: 65.3380879163742, loss: 82.6880292892456 
Train [3/11] | Epoch [53/160] |	nca: 5.871066126972437, flat: 10.106467515230179, pod: 67.69625425338745, loss: 83.67378830909729 
Train [3/11] | Epoch [54/160] |	nca: 3.6577359959483147, flat: 7.027321025729179, pod: 58.07663679122925, loss: 68.7616937160492 
Train [3/11] | Epoch [55/160] |	nca: 3.922444272786379, flat: 6.950525119900703, pod: 57.01421868801117, loss: 67.88718843460083 
Train [3/11] | Epoch [56/160] |	nca: 2.903756771236658, flat: 6.318593889474869, pod: 54.31057286262512, loss: 63.53292369842529 
Train [3/11] | Epoch [57/160] |	nca: 2.756378561258316, flat: 5.251290798187256, pod: 49.44067859649658, loss: 57.44834816455841 
Train [3/11] | Epoch [58/160] |	nca: 4.554750025272369, flat: 6.671685069799423, pod: 54.081337213516235, loss: 65.30777215957642 
Train [3/11] | Epoch [59/160] |	nca: 5.385550260543823, flat: 8.192181393504143, pod: 61.410220980644226, loss: 74.987952709198 
Train [3/11] | Epoch [60/160] |	nca: 3.804649204015732, flat: 7.646383032202721, pod: 58.56288146972656, loss: 70.01391386985779 
Train [3/11] | Epoch [61/160] |	nca: 2.3383199498057365, flat: 5.5728906244039536, pod: 50.550594329833984, loss: 58.46180522441864 
Train [3/11] | Epoch [62/160] |	nca: 2.7475279681384563, flat: 4.956383898854256, pod: 47.832568287849426, loss: 55.53648018836975 
Train [3/11] | Epoch [63/160] |	nca: 3.7024972066283226, flat: 5.777936026453972, pod: 51.54643654823303, loss: 61.026869893074036 
Train [3/11] | Epoch [64/160] |	nca: 3.3462833166122437, flat: 6.008678153157234, pod: 52.334402322769165, loss: 61.689363956451416 
Train [3/11] | Epoch [65/160] |	nca: 2.473129276186228, flat: 4.8318919986486435, pod: 46.86831092834473, loss: 54.17333197593689 
Train [3/11] | Epoch [66/160] |	nca: 2.8698899187147617, flat: 4.968221053481102, pod: 48.12303149700165, loss: 55.96114218235016 
Train [3/11] | Epoch [67/160] |	nca: 3.868925467133522, flat: 5.893228635191917, pod: 51.71809995174408, loss: 61.48025405406952 
Train [3/11] | Epoch [68/160] |	nca: 3.9446349777281284, flat: 6.504253759980202, pod: 54.80793297290802, loss: 65.25682199001312 
Train [3/11] | Epoch [69/160] |	nca: 2.7193386517465115, flat: 5.330513909459114, pod: 49.28787636756897, loss: 57.3377286195755 
Train [3/11] | Epoch [70/160] |	nca: 2.9504030011594296, flat: 4.861885130405426, pod: 47.43463218212128, loss: 55.246920108795166 
Train [3/11] | Epoch [71/160] |	nca: 3.0426776111125946, flat: 5.201692447066307, pod: 48.0904278755188, loss: 56.33479833602905 
Train [3/11] | Epoch [72/160] |	nca: 3.7353504672646523, flat: 6.125027105212212, pod: 54.142115235328674, loss: 64.00249242782593 
Train [3/11] | Epoch [73/160] |	nca: 2.8276645317673683, flat: 5.1694993525743484, pod: 48.71165978908539, loss: 56.70882332324982 
Train [3/11] | Epoch [74/160] |	nca: 2.663164548575878, flat: 4.694157376885414, pod: 46.57120716571808, loss: 53.928528904914856 
Train [3/11] | Epoch [75/160] |	nca: 2.8507954627275467, flat: 5.177073836326599, pod: 49.022653460502625, loss: 57.050522446632385 
Train [3/11] | Epoch [76/160] |	nca: 2.619898620992899, flat: 4.194403439760208, pod: 43.547765493392944, loss: 50.362067341804504 
Train [3/11] | Epoch [77/160] |	nca: 3.3181427381932735, flat: 4.741298198699951, pod: 45.70390963554382, loss: 53.76335060596466 
Train [3/11] | Epoch [78/160] |	nca: 2.762139167636633, flat: 4.738859593868256, pod: 47.40294408798218, loss: 54.903942584991455 
Train [3/11] | Epoch [79/160] |	nca: 2.6647122651338577, flat: 4.1383926793932915, pod: 43.63037347793579, loss: 50.433478474617004 
Train [3/11] | Epoch [80/160] |	nca: 2.8835449032485485, flat: 4.5030278116464615, pod: 45.95276176929474, loss: 53.33933460712433 
Train [3/11] | Epoch [81/160] |	nca: 2.6764921098947525, flat: 4.311047255992889, pod: 44.57568085193634, loss: 51.563220143318176 
Train [3/11] | Epoch [82/160] |	nca: 2.5675057768821716, flat: 3.8106440007686615, pod: 42.097288846969604, loss: 48.475438714027405 
Train [3/11] | Epoch [83/160] |	nca: 2.5384982749819756, flat: 3.874431885778904, pod: 42.372570633888245, loss: 48.7855007648468 
Train [3/11] | Epoch [84/160] |	nca: 2.7562422789633274, flat: 3.815872199833393, pod: 42.70608592033386, loss: 49.278200507164 
Train [3/11] | Epoch [85/160] |	nca: 3.7857462018728256, flat: 5.127304092049599, pod: 46.8609561920166, loss: 55.774006605148315 
Train [3/11] | Epoch [86/160] |	nca: 3.3759414963424206, flat: 4.855626821517944, pod: 46.41170954704285, loss: 54.643277406692505 
Train [3/11] | Epoch [87/160] |	nca: 2.906820837408304, flat: 4.612332716584206, pod: 44.33353579044342, loss: 51.85268950462341 
Train [3/11] | Epoch [88/160] |	nca: 2.2372867055237293, flat: 3.8182702511548996, pod: 42.0686811208725, loss: 48.12423849105835 
Train [3/11] | Epoch [89/160] |	nca: 2.3286079317331314, flat: 3.5902398973703384, pod: 40.20671772956848, loss: 46.12556517124176 
Train [3/11] | Epoch [90/160] |	nca: 3.0524114817380905, flat: 4.175730317831039, pod: 43.19576013088226, loss: 50.42390191555023 
Train [3/11] | Epoch [91/160] |	nca: 2.8515129536390305, flat: 4.578945949673653, pod: 45.82341754436493, loss: 53.25387680530548 
Train [3/11] | Epoch [92/160] |	nca: 2.4835116788744926, flat: 3.8277448788285255, pod: 42.06420302391052, loss: 48.37545955181122 
Train [3/11] | Epoch [93/160] |	nca: 2.892003946006298, flat: 3.8979308158159256, pod: 41.51771628856659, loss: 48.30765080451965 
Train [3/11] | Epoch [94/160] |	nca: 2.7928846701979637, flat: 4.091542102396488, pod: 42.128297328948975, loss: 49.01272404193878 
Train [3/11] | Epoch [95/160] |	nca: 2.7116259336471558, flat: 4.351456992328167, pod: 44.280545473098755, loss: 51.34362840652466 
Train [3/11] | Epoch [96/160] |	nca: 2.2940789945423603, flat: 3.5635402277112007, pod: 39.98430323600769, loss: 45.84192216396332 
Train [3/11] | Epoch [97/160] |	nca: 2.1300990153104067, flat: 3.233080133795738, pod: 37.481449127197266, loss: 42.8446284532547 
Train [3/11] | Epoch [98/160] |	nca: 2.4087899439036846, flat: 3.1609547659754753, pod: 37.59711956977844, loss: 43.1668643951416 
Train [3/11] | Epoch [99/160] |	nca: 2.848488099873066, flat: 3.2177321910858154, pod: 38.31268644332886, loss: 44.378907203674316 
Train [3/11] | Epoch [100/160] |	nca: 2.7784048430621624, flat: 3.9479363411664963, pod: 42.14674890041351, loss: 48.87309014797211 
Train [3/11] | Epoch [101/160] |	nca: 2.7883459329605103, flat: 3.562294125556946, pod: 39.28877007961273, loss: 45.63941025733948 
Train [3/11] | Epoch [102/160] |	nca: 2.9038517735898495, flat: 3.5912110432982445, pod: 39.33747851848602, loss: 45.83254134654999 
Train [3/11] | Epoch [103/160] |	nca: 2.4431981295347214, flat: 3.117236867547035, pod: 35.545501828193665, loss: 41.1059365272522 
Train [3/11] | Epoch [104/160] |	nca: 2.448013175278902, flat: 3.2709391117095947, pod: 38.445372462272644, loss: 44.16432476043701 
Train [3/11] | Epoch [105/160] |	nca: 2.3181001655757427, flat: 3.143354758620262, pod: 36.55731546878815, loss: 42.01877057552338 
Train [3/11] | Epoch [106/160] |	nca: 2.4264179803431034, flat: 2.925748534500599, pod: 35.13020384311676, loss: 40.48237061500549 
Train [3/11] | Epoch [107/160] |	nca: 2.5564339347183704, flat: 3.4609385430812836, pod: 38.75747203826904, loss: 44.77484428882599 
Train [3/11] | Epoch [108/160] |	nca: 2.30993165820837, flat: 2.9992445930838585, pod: 36.46853756904602, loss: 41.777713894844055 
Train [3/11] | Epoch [109/160] |	nca: 2.5386630557477474, flat: 3.184169866144657, pod: 37.07480573654175, loss: 42.79763889312744 
Train [3/11] | Epoch [110/160] |	nca: 2.265931360423565, flat: 3.0673254653811455, pod: 35.50341057777405, loss: 40.83666753768921 
Train [3/11] | Epoch [111/160] |	nca: 2.391491450369358, flat: 3.144785389304161, pod: 35.64493405818939, loss: 41.18121075630188 
Train [3/11] | Epoch [112/160] |	nca: 2.508658330887556, flat: 2.836941957473755, pod: 34.70724666118622, loss: 40.05284667015076 
Train [3/11] | Epoch [113/160] |	nca: 2.848225139081478, flat: 3.152740180492401, pod: 35.823675751686096, loss: 41.82464110851288 
Train [3/11] | Epoch [114/160] |	nca: 2.1290155313909054, flat: 2.7823876589536667, pod: 34.71732544898987, loss: 39.62872850894928 
Train [3/11] | Epoch [115/160] |	nca: 2.5147475972771645, flat: 2.7124639824032784, pod: 33.59840768575668, loss: 38.82561910152435 
Train [3/11] | Epoch [116/160] |	nca: 2.315086964517832, flat: 2.9062823057174683, pod: 34.37702387571335, loss: 39.59839308261871 
Train [3/11] | Epoch [117/160] |	nca: 2.3122757114470005, flat: 2.5464977994561195, pod: 31.98245197534561, loss: 36.84122550487518 
Train [3/11] | Epoch [118/160] |	nca: 2.8304053992033005, flat: 2.903656169772148, pod: 34.92337501049042, loss: 40.65743637084961 
Train [3/11] | Epoch [119/160] |	nca: 2.391837865114212, flat: 2.7923783510923386, pod: 33.17761421203613, loss: 38.3618301153183 
Train [3/11] | Epoch [120/160] |	nca: 2.360315255820751, flat: 2.740893989801407, pod: 32.976091265678406, loss: 38.077300667762756 
Train [3/11] | Epoch [121/160] |	nca: 2.241890512406826, flat: 2.5143329352140427, pod: 31.426447808742523, loss: 36.18267107009888 
Train [3/11] | Epoch [122/160] |	nca: 2.128119334578514, flat: 2.4752391427755356, pod: 31.8622807264328, loss: 36.46563923358917 
Train [3/11] | Epoch [123/160] |	nca: 2.180471945554018, flat: 2.4741910696029663, pod: 31.960453927516937, loss: 36.6151168346405 
Train [3/11] | Epoch [124/160] |	nca: 2.157300475984812, flat: 2.448816068470478, pod: 30.87244462966919, loss: 35.4785612821579 
Train [3/11] | Epoch [125/160] |	nca: 2.2641186825931072, flat: 2.4433955028653145, pod: 31.291407763957977, loss: 35.9989218711853 
Train [3/11] | Epoch [126/160] |	nca: 2.104332607239485, flat: 2.3042315244674683, pod: 30.557045459747314, loss: 34.965609550476074 
Train [3/11] | Epoch [127/160] |	nca: 2.1128400042653084, flat: 2.205881278961897, pod: 28.69945251941681, loss: 33.018173575401306 
Train [3/11] | Epoch [128/160] |	nca: 2.424544036388397, flat: 2.3777434676885605, pod: 29.607169449329376, loss: 34.409457206726074 
Train [3/11] | Epoch [129/160] |	nca: 2.083567403256893, flat: 2.3497460782527924, pod: 29.884432911872864, loss: 34.31774652004242 
Train [3/11] | Epoch [130/160] |	nca: 2.3454738445580006, flat: 2.2469507455825806, pod: 29.123200058937073, loss: 33.71562474966049 
Train [3/11] | Epoch [131/160] |	nca: 2.2948130443692207, flat: 2.2270151898264885, pod: 28.362957894802094, loss: 32.88478630781174 
Train [3/11] | Epoch [132/160] |	nca: 2.158167339861393, flat: 2.254354901611805, pod: 28.684853315353394, loss: 33.09737581014633 
Train [3/11] | Epoch [133/160] |	nca: 2.1178159303963184, flat: 2.145171418786049, pod: 28.06361812353134, loss: 32.32660531997681 
Train [3/11] | Epoch [134/160] |	nca: 2.39761696010828, flat: 2.205808997154236, pod: 28.28970843553543, loss: 32.89313465356827 
Train [3/11] | Epoch [135/160] |	nca: 2.519590876996517, flat: 2.2819413542747498, pod: 29.131906747817993, loss: 33.93343883752823 
Train [3/11] | Epoch [136/160] |	nca: 2.34004720300436, flat: 2.380048755556345, pod: 29.441307306289673, loss: 34.16140305995941 
Train [3/11] | Epoch [137/160] |	nca: 2.466330476105213, flat: 2.128860004246235, pod: 27.473531424999237, loss: 32.06872206926346 
Train [3/11] | Epoch [138/160] |	nca: 2.4162309169769287, flat: 2.1575116962194443, pod: 27.441366136074066, loss: 32.01510852575302 
Train [3/11] | Epoch [139/160] |	nca: 2.2208228334784508, flat: 2.211513914167881, pod: 28.02058631181717, loss: 32.4529230594635 
Train [3/11] | Epoch [140/160] |	nca: 2.1820967756211758, flat: 2.1489600762724876, pod: 27.979000508785248, loss: 32.310057640075684 
Train [3/11] | Epoch [141/160] |	nca: 2.0986429043114185, flat: 2.121192891150713, pod: 28.182943642139435, loss: 32.40277934074402 
Train [3/11] | Epoch [142/160] |	nca: 2.2479744032025337, flat: 2.0149045512080193, pod: 26.558294415473938, loss: 30.821173667907715 
Train [3/11] | Epoch [143/160] |	nca: 2.1013621632009745, flat: 2.069121364504099, pod: 26.685323238372803, loss: 30.85580664873123 
Train [3/11] | Epoch [144/160] |	nca: 2.0907306261360645, flat: 2.043134767562151, pod: 26.81434404850006, loss: 30.94820934534073 
Train [3/11] | Epoch [145/160] |	nca: 2.2771445624530315, flat: 1.9548542350530624, pod: 25.59996271133423, loss: 29.8319610953331 
Train [3/11] | Epoch [146/160] |	nca: 2.1653108410537243, flat: 1.9775597602128983, pod: 26.398937106132507, loss: 30.54180783033371 
Train [3/11] | Epoch [147/160] |	nca: 2.078110074624419, flat: 1.992040615528822, pod: 26.44685959815979, loss: 30.517010509967804 
Train [3/11] | Epoch [148/160] |	nca: 2.2332432456314564, flat: 1.9633645825088024, pod: 26.09319430589676, loss: 30.289802134037018 
Train [3/11] | Epoch [149/160] |	nca: 2.064185496419668, flat: 1.9593886509537697, pod: 25.61998164653778, loss: 29.64355570077896 
Train [3/11] | Epoch [150/160] |	nca: 2.130663935095072, flat: 1.9672173149883747, pod: 25.951293349266052, loss: 30.049174547195435 
Train [3/11] | Epoch [151/160] |	nca: 2.269512500613928, flat: 2.066432997584343, pod: 26.966024577617645, loss: 31.30197012424469 
Train [3/11] | Epoch [152/160] |	nca: 2.122674074023962, flat: 1.9770249091088772, pod: 25.995332181453705, loss: 30.095031142234802 
Train [3/11] | Epoch [153/160] |	nca: 1.9360599741339684, flat: 1.9142316728830338, pod: 25.23619371652603, loss: 29.08648544549942 
Train [3/11] | Epoch [154/160] |	nca: 2.3336880169808865, flat: 1.9521486088633537, pod: 25.104387760162354, loss: 29.39022433757782 
Train [3/11] | Epoch [155/160] |	nca: 1.891469195485115, flat: 1.9341593347489834, pod: 25.08996081352234, loss: 28.915589213371277 
Train [3/11] | Epoch [156/160] |	nca: 1.942900139838457, flat: 1.8576574251055717, pod: 24.805670976638794, loss: 28.606228351593018 
Train [3/11] | Epoch [157/160] |	nca: 2.266414277255535, flat: 1.9036907814443111, pod: 24.803862750530243, loss: 28.973967730998993 
Train [3/11] | Epoch [158/160] |	nca: 2.1424065940082073, flat: 1.8322464190423489, pod: 24.531129121780396, loss: 28.50578200817108 
Train [3/11] | Epoch [159/160] |	nca: 2.4604035951197147, flat: 1.9102195315063, pod: 24.896510362625122, loss: 29.267133235931396 
Train [3/11] | Epoch [160/160] |	nca: 1.9907467849552631, flat: 1.8344425968825817, pod: 24.317070364952087, loss: 28.14225995540619 
Fine-tuning
Building & updating memory.
Train [3/11] | Epoch [161/180] |	nca: 2.115218460559845, flat: 1.1995838731527328, pod: 13.759147644042969, loss: 17.073949813842773 
Train [3/11] | Epoch [162/180] |	nca: 1.1089847385883331, flat: 1.2080393135547638, pod: 13.975450158119202, loss: 16.292474389076233 
Train [3/11] | Epoch [163/180] |	nca: 0.763876523822546, flat: 1.1971810832619667, pod: 13.943926692008972, loss: 15.90498423576355 
Train [3/11] | Epoch [164/180] |	nca: 0.6318934895098209, flat: 1.1570596992969513, pod: 13.739261627197266, loss: 15.528214812278748 
Train [3/11] | Epoch [165/180] |	nca: 0.5104645825922489, flat: 1.1729040145874023, pod: 14.002684235572815, loss: 15.686052799224854 
Train [3/11] | Epoch [166/180] |	nca: 0.48764484375715256, flat: 1.212143249809742, pod: 14.016092658042908, loss: 15.715880870819092 
Train [3/11] | Epoch [167/180] |	nca: 0.44728485122323036, flat: 1.187674768269062, pod: 14.006443738937378, loss: 15.641403555870056 
Train [3/11] | Epoch [168/180] |	nca: 0.5625133328139782, flat: 1.1763215884566307, pod: 13.9420747756958, loss: 15.680909514427185 
Train [3/11] | Epoch [169/180] |	nca: 0.4528562091290951, flat: 1.1908055916428566, pod: 14.027320384979248, loss: 15.670982241630554 
Train [3/11] | Epoch [170/180] |	nca: 0.4778999574482441, flat: 1.2038158848881721, pod: 13.956886053085327, loss: 15.638601899147034 
Train [3/11] | Epoch [171/180] |	nca: 0.49365038610994816, flat: 1.171373963356018, pod: 13.756165742874146, loss: 15.42119026184082 
Train [3/11] | Epoch [172/180] |	nca: 0.44353879801928997, flat: 1.1929780766367912, pod: 13.91622519493103, loss: 15.552742004394531 
Train [3/11] | Epoch [173/180] |	nca: 0.41763706877827644, flat: 1.2181346341967583, pod: 13.995248675346375, loss: 15.631020665168762 
Train [3/11] | Epoch [174/180] |	nca: 0.36245109885931015, flat: 1.1765294522047043, pod: 13.846338391304016, loss: 15.385319113731384 
Train [3/11] | Epoch [175/180] |	nca: 0.4279487356543541, flat: 1.1991485580801964, pod: 13.96985650062561, loss: 15.596953630447388 
Train [3/11] | Epoch [176/180] |	nca: 0.43951319716870785, flat: 1.1870282962918282, pod: 13.814046859741211, loss: 15.440588355064392 
Train [3/11] | Epoch [177/180] |	nca: 0.37927551940083504, flat: 1.236867792904377, pod: 14.030054569244385, loss: 15.64619779586792 
Train [3/11] | Epoch [178/180] |	nca: 0.3599691018462181, flat: 1.197563886642456, pod: 13.772308349609375, loss: 15.329841494560242 
Train [3/11] | Epoch [179/180] |	nca: 0.36901164427399635, flat: 1.2315458804368973, pod: 14.209904789924622, loss: 15.810462355613708 
Train [3/11] | Epoch [180/180] |	nca: 0.39285300113260746, flat: 1.1783850863575935, pod: 14.16069221496582, loss: 15.731930375099182 
after task
Building & updating memory.
after task
Eval on 0->60.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.721.
Current acc: {'total': 0.693, '00-09': 0.756, '10-19': 0.709, '20-29': 0.634, '30-39': 0.666, '40-49': 0.717, '50-59': 0.675}.
Avg inc acc top5: 0.9236666666666666.
Current acc top5: {'total': 0.908}.
Forgetting: 0.039714285714285716.
Cord metric: 0.72.
Old accuracy: 0.69, mean: 0.71.
New accuracy: 0.72, mean: 0.70.
================Task 3 Start!================
Testing on False unseen tasks (max class = 65).
Set memory of size: 1200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 3 Training!================
The training samples number: 3700
Train on 60->65.
train task
nb 3700.
Train [4/11] | Epoch [1/160] |	nca: 31.44472187757492, flat: 11.300397038459778, pod: 74.30024135112762, loss: 117.0453588962555 
Train [4/11] | Epoch [2/160] |	nca: 19.495487451553345, flat: 12.364865332841873, pod: 80.37715792655945, loss: 112.2375111579895 
Train [4/11] | Epoch [3/160] |	nca: 15.652141004800797, flat: 10.299244940280914, pod: 73.08353924751282, loss: 99.03492546081543 
Train [4/11] | Epoch [4/160] |	nca: 12.745969027280807, flat: 8.775233328342438, pod: 68.21321511268616, loss: 89.73441791534424 
Train [4/11] | Epoch [5/160] |	nca: 11.154612362384796, flat: 8.02581176161766, pod: 64.742356300354, loss: 83.92278122901917 
Train [4/11] | Epoch [6/160] |	nca: 10.026804208755493, flat: 7.271278351545334, pod: 61.09376394748688, loss: 78.39184617996216 
Train [4/11] | Epoch [7/160] |	nca: 10.702148273587227, flat: 7.554482862353325, pod: 63.00595688819885, loss: 81.26258778572083 
Train [4/11] | Epoch [8/160] |	nca: 9.3528333902359, flat: 7.253547728061676, pod: 61.41660130023956, loss: 78.02298212051392 
Train [4/11] | Epoch [9/160] |	nca: 9.005788818001747, flat: 6.888818457722664, pod: 59.02910375595093, loss: 74.92371106147766 
Train [4/11] | Epoch [10/160] |	nca: 8.63156607747078, flat: 6.813059583306313, pod: 58.72405230998993, loss: 74.1686782836914 
Train [4/11] | Epoch [11/160] |	nca: 8.545375347137451, flat: 6.909681260585785, pod: 59.49789643287659, loss: 74.95295286178589 
Train [4/11] | Epoch [12/160] |	nca: 8.032889783382416, flat: 6.747827261686325, pod: 58.59209632873535, loss: 73.37281274795532 
Train [4/11] | Epoch [13/160] |	nca: 8.573261052370071, flat: 7.074050158262253, pod: 59.645426988601685, loss: 75.29273867607117 
Train [4/11] | Epoch [14/160] |	nca: 7.473126903176308, flat: 6.912051647901535, pod: 59.893203020095825, loss: 74.27838110923767 
Train [4/11] | Epoch [15/160] |	nca: 7.816541597247124, flat: 6.788839727640152, pod: 58.46708273887634, loss: 73.07246422767639 
Train [4/11] | Epoch [16/160] |	nca: 7.975130498409271, flat: 6.8926737159490585, pod: 58.899689078330994, loss: 73.76749300956726 
Train [4/11] | Epoch [17/160] |	nca: 6.901643320918083, flat: 6.5212521106004715, pod: 58.211098313331604, loss: 71.63399362564087 
Train [4/11] | Epoch [18/160] |	nca: 7.657833144068718, flat: 6.912606969475746, pod: 60.204487562179565, loss: 74.77492833137512 
Train [4/11] | Epoch [19/160] |	nca: 7.425398871302605, flat: 6.904837936162949, pod: 59.791370034217834, loss: 74.12160658836365 
Train [4/11] | Epoch [20/160] |	nca: 7.3111032992601395, flat: 6.884002432227135, pod: 58.60595786571503, loss: 72.80106401443481 
Train [4/11] | Epoch [21/160] |	nca: 6.304329551756382, flat: 6.4469935297966, pod: 57.16469967365265, loss: 69.91602301597595 
Train [4/11] | Epoch [22/160] |	nca: 6.142594695091248, flat: 6.417263522744179, pod: 56.861202239990234, loss: 69.42106032371521 
Train [4/11] | Epoch [23/160] |	nca: 7.057529106736183, flat: 6.41773484647274, pod: 56.94904696941376, loss: 70.42431092262268 
Train [4/11] | Epoch [24/160] |	nca: 6.820769876241684, flat: 6.47072733938694, pod: 57.64581060409546, loss: 70.93730783462524 
Train [4/11] | Epoch [25/160] |	nca: 6.602341756224632, flat: 6.795265018939972, pod: 58.64741098880768, loss: 72.04501700401306 
Train [4/11] | Epoch [26/160] |	nca: 6.772145569324493, flat: 6.519603535532951, pod: 56.72996473312378, loss: 70.02171444892883 
Train [4/11] | Epoch [27/160] |	nca: 6.5438298135995865, flat: 6.543735921382904, pod: 56.89490568637848, loss: 69.98247170448303 
Train [4/11] | Epoch [28/160] |	nca: 6.743977636098862, flat: 6.514424040913582, pod: 56.63015055656433, loss: 69.88855266571045 
Train [4/11] | Epoch [29/160] |	nca: 6.376990616321564, flat: 6.478373676538467, pod: 57.78143858909607, loss: 70.636803150177 
Train [4/11] | Epoch [30/160] |	nca: 6.201905012130737, flat: 6.434497743844986, pod: 57.40589773654938, loss: 70.0423002243042 
Train [4/11] | Epoch [31/160] |	nca: 5.485081009566784, flat: 5.935387432575226, pod: 54.912578105926514, loss: 66.3330466747284 
Train [4/11] | Epoch [32/160] |	nca: 5.915436118841171, flat: 5.8148336708545685, pod: 53.87491238117218, loss: 65.60518217086792 
Train [4/11] | Epoch [33/160] |	nca: 5.989173039793968, flat: 6.018784284591675, pod: 54.81737804412842, loss: 66.82533621788025 
Train [4/11] | Epoch [34/160] |	nca: 6.1619713306427, flat: 6.0591845363378525, pod: 55.28410565853119, loss: 67.50526165962219 
Train [4/11] | Epoch [35/160] |	nca: 5.94531711935997, flat: 6.05247263610363, pod: 55.520543336868286, loss: 67.51833319664001 
Train [4/11] | Epoch [36/160] |	nca: 6.03336238861084, flat: 6.00667068362236, pod: 54.977192878723145, loss: 67.01722621917725 
Train [4/11] | Epoch [37/160] |	nca: 5.780005648732185, flat: 5.87995120882988, pod: 54.38999617099762, loss: 66.04995274543762 
Train [4/11] | Epoch [38/160] |	nca: 6.033622771501541, flat: 6.04620324075222, pod: 55.81673741340637, loss: 67.89656352996826 
Train [4/11] | Epoch [39/160] |	nca: 5.667725130915642, flat: 6.027627468109131, pod: 54.86974537372589, loss: 66.56509780883789 
Train [4/11] | Epoch [40/160] |	nca: 6.115976877510548, flat: 6.072790011763573, pod: 55.473543763160706, loss: 67.66231060028076 
Train [4/11] | Epoch [41/160] |	nca: 6.330761477351189, flat: 6.214973971247673, pod: 55.74981701374054, loss: 68.29555225372314 
Train [4/11] | Epoch [42/160] |	nca: 5.720452219247818, flat: 6.136410668492317, pod: 55.739107608795166, loss: 67.59597110748291 
Train [4/11] | Epoch [43/160] |	nca: 5.5524027943611145, flat: 5.982546478509903, pod: 55.26013100147247, loss: 66.79508090019226 
Train [4/11] | Epoch [44/160] |	nca: 5.435589134693146, flat: 5.72899317741394, pod: 52.38908660411835, loss: 63.553669452667236 
Train [4/11] | Epoch [45/160] |	nca: 5.701770663261414, flat: 5.7523621916770935, pod: 53.62588393688202, loss: 65.08001661300659 
Train [4/11] | Epoch [46/160] |	nca: 5.828972287476063, flat: 5.775145813822746, pod: 54.289023637771606, loss: 65.89314222335815 
Train [4/11] | Epoch [47/160] |	nca: 5.460020795464516, flat: 5.600213065743446, pod: 52.94383502006531, loss: 64.00406908988953 
Train [4/11] | Epoch [48/160] |	nca: 5.972689546644688, flat: 5.733953058719635, pod: 54.435433864593506, loss: 66.14207625389099 
Train [4/11] | Epoch [49/160] |	nca: 5.414357110857964, flat: 5.706805646419525, pod: 53.73791229724884, loss: 64.85907506942749 
Train [4/11] | Epoch [50/160] |	nca: 5.440876744687557, flat: 5.328281909227371, pod: 51.03051054477692, loss: 61.79966878890991 
Train [4/11] | Epoch [51/160] |	nca: 5.516933351755142, flat: 5.5470031052827835, pod: 52.322802901268005, loss: 63.38673973083496 
Train [4/11] | Epoch [52/160] |	nca: 4.728901445865631, flat: 5.69307915866375, pod: 53.11944127082825, loss: 63.54142141342163 
Train [4/11] | Epoch [53/160] |	nca: 5.146000124514103, flat: 5.130160436034203, pod: 49.47587263584137, loss: 59.75203323364258 
Train [4/11] | Epoch [54/160] |	nca: 5.6342073529958725, flat: 5.262472361326218, pod: 50.931739807128906, loss: 61.82841980457306 
Train [4/11] | Epoch [55/160] |	nca: 5.199193097651005, flat: 5.370695263147354, pod: 51.59191703796387, loss: 62.161805510520935 
Train [4/11] | Epoch [56/160] |	nca: 5.110670983791351, flat: 5.350634276866913, pod: 51.172794580459595, loss: 61.6340993642807 
Train [4/11] | Epoch [57/160] |	nca: 5.191650450229645, flat: 5.031999692320824, pod: 49.17087173461914, loss: 59.39452111721039 
Train [4/11] | Epoch [58/160] |	nca: 5.397859916090965, flat: 5.185629412531853, pod: 50.766618847846985, loss: 61.35010862350464 
Train [4/11] | Epoch [59/160] |	nca: 5.054823189973831, flat: 5.172230675816536, pod: 50.037336349487305, loss: 60.264389991760254 
Train [4/11] | Epoch [60/160] |	nca: 4.891634613275528, flat: 5.1548963487148285, pod: 50.79181122779846, loss: 60.83834266662598 
Train [4/11] | Epoch [61/160] |	nca: 4.590470254421234, flat: 4.796058252453804, pod: 48.269896030426025, loss: 57.6564245223999 
Train [4/11] | Epoch [62/160] |	nca: 4.906268373131752, flat: 5.02324403822422, pod: 49.007768869400024, loss: 58.937281370162964 
Train [4/11] | Epoch [63/160] |	nca: 4.780909202992916, flat: 4.8261018097400665, pod: 48.061330914497375, loss: 57.66834199428558 
Train [4/11] | Epoch [64/160] |	nca: 5.144385650753975, flat: 4.677522987127304, pod: 47.389894247055054, loss: 57.21180248260498 
Train [4/11] | Epoch [65/160] |	nca: 4.761418417096138, flat: 4.79514479637146, pod: 48.46624052524567, loss: 58.02280390262604 
Train [4/11] | Epoch [66/160] |	nca: 4.903740674257278, flat: 4.752718880772591, pod: 48.46970820426941, loss: 58.12616765499115 
Train [4/11] | Epoch [67/160] |	nca: 5.268717177212238, flat: 4.94029001891613, pod: 48.59496092796326, loss: 58.80396771430969 
Train [4/11] | Epoch [68/160] |	nca: 4.736426435410976, flat: 4.920658856630325, pod: 48.637338042259216, loss: 58.29442346096039 
Train [4/11] | Epoch [69/160] |	nca: 4.837655581533909, flat: 4.597787246108055, pod: 47.058977127075195, loss: 56.49441969394684 
Train [4/11] | Epoch [70/160] |	nca: 4.663382738828659, flat: 4.743533790111542, pod: 48.15450417995453, loss: 57.561421155929565 
Train [4/11] | Epoch [71/160] |	nca: 4.67857751250267, flat: 4.522329896688461, pod: 46.23369562625885, loss: 55.43460309505463 
Train [4/11] | Epoch [72/160] |	nca: 4.46954770386219, flat: 4.358713164925575, pod: 45.48256754875183, loss: 54.31082904338837 
Train [4/11] | Epoch [73/160] |	nca: 4.658041946589947, flat: 4.386394411325455, pod: 45.48216235637665, loss: 54.52659869194031 
Train [4/11] | Epoch [74/160] |	nca: 4.950582720339298, flat: 4.482942163944244, pod: 46.22582221031189, loss: 55.65934717655182 
Train [4/11] | Epoch [75/160] |	nca: 4.5381709933280945, flat: 4.3248648047447205, pod: 45.18207657337189, loss: 54.04511213302612 
Train [4/11] | Epoch [76/160] |	nca: 4.719918206334114, flat: 4.287980005145073, pod: 45.02121126651764, loss: 54.029109597206116 
Train [4/11] | Epoch [77/160] |	nca: 4.8391900435090065, flat: 4.214441940188408, pod: 43.82583546638489, loss: 52.879467129707336 
Train [4/11] | Epoch [78/160] |	nca: 4.559909634292126, flat: 4.28909008204937, pod: 45.447083711624146, loss: 54.29608333110809 
Train [4/11] | Epoch [79/160] |	nca: 4.009055860340595, flat: 4.111386254429817, pod: 43.39871287345886, loss: 51.51915502548218 
Train [4/11] | Epoch [80/160] |	nca: 4.330453544855118, flat: 4.099364422261715, pod: 43.690263986587524, loss: 52.120081663131714 
Train [4/11] | Epoch [81/160] |	nca: 4.202316641807556, flat: 3.891121670603752, pod: 42.345239758491516, loss: 50.43867778778076 
Train [4/11] | Epoch [82/160] |	nca: 4.8531790897250175, flat: 4.049281008541584, pod: 42.50738787651062, loss: 51.40984809398651 
Train [4/11] | Epoch [83/160] |	nca: 4.3378651663661, flat: 4.088635735213757, pod: 43.89647901058197, loss: 52.32298016548157 
Train [4/11] | Epoch [84/160] |	nca: 4.263343654572964, flat: 3.770283728837967, pod: 41.6453754901886, loss: 49.6790030002594 
Train [4/11] | Epoch [85/160] |	nca: 4.423136070370674, flat: 3.9914401844143867, pod: 44.36729454994202, loss: 52.78187084197998 
Train [4/11] | Epoch [86/160] |	nca: 4.228026866912842, flat: 3.98374792188406, pod: 43.9391815662384, loss: 52.15095615386963 
Train [4/11] | Epoch [87/160] |	nca: 4.279125064611435, flat: 3.868975944817066, pod: 43.027183294296265, loss: 51.17528462409973 
Train [4/11] | Epoch [88/160] |	nca: 4.122598372399807, flat: 3.7200850397348404, pod: 41.21539354324341, loss: 49.05807709693909 
Train [4/11] | Epoch [89/160] |	nca: 4.046552695333958, flat: 3.719587452709675, pod: 41.17352330684662, loss: 48.93966352939606 
Train [4/11] | Epoch [90/160] |	nca: 4.074239544570446, flat: 3.611084520816803, pod: 41.089253425598145, loss: 48.774577379226685 
Train [4/11] | Epoch [91/160] |	nca: 4.710030809044838, flat: 3.7355924546718597, pod: 41.81981134414673, loss: 50.2654345035553 
Train [4/11] | Epoch [92/160] |	nca: 4.285650476813316, flat: 3.597807988524437, pod: 40.20862889289856, loss: 48.092087507247925 
Train [4/11] | Epoch [93/160] |	nca: 3.853183165192604, flat: 3.3892331272363663, pod: 38.21407639980316, loss: 45.4564927816391 
Train [4/11] | Epoch [94/160] |	nca: 4.6256333366036415, flat: 3.503829762339592, pod: 40.43326663970947, loss: 48.562729716300964 
Train [4/11] | Epoch [95/160] |	nca: 4.125733472406864, flat: 3.589099742472172, pod: 42.253177523612976, loss: 49.968010783195496 
Train [4/11] | Epoch [96/160] |	nca: 3.9589528664946556, flat: 3.391064040362835, pod: 39.373947858810425, loss: 46.72396504878998 
Train [4/11] | Epoch [97/160] |	nca: 3.847259007394314, flat: 3.270541734993458, pod: 38.08864760398865, loss: 45.20644819736481 
Train [4/11] | Epoch [98/160] |	nca: 4.509812407195568, flat: 3.271555431187153, pod: 38.086204051971436, loss: 45.86757183074951 
Train [4/11] | Epoch [99/160] |	nca: 3.8753633201122284, flat: 3.3172961324453354, pod: 38.32071924209595, loss: 45.513378262519836 
Train [4/11] | Epoch [100/160] |	nca: 3.9015908539295197, flat: 3.0976306572556496, pod: 36.150230884552, loss: 43.14945209026337 
Train [4/11] | Epoch [101/160] |	nca: 4.178745165467262, flat: 3.1748194471001625, pod: 37.45301103591919, loss: 44.806575417518616 
Train [4/11] | Epoch [102/160] |	nca: 3.702040269970894, flat: 3.096957303583622, pod: 37.01531410217285, loss: 43.81431186199188 
Train [4/11] | Epoch [103/160] |	nca: 4.2999817952513695, flat: 3.009711764752865, pod: 35.97704219818115, loss: 43.28673565387726 
Train [4/11] | Epoch [104/160] |	nca: 3.9826207607984543, flat: 3.092311128973961, pod: 35.98724687099457, loss: 43.06217885017395 
Train [4/11] | Epoch [105/160] |	nca: 3.898155950009823, flat: 2.9610750004649162, pod: 35.27622830867767, loss: 42.135459184646606 
Train [4/11] | Epoch [106/160] |	nca: 3.9381625577807426, flat: 2.9943179860711098, pod: 36.480404019355774, loss: 43.41288459300995 
Train [4/11] | Epoch [107/160] |	nca: 3.668454684317112, flat: 2.8903849720954895, pod: 35.03605532646179, loss: 41.594895243644714 
Train [4/11] | Epoch [108/160] |	nca: 3.624164916574955, flat: 2.815559946000576, pod: 34.46022439002991, loss: 40.89994955062866 
Train [4/11] | Epoch [109/160] |	nca: 4.015981025993824, flat: 2.8814725801348686, pod: 35.77972662448883, loss: 42.67718005180359 
Train [4/11] | Epoch [110/160] |	nca: 3.5428797379136086, flat: 2.858102038502693, pod: 34.77999496459961, loss: 41.18097674846649 
Train [4/11] | Epoch [111/160] |	nca: 3.922205373644829, flat: 2.7032428979873657, pod: 33.454039216041565, loss: 40.079487323760986 
Train [4/11] | Epoch [112/160] |	nca: 3.7659736648201942, flat: 2.8718805760145187, pod: 34.455430030822754, loss: 41.093284130096436 
Train [4/11] | Epoch [113/160] |	nca: 3.8230014368891716, flat: 2.764283314347267, pod: 34.02381777763367, loss: 40.61110293865204 
Train [4/11] | Epoch [114/160] |	nca: 3.8871796876192093, flat: 2.743091680109501, pod: 33.59695315361023, loss: 40.227224826812744 
Train [4/11] | Epoch [115/160] |	nca: 3.601942576467991, flat: 2.6465297788381577, pod: 32.83967697620392, loss: 39.088149189949036 
Train [4/11] | Epoch [116/160] |	nca: 3.908840022981167, flat: 2.5373251140117645, pod: 31.687090694904327, loss: 38.13325583934784 
Train [4/11] | Epoch [117/160] |	nca: 3.897976316511631, flat: 2.6143655478954315, pod: 32.104837357997894, loss: 38.61717903614044 
Train [4/11] | Epoch [118/160] |	nca: 3.7919818833470345, flat: 2.5150465294718742, pod: 31.85421770811081, loss: 38.16124629974365 
Train [4/11] | Epoch [119/160] |	nca: 3.634642630815506, flat: 2.526736743748188, pod: 31.9886794090271, loss: 38.15005874633789 
Train [4/11] | Epoch [120/160] |	nca: 3.5225828923285007, flat: 2.504908211529255, pod: 32.616515934467316, loss: 38.644006967544556 
Train [4/11] | Epoch [121/160] |	nca: 3.5890239477157593, flat: 2.3582924753427505, pod: 30.923048555850983, loss: 36.870365023612976 
Train [4/11] | Epoch [122/160] |	nca: 3.8824986070394516, flat: 2.382507935166359, pod: 30.354222118854523, loss: 36.61922883987427 
Train [4/11] | Epoch [123/160] |	nca: 3.633721426129341, flat: 2.393524669110775, pod: 30.62742853164673, loss: 36.6546745300293 
Train [4/11] | Epoch [124/160] |	nca: 3.8616387471556664, flat: 2.399837590754032, pod: 31.03358829021454, loss: 37.2950644493103 
Train [4/11] | Epoch [125/160] |	nca: 3.8553481698036194, flat: 2.3720574751496315, pod: 31.18817502260208, loss: 37.41558063030243 
Train [4/11] | Epoch [126/160] |	nca: 3.7112372294068336, flat: 2.2914223298430443, pod: 29.809035897254944, loss: 35.81169509887695 
Train [4/11] | Epoch [127/160] |	nca: 3.6662373766303062, flat: 2.2859975174069405, pod: 29.831811487674713, loss: 35.78404641151428 
Train [4/11] | Epoch [128/160] |	nca: 3.576131023466587, flat: 2.31992606818676, pod: 30.52985906600952, loss: 36.42591619491577 
Train [4/11] | Epoch [129/160] |	nca: 3.7295754328370094, flat: 2.2760609686374664, pod: 29.574126958847046, loss: 35.579763412475586 
Train [4/11] | Epoch [130/160] |	nca: 3.404092289507389, flat: 2.2304088473320007, pod: 29.052011132240295, loss: 34.68651235103607 
Train [4/11] | Epoch [131/160] |	nca: 3.4979410246014595, flat: 2.1787078343331814, pod: 28.14573734998703, loss: 33.822386384010315 
Train [4/11] | Epoch [132/160] |	nca: 3.5524045825004578, flat: 2.156400717794895, pod: 28.364758551120758, loss: 34.0735639333725 
Train [4/11] | Epoch [133/160] |	nca: 3.567280501127243, flat: 2.172946088016033, pod: 29.07215839624405, loss: 34.81238508224487 
Train [4/11] | Epoch [134/160] |	nca: 3.4875035881996155, flat: 2.088722124695778, pod: 27.41292917728424, loss: 32.98915469646454 
Train [4/11] | Epoch [135/160] |	nca: 3.546581730246544, flat: 2.04556792229414, pod: 27.497629284858704, loss: 33.08977895975113 
Train [4/11] | Epoch [136/160] |	nca: 3.4767917692661285, flat: 2.1209314465522766, pod: 28.133098483085632, loss: 33.73082172870636 
Train [4/11] | Epoch [137/160] |	nca: 3.525560200214386, flat: 2.0430145002901554, pod: 26.891757667064667, loss: 32.460332691669464 
Train [4/11] | Epoch [138/160] |	nca: 3.3601245507597923, flat: 2.053284425288439, pod: 27.060246765613556, loss: 32.47365576028824 
Train [4/11] | Epoch [139/160] |	nca: 3.614230252802372, flat: 2.05941903591156, pod: 26.616306126117706, loss: 32.289955496788025 
Train [4/11] | Epoch [140/160] |	nca: 3.3750392347574234, flat: 2.0321885980665684, pod: 27.009375989437103, loss: 32.41660374403 
Train [4/11] | Epoch [141/160] |	nca: 3.3193969130516052, flat: 1.9621180184185505, pod: 26.58999812602997, loss: 31.87151312828064 
Train [4/11] | Epoch [142/160] |	nca: 3.529709756374359, flat: 2.0459954738616943, pod: 26.810120344161987, loss: 32.38582557439804 
Train [4/11] | Epoch [143/160] |	nca: 3.279342897236347, flat: 1.9142090938985348, pod: 25.191456079483032, loss: 30.385008096694946 
Train [4/11] | Epoch [144/160] |	nca: 3.505748864263296, flat: 1.9172407612204552, pod: 26.218656420707703, loss: 31.64164626598358 
Train [4/11] | Epoch [145/160] |	nca: 3.6202245950698853, flat: 1.9745100103318691, pod: 26.979818403720856, loss: 32.5745530128479 
Train [4/11] | Epoch [146/160] |	nca: 3.41038366407156, flat: 1.9681281559169292, pod: 26.341005861759186, loss: 31.719517827033997 
Train [4/11] | Epoch [147/160] |	nca: 3.3317969366908073, flat: 1.871158480644226, pod: 25.56697940826416, loss: 30.76993501186371 
Train [4/11] | Epoch [148/160] |	nca: 3.294629916548729, flat: 1.8973605409264565, pod: 25.552358150482178, loss: 30.74434870481491 
Train [4/11] | Epoch [149/160] |	nca: 3.2847143933176994, flat: 1.8843546584248543, pod: 25.45894104242325, loss: 30.62801033258438 
Train [4/11] | Epoch [150/160] |	nca: 3.3903336077928543, flat: 1.8241145089268684, pod: 24.70080178976059, loss: 29.91524964570999 
Train [4/11] | Epoch [151/160] |	nca: 3.3913956731557846, flat: 1.859453909099102, pod: 24.58011305332184, loss: 29.830962657928467 
Train [4/11] | Epoch [152/160] |	nca: 3.3841219171881676, flat: 1.837504405528307, pod: 24.573622822761536, loss: 29.795248866081238 
Train [4/11] | Epoch [153/160] |	nca: 3.3540467247366905, flat: 1.8351074159145355, pod: 24.983438372612, loss: 30.172592520713806 
Train [4/11] | Epoch [154/160] |	nca: 3.2448355555534363, flat: 1.875033412128687, pod: 25.42025589942932, loss: 30.540125012397766 
Train [4/11] | Epoch [155/160] |	nca: 3.263365216553211, flat: 1.8275689668953419, pod: 24.726201832294464, loss: 29.81713581085205 
Train [4/11] | Epoch [156/160] |	nca: 3.537896417081356, flat: 1.8558036796748638, pod: 25.21402370929718, loss: 30.607723712921143 
Train [4/11] | Epoch [157/160] |	nca: 3.318744443356991, flat: 1.825568065047264, pod: 24.72686541080475, loss: 29.871178030967712 
Train [4/11] | Epoch [158/160] |	nca: 3.236878424882889, flat: 1.8380602486431599, pod: 24.688915133476257, loss: 29.76385372877121 
Train [4/11] | Epoch [159/160] |	nca: 3.5019764378666878, flat: 1.82914038002491, pod: 24.41463202238083, loss: 29.745748937129974 
Train [4/11] | Epoch [160/160] |	nca: 3.315990559756756, flat: 1.8269367553293705, pod: 24.766038060188293, loss: 29.908965170383453 
Fine-tuning
Building & updating memory.
Train [4/11] | Epoch [161/180] |	nca: 4.048921838402748, flat: 2.1314077228307724, pod: 19.755500078201294, loss: 25.935829758644104 
Train [4/11] | Epoch [162/180] |	nca: 1.589292325079441, flat: 2.076135531067848, pod: 19.543906688690186, loss: 23.20933496952057 
Train [4/11] | Epoch [163/180] |	nca: 1.1954670399427414, flat: 2.216698259115219, pod: 20.076231002807617, loss: 23.488396406173706 
Train [4/11] | Epoch [164/180] |	nca: 0.8884903341531754, flat: 2.072588697075844, pod: 19.124577522277832, loss: 22.08565664291382 
Train [4/11] | Epoch [165/180] |	nca: 0.9653705544769764, flat: 2.2502115964889526, pod: 20.049665808677673, loss: 23.26524806022644 
Train [4/11] | Epoch [166/180] |	nca: 0.7385974638164043, flat: 2.140749081969261, pod: 19.889018535614014, loss: 22.768365263938904 
Train [4/11] | Epoch [167/180] |	nca: 0.7430046908557415, flat: 2.1372395902872086, pod: 19.685139179229736, loss: 22.565383195877075 
Train [4/11] | Epoch [168/180] |	nca: 0.7954731807112694, flat: 2.029380187392235, pod: 19.165321826934814, loss: 21.990175008773804 
Train [4/11] | Epoch [169/180] |	nca: 0.7085379511117935, flat: 2.062190368771553, pod: 19.537498474121094, loss: 22.308226704597473 
Train [4/11] | Epoch [170/180] |	nca: 0.8123627677559853, flat: 2.2148149460554123, pod: 19.63121998310089, loss: 22.658397674560547 
Train [4/11] | Epoch [171/180] |	nca: 0.8995540216565132, flat: 2.2106800824403763, pod: 19.936097502708435, loss: 23.046331763267517 
Train [4/11] | Epoch [172/180] |	nca: 0.7812600210309029, flat: 2.1780446618795395, pod: 19.601656675338745, loss: 22.560961365699768 
Train [4/11] | Epoch [173/180] |	nca: 0.9058946929872036, flat: 2.2810807824134827, pod: 19.895557641983032, loss: 23.08253300189972 
Train [4/11] | Epoch [174/180] |	nca: 0.6898747030645609, flat: 2.129383012652397, pod: 19.64062464237213, loss: 22.459882140159607 
Train [4/11] | Epoch [175/180] |	nca: 0.638330478221178, flat: 2.1406764090061188, pod: 19.847684383392334, loss: 22.626691222190857 
Train [4/11] | Epoch [176/180] |	nca: 0.5691192299127579, flat: 2.1287776231765747, pod: 19.59183704853058, loss: 22.28973376750946 
Train [4/11] | Epoch [177/180] |	nca: 0.6146550551056862, flat: 2.1153052300214767, pod: 19.423630833625793, loss: 22.15359091758728 
Train [4/11] | Epoch [178/180] |	nca: 0.5925490204244852, flat: 2.1043450832366943, pod: 19.291102051734924, loss: 21.987996339797974 
Train [4/11] | Epoch [179/180] |	nca: 0.6610778979957104, flat: 2.2719596773386, pod: 19.811717987060547, loss: 22.744755506515503 
Train [4/11] | Epoch [180/180] |	nca: 0.48848058469593525, flat: 2.064722001552582, pod: 19.404880046844482, loss: 21.95808231830597 
after task
Building & updating memory.
after task
Eval on 0->65.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.7035.
Current acc: {'total': 0.651, '00-09': 0.707, '10-19': 0.68, '20-29': 0.582, '30-39': 0.628, '40-49': 0.682, '50-59': 0.667, '60-69': 0.568}.
Avg inc acc top5: 0.91425.
Current acc top5: {'total': 0.886}.
Forgetting: -0.008999999999999994.
Cord metric: 0.69.
Old accuracy: 0.66, mean: 0.69.
New accuracy: 0.57, mean: 0.65.
================Task 4 Start!================
Testing on False unseen tasks (max class = 70).
Set memory of size: 1300.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 4 Training!================
The training samples number: 3800
Train on 65->70.
train task
nb 3800.
Train [5/11] | Epoch [1/160] |	nca: 27.850848078727722, flat: 8.458067007362843, pod: 67.8050445318222, loss: 104.11395931243896 
Train [5/11] | Epoch [2/160] |	nca: 20.66493660211563, flat: 12.265290260314941, pod: 85.3531002998352, loss: 118.28332686424255 
Train [5/11] | Epoch [3/160] |	nca: 13.601205974817276, flat: 9.448650926351547, pod: 75.32813858985901, loss: 98.37799572944641 
Train [5/11] | Epoch [4/160] |	nca: 10.318779408931732, flat: 7.260752975940704, pod: 65.40833449363708, loss: 82.9878671169281 
Train [5/11] | Epoch [5/160] |	nca: 9.576135247945786, flat: 6.4488465040922165, pod: 62.375119805336, loss: 78.40010213851929 
Train [5/11] | Epoch [6/160] |	nca: 8.996308773756027, flat: 6.238683238625526, pod: 60.598068594932556, loss: 75.83306097984314 
Train [5/11] | Epoch [7/160] |	nca: 8.403802588582039, flat: 6.176794931292534, pod: 60.927173137664795, loss: 75.5077714920044 
Train [5/11] | Epoch [8/160] |	nca: 7.911639034748077, flat: 5.71362441778183, pod: 58.56953501701355, loss: 72.19479846954346 
Train [5/11] | Epoch [9/160] |	nca: 7.766561061143875, flat: 5.762208461761475, pod: 59.08574068546295, loss: 72.614511013031 
Train [5/11] | Epoch [10/160] |	nca: 8.049243286252022, flat: 5.794930621981621, pod: 59.38492727279663, loss: 73.2291009426117 
Train [5/11] | Epoch [11/160] |	nca: 7.1044115871191025, flat: 5.644426718354225, pod: 57.69265365600586, loss: 70.4414918422699 
Train [5/11] | Epoch [12/160] |	nca: 7.456432491540909, flat: 5.583565384149551, pod: 57.0375634431839, loss: 70.07756185531616 
Train [5/11] | Epoch [13/160] |	nca: 6.574629157781601, flat: 5.37275604903698, pod: 54.64694082736969, loss: 66.59432482719421 
Train [5/11] | Epoch [14/160] |	nca: 6.8039612621068954, flat: 5.269585266709328, pod: 55.48211336135864, loss: 67.55565977096558 
Train [5/11] | Epoch [15/160] |	nca: 6.557564601302147, flat: 5.498513922095299, pod: 57.32162892818451, loss: 69.3777072429657 
Train [5/11] | Epoch [16/160] |	nca: 6.936556786298752, flat: 5.405667021870613, pod: 55.339680194854736, loss: 67.68190455436707 
Train [5/11] | Epoch [17/160] |	nca: 6.621592938899994, flat: 5.478780269622803, pod: 56.357791781425476, loss: 68.45816397666931 
Train [5/11] | Epoch [18/160] |	nca: 6.188951671123505, flat: 5.248730227351189, pod: 55.85172665119171, loss: 67.28940844535828 
Train [5/11] | Epoch [19/160] |	nca: 6.068333312869072, flat: 5.044836461544037, pod: 54.421817779541016, loss: 65.534987449646 
Train [5/11] | Epoch [20/160] |	nca: 6.115356914699078, flat: 5.081626877188683, pod: 54.50988221168518, loss: 65.70686554908752 
Train [5/11] | Epoch [21/160] |	nca: 6.290801763534546, flat: 5.14317561686039, pod: 54.953399300575256, loss: 66.3873770236969 
Train [5/11] | Epoch [22/160] |	nca: 6.850230559706688, flat: 5.51793073117733, pod: 55.48121428489685, loss: 67.84937524795532 
Train [5/11] | Epoch [23/160] |	nca: 5.676700443029404, flat: 5.052809581160545, pod: 53.11149501800537, loss: 63.841004610061646 
Train [5/11] | Epoch [24/160] |	nca: 5.628547012805939, flat: 4.8527427315711975, pod: 53.52353394031525, loss: 64.00482428073883 
Train [5/11] | Epoch [25/160] |	nca: 6.341330677270889, flat: 5.197122171521187, pod: 55.743366718292236, loss: 67.28181982040405 
Train [5/11] | Epoch [26/160] |	nca: 6.272241398692131, flat: 5.281239822506905, pod: 56.834359884262085, loss: 68.38784050941467 
Train [5/11] | Epoch [27/160] |	nca: 5.858429476618767, flat: 5.16137333214283, pod: 54.46714675426483, loss: 65.48694920539856 
Train [5/11] | Epoch [28/160] |	nca: 6.033896267414093, flat: 5.256470575928688, pod: 55.2307710647583, loss: 66.52113842964172 
Train [5/11] | Epoch [29/160] |	nca: 5.3247848972678185, flat: 4.915172845125198, pod: 52.17666494846344, loss: 62.41662263870239 
Train [5/11] | Epoch [30/160] |	nca: 5.38252492249012, flat: 4.724234521389008, pod: 52.71532154083252, loss: 62.82208180427551 
Train [5/11] | Epoch [31/160] |	nca: 5.644468851387501, flat: 4.889992132782936, pod: 52.99863862991333, loss: 63.53309965133667 
Train [5/11] | Epoch [32/160] |	nca: 5.32409330457449, flat: 4.760169222950935, pod: 51.972265005111694, loss: 62.05652737617493 
Train [5/11] | Epoch [33/160] |	nca: 5.0631895288825035, flat: 4.766960218548775, pod: 52.298789620399475, loss: 62.12893855571747 
Train [5/11] | Epoch [34/160] |	nca: 5.410452388226986, flat: 4.628858342766762, pod: 51.24710702896118, loss: 61.28641748428345 
Train [5/11] | Epoch [35/160] |	nca: 5.4087304919958115, flat: 4.796575576066971, pod: 52.614365100860596, loss: 62.81967091560364 
Train [5/11] | Epoch [36/160] |	nca: 5.554653659462929, flat: 4.790691152215004, pod: 51.668721318244934, loss: 62.014065861701965 
Train [5/11] | Epoch [37/160] |	nca: 5.239298045635223, flat: 4.675277650356293, pod: 50.733092188835144, loss: 60.64766776561737 
Train [5/11] | Epoch [38/160] |	nca: 5.126560680568218, flat: 4.70138555765152, pod: 52.32327115535736, loss: 62.151217341423035 
Train [5/11] | Epoch [39/160] |	nca: 4.709168367087841, flat: 4.3346027135849, pod: 50.280311822891235, loss: 59.32408332824707 
Train [5/11] | Epoch [40/160] |	nca: 5.162847839295864, flat: 4.474457949399948, pod: 50.572317123413086, loss: 60.20962345600128 
Train [5/11] | Epoch [41/160] |	nca: 4.371280960738659, flat: 4.264839947223663, pod: 48.59085929393768, loss: 57.22697973251343 
Train [5/11] | Epoch [42/160] |	nca: 5.744759522378445, flat: 4.4159039705991745, pod: 49.89558792114258, loss: 60.05625116825104 
Train [5/11] | Epoch [43/160] |	nca: 5.836434036493301, flat: 5.179358288645744, pod: 54.7715927362442, loss: 65.78738522529602 
Train [5/11] | Epoch [44/160] |	nca: 5.778318874537945, flat: 5.039120674133301, pod: 52.85607349872589, loss: 63.67351233959198 
Train [5/11] | Epoch [45/160] |	nca: 4.921580582857132, flat: 4.818781018257141, pod: 51.80451548099518, loss: 61.54487693309784 
Train [5/11] | Epoch [46/160] |	nca: 4.971737258136272, flat: 4.436362862586975, pod: 48.90081775188446, loss: 58.308917760849 
Train [5/11] | Epoch [47/160] |	nca: 5.148661784827709, flat: 4.442323639988899, pod: 49.57077443599701, loss: 59.161760330200195 
Train [5/11] | Epoch [48/160] |	nca: 4.869128338992596, flat: 4.421641021966934, pod: 49.10526704788208, loss: 58.39603638648987 
Train [5/11] | Epoch [49/160] |	nca: 4.539157964289188, flat: 4.095220603048801, pod: 47.50653886795044, loss: 56.14091753959656 
Train [5/11] | Epoch [50/160] |	nca: 5.218977510929108, flat: 4.305824786424637, pod: 48.86645865440369, loss: 58.391260623931885 
Train [5/11] | Epoch [51/160] |	nca: 5.232600212097168, flat: 4.504290848970413, pod: 50.13869559764862, loss: 59.87558650970459 
Train [5/11] | Epoch [52/160] |	nca: 4.893049903213978, flat: 4.433503597974777, pod: 50.03027951717377, loss: 59.35683310031891 
Train [5/11] | Epoch [53/160] |	nca: 5.153936043381691, flat: 4.451176017522812, pod: 49.38043463230133, loss: 58.985546946525574 
Train [5/11] | Epoch [54/160] |	nca: 5.054955996572971, flat: 4.37885157763958, pod: 49.83446204662323, loss: 59.26826989650726 
Train [5/11] | Epoch [55/160] |	nca: 4.686018727719784, flat: 4.365821108222008, pod: 48.51574683189392, loss: 57.56758689880371 
Train [5/11] | Epoch [56/160] |	nca: 4.265569552779198, flat: 3.8939266204833984, pod: 46.335009932518005, loss: 54.494505643844604 
Train [5/11] | Epoch [57/160] |	nca: 4.736787222325802, flat: 4.098114393651485, pod: 47.96866190433502, loss: 56.803563475608826 
Train [5/11] | Epoch [58/160] |	nca: 4.498080343008041, flat: 4.037904784083366, pod: 46.93578827381134, loss: 55.47177350521088 
Train [5/11] | Epoch [59/160] |	nca: 4.488255508244038, flat: 4.229652747511864, pod: 48.367026686668396, loss: 57.0849347114563 
Train [5/11] | Epoch [60/160] |	nca: 4.467253118753433, flat: 4.009722352027893, pod: 48.460750102996826, loss: 56.93772566318512 
Train [5/11] | Epoch [61/160] |	nca: 5.347443252801895, flat: 4.2994851022958755, pod: 48.664087653160095, loss: 58.31101584434509 
Train [5/11] | Epoch [62/160] |	nca: 4.347370691597462, flat: 4.197667382657528, pod: 48.477133989334106, loss: 57.02217233181 
Train [5/11] | Epoch [63/160] |	nca: 4.370314799249172, flat: 3.9989421740174294, pod: 47.83192217350006, loss: 56.201178669929504 
Train [5/11] | Epoch [64/160] |	nca: 4.246939949691296, flat: 3.938112124800682, pod: 46.31760549545288, loss: 54.502657532691956 
Train [5/11] | Epoch [65/160] |	nca: 4.3615883737802505, flat: 3.8684578016400337, pod: 46.0537428855896, loss: 54.28378939628601 
Train [5/11] | Epoch [66/160] |	nca: 4.176892764866352, flat: 3.7580013498663902, pod: 45.33865547180176, loss: 53.27354955673218 
Train [5/11] | Epoch [67/160] |	nca: 3.8026061058044434, flat: 3.5531091317534447, pod: 44.10927605628967, loss: 51.464991211891174 
Train [5/11] | Epoch [68/160] |	nca: 4.412979632616043, flat: 3.5593894720077515, pod: 43.501598596572876, loss: 51.47396743297577 
Train [5/11] | Epoch [69/160] |	nca: 4.185375727713108, flat: 3.5864945352077484, pod: 43.791186451911926, loss: 51.56305694580078 
Train [5/11] | Epoch [70/160] |	nca: 4.339749351143837, flat: 3.493609793484211, pod: 43.92186737060547, loss: 51.755226612091064 
Train [5/11] | Epoch [71/160] |	nca: 4.19909592717886, flat: 3.58340435475111, pod: 44.61248743534088, loss: 52.39498794078827 
Train [5/11] | Epoch [72/160] |	nca: 4.229122452437878, flat: 3.6071395576000214, pod: 45.156200528144836, loss: 52.99246275424957 
Train [5/11] | Epoch [73/160] |	nca: 4.103265851736069, flat: 3.449810743331909, pod: 43.03764259815216, loss: 50.59071934223175 
Train [5/11] | Epoch [74/160] |	nca: 4.1148377135396, flat: 3.438017137348652, pod: 43.250089049339294, loss: 50.80294406414032 
Train [5/11] | Epoch [75/160] |	nca: 4.44988176971674, flat: 3.462386339902878, pod: 43.52274823188782, loss: 51.43501627445221 
Train [5/11] | Epoch [76/160] |	nca: 4.312507875263691, flat: 3.3847428262233734, pod: 42.03832817077637, loss: 49.735578775405884 
Train [5/11] | Epoch [77/160] |	nca: 4.178808875381947, flat: 3.297742620110512, pod: 42.51390027999878, loss: 49.99045205116272 
Train [5/11] | Epoch [78/160] |	nca: 4.1031735092401505, flat: 3.475150264799595, pod: 44.31055760383606, loss: 51.88888132572174 
Train [5/11] | Epoch [79/160] |	nca: 4.342727847397327, flat: 3.3446616381406784, pod: 42.2953964471817, loss: 49.98278605937958 
Train [5/11] | Epoch [80/160] |	nca: 4.10636330395937, flat: 3.3299382776021957, pod: 42.06521260738373, loss: 49.50151443481445 
Train [5/11] | Epoch [81/160] |	nca: 4.1394637525081635, flat: 3.3178094625473022, pod: 42.16025984287262, loss: 49.61753273010254 
Train [5/11] | Epoch [82/160] |	nca: 4.022225946187973, flat: 3.2425021678209305, pod: 41.9204466342926, loss: 49.18517482280731 
Train [5/11] | Epoch [83/160] |	nca: 4.165048390626907, flat: 3.163635104894638, pod: 41.24184465408325, loss: 48.57052826881409 
Train [5/11] | Epoch [84/160] |	nca: 3.6405711323022842, flat: 3.040716528892517, pod: 40.31341850757599, loss: 46.99470627307892 
Train [5/11] | Epoch [85/160] |	nca: 3.9417336881160736, flat: 3.060297779738903, pod: 40.21066105365753, loss: 47.21269237995148 
Train [5/11] | Epoch [86/160] |	nca: 3.780388005077839, flat: 3.069455400109291, pod: 40.156453132629395, loss: 47.00629651546478 
Train [5/11] | Epoch [87/160] |	nca: 3.9533205777406693, flat: 2.898568645119667, pod: 40.157987117767334, loss: 47.0098762512207 
Train [5/11] | Epoch [88/160] |	nca: 3.7878649532794952, flat: 3.032293401658535, pod: 39.78906559944153, loss: 46.60922360420227 
Train [5/11] | Epoch [89/160] |	nca: 3.8417291715741158, flat: 2.9208898320794106, pod: 39.131807923316956, loss: 45.89442682266235 
Train [5/11] | Epoch [90/160] |	nca: 3.802745819091797, flat: 2.871726907789707, pod: 38.2586088180542, loss: 44.93308138847351 
Train [5/11] | Epoch [91/160] |	nca: 3.554158642888069, flat: 2.795794188976288, pod: 38.65418088436127, loss: 45.00413393974304 
Train [5/11] | Epoch [92/160] |	nca: 3.865134246647358, flat: 2.790179803967476, pod: 37.62637186050415, loss: 44.2816858291626 
Train [5/11] | Epoch [93/160] |	nca: 3.6861626133322716, flat: 2.874806545674801, pod: 38.99324905872345, loss: 45.55421817302704 
Train [5/11] | Epoch [94/160] |	nca: 3.495047576725483, flat: 2.657691217958927, pod: 37.635666251182556, loss: 43.78840506076813 
Train [5/11] | Epoch [95/160] |	nca: 3.649762436747551, flat: 2.7438044250011444, pod: 37.702903747558594, loss: 44.09647023677826 
Train [5/11] | Epoch [96/160] |	nca: 3.8488121554255486, flat: 2.7048821300268173, pod: 37.33290433883667, loss: 43.88659882545471 
Train [5/11] | Epoch [97/160] |	nca: 3.7221732288599014, flat: 2.783829241991043, pod: 38.374754309654236, loss: 44.88075661659241 
Train [5/11] | Epoch [98/160] |	nca: 3.509734518826008, flat: 2.80528461933136, pod: 38.04510760307312, loss: 44.36012649536133 
Train [5/11] | Epoch [99/160] |	nca: 3.8406357541680336, flat: 2.521805264055729, pod: 35.4060800075531, loss: 41.76852059364319 
Train [5/11] | Epoch [100/160] |	nca: 4.108252011239529, flat: 2.700878396630287, pod: 36.69434654712677, loss: 43.50347697734833 
Train [5/11] | Epoch [101/160] |	nca: 3.284265883266926, flat: 2.518155485391617, pod: 35.51349461078644, loss: 41.31591582298279 
Train [5/11] | Epoch [102/160] |	nca: 3.796348884701729, flat: 2.5240507274866104, pod: 35.63058280944824, loss: 41.950982093811035 
Train [5/11] | Epoch [103/160] |	nca: 3.4685579240322113, flat: 2.446578949689865, pod: 35.223451137542725, loss: 41.138588190078735 
Train [5/11] | Epoch [104/160] |	nca: 3.342103525996208, flat: 2.2884035781025887, pod: 32.83839589357376, loss: 38.468902826309204 
Train [5/11] | Epoch [105/160] |	nca: 3.52742962539196, flat: 2.462556727230549, pod: 34.714269161224365, loss: 40.70425581932068 
Train [5/11] | Epoch [106/160] |	nca: 3.6820081397891045, flat: 2.399102658033371, pod: 34.598615646362305, loss: 40.679726243019104 
Train [5/11] | Epoch [107/160] |	nca: 3.4542168378829956, flat: 2.3074547946453094, pod: 33.29409897327423, loss: 39.05577063560486 
Train [5/11] | Epoch [108/160] |	nca: 3.2295324355363846, flat: 2.176091928035021, pod: 31.798415541648865, loss: 37.204039454460144 
Train [5/11] | Epoch [109/160] |	nca: 3.712824895977974, flat: 2.241593576967716, pod: 33.51724863052368, loss: 39.47166693210602 
Train [5/11] | Epoch [110/160] |	nca: 3.4434291794896126, flat: 2.2906392589211464, pod: 33.18100333213806, loss: 38.91507172584534 
Train [5/11] | Epoch [111/160] |	nca: 3.65055088698864, flat: 2.17118276655674, pod: 32.01241946220398, loss: 37.834153175354004 
Train [5/11] | Epoch [112/160] |	nca: 3.479082338511944, flat: 2.2120984345674515, pod: 31.98962515592575, loss: 37.680805921554565 
Train [5/11] | Epoch [113/160] |	nca: 3.2802290469408035, flat: 2.1324435584247112, pod: 31.45121431350708, loss: 36.86388683319092 
Train [5/11] | Epoch [114/160] |	nca: 3.305705204606056, flat: 2.055600345134735, pod: 30.380461037158966, loss: 35.741766571998596 
Train [5/11] | Epoch [115/160] |	nca: 3.451755501329899, flat: 1.9986475445330143, pod: 30.188130021095276, loss: 35.63853311538696 
Train [5/11] | Epoch [116/160] |	nca: 3.435664616525173, flat: 2.090579368174076, pod: 31.222268164157867, loss: 36.748512268066406 
Train [5/11] | Epoch [117/160] |	nca: 3.394901379942894, flat: 1.9585121348500252, pod: 30.23359501361847, loss: 35.587008476257324 
Train [5/11] | Epoch [118/160] |	nca: 3.300609104335308, flat: 1.9778620675206184, pod: 30.586252331733704, loss: 35.864723443984985 
Train [5/11] | Epoch [119/160] |	nca: 3.292419947683811, flat: 1.9212981015443802, pod: 30.157490968704224, loss: 35.37120878696442 
Train [5/11] | Epoch [120/160] |	nca: 3.5335477218031883, flat: 2.1157331690192223, pod: 33.052341997623444, loss: 38.70162296295166 
Train [5/11] | Epoch [121/160] |	nca: 3.1518692299723625, flat: 1.9226387813687325, pod: 30.04037654399872, loss: 35.11488437652588 
Train [5/11] | Epoch [122/160] |	nca: 3.2969316095113754, flat: 1.955692570656538, pod: 30.02091693878174, loss: 35.2735413312912 
Train [5/11] | Epoch [123/160] |	nca: 3.3635351583361626, flat: 1.9199276752769947, pod: 29.320576429367065, loss: 34.604039549827576 
Train [5/11] | Epoch [124/160] |	nca: 3.1312023773789406, flat: 1.8195434845983982, pod: 28.256951689720154, loss: 33.207697212696075 
Train [5/11] | Epoch [125/160] |	nca: 3.1718116998672485, flat: 1.8249131478369236, pod: 27.769751250743866, loss: 32.7664760351181 
Train [5/11] | Epoch [126/160] |	nca: 3.2941822707653046, flat: 1.8593597002327442, pod: 29.7665256857872, loss: 34.92006802558899 
Train [5/11] | Epoch [127/160] |	nca: 3.2737558260560036, flat: 1.8015412278473377, pod: 27.937680959701538, loss: 33.01297813653946 
Train [5/11] | Epoch [128/160] |	nca: 3.2611672952771187, flat: 1.785387497395277, pod: 28.439694464206696, loss: 33.48624897003174 
Train [5/11] | Epoch [129/160] |	nca: 3.1723881885409355, flat: 1.7321233935654163, pod: 27.07930850982666, loss: 31.983820378780365 
Train [5/11] | Epoch [130/160] |	nca: 3.197307199239731, flat: 1.7189826406538486, pod: 27.357109367847443, loss: 32.27339917421341 
Train [5/11] | Epoch [131/160] |	nca: 3.1484052762389183, flat: 1.6972536630928516, pod: 26.48428863286972, loss: 31.329947412014008 
Train [5/11] | Epoch [132/160] |	nca: 3.045893870294094, flat: 1.6711258441209793, pod: 26.469676613807678, loss: 31.186696350574493 
Train [5/11] | Epoch [133/160] |	nca: 3.1619523391127586, flat: 1.6145034730434418, pod: 26.02980488538742, loss: 30.806260645389557 
Train [5/11] | Epoch [134/160] |	nca: 3.1145070791244507, flat: 1.638491403311491, pod: 26.642011642456055, loss: 31.39501017332077 
Train [5/11] | Epoch [135/160] |	nca: 3.0968728810548782, flat: 1.6697980463504791, pod: 26.221034228801727, loss: 30.98770523071289 
Train [5/11] | Epoch [136/160] |	nca: 3.0769131407141685, flat: 1.5385658107697964, pod: 24.958657562732697, loss: 29.57413649559021 
Train [5/11] | Epoch [137/160] |	nca: 3.0396784096956253, flat: 1.5714509263634682, pod: 25.670080304145813, loss: 30.281209766864777 
Train [5/11] | Epoch [138/160] |	nca: 3.2429376244544983, flat: 1.542794905602932, pod: 25.23469787836075, loss: 30.020430505275726 
Train [5/11] | Epoch [139/160] |	nca: 2.894477389752865, flat: 1.579950649291277, pod: 25.336146414279938, loss: 29.81057471036911 
Train [5/11] | Epoch [140/160] |	nca: 3.20226139575243, flat: 1.5639693662524223, pod: 25.33793866634369, loss: 30.104169189929962 
Train [5/11] | Epoch [141/160] |	nca: 3.2554579377174377, flat: 1.5225644707679749, pod: 24.951617121696472, loss: 29.729639410972595 
Train [5/11] | Epoch [142/160] |	nca: 3.21953172236681, flat: 1.5259955897927284, pod: 25.14557385444641, loss: 29.89110094308853 
Train [5/11] | Epoch [143/160] |	nca: 3.054580792784691, flat: 1.497075829654932, pod: 23.933261692523956, loss: 28.484918355941772 
Train [5/11] | Epoch [144/160] |	nca: 3.044977866113186, flat: 1.4971158131957054, pod: 23.59531807899475, loss: 28.13741183280945 
Train [5/11] | Epoch [145/160] |	nca: 3.240165539085865, flat: 1.488801758736372, pod: 24.027360022068024, loss: 28.756327509880066 
Train [5/11] | Epoch [146/160] |	nca: 2.942943647503853, flat: 1.4545946530997753, pod: 23.67623919248581, loss: 28.07377737760544 
Train [5/11] | Epoch [147/160] |	nca: 3.2324173226952553, flat: 1.4451546892523766, pod: 23.662416398525238, loss: 28.33998841047287 
Train [5/11] | Epoch [148/160] |	nca: 2.986660450696945, flat: 1.451677292585373, pod: 23.1396341919899, loss: 27.577971875667572 
Train [5/11] | Epoch [149/160] |	nca: 3.0999057553708553, flat: 1.4943801313638687, pod: 23.92280948162079, loss: 28.51709496974945 
Train [5/11] | Epoch [150/160] |	nca: 2.9940806850790977, flat: 1.4983499832451344, pod: 23.947262167930603, loss: 28.439692974090576 
Train [5/11] | Epoch [151/160] |	nca: 3.171844221651554, flat: 1.4332981929183006, pod: 22.82517683506012, loss: 27.43031919002533 
Train [5/11] | Epoch [152/160] |	nca: 2.8947693184018135, flat: 1.4285561256110668, pod: 23.03299880027771, loss: 27.356324315071106 
Train [5/11] | Epoch [153/160] |	nca: 3.065968468785286, flat: 1.455340389162302, pod: 23.422882616519928, loss: 27.944191455841064 
Train [5/11] | Epoch [154/160] |	nca: 3.062909781932831, flat: 1.425005815923214, pod: 22.719696283340454, loss: 27.20761203765869 
Train [5/11] | Epoch [155/160] |	nca: 2.973404221236706, flat: 1.3894006349146366, pod: 22.49441123008728, loss: 26.857215881347656 
Train [5/11] | Epoch [156/160] |	nca: 3.00490465760231, flat: 1.429459873586893, pod: 22.596110343933105, loss: 27.03047502040863 
Train [5/11] | Epoch [157/160] |	nca: 3.140748370438814, flat: 1.4291671216487885, pod: 22.93999344110489, loss: 27.509908974170685 
Train [5/11] | Epoch [158/160] |	nca: 3.223641000688076, flat: 1.445434533059597, pod: 23.066300094127655, loss: 27.73537564277649 
Train [5/11] | Epoch [159/160] |	nca: 3.0343401357531548, flat: 1.4096875675022602, pod: 22.437345445156097, loss: 26.881373167037964 
Train [5/11] | Epoch [160/160] |	nca: 3.125541113317013, flat: 1.4271867871284485, pod: 22.860940158367157, loss: 27.41366809606552 
Fine-tuning
Building & updating memory.
Train [5/11] | Epoch [161/180] |	nca: 2.140569418668747, flat: 1.048942707479, pod: 12.436296045780182, loss: 15.625807881355286 
Train [5/11] | Epoch [162/180] |	nca: 0.9649862572550774, flat: 1.0759308338165283, pod: 12.560581028461456, loss: 14.601498007774353 
Train [5/11] | Epoch [163/180] |	nca: 0.8055112324655056, flat: 1.055109716951847, pod: 12.362983167171478, loss: 14.223604202270508 
Train [5/11] | Epoch [164/180] |	nca: 0.7038748599588871, flat: 1.0855679586529732, pod: 12.608528733253479, loss: 14.397971510887146 
Train [5/11] | Epoch [165/180] |	nca: 0.6297403685748577, flat: 1.04376021027565, pod: 12.390567123889923, loss: 14.064067602157593 
Train [5/11] | Epoch [166/180] |	nca: 0.543905608355999, flat: 1.0453573390841484, pod: 12.540114879608154, loss: 14.129377722740173 
Train [5/11] | Epoch [167/180] |	nca: 0.5058199018239975, flat: 1.0610109642148018, pod: 12.403718769550323, loss: 13.970549702644348 
Train [5/11] | Epoch [168/180] |	nca: 0.4558822102844715, flat: 1.0733580142259598, pod: 12.474069356918335, loss: 14.003309607505798 
Train [5/11] | Epoch [169/180] |	nca: 0.49377577751874924, flat: 1.0688335075974464, pod: 12.562223613262177, loss: 14.12483298778534 
Train [5/11] | Epoch [170/180] |	nca: 0.46608766913414, flat: 1.0538436993956566, pod: 12.436606228351593, loss: 13.95653760433197 
Train [5/11] | Epoch [171/180] |	nca: 0.48099736869335175, flat: 1.061769314110279, pod: 12.48236483335495, loss: 14.025131642818451 
Train [5/11] | Epoch [172/180] |	nca: 0.4688337370753288, flat: 1.08804751932621, pod: 12.621084153652191, loss: 14.177965641021729 
Train [5/11] | Epoch [173/180] |	nca: 0.4453441556543112, flat: 1.0443858355283737, pod: 12.152681946754456, loss: 13.642412066459656 
Train [5/11] | Epoch [174/180] |	nca: 0.44223819859325886, flat: 1.0822755247354507, pod: 12.474386990070343, loss: 13.998900592327118 
Train [5/11] | Epoch [175/180] |	nca: 0.4479626640677452, flat: 1.0348851829767227, pod: 12.217350006103516, loss: 13.70019793510437 
Train [5/11] | Epoch [176/180] |	nca: 0.4289706200361252, flat: 1.057921089231968, pod: 12.50538420677185, loss: 13.992275834083557 
Train [5/11] | Epoch [177/180] |	nca: 0.4117034748196602, flat: 1.0751396864652634, pod: 12.415794789791107, loss: 13.902637958526611 
Train [5/11] | Epoch [178/180] |	nca: 0.4542532227933407, flat: 1.0583750307559967, pod: 12.427609205245972, loss: 13.940237283706665 
Train [5/11] | Epoch [179/180] |	nca: 0.4177745506167412, flat: 1.0745464116334915, pod: 12.526574850082397, loss: 14.018895864486694 
Train [5/11] | Epoch [180/180] |	nca: 0.39086982049047947, flat: 1.0561645478010178, pod: 12.267066895961761, loss: 13.714101195335388 
after task
Building & updating memory.
after task
Eval on 0->70.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6872.
Current acc: {'total': 0.622, '00-09': 0.695, '10-19': 0.628, '20-29': 0.567, '30-39': 0.595, '40-49': 0.671, '50-59': 0.633, '60-69': 0.562}.
Avg inc acc top5: 0.9052.
Current acc top5: {'total': 0.869}.
Forgetting: 0.082375.
Cord metric: 0.67.
Old accuracy: 0.62, mean: 0.67.
New accuracy: 0.59, mean: 0.64.
================Task 5 Start!================
Testing on False unseen tasks (max class = 75).
Set memory of size: 1400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 5 Training!================
The training samples number: 3900
Train on 70->75.
train task
nb 3900.
Train [6/11] | Epoch [1/160] |	nca: 22.79964166879654, flat: 9.264670580625534, pod: 74.0490335226059, loss: 106.11334562301636 
Train [6/11] | Epoch [2/160] |	nca: 19.254088580608368, flat: 13.66216242313385, pod: 94.62533783912659, loss: 127.54158902168274 
Train [6/11] | Epoch [3/160] |	nca: 12.10209408402443, flat: 10.45624715089798, pod: 82.80331206321716, loss: 105.3616533279419 
Train [6/11] | Epoch [4/160] |	nca: 9.312509998679161, flat: 8.347888469696045, pod: 75.1674816608429, loss: 92.8278796672821 
Train [6/11] | Epoch [5/160] |	nca: 7.47308050096035, flat: 7.067857250571251, pod: 68.19067800045013, loss: 82.73161602020264 
Train [6/11] | Epoch [6/160] |	nca: 6.515684634447098, flat: 5.928333267569542, pod: 62.77624499797821, loss: 75.22026300430298 
Train [6/11] | Epoch [7/160] |	nca: 6.696597643196583, flat: 5.955009743571281, pod: 63.5387247800827, loss: 76.19033241271973 
Train [6/11] | Epoch [8/160] |	nca: 6.1457081362605095, flat: 5.484734266996384, pod: 60.40834188461304, loss: 72.03878378868103 
Train [6/11] | Epoch [9/160] |	nca: 5.341192409396172, flat: 5.225844696164131, pod: 59.57564091682434, loss: 70.14267778396606 
Train [6/11] | Epoch [10/160] |	nca: 6.0006285682320595, flat: 5.312039256095886, pod: 59.83839964866638, loss: 71.15106773376465 
Train [6/11] | Epoch [11/160] |	nca: 5.975175440311432, flat: 5.431088820099831, pod: 60.16429328918457, loss: 71.5705578327179 
Train [6/11] | Epoch [12/160] |	nca: 5.378410920500755, flat: 5.206879496574402, pod: 58.441911816596985, loss: 69.02720201015472 
Train [6/11] | Epoch [13/160] |	nca: 5.086030311882496, flat: 4.893603160977364, pod: 56.98513686656952, loss: 66.9647707939148 
Train [6/11] | Epoch [14/160] |	nca: 5.476679839193821, flat: 5.000742629170418, pod: 57.19336128234863, loss: 67.67078375816345 
Train [6/11] | Epoch [15/160] |	nca: 5.632701367139816, flat: 5.334324508905411, pod: 59.961373805999756, loss: 70.9283995628357 
Train [6/11] | Epoch [16/160] |	nca: 5.717739619314671, flat: 5.269218772649765, pod: 58.892782330513, loss: 69.87974071502686 
Train [6/11] | Epoch [17/160] |	nca: 5.205978706479073, flat: 5.125403702259064, pod: 59.03433668613434, loss: 69.36571836471558 
Train [6/11] | Epoch [18/160] |	nca: 4.942082457244396, flat: 4.741639390587807, pod: 56.11123204231262, loss: 65.79495406150818 
Train [6/11] | Epoch [19/160] |	nca: 4.626818902790546, flat: 4.571350261569023, pod: 54.2798308134079, loss: 63.477999567985535 
Train [6/11] | Epoch [20/160] |	nca: 4.698747999966145, flat: 4.576252803206444, pod: 54.484206557273865, loss: 63.759207367897034 
Train [6/11] | Epoch [21/160] |	nca: 5.172764040529728, flat: 4.958620205521584, pod: 56.855812788009644, loss: 66.9871973991394 
Train [6/11] | Epoch [22/160] |	nca: 5.213115431368351, flat: 5.018374517560005, pod: 57.0054270029068, loss: 67.23691606521606 
Train [6/11] | Epoch [23/160] |	nca: 5.392892561852932, flat: 5.048830538988113, pod: 56.846930503845215, loss: 67.28865385055542 
Train [6/11] | Epoch [24/160] |	nca: 4.869655624032021, flat: 4.789951100945473, pod: 55.29565382003784, loss: 64.95526039600372 
Train [6/11] | Epoch [25/160] |	nca: 4.404727578163147, flat: 4.472340442240238, pod: 53.739614367485046, loss: 62.616682171821594 
Train [6/11] | Epoch [26/160] |	nca: 4.840520814061165, flat: 4.867446660995483, pod: 55.77670681476593, loss: 65.48467481136322 
Train [6/11] | Epoch [27/160] |	nca: 4.6909657791256905, flat: 4.635819390416145, pod: 54.62905418872833, loss: 63.95583891868591 
Train [6/11] | Epoch [28/160] |	nca: 4.362012691795826, flat: 4.5661255568265915, pod: 53.61243200302124, loss: 62.54057025909424 
Train [6/11] | Epoch [29/160] |	nca: 4.521890386939049, flat: 4.1850708946585655, pod: 51.754119753837585, loss: 60.46108150482178 
Train [6/11] | Epoch [30/160] |	nca: 4.4372743293643, flat: 4.301022924482822, pod: 53.250911593437195, loss: 61.98920822143555 
Train [6/11] | Epoch [31/160] |	nca: 4.760237395763397, flat: 4.436616003513336, pod: 52.82435703277588, loss: 62.02121043205261 
Train [6/11] | Epoch [32/160] |	nca: 4.1133250668644905, flat: 4.342701882123947, pod: 52.352084040641785, loss: 60.80811023712158 
Train [6/11] | Epoch [33/160] |	nca: 4.848820127546787, flat: 4.487538404762745, pod: 53.682162284851074, loss: 63.01852071285248 
Train [6/11] | Epoch [34/160] |	nca: 4.031298525631428, flat: 4.2418956235051155, pod: 51.494083762168884, loss: 59.76727783679962 
Train [6/11] | Epoch [35/160] |	nca: 4.790495932102203, flat: 4.341511115431786, pod: 52.75629198551178, loss: 61.888298749923706 
Train [6/11] | Epoch [36/160] |	nca: 4.450883522629738, flat: 4.477418579161167, pod: 53.073747634887695, loss: 62.002049803733826 
Train [6/11] | Epoch [37/160] |	nca: 4.412242315709591, flat: 4.056404419243336, pod: 50.10590147972107, loss: 58.57454836368561 
Train [6/11] | Epoch [38/160] |	nca: 4.60916768014431, flat: 4.4303411692380905, pod: 52.459477186203, loss: 61.49898636341095 
Train [6/11] | Epoch [39/160] |	nca: 4.174744442105293, flat: 4.045916453003883, pod: 50.22621989250183, loss: 58.4468811750412 
Train [6/11] | Epoch [40/160] |	nca: 4.1008187755942345, flat: 4.018560990691185, pod: 51.0268315076828, loss: 59.14621126651764 
Train [6/11] | Epoch [41/160] |	nca: 4.690740987658501, flat: 4.455295205116272, pod: 54.30834114551544, loss: 63.4543776512146 
Train [6/11] | Epoch [42/160] |	nca: 4.274829193949699, flat: 4.203179821372032, pod: 51.916879415512085, loss: 60.394888520240784 
Train [6/11] | Epoch [43/160] |	nca: 3.956693723797798, flat: 4.027203232049942, pod: 51.353795289993286, loss: 59.33769226074219 
Train [6/11] | Epoch [44/160] |	nca: 3.8089410811662674, flat: 3.653400056064129, pod: 47.65893495082855, loss: 55.121275901794434 
Train [6/11] | Epoch [45/160] |	nca: 3.890241228044033, flat: 3.6851386576890945, pod: 48.379950165748596, loss: 55.95533013343811 
Train [6/11] | Epoch [46/160] |	nca: 4.036277197301388, flat: 3.9606109485030174, pod: 50.245834946632385, loss: 58.24272334575653 
Train [6/11] | Epoch [47/160] |	nca: 3.706778183579445, flat: 3.787044771015644, pod: 49.53235864639282, loss: 57.02618157863617 
Train [6/11] | Epoch [48/160] |	nca: 4.006820946931839, flat: 3.983007311820984, pod: 51.061521768569946, loss: 59.051350235939026 
Train [6/11] | Epoch [49/160] |	nca: 4.187397688627243, flat: 3.8233241736888885, pod: 49.26732647418976, loss: 57.278048515319824 
Train [6/11] | Epoch [50/160] |	nca: 4.195659250020981, flat: 4.052898079156876, pod: 51.4272198677063, loss: 59.675777077674866 
Train [6/11] | Epoch [51/160] |	nca: 3.820564202964306, flat: 3.862101584672928, pod: 49.93840730190277, loss: 57.62107264995575 
Train [6/11] | Epoch [52/160] |	nca: 4.2524608746171, flat: 3.917733743786812, pod: 50.459778785705566, loss: 58.62997376918793 
Train [6/11] | Epoch [53/160] |	nca: 4.121512554585934, flat: 3.808677241206169, pod: 50.813750982284546, loss: 58.743940591812134 
Train [6/11] | Epoch [54/160] |	nca: 3.936754323542118, flat: 3.9241524785757065, pod: 49.06941783428192, loss: 56.93032455444336 
Train [6/11] | Epoch [55/160] |	nca: 4.262063980102539, flat: 3.7707154601812363, pod: 48.81879436969757, loss: 56.85157358646393 
Train [6/11] | Epoch [56/160] |	nca: 3.708651177585125, flat: 3.8593232184648514, pod: 49.444578647613525, loss: 57.012553215026855 
Train [6/11] | Epoch [57/160] |	nca: 3.702125832438469, flat: 3.721545495092869, pod: 48.05067229270935, loss: 55.47434318065643 
Train [6/11] | Epoch [58/160] |	nca: 4.35150058567524, flat: 3.803243100643158, pod: 49.835466742515564, loss: 57.99021017551422 
Train [6/11] | Epoch [59/160] |	nca: 3.7255249693989754, flat: 3.5181524232029915, pod: 46.5028110742569, loss: 53.74648880958557 
Train [6/11] | Epoch [60/160] |	nca: 4.118237689137459, flat: 3.6301177367568016, pod: 47.370426654815674, loss: 55.11878192424774 
Train [6/11] | Epoch [61/160] |	nca: 3.6201546862721443, flat: 3.42163597792387, pod: 45.22428023815155, loss: 52.2660710811615 
Train [6/11] | Epoch [62/160] |	nca: 3.886460080742836, flat: 3.3602385222911835, pod: 45.9263231754303, loss: 53.17302191257477 
Train [6/11] | Epoch [63/160] |	nca: 3.988639496266842, flat: 3.4253866225481033, pod: 46.243539214134216, loss: 53.6575653553009 
Train [6/11] | Epoch [64/160] |	nca: 3.751432918012142, flat: 3.366494730114937, pod: 45.710415959358215, loss: 52.82834303379059 
Train [6/11] | Epoch [65/160] |	nca: 3.7686440497636795, flat: 3.3799240216612816, pod: 45.613609194755554, loss: 52.76217722892761 
Train [6/11] | Epoch [66/160] |	nca: 3.719436250627041, flat: 3.11409280449152, pod: 43.66085112094879, loss: 50.49437987804413 
Train [6/11] | Epoch [67/160] |	nca: 3.866289272904396, flat: 3.432149864733219, pod: 45.89805769920349, loss: 53.1964967250824 
Train [6/11] | Epoch [68/160] |	nca: 3.5422424972057343, flat: 3.2235701829195023, pod: 44.82003045082092, loss: 51.585843205451965 
Train [6/11] | Epoch [69/160] |	nca: 3.8104965426027775, flat: 3.299224331974983, pod: 45.58511936664581, loss: 52.6948401927948 
Train [6/11] | Epoch [70/160] |	nca: 4.085272990167141, flat: 3.494212046265602, pod: 46.21635282039642, loss: 53.79583811759949 
Train [6/11] | Epoch [71/160] |	nca: 4.120842732489109, flat: 3.5642995312809944, pod: 47.33083736896515, loss: 55.01597988605499 
Train [6/11] | Epoch [72/160] |	nca: 3.5787840336561203, flat: 3.3823486641049385, pod: 45.696805357933044, loss: 52.65793776512146 
Train [6/11] | Epoch [73/160] |	nca: 3.3332240507006645, flat: 3.1678730696439743, pod: 44.77130579948425, loss: 51.27240264415741 
Train [6/11] | Epoch [74/160] |	nca: 3.322896972298622, flat: 2.884935975074768, pod: 41.58188807964325, loss: 47.78972125053406 
Train [6/11] | Epoch [75/160] |	nca: 3.60373891890049, flat: 2.986728586256504, pod: 44.05149579048157, loss: 50.641963601112366 
Train [6/11] | Epoch [76/160] |	nca: 3.745430573821068, flat: 3.2077012211084366, pod: 44.96756386756897, loss: 51.920695185661316 
Train [6/11] | Epoch [77/160] |	nca: 3.4221398159861565, flat: 2.9235109612345695, pod: 43.393375396728516, loss: 49.73902606964111 
Train [6/11] | Epoch [78/160] |	nca: 3.5425071716308594, flat: 2.7188090458512306, pod: 41.61089849472046, loss: 47.872215032577515 
Train [6/11] | Epoch [79/160] |	nca: 3.7389330863952637, flat: 3.111401081085205, pod: 43.12759232521057, loss: 49.97792625427246 
Train [6/11] | Epoch [80/160] |	nca: 3.5726228281855583, flat: 3.0557639226317406, pod: 43.44531583786011, loss: 50.073702812194824 
Train [6/11] | Epoch [81/160] |	nca: 3.537162333726883, flat: 2.863255299627781, pod: 42.29563391208649, loss: 48.696051478385925 
Train [6/11] | Epoch [82/160] |	nca: 3.4751865342259407, flat: 2.9333005771040916, pod: 42.65605688095093, loss: 49.06454408168793 
Train [6/11] | Epoch [83/160] |	nca: 3.1178325787186623, flat: 2.7133613973855972, pod: 40.631685972213745, loss: 46.46288001537323 
Train [6/11] | Epoch [84/160] |	nca: 3.4243664667010307, flat: 2.701492339372635, pod: 40.580981850624084, loss: 46.7068407535553 
Train [6/11] | Epoch [85/160] |	nca: 3.4504096284508705, flat: 2.688083954155445, pod: 40.151845932006836, loss: 46.29033982753754 
Train [6/11] | Epoch [86/160] |	nca: 3.4019957035779953, flat: 2.6651076897978783, pod: 39.99522244930267, loss: 46.062326192855835 
Train [6/11] | Epoch [87/160] |	nca: 3.3307367376983166, flat: 2.7252362221479416, pod: 41.311946630477905, loss: 47.36791956424713 
Train [6/11] | Epoch [88/160] |	nca: 3.6050321981310844, flat: 2.7790054380893707, pod: 41.82261335849762, loss: 48.20665085315704 
Train [6/11] | Epoch [89/160] |	nca: 3.4443982765078545, flat: 2.665261246263981, pod: 40.11250102519989, loss: 46.22216069698334 
Train [6/11] | Epoch [90/160] |	nca: 3.1406112611293793, flat: 2.6091858446598053, pod: 40.643791913986206, loss: 46.39358842372894 
Train [6/11] | Epoch [91/160] |	nca: 3.378707133233547, flat: 2.4939286410808563, pod: 38.27722644805908, loss: 44.14986252784729 
Train [6/11] | Epoch [92/160] |	nca: 3.445798471570015, flat: 2.557369988411665, pod: 38.49810862541199, loss: 44.50127685070038 
Train [6/11] | Epoch [93/160] |	nca: 3.3264561593532562, flat: 2.5135240107774734, pod: 39.261104345321655, loss: 45.10108435153961 
Train [6/11] | Epoch [94/160] |	nca: 3.4360080882906914, flat: 2.4847701266407967, pod: 38.15307700634003, loss: 44.07385551929474 
Train [6/11] | Epoch [95/160] |	nca: 3.12992674857378, flat: 2.3241742849349976, pod: 38.418068289756775, loss: 43.87216925621033 
Train [6/11] | Epoch [96/160] |	nca: 3.02957059442997, flat: 2.2491034492850304, pod: 36.04408872127533, loss: 41.32276272773743 
Train [6/11] | Epoch [97/160] |	nca: 3.202952243387699, flat: 2.3261327482759953, pod: 37.18559372425079, loss: 42.71467912197113 
Train [6/11] | Epoch [98/160] |	nca: 3.2721515260636806, flat: 2.327807702124119, pod: 36.69722354412079, loss: 42.29718291759491 
Train [6/11] | Epoch [99/160] |	nca: 3.1461140289902687, flat: 2.202796533703804, pod: 35.488270699977875, loss: 40.83718132972717 
Train [6/11] | Epoch [100/160] |	nca: 3.092070784419775, flat: 2.1417372711002827, pod: 34.46559417247772, loss: 39.69940185546875 
Train [6/11] | Epoch [101/160] |	nca: 3.218300610780716, flat: 2.181412849575281, pod: 35.165775179862976, loss: 40.56548845767975 
Train [6/11] | Epoch [102/160] |	nca: 3.212088745087385, flat: 2.153320536017418, pod: 35.105916917324066, loss: 40.47132647037506 
Train [6/11] | Epoch [103/160] |	nca: 3.160631962120533, flat: 2.1920843757689, pod: 36.59950339794159, loss: 41.95221960544586 
Train [6/11] | Epoch [104/160] |	nca: 2.9409343898296356, flat: 2.1171949803829193, pod: 36.21709281206131, loss: 41.275221824645996 
Train [6/11] | Epoch [105/160] |	nca: 2.8379283770918846, flat: 1.9558661803603172, pod: 34.60191613435745, loss: 39.395710706710815 
Train [6/11] | Epoch [106/160] |	nca: 3.359125543385744, flat: 2.1430489979684353, pod: 35.0923553109169, loss: 40.59453010559082 
Train [6/11] | Epoch [107/160] |	nca: 3.3810332603752613, flat: 2.100501596927643, pod: 34.735611259937286, loss: 40.217145919799805 
Train [6/11] | Epoch [108/160] |	nca: 3.0178975835442543, flat: 2.008743029087782, pod: 33.66408896446228, loss: 38.6907297372818 
Train [6/11] | Epoch [109/160] |	nca: 2.902305979281664, flat: 1.8501541465520859, pod: 31.815569162368774, loss: 36.56802940368652 
Train [6/11] | Epoch [110/160] |	nca: 2.9427579268813133, flat: 1.856705468147993, pod: 32.84160214662552, loss: 37.6410653591156 
Train [6/11] | Epoch [111/160] |	nca: 3.07656529545784, flat: 1.8480095230042934, pod: 32.67002832889557, loss: 37.594603419303894 
Train [6/11] | Epoch [112/160] |	nca: 3.27036589384079, flat: 1.9275118112564087, pod: 32.77891343832016, loss: 37.97679114341736 
Train [6/11] | Epoch [113/160] |	nca: 3.148929573595524, flat: 1.8778143376111984, pod: 32.98314160108566, loss: 38.00988566875458 
Train [6/11] | Epoch [114/160] |	nca: 2.8653457276523113, flat: 1.9043546915054321, pod: 33.059134781360626, loss: 37.828834772109985 
Train [6/11] | Epoch [115/160] |	nca: 2.8700281158089638, flat: 1.7614319026470184, pod: 31.54374998807907, loss: 36.17520999908447 
Train [6/11] | Epoch [116/160] |	nca: 3.0926388017833233, flat: 1.7234301529824734, pod: 30.798333823680878, loss: 35.61440223455429 
Train [6/11] | Epoch [117/160] |	nca: 2.892945386469364, flat: 1.703805685043335, pod: 30.54588431119919, loss: 35.14263552427292 
Train [6/11] | Epoch [118/160] |	nca: 2.8833533599972725, flat: 1.6939482428133488, pod: 30.19140326976776, loss: 34.76870495080948 
Train [6/11] | Epoch [119/160] |	nca: 2.857727352529764, flat: 1.6207681335508823, pod: 29.14160054922104, loss: 33.62009572982788 
Train [6/11] | Epoch [120/160] |	nca: 2.929474502801895, flat: 1.6299667358398438, pod: 29.904179215431213, loss: 34.46362054347992 
Train [6/11] | Epoch [121/160] |	nca: 2.948724739253521, flat: 1.6678045876324177, pod: 30.89404535293579, loss: 35.51057469844818 
Train [6/11] | Epoch [122/160] |	nca: 2.9458889067173004, flat: 1.6013966873288155, pod: 29.639825105667114, loss: 34.18711066246033 
Train [6/11] | Epoch [123/160] |	nca: 2.948803350329399, flat: 1.6272459141910076, pod: 28.805042684078217, loss: 33.38109189271927 
Train [6/11] | Epoch [124/160] |	nca: 3.054526813328266, flat: 1.575931590050459, pod: 29.23349791765213, loss: 33.86395651102066 
Train [6/11] | Epoch [125/160] |	nca: 3.085390482097864, flat: 1.5694315284490585, pod: 28.72730702161789, loss: 33.382129192352295 
Train [6/11] | Epoch [126/160] |	nca: 2.8756016455590725, flat: 1.5226356349885464, pod: 28.18376225233078, loss: 32.58199954032898 
Train [6/11] | Epoch [127/160] |	nca: 2.921175330877304, flat: 1.5637085661292076, pod: 29.765209794044495, loss: 34.25009340047836 
Train [6/11] | Epoch [128/160] |	nca: 2.827711895108223, flat: 1.5513690300285816, pod: 28.19991511106491, loss: 32.57899582386017 
Train [6/11] | Epoch [129/160] |	nca: 2.9899181872606277, flat: 1.394625123590231, pod: 27.237732529640198, loss: 31.62227588891983 
Train [6/11] | Epoch [130/160] |	nca: 3.0507736951112747, flat: 1.4664528891444206, pod: 27.13901686668396, loss: 31.656243562698364 
Train [6/11] | Epoch [131/160] |	nca: 2.865101885050535, flat: 1.4637910537421703, pod: 28.070861220359802, loss: 32.39975434541702 
Train [6/11] | Epoch [132/160] |	nca: 2.7609937600791454, flat: 1.3628094233572483, pod: 26.64933282136917, loss: 30.773136138916016 
Train [6/11] | Epoch [133/160] |	nca: 2.803415108472109, flat: 1.3436509724706411, pod: 25.813741385936737, loss: 29.9608074426651 
Train [6/11] | Epoch [134/160] |	nca: 2.843484677374363, flat: 1.3059101402759552, pod: 25.474376142024994, loss: 29.62377095222473 
Train [6/11] | Epoch [135/160] |	nca: 2.7827493511140347, flat: 1.306812696158886, pod: 25.115621030330658, loss: 29.20518308877945 
Train [6/11] | Epoch [136/160] |	nca: 2.7703049033880234, flat: 1.2889410220086575, pod: 25.08456379175186, loss: 29.143809914588928 
Train [6/11] | Epoch [137/160] |	nca: 2.9435267485678196, flat: 1.341319853439927, pod: 26.256486117839813, loss: 30.541332840919495 
Train [6/11] | Epoch [138/160] |	nca: 2.9556868597865105, flat: 1.2859587110579014, pod: 25.057386994361877, loss: 29.299032509326935 
Train [6/11] | Epoch [139/160] |	nca: 2.8637863472104073, flat: 1.2988107353448868, pod: 25.239061057567596, loss: 29.401658296585083 
Train [6/11] | Epoch [140/160] |	nca: 2.95668838173151, flat: 1.284448018297553, pod: 25.202665090560913, loss: 29.44380134344101 
Train [6/11] | Epoch [141/160] |	nca: 2.9318658225238323, flat: 1.2639411576092243, pod: 24.360550343990326, loss: 28.556357443332672 
Train [6/11] | Epoch [142/160] |	nca: 2.7982220835983753, flat: 1.276388619095087, pod: 24.681160032749176, loss: 28.755770802497864 
Train [6/11] | Epoch [143/160] |	nca: 3.003976821899414, flat: 1.2471575736999512, pod: 24.6204314827919, loss: 28.871565759181976 
Train [6/11] | Epoch [144/160] |	nca: 2.838231585919857, flat: 1.2131177950650454, pod: 23.8685405254364, loss: 27.919889986515045 
Train [6/11] | Epoch [145/160] |	nca: 2.8376598097383976, flat: 1.1376927383244038, pod: 22.45900547504425, loss: 26.43435800075531 
Train [6/11] | Epoch [146/160] |	nca: 2.624155804514885, flat: 1.2126678321510553, pod: 23.6824951171875, loss: 27.519318640232086 
Train [6/11] | Epoch [147/160] |	nca: 2.943453848361969, flat: 1.1730791758745909, pod: 23.238397538661957, loss: 27.354930639266968 
Train [6/11] | Epoch [148/160] |	nca: 2.764574855566025, flat: 1.1404023244976997, pod: 23.217921137809753, loss: 27.12289822101593 
Train [6/11] | Epoch [149/160] |	nca: 2.7059486359357834, flat: 1.1701457910239697, pod: 23.29251664876938, loss: 27.168610870838165 
Train [6/11] | Epoch [150/160] |	nca: 2.7959245145320892, flat: 1.1309794895350933, pod: 22.688862562179565, loss: 26.615766525268555 
Train [6/11] | Epoch [151/160] |	nca: 2.743594963103533, flat: 1.1777056753635406, pod: 23.051711678504944, loss: 26.973012447357178 
Train [6/11] | Epoch [152/160] |	nca: 2.864149324595928, flat: 1.1708382461220026, pod: 23.163292169570923, loss: 27.19827950000763 
Train [6/11] | Epoch [153/160] |	nca: 2.7452844716608524, flat: 1.1166448667645454, pod: 22.25987136363983, loss: 26.12180083990097 
Train [6/11] | Epoch [154/160] |	nca: 2.8554728366434574, flat: 1.1023414321243763, pod: 22.007178783416748, loss: 25.964992702007294 
Train [6/11] | Epoch [155/160] |	nca: 2.6404767967760563, flat: 1.1376678347587585, pod: 22.21472591161728, loss: 25.992870569229126 
Train [6/11] | Epoch [156/160] |	nca: 2.5926237776875496, flat: 1.0996300354599953, pod: 22.292364299297333, loss: 25.98461800813675 
Train [6/11] | Epoch [157/160] |	nca: 2.702952153980732, flat: 1.1192004326730967, pod: 22.331489980220795, loss: 26.153642535209656 
Train [6/11] | Epoch [158/160] |	nca: 2.9177398830652237, flat: 1.1444126907736063, pod: 22.71384769678116, loss: 26.776000261306763 
Train [6/11] | Epoch [159/160] |	nca: 2.713045958429575, flat: 1.0738820191472769, pod: 21.264143645763397, loss: 25.0510715842247 
Train [6/11] | Epoch [160/160] |	nca: 2.7742650099098682, flat: 1.1154611017554998, pod: 22.119940280914307, loss: 26.00966638326645 
Fine-tuning
Building & updating memory.
Train [6/11] | Epoch [161/180] |	nca: 1.850291296839714, flat: 0.931088499724865, pod: 13.205800712108612, loss: 15.987180471420288 
Train [6/11] | Epoch [162/180] |	nca: 0.9092853255569935, flat: 0.9479157812893391, pod: 12.897088944911957, loss: 14.754290103912354 
Train [6/11] | Epoch [163/180] |	nca: 0.6785808242857456, flat: 0.9338386431336403, pod: 13.046850740909576, loss: 14.659270286560059 
Train [6/11] | Epoch [164/180] |	nca: 0.6523683443665504, flat: 0.9520357996225357, pod: 13.123905420303345, loss: 14.728309750556946 
Train [6/11] | Epoch [165/180] |	nca: 0.5950367636978626, flat: 0.9298520013689995, pod: 12.88090044260025, loss: 14.405789256095886 
Train [6/11] | Epoch [166/180] |	nca: 0.5473785512149334, flat: 0.9089820794761181, pod: 12.657309234142303, loss: 14.113669753074646 
Train [6/11] | Epoch [167/180] |	nca: 0.563083304092288, flat: 0.9512993842363358, pod: 13.28187608718872, loss: 14.796258687973022 
Train [6/11] | Epoch [168/180] |	nca: 0.601682260632515, flat: 0.9309192001819611, pod: 12.794249773025513, loss: 14.32685112953186 
Train [6/11] | Epoch [169/180] |	nca: 0.5466826818883419, flat: 0.9373553395271301, pod: 12.896180510520935, loss: 14.380218386650085 
Train [6/11] | Epoch [170/180] |	nca: 0.5262309685349464, flat: 0.9325845800340176, pod: 12.830034911632538, loss: 14.2888503074646 
Train [6/11] | Epoch [171/180] |	nca: 0.5101161077618599, flat: 0.9528950527310371, pod: 13.117463290691376, loss: 14.58047467470169 
Train [6/11] | Epoch [172/180] |	nca: 0.48463163897395134, flat: 0.9365610852837563, pod: 13.191551208496094, loss: 14.612743854522705 
Train [6/11] | Epoch [173/180] |	nca: 0.4606395401060581, flat: 0.9071301631629467, pod: 12.624195516109467, loss: 13.991965413093567 
Train [6/11] | Epoch [174/180] |	nca: 0.5066949967294931, flat: 0.9088386669754982, pod: 12.632639527320862, loss: 14.048173189163208 
Train [6/11] | Epoch [175/180] |	nca: 0.4707198441028595, flat: 0.8984428495168686, pod: 12.425895392894745, loss: 13.795057892799377 
Train [6/11] | Epoch [176/180] |	nca: 0.4940737709403038, flat: 0.9391800090670586, pod: 13.341639459133148, loss: 14.774893283843994 
Train [6/11] | Epoch [177/180] |	nca: 0.5349806994199753, flat: 0.95754474401474, pod: 13.006078839302063, loss: 14.498604416847229 
Train [6/11] | Epoch [178/180] |	nca: 0.47878143563866615, flat: 0.959678590297699, pod: 13.15549647808075, loss: 14.593956470489502 
Train [6/11] | Epoch [179/180] |	nca: 0.48729395121335983, flat: 0.96579559892416, pod: 12.930893898010254, loss: 14.383983373641968 
Train [6/11] | Epoch [180/180] |	nca: 0.4385388232767582, flat: 0.9245304055511951, pod: 12.654323518276215, loss: 14.017392694950104 
after task
Building & updating memory.
after task
Eval on 0->75.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6741666666666667.
Current acc: {'total': 0.609, '00-09': 0.685, '10-19': 0.603, '20-29': 0.557, '30-39': 0.577, '40-49': 0.652, '50-59': 0.612, '60-69': 0.537, '70-79': 0.696}.
Avg inc acc top5: 0.8993333333333333.
Current acc top5: {'total': 0.87}.
Forgetting: 0.010111111111111107.
Cord metric: 0.66.
Old accuracy: 0.60, mean: 0.66.
New accuracy: 0.70, mean: 0.65.
================Task 6 Start!================
Testing on False unseen tasks (max class = 80).
Set memory of size: 1500.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 6 Training!================
The training samples number: 4000
Train on 75->80.
train task
nb 4000.
Train [7/11] | Epoch [1/160] |	nca: 23.953242480754852, flat: 8.128118120133877, pod: 71.43908333778381, loss: 103.52044427394867 
Train [7/11] | Epoch [2/160] |	nca: 22.929286062717438, flat: 13.336004704236984, pod: 96.11342787742615, loss: 132.37871837615967 
Train [7/11] | Epoch [3/160] |	nca: 16.019536823034286, flat: 10.586089253425598, pod: 86.77516055107117, loss: 113.38078689575195 
Train [7/11] | Epoch [4/160] |	nca: 11.796904534101486, flat: 8.479208037257195, pod: 77.98864603042603, loss: 98.2647590637207 
Train [7/11] | Epoch [5/160] |	nca: 9.720584437251091, flat: 7.315790727734566, pod: 72.58761262893677, loss: 89.62398743629456 
Train [7/11] | Epoch [6/160] |	nca: 9.513070598244667, flat: 6.997695699334145, pod: 70.66529273986816, loss: 87.17605924606323 
Train [7/11] | Epoch [7/160] |	nca: 7.804317221045494, flat: 5.867035999894142, pod: 64.26332354545593, loss: 77.93467688560486 
Train [7/11] | Epoch [8/160] |	nca: 8.589253664016724, flat: 6.502143681049347, pod: 69.41758871078491, loss: 84.5089864730835 
Train [7/11] | Epoch [9/160] |	nca: 8.39672565460205, flat: 5.989835396409035, pod: 65.04013228416443, loss: 79.42669367790222 
Train [7/11] | Epoch [10/160] |	nca: 7.172307252883911, flat: 5.65045952796936, pod: 65.53615355491638, loss: 78.35892009735107 
Train [7/11] | Epoch [11/160] |	nca: 7.557687401771545, flat: 5.917855784296989, pod: 65.02040147781372, loss: 78.49594449996948 
Train [7/11] | Epoch [12/160] |	nca: 7.161618754267693, flat: 5.238772004842758, pod: 61.14732384681702, loss: 73.5477147102356 
Train [7/11] | Epoch [13/160] |	nca: 6.896982789039612, flat: 5.441442891955376, pod: 61.72834360599518, loss: 74.06677007675171 
Train [7/11] | Epoch [14/160] |	nca: 6.026513494551182, flat: 4.933392554521561, pod: 58.73254883289337, loss: 69.69245481491089 
Train [7/11] | Epoch [15/160] |	nca: 6.5120014771819115, flat: 5.0381830632686615, pod: 60.46374213695526, loss: 72.01392650604248 
Train [7/11] | Epoch [16/160] |	nca: 7.174653634428978, flat: 5.4148697555065155, pod: 61.34060263633728, loss: 73.93012571334839 
Train [7/11] | Epoch [17/160] |	nca: 6.364655405282974, flat: 5.2431555688381195, pod: 59.48203098773956, loss: 71.08984160423279 
Train [7/11] | Epoch [18/160] |	nca: 6.836200773715973, flat: 5.51411908864975, pod: 62.637474060058594, loss: 74.98779344558716 
Train [7/11] | Epoch [19/160] |	nca: 6.630699247121811, flat: 5.532490149140358, pod: 63.02370309829712, loss: 75.18689227104187 
Train [7/11] | Epoch [20/160] |	nca: 6.754583582282066, flat: 5.447060912847519, pod: 62.34129536151886, loss: 74.54293990135193 
Train [7/11] | Epoch [21/160] |	nca: 6.7882809191942215, flat: 5.368267893791199, pod: 60.77434277534485, loss: 72.93089127540588 
Train [7/11] | Epoch [22/160] |	nca: 6.4544863030314445, flat: 5.2152097672224045, pod: 61.23151218891144, loss: 72.9012086391449 
Train [7/11] | Epoch [23/160] |	nca: 6.118401974439621, flat: 5.276392087340355, pod: 61.75838875770569, loss: 73.15318298339844 
Train [7/11] | Epoch [24/160] |	nca: 5.845374129712582, flat: 4.922521084547043, pod: 58.82268476486206, loss: 69.59057939052582 
Train [7/11] | Epoch [25/160] |	nca: 5.687623843550682, flat: 4.847650200128555, pod: 58.330517172813416, loss: 68.86579132080078 
Train [7/11] | Epoch [26/160] |	nca: 5.772282749414444, flat: 4.59732286632061, pod: 56.966206789016724, loss: 67.33581221103668 
Train [7/11] | Epoch [27/160] |	nca: 5.994041509926319, flat: 4.787131160497665, pod: 58.45265066623688, loss: 69.23382258415222 
Train [7/11] | Epoch [28/160] |	nca: 7.401865854859352, flat: 5.534162789583206, pod: 62.27973198890686, loss: 75.21576118469238 
Train [7/11] | Epoch [29/160] |	nca: 6.667639866471291, flat: 5.846377685666084, pod: 63.61953258514404, loss: 76.13354969024658 
Train [7/11] | Epoch [30/160] |	nca: 5.586319364607334, flat: 4.780532233417034, pod: 57.51219725608826, loss: 67.87904953956604 
Train [7/11] | Epoch [31/160] |	nca: 5.683171302080154, flat: 4.637280717492104, pod: 56.74208199977875, loss: 67.06253385543823 
Train [7/11] | Epoch [32/160] |	nca: 5.9484990909695625, flat: 4.898510470986366, pod: 58.647987604141235, loss: 69.49499726295471 
Train [7/11] | Epoch [33/160] |	nca: 5.687414564192295, flat: 4.895869463682175, pod: 57.968289732933044, loss: 68.55157399177551 
Train [7/11] | Epoch [34/160] |	nca: 5.660032980144024, flat: 4.8669553399086, pod: 59.05216109752655, loss: 69.57914865016937 
Train [7/11] | Epoch [35/160] |	nca: 5.439113825559616, flat: 4.664310589432716, pod: 56.88843357563019, loss: 66.9918577671051 
Train [7/11] | Epoch [36/160] |	nca: 5.193857260048389, flat: 4.436554439365864, pod: 56.36719250679016, loss: 65.99760413169861 
Train [7/11] | Epoch [37/160] |	nca: 5.718327037990093, flat: 4.728023812174797, pod: 58.177358508110046, loss: 68.62370932102203 
Train [7/11] | Epoch [38/160] |	nca: 5.252840638160706, flat: 4.449527859687805, pod: 55.02975332736969, loss: 64.73212206363678 
Train [7/11] | Epoch [39/160] |	nca: 4.838674530386925, flat: 4.216958023607731, pod: 53.86748290061951, loss: 62.923115253448486 
Train [7/11] | Epoch [40/160] |	nca: 4.627856478095055, flat: 4.157053381204605, pod: 54.158578753471375, loss: 62.94348847866058 
Train [7/11] | Epoch [41/160] |	nca: 5.1011610478162766, flat: 4.208842843770981, pod: 54.07310461997986, loss: 63.383108496665955 
Train [7/11] | Epoch [42/160] |	nca: 4.811182677745819, flat: 4.1355520114302635, pod: 54.38831579685211, loss: 63.335049629211426 
Train [7/11] | Epoch [43/160] |	nca: 5.039270617067814, flat: 4.02532347291708, pod: 53.179556369781494, loss: 62.244150280952454 
Train [7/11] | Epoch [44/160] |	nca: 5.614883951842785, flat: 4.3729608207941055, pod: 55.869521617889404, loss: 65.85736584663391 
Train [7/11] | Epoch [45/160] |	nca: 4.8846199586987495, flat: 4.179151304066181, pod: 54.25250279903412, loss: 63.31627380847931 
Train [7/11] | Epoch [46/160] |	nca: 5.009829372167587, flat: 3.9316286891698837, pod: 52.40128517150879, loss: 61.34274339675903 
Train [7/11] | Epoch [47/160] |	nca: 5.522975601255894, flat: 4.251312553882599, pod: 55.1175616979599, loss: 64.89184939861298 
Train [7/11] | Epoch [48/160] |	nca: 5.954839698970318, flat: 4.605606436729431, pod: 55.20819139480591, loss: 65.76863741874695 
Train [7/11] | Epoch [49/160] |	nca: 5.01216284930706, flat: 4.245025970041752, pod: 54.04657852649689, loss: 63.30376720428467 
Train [7/11] | Epoch [50/160] |	nca: 4.939907789230347, flat: 4.330589555203915, pod: 55.211161851882935, loss: 64.48165905475616 
Train [7/11] | Epoch [51/160] |	nca: 5.840869747102261, flat: 4.631235241889954, pod: 55.83652484416962, loss: 66.3086302280426 
Train [7/11] | Epoch [52/160] |	nca: 4.39101305603981, flat: 3.936671830713749, pod: 51.828349471092224, loss: 60.15603494644165 
Train [7/11] | Epoch [53/160] |	nca: 4.848854497075081, flat: 3.8171259611845016, pod: 51.4658579826355, loss: 60.13183867931366 
Train [7/11] | Epoch [54/160] |	nca: 4.230924479663372, flat: 3.840134084224701, pod: 51.31429183483124, loss: 59.385350823402405 
Train [7/11] | Epoch [55/160] |	nca: 4.667939275503159, flat: 3.515538401901722, pod: 49.23018741607666, loss: 57.41366517543793 
Train [7/11] | Epoch [56/160] |	nca: 5.35260359197855, flat: 4.236528351902962, pod: 54.21883702278137, loss: 63.807968735694885 
Train [7/11] | Epoch [57/160] |	nca: 5.094981037080288, flat: 4.1856943890452385, pod: 53.2919784784317, loss: 62.572654128074646 
Train [7/11] | Epoch [58/160] |	nca: 4.524744778871536, flat: 3.7470313906669617, pod: 50.91490352153778, loss: 59.18667960166931 
Train [7/11] | Epoch [59/160] |	nca: 4.72159781306982, flat: 3.847945563495159, pod: 50.604326367378235, loss: 59.17387020587921 
Train [7/11] | Epoch [60/160] |	nca: 4.2199175879359245, flat: 3.5785087198019028, pod: 50.049970626831055, loss: 57.84839701652527 
Train [7/11] | Epoch [61/160] |	nca: 4.7634469866752625, flat: 3.6486052125692368, pod: 48.96531403064728, loss: 57.37736642360687 
Train [7/11] | Epoch [62/160] |	nca: 4.380483604967594, flat: 3.4698526188731194, pod: 47.57081079483032, loss: 55.421146869659424 
Train [7/11] | Epoch [63/160] |	nca: 4.1679412946105, flat: 3.2993052303791046, pod: 46.73972451686859, loss: 54.2069708108902 
Train [7/11] | Epoch [64/160] |	nca: 4.8065027222037315, flat: 3.475662350654602, pod: 49.32182478904724, loss: 57.60398983955383 
Train [7/11] | Epoch [65/160] |	nca: 4.909715540707111, flat: 3.6919618248939514, pod: 50.101181507110596, loss: 58.70285892486572 
Train [7/11] | Epoch [66/160] |	nca: 4.4823892042040825, flat: 3.6204979568719864, pod: 50.44756901264191, loss: 58.550455927848816 
Train [7/11] | Epoch [67/160] |	nca: 4.245935760438442, flat: 3.358866326510906, pod: 47.512216687202454, loss: 55.117018699645996 
Train [7/11] | Epoch [68/160] |	nca: 4.02342389523983, flat: 3.1403173357248306, pod: 45.43795645236969, loss: 52.60169744491577 
Train [7/11] | Epoch [69/160] |	nca: 4.2601606994867325, flat: 3.168407142162323, pod: 45.791489243507385, loss: 53.220057129859924 
Train [7/11] | Epoch [70/160] |	nca: 4.526942126452923, flat: 3.2837554663419724, pod: 47.20462954044342, loss: 55.01532685756683 
Train [7/11] | Epoch [71/160] |	nca: 4.42986187338829, flat: 3.493477016687393, pod: 48.09063386917114, loss: 56.013972759246826 
Train [7/11] | Epoch [72/160] |	nca: 4.705493807792664, flat: 3.4095869213342667, pod: 47.8918981552124, loss: 56.00697863101959 
Train [7/11] | Epoch [73/160] |	nca: 4.000431388616562, flat: 3.1032999604940414, pod: 46.010172605514526, loss: 53.113903880119324 
Train [7/11] | Epoch [74/160] |	nca: 4.060592517256737, flat: 3.024511769413948, pod: 44.92333650588989, loss: 52.00844061374664 
Train [7/11] | Epoch [75/160] |	nca: 3.8953347206115723, flat: 3.0017190352082253, pod: 44.793068170547485, loss: 51.69012200832367 
Train [7/11] | Epoch [76/160] |	nca: 4.492988802492619, flat: 3.1279645189642906, pod: 45.72581243515015, loss: 53.34676551818848 
Train [7/11] | Epoch [77/160] |	nca: 4.795733213424683, flat: 3.325944721698761, pod: 47.6379337310791, loss: 55.75961196422577 
Train [7/11] | Epoch [78/160] |	nca: 4.118855878710747, flat: 3.2179783955216408, pod: 45.96943008899689, loss: 53.3062641620636 
Train [7/11] | Epoch [79/160] |	nca: 4.171247974038124, flat: 3.0393801778554916, pod: 45.484790444374084, loss: 52.69541835784912 
Train [7/11] | Epoch [80/160] |	nca: 4.222395732998848, flat: 3.123114086687565, pod: 45.39012575149536, loss: 52.73563539981842 
Train [7/11] | Epoch [81/160] |	nca: 4.670266658067703, flat: 3.1924146115779877, pod: 46.41585898399353, loss: 54.27854037284851 
Train [7/11] | Epoch [82/160] |	nca: 4.340523153543472, flat: 3.431342601776123, pod: 47.586809515953064, loss: 55.35867536067963 
Train [7/11] | Epoch [83/160] |	nca: 4.081793777644634, flat: 2.8950674906373024, pod: 43.68686783313751, loss: 50.66372883319855 
Train [7/11] | Epoch [84/160] |	nca: 4.352582074701786, flat: 2.960556596517563, pod: 44.33964931964874, loss: 51.652788043022156 
Train [7/11] | Epoch [85/160] |	nca: 3.762638933956623, flat: 3.045804224908352, pod: 44.606770396232605, loss: 51.41521370410919 
Train [7/11] | Epoch [86/160] |	nca: 3.910985842347145, flat: 2.703178972005844, pod: 42.29852318763733, loss: 48.91268789768219 
Train [7/11] | Epoch [87/160] |	nca: 4.038728129118681, flat: 2.6931785121560097, pod: 41.362592816352844, loss: 48.094499707221985 
Train [7/11] | Epoch [88/160] |	nca: 3.6349362656474113, flat: 2.6192483752965927, pod: 41.6742399930954, loss: 47.92842471599579 
Train [7/11] | Epoch [89/160] |	nca: 3.980995960533619, flat: 2.5969181433320045, pod: 41.65425634384155, loss: 48.23217058181763 
Train [7/11] | Epoch [90/160] |	nca: 4.1571739092469215, flat: 2.858101524412632, pod: 44.395678997039795, loss: 51.410953998565674 
Train [7/11] | Epoch [91/160] |	nca: 3.9499868229031563, flat: 2.6106074303388596, pod: 41.255130767822266, loss: 47.81572473049164 
Train [7/11] | Epoch [92/160] |	nca: 4.187420159578323, flat: 2.8317388966679573, pod: 42.125178933143616, loss: 49.14433825016022 
Train [7/11] | Epoch [93/160] |	nca: 3.7608991600573063, flat: 2.6787228509783745, pod: 41.45309865474701, loss: 47.892720341682434 
Train [7/11] | Epoch [94/160] |	nca: 3.720222979784012, flat: 2.521337777376175, pod: 41.60608720779419, loss: 47.84764814376831 
Train [7/11] | Epoch [95/160] |	nca: 3.5780329294502735, flat: 2.345524325966835, pod: 39.04196298122406, loss: 44.96552038192749 
Train [7/11] | Epoch [96/160] |	nca: 3.6974675953388214, flat: 2.4516798481345177, pod: 39.578810691833496, loss: 45.72795820236206 
Train [7/11] | Epoch [97/160] |	nca: 3.8723893128335476, flat: 2.417010009288788, pod: 39.94591736793518, loss: 46.23531675338745 
Train [7/11] | Epoch [98/160] |	nca: 3.7044805139303207, flat: 2.3936042487621307, pod: 38.979223132133484, loss: 45.07730793952942 
Train [7/11] | Epoch [99/160] |	nca: 3.8709063604474068, flat: 2.459062471985817, pod: 40.295639514923096, loss: 46.62560820579529 
Train [7/11] | Epoch [100/160] |	nca: 3.489048160612583, flat: 2.2686027698218822, pod: 38.30010759830475, loss: 44.0577586889267 
Train [7/11] | Epoch [101/160] |	nca: 3.543389342725277, flat: 2.2252733036875725, pod: 37.6220098733902, loss: 43.39067268371582 
Train [7/11] | Epoch [102/160] |	nca: 3.7457351982593536, flat: 2.2594701424241066, pod: 37.73938727378845, loss: 43.74459254741669 
Train [7/11] | Epoch [103/160] |	nca: 3.6077791005373, flat: 2.130083564668894, pod: 36.235154032707214, loss: 41.97301685810089 
Train [7/11] | Epoch [104/160] |	nca: 3.544314920902252, flat: 2.0807868242263794, pod: 35.370291352272034, loss: 40.99539339542389 
Train [7/11] | Epoch [105/160] |	nca: 3.7955239564180374, flat: 2.053100649267435, pod: 35.88234221935272, loss: 41.730966687202454 
Train [7/11] | Epoch [106/160] |	nca: 3.6211540177464485, flat: 2.1157968938350677, pod: 37.068634271621704, loss: 42.80558514595032 
Train [7/11] | Epoch [107/160] |	nca: 3.3876803144812584, flat: 2.0574149191379547, pod: 35.32113039493561, loss: 40.766225695610046 
Train [7/11] | Epoch [108/160] |	nca: 3.4449126720428467, flat: 2.0339681804180145, pod: 35.7200728058815, loss: 41.19895339012146 
Train [7/11] | Epoch [109/160] |	nca: 3.574399597942829, flat: 1.9789944551885128, pod: 35.2620535492897, loss: 40.81544780731201 
Train [7/11] | Epoch [110/160] |	nca: 3.6029968932271004, flat: 1.9000830426812172, pod: 34.2251056432724, loss: 39.728185534477234 
Train [7/11] | Epoch [111/160] |	nca: 3.5307732671499252, flat: 2.039549145847559, pod: 35.249930024147034, loss: 40.82025218009949 
Train [7/11] | Epoch [112/160] |	nca: 3.6632144302129745, flat: 2.0406438410282135, pod: 35.82679384946823, loss: 41.5306521654129 
Train [7/11] | Epoch [113/160] |	nca: 3.5511042810976505, flat: 1.8257519789040089, pod: 32.541014075279236, loss: 37.9178706407547 
Train [7/11] | Epoch [114/160] |	nca: 3.6252307407557964, flat: 1.943143043667078, pod: 34.240140199661255, loss: 39.80851435661316 
Train [7/11] | Epoch [115/160] |	nca: 3.176900628954172, flat: 1.9345873780548573, pod: 34.41984236240387, loss: 39.53133046627045 
Train [7/11] | Epoch [116/160] |	nca: 3.347463369369507, flat: 1.6900639608502388, pod: 31.7037256360054, loss: 36.7412526011467 
Train [7/11] | Epoch [117/160] |	nca: 3.6835191547870636, flat: 1.892120685428381, pod: 33.863140881061554, loss: 39.438780665397644 
Train [7/11] | Epoch [118/160] |	nca: 3.4079009294509888, flat: 1.787530805915594, pod: 33.21948117017746, loss: 38.414913058280945 
Train [7/11] | Epoch [119/160] |	nca: 3.456160254776478, flat: 1.7987388335168362, pod: 32.52056419849396, loss: 37.77546375989914 
Train [7/11] | Epoch [120/160] |	nca: 3.339989960193634, flat: 1.6912892796099186, pod: 31.363124787807465, loss: 36.39440381526947 
Train [7/11] | Epoch [121/160] |	nca: 3.58676890283823, flat: 1.6986190490424633, pod: 31.291427195072174, loss: 36.57681494951248 
Train [7/11] | Epoch [122/160] |	nca: 3.44364033639431, flat: 1.6920673809945583, pod: 32.096633553504944, loss: 37.23234140872955 
Train [7/11] | Epoch [123/160] |	nca: 3.4166907109320164, flat: 1.61383955180645, pod: 30.77864807844162, loss: 35.80917817354202 
Train [7/11] | Epoch [124/160] |	nca: 3.4083208441734314, flat: 1.668845683336258, pod: 31.557799339294434, loss: 36.6349658370018 
Train [7/11] | Epoch [125/160] |	nca: 3.358694463968277, flat: 1.5911688320338726, pod: 30.820105373859406, loss: 35.76996886730194 
Train [7/11] | Epoch [126/160] |	nca: 3.1600626222789288, flat: 1.5066796280443668, pod: 29.201800227165222, loss: 33.868542551994324 
Train [7/11] | Epoch [127/160] |	nca: 3.2772887982428074, flat: 1.5385472998023033, pod: 29.59365737438202, loss: 34.40949350595474 
Train [7/11] | Epoch [128/160] |	nca: 3.422270253300667, flat: 1.5126887783408165, pod: 28.7061225771904, loss: 33.641081750392914 
Train [7/11] | Epoch [129/160] |	nca: 3.2643774449825287, flat: 1.507177997380495, pod: 29.243921220302582, loss: 34.0154767036438 
Train [7/11] | Epoch [130/160] |	nca: 3.4044359922409058, flat: 1.4665462486445904, pod: 28.64941054582596, loss: 33.520392656326294 
Train [7/11] | Epoch [131/160] |	nca: 3.21965716406703, flat: 1.5088107287883759, pod: 28.546049118041992, loss: 33.27451711893082 
Train [7/11] | Epoch [132/160] |	nca: 3.2885550931096077, flat: 1.506889220327139, pod: 29.372998654842377, loss: 34.16844308376312 
Train [7/11] | Epoch [133/160] |	nca: 3.245831035077572, flat: 1.4087934829294682, pod: 28.113596737384796, loss: 32.768221497535706 
Train [7/11] | Epoch [134/160] |	nca: 3.1266419030725956, flat: 1.486630629748106, pod: 29.21610152721405, loss: 33.829373836517334 
Train [7/11] | Epoch [135/160] |	nca: 3.1741457916796207, flat: 1.4439812786877155, pod: 28.33051574230194, loss: 32.94864308834076 
Train [7/11] | Epoch [136/160] |	nca: 3.1551702693104744, flat: 1.3475938364863396, pod: 26.847693502902985, loss: 31.35045737028122 
Train [7/11] | Epoch [137/160] |	nca: 3.4012055844068527, flat: 1.3520242869853973, pod: 26.65768575668335, loss: 31.41091549396515 
Train [7/11] | Epoch [138/160] |	nca: 3.1858974508941174, flat: 1.3348898813128471, pod: 26.625327229499817, loss: 31.146114587783813 
Train [7/11] | Epoch [139/160] |	nca: 3.263597935438156, flat: 1.2908692546188831, pod: 26.299478232860565, loss: 30.853945553302765 
Train [7/11] | Epoch [140/160] |	nca: 3.237223297357559, flat: 1.2982123456895351, pod: 25.779806315898895, loss: 30.315241813659668 
Train [7/11] | Epoch [141/160] |	nca: 3.145155683159828, flat: 1.2779217921197414, pod: 25.552936136722565, loss: 29.97601354122162 
Train [7/11] | Epoch [142/160] |	nca: 3.1803223714232445, flat: 1.2896575145423412, pod: 25.62385880947113, loss: 30.09383863210678 
Train [7/11] | Epoch [143/160] |	nca: 3.05158631503582, flat: 1.3151305504143238, pod: 26.308293879032135, loss: 30.6750106215477 
Train [7/11] | Epoch [144/160] |	nca: 3.093411434441805, flat: 1.2108901366591454, pod: 24.517489314079285, loss: 28.82179093360901 
Train [7/11] | Epoch [145/160] |	nca: 3.083525851368904, flat: 1.2133039254695177, pod: 25.01771193742752, loss: 29.31454163789749 
Train [7/11] | Epoch [146/160] |	nca: 3.13655074685812, flat: 1.2266245186328888, pod: 25.15391492843628, loss: 29.51709020137787 
Train [7/11] | Epoch [147/160] |	nca: 3.067740276455879, flat: 1.2439700569957495, pod: 25.161481618881226, loss: 29.473191916942596 
Train [7/11] | Epoch [148/160] |	nca: 3.244635410606861, flat: 1.2699233405292034, pod: 25.63438582420349, loss: 30.148944556713104 
Train [7/11] | Epoch [149/160] |	nca: 3.2283462285995483, flat: 1.261599786579609, pod: 25.21298110485077, loss: 29.702927112579346 
Train [7/11] | Epoch [150/160] |	nca: 3.180249772965908, flat: 1.229595573619008, pod: 24.601880073547363, loss: 29.01172524690628 
Train [7/11] | Epoch [151/160] |	nca: 3.133206285536289, flat: 1.210793748497963, pod: 24.528575539588928, loss: 28.872575759887695 
Train [7/11] | Epoch [152/160] |	nca: 3.095889188349247, flat: 1.2420024797320366, pod: 25.05181211233139, loss: 29.389703691005707 
Train [7/11] | Epoch [153/160] |	nca: 3.0565904155373573, flat: 1.159977925941348, pod: 23.707027554512024, loss: 27.9235959649086 
Train [7/11] | Epoch [154/160] |	nca: 3.0479071959853172, flat: 1.1774130258709192, pod: 24.244612455368042, loss: 28.469932794570923 
Train [7/11] | Epoch [155/160] |	nca: 3.2630528435111046, flat: 1.1788368206471205, pod: 23.576771676540375, loss: 28.018661201000214 
Train [7/11] | Epoch [156/160] |	nca: 3.1653439886868, flat: 1.212847787886858, pod: 24.335519075393677, loss: 28.713711082935333 
Train [7/11] | Epoch [157/160] |	nca: 3.196607679128647, flat: 1.195476971566677, pod: 24.388145208358765, loss: 28.780229926109314 
Train [7/11] | Epoch [158/160] |	nca: 3.0392377004027367, flat: 1.1767703406512737, pod: 23.5630784034729, loss: 27.779086470603943 
Train [7/11] | Epoch [159/160] |	nca: 3.0487546175718307, flat: 1.1332459039986134, pod: 23.08753329515457, loss: 27.269533932209015 
Train [7/11] | Epoch [160/160] |	nca: 3.008767381310463, flat: 1.1795353684574366, pod: 23.55667906999588, loss: 27.744981825351715 
Fine-tuning
Building & updating memory.
Train [7/11] | Epoch [161/180] |	nca: 1.8796435743570328, flat: 0.848521213978529, pod: 14.746356785297394, loss: 17.47452163696289 
Train [7/11] | Epoch [162/180] |	nca: 1.107595656067133, flat: 0.8269095793366432, pod: 14.630809724330902, loss: 16.56531512737274 
Train [7/11] | Epoch [163/180] |	nca: 0.9050651714205742, flat: 0.8274404481053352, pod: 14.393902838230133, loss: 16.126408457756042 
Train [7/11] | Epoch [164/180] |	nca: 0.9009091854095459, flat: 0.8656639605760574, pod: 14.5864217877388, loss: 16.352995097637177 
Train [7/11] | Epoch [165/180] |	nca: 0.7652598433196545, flat: 0.8430351205170155, pod: 14.728074789047241, loss: 16.33636963367462 
Train [7/11] | Epoch [166/180] |	nca: 0.7751550264656544, flat: 0.894973523914814, pod: 15.024901688098907, loss: 16.695030093193054 
Train [7/11] | Epoch [167/180] |	nca: 0.7231876999139786, flat: 0.8614032976329327, pod: 14.875791192054749, loss: 16.460382342338562 
Train [7/11] | Epoch [168/180] |	nca: 0.707497101277113, flat: 0.8551105782389641, pod: 14.685328483581543, loss: 16.247936129570007 
Train [7/11] | Epoch [169/180] |	nca: 0.6853766404092312, flat: 0.8326386846601963, pod: 14.37551611661911, loss: 15.893531441688538 
Train [7/11] | Epoch [170/180] |	nca: 0.6825297512114048, flat: 0.8250214159488678, pod: 14.450595796108246, loss: 15.958147048950195 
Train [7/11] | Epoch [171/180] |	nca: 0.6351900063455105, flat: 0.8250928148627281, pod: 14.443742632865906, loss: 15.904025375843048 
Train [7/11] | Epoch [172/180] |	nca: 0.6837965659797192, flat: 0.8341368548572063, pod: 14.43366414308548, loss: 15.951597571372986 
Train [7/11] | Epoch [173/180] |	nca: 0.6484114155173302, flat: 0.8615233972668648, pod: 14.715071558952332, loss: 16.225006461143494 
Train [7/11] | Epoch [174/180] |	nca: 0.6124147344380617, flat: 0.8399646319448948, pod: 14.80226480960846, loss: 16.254644215106964 
Train [7/11] | Epoch [175/180] |	nca: 0.620294589549303, flat: 0.8026917800307274, pod: 14.068331003189087, loss: 15.491317391395569 
Train [7/11] | Epoch [176/180] |	nca: 0.6529191769659519, flat: 0.8922008834779263, pod: 14.796733379364014, loss: 16.341853380203247 
Train [7/11] | Epoch [177/180] |	nca: 0.6073086000978947, flat: 0.8757799305021763, pod: 14.631231546401978, loss: 16.114320278167725 
Train [7/11] | Epoch [178/180] |	nca: 0.5509621351957321, flat: 0.8653778396546841, pod: 14.833258032798767, loss: 16.249598026275635 
Train [7/11] | Epoch [179/180] |	nca: 0.5932313315570354, flat: 0.846164133399725, pod: 14.582444608211517, loss: 16.02184009552002 
Train [7/11] | Epoch [180/180] |	nca: 0.5551534257829189, flat: 0.8666180819272995, pod: 14.73322868347168, loss: 16.15500009059906 
after task
Building & updating memory.
after task
Eval on 0->80.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6625714285714286.
Current acc: {'total': 0.593, '00-09': 0.663, '10-19': 0.595, '20-29': 0.524, '30-39': 0.565, '40-49': 0.622, '50-59': 0.61, '60-69': 0.498, '70-79': 0.664}.
Avg inc acc top5: 0.8924285714285715.
Current acc top5: {'total': 0.851}.
Forgetting: 0.10722222222222222.
Cord metric: 0.65.
Old accuracy: 0.59, mean: 0.65.
New accuracy: 0.65, mean: 0.65.
================Task 7 Start!================
Testing on False unseen tasks (max class = 85).
Set memory of size: 1600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 7 Training!================
The training samples number: 4100
Train on 80->85.
train task
nb 4100.
Train [8/11] | Epoch [1/160] |	nca: 25.606754183769226, flat: 9.469308227300644, pod: 82.83324694633484, loss: 117.90930819511414 
Train [8/11] | Epoch [2/160] |	nca: 52.68575930595398, flat: 25.29618388414383, pod: 149.54970622062683, loss: 227.53164911270142 
Train [8/11] | Epoch [3/160] |	nca: 35.82218426465988, flat: 20.179317623376846, pod: 131.02639603614807, loss: 187.02789688110352 
Train [8/11] | Epoch [4/160] |	nca: 39.702817380428314, flat: 22.622914910316467, pod: 138.648530960083, loss: 200.97426319122314 
Train [8/11] | Epoch [5/160] |	nca: 21.8388514816761, flat: 15.16445529460907, pod: 109.42562890052795, loss: 146.4289367198944 
Train [8/11] | Epoch [6/160] |	nca: 27.363931715488434, flat: 17.487272083759308, pod: 118.34524464607239, loss: 163.19644737243652 
Train [8/11] | Epoch [7/160] |	nca: 19.356961578130722, flat: 13.949918657541275, pod: 103.99345469474792, loss: 137.3003351688385 
Train [8/11] | Epoch [8/160] |	nca: 20.12561121582985, flat: 14.676750391721725, pod: 107.88816213607788, loss: 142.690523147583 
Train [8/11] | Epoch [9/160] |	nca: 27.142136335372925, flat: 17.495314925909042, pod: 115.19981551170349, loss: 159.8372664451599 
Train [8/11] | Epoch [10/160] |	nca: 17.36584112048149, flat: 13.857985615730286, pod: 103.21370148658752, loss: 134.43752694129944 
Train [8/11] | Epoch [11/160] |	nca: 17.860700637102127, flat: 13.598698675632477, pod: 101.92308568954468, loss: 133.3824851512909 
Train [8/11] | Epoch [12/160] |	nca: 22.16578122973442, flat: 15.356380254030228, pod: 107.87212538719177, loss: 145.39428567886353 
Train [8/11] | Epoch [13/160] |	nca: 26.973469704389572, flat: 18.732879668474197, pod: 121.75069546699524, loss: 167.4570460319519 
Train [8/11] | Epoch [14/160] |	nca: 18.441258996725082, flat: 13.810781925916672, pod: 102.32080578804016, loss: 134.572847366333 
Train [8/11] | Epoch [15/160] |	nca: 19.48815217614174, flat: 13.988621860742569, pod: 103.62951874732971, loss: 137.10629296302795 
Train [8/11] | Epoch [16/160] |	nca: 17.648026645183563, flat: 14.012262880802155, pod: 103.82661819458008, loss: 135.48690676689148 
Train [8/11] | Epoch [17/160] |	nca: 14.394499689340591, flat: 12.331943154335022, pod: 97.72243881225586, loss: 124.44888186454773 
Train [8/11] | Epoch [18/160] |	nca: 20.051999807357788, flat: 14.724244564771652, pod: 104.96237683296204, loss: 139.73862147331238 
Train [8/11] | Epoch [19/160] |	nca: 27.55537983775139, flat: 17.168932795524597, pod: 117.49028277397156, loss: 162.2145960330963 
Train [8/11] | Epoch [20/160] |	nca: 21.1190382540226, flat: 14.278899163007736, pod: 105.47115182876587, loss: 140.86908864974976 
Train [8/11] | Epoch [21/160] |	nca: 23.935728013515472, flat: 17.132743179798126, pod: 116.16463255882263, loss: 157.2331051826477 
Train [8/11] | Epoch [22/160] |	nca: 16.317078292369843, flat: 13.700568407773972, pod: 103.06302499771118, loss: 133.08067059516907 
Train [8/11] | Epoch [23/160] |	nca: 13.143942818045616, flat: 12.111207395792007, pod: 95.72330904006958, loss: 120.97845959663391 
Train [8/11] | Epoch [24/160] |	nca: 12.963838756084442, flat: 11.911711484193802, pod: 95.35302472114563, loss: 120.22857403755188 
Train [8/11] | Epoch [25/160] |	nca: 8.442036300897598, flat: 9.320495799183846, pod: 83.50948405265808, loss: 101.27201628684998 
Train [8/11] | Epoch [26/160] |	nca: 11.480739802122116, flat: 9.940974965691566, pod: 86.35817790031433, loss: 107.7798924446106 
Train [8/11] | Epoch [27/160] |	nca: 15.668726235628128, flat: 11.74542248249054, pod: 93.32570123672485, loss: 120.73985004425049 
Train [8/11] | Epoch [28/160] |	nca: 12.517598763108253, flat: 10.784981951117516, pod: 88.85491609573364, loss: 112.15749621391296 
Train [8/11] | Epoch [29/160] |	nca: 13.725420281291008, flat: 11.420242547988892, pod: 92.30496549606323, loss: 117.4506287574768 
Train [8/11] | Epoch [30/160] |	nca: 14.735152319073677, flat: 13.68102514743805, pod: 102.0906434059143, loss: 130.50682163238525 
Train [8/11] | Epoch [31/160] |	nca: 9.07201500236988, flat: 9.519149705767632, pod: 83.95718216896057, loss: 102.54834651947021 
Train [8/11] | Epoch [32/160] |	nca: 9.783101439476013, flat: 9.298288628458977, pod: 81.17533850669861, loss: 100.25672817230225 
Train [8/11] | Epoch [33/160] |	nca: 12.62070469558239, flat: 10.170889407396317, pod: 87.8327283859253, loss: 110.62432217597961 
Train [8/11] | Epoch [34/160] |	nca: 16.626136153936386, flat: 13.508862257003784, pod: 99.37993812561035, loss: 129.51493573188782 
Train [8/11] | Epoch [35/160] |	nca: 12.38534490764141, flat: 10.920142263174057, pod: 89.82136631011963, loss: 113.1268539428711 
Train [8/11] | Epoch [36/160] |	nca: 18.711237400770187, flat: 14.089854329824448, pod: 102.34415888786316, loss: 135.14525198936462 
Train [8/11] | Epoch [37/160] |	nca: 13.407242849469185, flat: 11.896170377731323, pod: 93.44504189491272, loss: 118.74845457077026 
Train [8/11] | Epoch [38/160] |	nca: 7.286367021501064, flat: 8.51467490196228, pod: 78.80332088470459, loss: 94.60436344146729 
Train [8/11] | Epoch [39/160] |	nca: 12.800651669502258, flat: 11.758361250162125, pod: 91.75261378288269, loss: 116.31162667274475 
Train [8/11] | Epoch [40/160] |	nca: 10.245018944144249, flat: 9.821805462241173, pod: 85.7387683391571, loss: 105.80559253692627 
Train [8/11] | Epoch [41/160] |	nca: 9.38488581776619, flat: 9.604793936014175, pod: 83.75696277618408, loss: 102.74664211273193 
Train [8/11] | Epoch [42/160] |	nca: 7.010668784379959, flat: 8.110043928027153, pod: 77.195809841156, loss: 92.31652307510376 
Train [8/11] | Epoch [43/160] |	nca: 8.058607161045074, flat: 8.43909640610218, pod: 78.02071690559387, loss: 94.51842141151428 
Train [8/11] | Epoch [44/160] |	nca: 9.967283576726913, flat: 9.690045177936554, pod: 83.37450098991394, loss: 103.03183007240295 
Train [8/11] | Epoch [45/160] |	nca: 12.228280708193779, flat: 10.715567901730537, pod: 91.05158710479736, loss: 113.99543619155884 
Train [8/11] | Epoch [46/160] |	nca: 7.745075613260269, flat: 7.817973256111145, pod: 75.72157502174377, loss: 91.28462362289429 
Train [8/11] | Epoch [47/160] |	nca: 16.795195281505585, flat: 12.90249040722847, pod: 100.06523633003235, loss: 129.76292157173157 
Train [8/11] | Epoch [48/160] |	nca: 12.552047088742256, flat: 11.015070229768753, pod: 88.01522207260132, loss: 111.58234000205994 
Train [8/11] | Epoch [49/160] |	nca: 17.820754557847977, flat: 14.504941642284393, pod: 105.42316150665283, loss: 137.7488570213318 
Train [8/11] | Epoch [50/160] |	nca: 10.713656410574913, flat: 10.997159168124199, pod: 88.7904098033905, loss: 110.50122594833374 
Train [8/11] | Epoch [51/160] |	nca: 7.650754496455193, flat: 8.895042166113853, pod: 79.35373306274414, loss: 95.89952993392944 
Train [8/11] | Epoch [52/160] |	nca: 9.686941549181938, flat: 9.86273156106472, pod: 83.50635194778442, loss: 103.05602526664734 
Train [8/11] | Epoch [53/160] |	nca: 10.551167637109756, flat: 10.610920175909996, pod: 86.64936137199402, loss: 107.8114492893219 
Train [8/11] | Epoch [54/160] |	nca: 17.26359371840954, flat: 11.60877138376236, pod: 91.69413161277771, loss: 120.56649661064148 
Train [8/11] | Epoch [55/160] |	nca: 18.141199208796024, flat: 13.017371863126755, pod: 97.38372588157654, loss: 128.54229640960693 
Train [8/11] | Epoch [56/160] |	nca: 7.510831713676453, flat: 8.383888497948647, pod: 77.97337365150452, loss: 93.868093252182 
Train [8/11] | Epoch [57/160] |	nca: 16.799396187067032, flat: 13.226980715990067, pod: 97.66045689582825, loss: 127.68683409690857 
Train [8/11] | Epoch [58/160] |	nca: 11.385672926902771, flat: 10.537107214331627, pod: 86.96006846427917, loss: 108.88284850120544 
Train [8/11] | Epoch [59/160] |	nca: 12.19972950220108, flat: 11.045607313513756, pod: 88.87199997901917, loss: 112.11733722686768 
Train [8/11] | Epoch [60/160] |	nca: 11.046102479100227, flat: 10.313700944185257, pod: 85.26205372810364, loss: 106.62185621261597 
Train [8/11] | Epoch [61/160] |	nca: 12.608701810240746, flat: 11.646991610527039, pod: 90.81775426864624, loss: 115.07344841957092 
Train [8/11] | Epoch [62/160] |	nca: 15.027746573090553, flat: 11.169053494930267, pod: 89.72556829452515, loss: 115.92236852645874 
Train [8/11] | Epoch [63/160] |	nca: 17.326413720846176, flat: 13.851905345916748, pod: 97.82822155952454, loss: 129.0065393447876 
Train [8/11] | Epoch [64/160] |	nca: 12.390968456864357, flat: 11.878350734710693, pod: 90.99409103393555, loss: 115.2634105682373 
Train [8/11] | Epoch [65/160] |	nca: 12.58374834060669, flat: 11.361914277076721, pod: 91.71425724029541, loss: 115.65992045402527 
Train [8/11] | Epoch [66/160] |	nca: 14.11136443912983, flat: 12.756704598665237, pod: 95.14768648147583, loss: 122.01575493812561 
Train [8/11] | Epoch [67/160] |	nca: 7.161710396409035, flat: 9.465272158384323, pod: 81.82567071914673, loss: 98.45265340805054 
Train [8/11] | Epoch [68/160] |	nca: 6.567410282790661, flat: 8.131796464323997, pod: 76.38438296318054, loss: 91.08359026908875 
Train [8/11] | Epoch [69/160] |	nca: 9.385405898094177, flat: 9.75190332531929, pod: 87.2926344871521, loss: 106.42994332313538 
Train [8/11] | Epoch [70/160] |	nca: 10.457230389118195, flat: 9.7750144302845, pod: 83.75833296775818, loss: 103.99057745933533 
Train [8/11] | Epoch [71/160] |	nca: 14.391375467181206, flat: 11.288607522845268, pod: 88.21837258338928, loss: 113.89835619926453 
Train [8/11] | Epoch [72/160] |	nca: 14.621428370475769, flat: 10.516079857945442, pod: 86.770920753479, loss: 111.90842866897583 
Train [8/11] | Epoch [73/160] |	nca: 13.948568940162659, flat: 11.27854984998703, pod: 88.90072727203369, loss: 114.12784576416016 
Train [8/11] | Epoch [74/160] |	nca: 11.628533363342285, flat: 11.121091157197952, pod: 85.69438862800598, loss: 108.44401335716248 
Train [8/11] | Epoch [75/160] |	nca: 9.821117609739304, flat: 10.303564891219139, pod: 84.98028516769409, loss: 105.10496783256531 
Train [8/11] | Epoch [76/160] |	nca: 7.782669775187969, flat: 8.748358577489853, pod: 78.7709412574768, loss: 95.30196952819824 
Train [8/11] | Epoch [77/160] |	nca: 5.209316045045853, flat: 7.454374581575394, pod: 71.48332345485687, loss: 84.14701414108276 
Train [8/11] | Epoch [78/160] |	nca: 6.421745993196964, flat: 6.839237093925476, pod: 67.27314579486847, loss: 80.53412866592407 
Train [8/11] | Epoch [79/160] |	nca: 10.374448165297508, flat: 8.984155431389809, pod: 77.22103595733643, loss: 96.57963967323303 
Train [8/11] | Epoch [80/160] |	nca: 7.547336548566818, flat: 9.101763159036636, pod: 80.40691184997559, loss: 97.05601119995117 
Train [8/11] | Epoch [81/160] |	nca: 8.184755109250546, flat: 8.941473841667175, pod: 76.9418671131134, loss: 94.06809639930725 
Train [8/11] | Epoch [82/160] |	nca: 9.675300560891628, flat: 8.90403737127781, pod: 77.98708081245422, loss: 96.56641817092896 
Train [8/11] | Epoch [83/160] |	nca: 10.27578791975975, flat: 8.943108513951302, pod: 79.24415946006775, loss: 98.46305656433105 
Train [8/11] | Epoch [84/160] |	nca: 11.886573880910873, flat: 9.929273292422295, pod: 83.63835668563843, loss: 105.45420360565186 
Train [8/11] | Epoch [85/160] |	nca: 15.39952702820301, flat: 11.61070828139782, pod: 90.04213356971741, loss: 117.05236887931824 
Train [8/11] | Epoch [86/160] |	nca: 11.82411852478981, flat: 10.837510898709297, pod: 86.56008839607239, loss: 109.22171783447266 
Train [8/11] | Epoch [87/160] |	nca: 10.8053789883852, flat: 11.127599105238914, pod: 84.49600553512573, loss: 106.42898321151733 
Train [8/11] | Epoch [88/160] |	nca: 5.916481584310532, flat: 7.599609434604645, pod: 71.66879940032959, loss: 85.18489098548889 
Train [8/11] | Epoch [89/160] |	nca: 6.59811232984066, flat: 7.79704475402832, pod: 72.0993994474411, loss: 86.49455642700195 
Train [8/11] | Epoch [90/160] |	nca: 9.249400667846203, flat: 8.37825034558773, pod: 75.6590029001236, loss: 93.28665399551392 
Train [8/11] | Epoch [91/160] |	nca: 8.83524252474308, flat: 9.069378525018692, pod: 77.5421929359436, loss: 95.4468138217926 
Train [8/11] | Epoch [92/160] |	nca: 10.930246502161026, flat: 9.42965216934681, pod: 82.69517469406128, loss: 103.05507349967957 
Train [8/11] | Epoch [93/160] |	nca: 10.112615764141083, flat: 8.970504835247993, pod: 78.31803679466248, loss: 97.40115737915039 
Train [8/11] | Epoch [94/160] |	nca: 9.010107330977917, flat: 8.223899006843567, pod: 74.03097701072693, loss: 91.26498293876648 
Train [8/11] | Epoch [95/160] |	nca: 6.8893972262740135, flat: 8.177449122071266, pod: 75.3701331615448, loss: 90.4369785785675 
Train [8/11] | Epoch [96/160] |	nca: 4.169844552874565, flat: 6.3617763966321945, pod: 65.5741857290268, loss: 76.10580706596375 
Train [8/11] | Epoch [97/160] |	nca: 4.5167431011796, flat: 6.078878566622734, pod: 63.47496712207794, loss: 74.07058835029602 
Train [8/11] | Epoch [98/160] |	nca: 6.965153954923153, flat: 6.7372632920742035, pod: 66.85628008842468, loss: 80.55869746208191 
Train [8/11] | Epoch [99/160] |	nca: 5.475681908428669, flat: 6.8634210377931595, pod: 67.69346368312836, loss: 80.03256678581238 
Train [8/11] | Epoch [100/160] |	nca: 5.573557361960411, flat: 5.925714984536171, pod: 62.625704765319824, loss: 74.12497627735138 
Train [8/11] | Epoch [101/160] |	nca: 8.03667065501213, flat: 8.222544997930527, pod: 73.22442984580994, loss: 89.48364520072937 
Train [8/11] | Epoch [102/160] |	nca: 6.03334229439497, flat: 6.5327669233083725, pod: 65.5275319814682, loss: 78.09364128112793 
Train [8/11] | Epoch [103/160] |	nca: 7.162239156663418, flat: 6.690674886107445, pod: 65.6390951871872, loss: 79.49200963973999 
Train [8/11] | Epoch [104/160] |	nca: 5.320140324532986, flat: 7.422752991318703, pod: 69.47058737277985, loss: 82.21348094940186 
Train [8/11] | Epoch [105/160] |	nca: 4.286056563258171, flat: 5.81646865606308, pod: 62.047845244407654, loss: 72.15036976337433 
Train [8/11] | Epoch [106/160] |	nca: 3.5964440554380417, flat: 5.166837617754936, pod: 58.077879428863525, loss: 66.84116125106812 
Train [8/11] | Epoch [107/160] |	nca: 4.331190288066864, flat: 4.931768909096718, pod: 56.0654981136322, loss: 65.32845723628998 
Train [8/11] | Epoch [108/160] |	nca: 5.176207862794399, flat: 6.078070938587189, pod: 62.96998953819275, loss: 74.22426867485046 
Train [8/11] | Epoch [109/160] |	nca: 4.6462869346141815, flat: 5.253766134381294, pod: 59.08549392223358, loss: 68.985546708107 
Train [8/11] | Epoch [110/160] |	nca: 4.580549694597721, flat: 5.525788605213165, pod: 59.055755615234375, loss: 69.16209375858307 
Train [8/11] | Epoch [111/160] |	nca: 4.270064413547516, flat: 5.198205828666687, pod: 57.45160639286041, loss: 66.919877409935 
Train [8/11] | Epoch [112/160] |	nca: 5.026978135108948, flat: 5.825779005885124, pod: 60.396734833717346, loss: 71.24949169158936 
Train [8/11] | Epoch [113/160] |	nca: 4.15464524179697, flat: 5.054060660302639, pod: 55.668558835983276, loss: 64.87726473808289 
Train [8/11] | Epoch [114/160] |	nca: 5.9386887550354, flat: 5.068675637245178, pod: 56.46198761463165, loss: 67.46935224533081 
Train [8/11] | Epoch [115/160] |	nca: 7.18232124298811, flat: 5.843515455722809, pod: 59.074076533317566, loss: 72.09991312026978 
Train [8/11] | Epoch [116/160] |	nca: 5.484957315027714, flat: 6.4468416422605515, pod: 60.92475152015686, loss: 72.8565503358841 
Train [8/11] | Epoch [117/160] |	nca: 6.435086794197559, flat: 5.548861816525459, pod: 58.392340421676636, loss: 70.37628889083862 
Train [8/11] | Epoch [118/160] |	nca: 8.213870093226433, flat: 6.086596131324768, pod: 59.24972760677338, loss: 73.5501948595047 
Train [8/11] | Epoch [119/160] |	nca: 7.739449575543404, flat: 6.688137650489807, pod: 66.69834983348846, loss: 81.12593710422516 
Train [8/11] | Epoch [120/160] |	nca: 4.874700844287872, flat: 5.595265224575996, pod: 60.4951194524765, loss: 70.96508574485779 
Train [8/11] | Epoch [121/160] |	nca: 12.027758374810219, flat: 5.452228210866451, pod: 56.33726251125336, loss: 73.81724858283997 
Train [8/11] | Epoch [122/160] |	nca: 5.801051393151283, flat: 6.096741080284119, pod: 59.62850844860077, loss: 71.52630090713501 
Train [8/11] | Epoch [123/160] |	nca: 4.67462383210659, flat: 5.71064156293869, pod: 59.339187264442444, loss: 69.72445225715637 
Train [8/11] | Epoch [124/160] |	nca: 5.332240454852581, flat: 4.682302787899971, pod: 55.08927392959595, loss: 65.10381698608398 
Train [8/11] | Epoch [125/160] |	nca: 4.026193585246801, flat: 4.849088452756405, pod: 54.7431401014328, loss: 63.61842167377472 
Train [8/11] | Epoch [126/160] |	nca: 3.8415561467409134, flat: 4.459789529442787, pod: 52.615710496902466, loss: 60.91705656051636 
Train [8/11] | Epoch [127/160] |	nca: 4.236780002713203, flat: 4.814143173396587, pod: 53.96503555774689, loss: 63.01595878601074 
Train [8/11] | Epoch [128/160] |	nca: 4.2600583881139755, flat: 4.83147232234478, pod: 54.43019473552704, loss: 63.52172529697418 
Train [8/11] | Epoch [129/160] |	nca: 4.466151662170887, flat: 4.442766293883324, pod: 52.66473162174225, loss: 61.573649644851685 
Train [8/11] | Epoch [130/160] |	nca: 3.3325630202889442, flat: 4.6505584344267845, pod: 52.32782793045044, loss: 60.31094932556152 
Train [8/11] | Epoch [131/160] |	nca: 3.175132095813751, flat: 4.3846141546964645, pod: 50.65279257297516, loss: 58.212538838386536 
Train [8/11] | Epoch [132/160] |	nca: 6.819656901061535, flat: 4.165661104023457, pod: 48.870323061943054, loss: 59.85564088821411 
Train [8/11] | Epoch [133/160] |	nca: 4.017963707447052, flat: 4.936511978507042, pod: 53.83593463897705, loss: 62.79041028022766 
Train [8/11] | Epoch [134/160] |	nca: 4.289388999342918, flat: 4.187683939933777, pod: 50.02696931362152, loss: 58.50404191017151 
Train [8/11] | Epoch [135/160] |	nca: 6.03759329020977, flat: 4.512895755469799, pod: 51.11255967617035, loss: 61.66304862499237 
Train [8/11] | Epoch [136/160] |	nca: 5.3867790177464485, flat: 4.368263892829418, pod: 50.683422923088074, loss: 60.43846595287323 
Train [8/11] | Epoch [137/160] |	nca: 4.242334872484207, flat: 4.456298589706421, pod: 50.27174520492554, loss: 58.97037875652313 
Train [8/11] | Epoch [138/160] |	nca: 4.470795042812824, flat: 4.257737085223198, pod: 50.51150047779083, loss: 59.24003255367279 
Train [8/11] | Epoch [139/160] |	nca: 4.827083125710487, flat: 4.421117939054966, pod: 49.887134194374084, loss: 59.135334610939026 
Train [8/11] | Epoch [140/160] |	nca: 3.2591406106948853, flat: 4.40402914583683, pod: 51.09112012386322, loss: 58.754289865493774 
Train [8/11] | Epoch [141/160] |	nca: 4.619627445936203, flat: 4.3382400050759315, pod: 48.91886878013611, loss: 57.876736640930176 
Train [8/11] | Epoch [142/160] |	nca: 3.081960506737232, flat: 3.92768694460392, pod: 47.8756297826767, loss: 54.88527703285217 
Train [8/11] | Epoch [143/160] |	nca: 4.299491822719574, flat: 4.12548690289259, pod: 48.40708076953888, loss: 56.832059264183044 
Train [8/11] | Epoch [144/160] |	nca: 3.8281170912086964, flat: 4.07180742919445, pod: 48.63373041152954, loss: 56.5336549282074 
Train [8/11] | Epoch [145/160] |	nca: 3.1840134412050247, flat: 4.290177270770073, pod: 49.32393789291382, loss: 56.79812812805176 
Train [8/11] | Epoch [146/160] |	nca: 4.34060687571764, flat: 4.062045067548752, pod: 47.06278920173645, loss: 55.46544110774994 
Train [8/11] | Epoch [147/160] |	nca: 3.772651694715023, flat: 4.04569548368454, pod: 47.931445956230164, loss: 55.74979341030121 
Train [8/11] | Epoch [148/160] |	nca: 3.5915223732590675, flat: 3.85684522241354, pod: 47.10442328453064, loss: 54.55279076099396 
Train [8/11] | Epoch [149/160] |	nca: 4.148061953485012, flat: 3.995117351412773, pod: 47.36639404296875, loss: 55.50957369804382 
Train [8/11] | Epoch [150/160] |	nca: 4.269160058349371, flat: 3.9078674614429474, pod: 46.60989427566528, loss: 54.78692162036896 
Train [8/11] | Epoch [151/160] |	nca: 3.980624742805958, flat: 4.026467852294445, pod: 47.279993653297424, loss: 55.28708612918854 
Train [8/11] | Epoch [152/160] |	nca: 3.2706410475075245, flat: 3.9898819252848625, pod: 47.914188623428345, loss: 55.17471146583557 
Train [8/11] | Epoch [153/160] |	nca: 3.352688044309616, flat: 3.7643891349434853, pod: 46.093474984169006, loss: 53.21055257320404 
Train [8/11] | Epoch [154/160] |	nca: 5.216610066592693, flat: 3.92471694201231, pod: 46.34430372714996, loss: 55.48563039302826 
Train [8/11] | Epoch [155/160] |	nca: 4.860755778849125, flat: 4.0734862089157104, pod: 47.64168870449066, loss: 56.57593095302582 
Train [8/11] | Epoch [156/160] |	nca: 4.037268206477165, flat: 3.771503135561943, pod: 46.64925289154053, loss: 54.45802402496338 
Train [8/11] | Epoch [157/160] |	nca: 3.051118850708008, flat: 3.7448215633630753, pod: 46.61510896682739, loss: 53.411049008369446 
Train [8/11] | Epoch [158/160] |	nca: 3.0990353785455227, flat: 3.729857623577118, pod: 45.72832703590393, loss: 52.557220458984375 
Train [8/11] | Epoch [159/160] |	nca: 5.404454231262207, flat: 4.000293701887131, pod: 46.15397882461548, loss: 55.55872678756714 
Train [8/11] | Epoch [160/160] |	nca: 3.6574247628450394, flat: 3.972880855202675, pod: 46.860276103019714, loss: 54.49058127403259 
Fine-tuning
Building & updating memory.
Train [8/11] | Epoch [161/180] |	nca: 2.713320553302765, flat: 2.0106087252497673, pod: 25.581167578697205, loss: 30.305096864700317 
Train [8/11] | Epoch [162/180] |	nca: 1.442892849445343, flat: 1.9985355958342552, pod: 25.301053524017334, loss: 28.74248242378235 
Train [8/11] | Epoch [163/180] |	nca: 1.3158592954277992, flat: 1.996516965329647, pod: 25.3337082862854, loss: 28.646084189414978 
Train [8/11] | Epoch [164/180] |	nca: 1.2372565940022469, flat: 2.0194916427135468, pod: 25.243600964546204, loss: 28.500349640846252 
Train [8/11] | Epoch [165/180] |	nca: 1.202316265553236, flat: 2.004884123802185, pod: 25.27633273601532, loss: 28.483532786369324 
Train [8/11] | Epoch [166/180] |	nca: 1.1925301551818848, flat: 1.9941909462213516, pod: 25.394103050231934, loss: 28.58082413673401 
Train [8/11] | Epoch [167/180] |	nca: 1.182499274611473, flat: 1.9882331043481827, pod: 25.299279928207397, loss: 28.470011830329895 
Train [8/11] | Epoch [168/180] |	nca: 1.0952930822968483, flat: 1.9715725183486938, pod: 25.084712624549866, loss: 28.151578187942505 
Train [8/11] | Epoch [169/180] |	nca: 1.1119724437594414, flat: 2.008224919438362, pod: 25.43380320072174, loss: 28.55400049686432 
Train [8/11] | Epoch [170/180] |	nca: 1.0692491382360458, flat: 2.0198527798056602, pod: 25.381784200668335, loss: 28.47088611125946 
Train [8/11] | Epoch [171/180] |	nca: 1.1640983410179615, flat: 2.0131044536828995, pod: 25.712968826293945, loss: 28.89017128944397 
Train [8/11] | Epoch [172/180] |	nca: 1.0119776166975498, flat: 1.9765648245811462, pod: 25.301920652389526, loss: 28.29046320915222 
Train [8/11] | Epoch [173/180] |	nca: 1.0423730574548244, flat: 2.0135179236531258, pod: 25.37365448474884, loss: 28.429545640945435 
Train [8/11] | Epoch [174/180] |	nca: 0.9411377534270287, flat: 2.0136044546961784, pod: 25.44440746307373, loss: 28.399149894714355 
Train [8/11] | Epoch [175/180] |	nca: 0.9545754157006741, flat: 1.9909025430679321, pod: 25.129356861114502, loss: 28.074835181236267 
Train [8/11] | Epoch [176/180] |	nca: 1.0063899010419846, flat: 1.9974368214607239, pod: 25.35626518726349, loss: 28.360092163085938 
Train [8/11] | Epoch [177/180] |	nca: 0.903910618275404, flat: 2.011732369661331, pod: 25.377588152885437, loss: 28.293230891227722 
Train [8/11] | Epoch [178/180] |	nca: 0.9986960887908936, flat: 1.9721414297819138, pod: 25.110775113105774, loss: 28.081612944602966 
Train [8/11] | Epoch [179/180] |	nca: 0.8865331411361694, flat: 2.010467231273651, pod: 25.33478045463562, loss: 28.231780648231506 
Train [8/11] | Epoch [180/180] |	nca: 0.9238432794809341, flat: 2.015675589442253, pod: 25.512262225151062, loss: 28.451780915260315 
after task
Building & updating memory.
after task
Eval on 0->85.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.651125.
Current acc: {'total': 0.571, '00-09': 0.659, '10-19': 0.584, '20-29': 0.497, '30-39': 0.534, '40-49': 0.598, '50-59': 0.557, '60-69': 0.496, '70-79': 0.598, '80-89': 0.662}.
Avg inc acc top5: 0.8865.
Current acc top5: {'total': 0.845}.
Forgetting: 0.05209999999999998.
Cord metric: 0.64.
Old accuracy: 0.56, mean: 0.64.
New accuracy: 0.66, mean: 0.65.
================Task 8 Start!================
Testing on False unseen tasks (max class = 90).
Set memory of size: 1700.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 8 Training!================
The training samples number: 4200
Train on 85->90.
train task
nb 4200.
Train [9/11] | Epoch [1/160] |	nca: 14.180071473121643, flat: 3.327231615781784, pod: 50.90447008609772, loss: 68.41177225112915 
Train [9/11] | Epoch [2/160] |	nca: 8.890512943267822, flat: 3.2340071350336075, pod: 54.598872661590576, loss: 66.72339284420013 
Train [9/11] | Epoch [3/160] |	nca: 7.9984510987997055, flat: 3.2055772691965103, pod: 54.387595653533936, loss: 65.59162437915802 
Train [9/11] | Epoch [4/160] |	nca: 7.020771995186806, flat: 3.016627475619316, pod: 50.543593883514404, loss: 60.58099353313446 
Train [9/11] | Epoch [5/160] |	nca: 6.603514596819878, flat: 2.794097863137722, pod: 50.06609511375427, loss: 59.463706970214844 
Train [9/11] | Epoch [6/160] |	nca: 6.299872696399689, flat: 2.796181380748749, pod: 49.38267970085144, loss: 58.4787335395813 
Train [9/11] | Epoch [7/160] |	nca: 6.101324737071991, flat: 2.8236185386776924, pod: 50.76078128814697, loss: 59.6857248544693 
Train [9/11] | Epoch [8/160] |	nca: 6.196043744683266, flat: 3.0337635204195976, pod: 51.97216546535492, loss: 61.20197284221649 
Train [9/11] | Epoch [9/160] |	nca: 5.538036324083805, flat: 2.710577480494976, pod: 48.11793351173401, loss: 56.36654722690582 
Train [9/11] | Epoch [10/160] |	nca: 6.025943636894226, flat: 3.0055538341403008, pod: 51.17028069496155, loss: 60.201777935028076 
Train [9/11] | Epoch [11/160] |	nca: 5.765844918787479, flat: 3.116572894155979, pod: 53.06399929523468, loss: 61.94641709327698 
Train [9/11] | Epoch [12/160] |	nca: 5.763944789767265, flat: 2.901724860072136, pod: 50.567620158195496, loss: 59.23328948020935 
Train [9/11] | Epoch [13/160] |	nca: 5.291197665035725, flat: 2.747535675764084, pod: 48.25926661491394, loss: 56.2979998588562 
Train [9/11] | Epoch [14/160] |	nca: 5.366719104349613, flat: 2.8473002165555954, pod: 47.93877053260803, loss: 56.15279018878937 
Train [9/11] | Epoch [15/160] |	nca: 5.344814151525497, flat: 2.783499352633953, pod: 49.46730411052704, loss: 57.5956175327301 
Train [9/11] | Epoch [16/160] |	nca: 5.277797743678093, flat: 2.9490935504436493, pod: 50.232895851135254, loss: 58.459787130355835 
Train [9/11] | Epoch [17/160] |	nca: 5.222830027341843, flat: 2.711245581507683, pod: 47.40114951133728, loss: 55.335224747657776 
Train [9/11] | Epoch [18/160] |	nca: 5.5267225205898285, flat: 2.986515872180462, pod: 50.99198269844055, loss: 59.505221009254456 
Train [9/11] | Epoch [19/160] |	nca: 5.011787302792072, flat: 3.071463391184807, pod: 53.44781577587128, loss: 61.53106617927551 
Train [9/11] | Epoch [20/160] |	nca: 5.259717829525471, flat: 2.905160069465637, pod: 48.84208154678345, loss: 57.006959438323975 
Train [9/11] | Epoch [21/160] |	nca: 5.3048452734947205, flat: 3.407395027577877, pod: 53.30051875114441, loss: 62.01275897026062 
Train [9/11] | Epoch [22/160] |	nca: 5.66257531195879, flat: 3.047653578221798, pod: 50.61244523525238, loss: 59.32267415523529 
Train [9/11] | Epoch [23/160] |	nca: 5.27981411665678, flat: 3.181838668882847, pod: 52.04942977428436, loss: 60.51108264923096 
Train [9/11] | Epoch [24/160] |	nca: 5.38917475938797, flat: 3.4301009252667427, pod: 54.844204902648926, loss: 63.66348052024841 
Train [9/11] | Epoch [25/160] |	nca: 5.241596207022667, flat: 3.2078560516238213, pod: 51.77178597450256, loss: 60.22123825550079 
Train [9/11] | Epoch [26/160] |	nca: 4.716479457914829, flat: 2.7974396720528603, pod: 48.42919063568115, loss: 55.94310986995697 
Train [9/11] | Epoch [27/160] |	nca: 5.049931153655052, flat: 2.848258927464485, pod: 49.01551342010498, loss: 56.91370356082916 
Train [9/11] | Epoch [28/160] |	nca: 5.089335508644581, flat: 3.0188047736883163, pod: 50.64448046684265, loss: 58.75262129306793 
Train [9/11] | Epoch [29/160] |	nca: 5.078816846013069, flat: 3.272105745971203, pod: 53.46229159832001, loss: 61.81321454048157 
Train [9/11] | Epoch [30/160] |	nca: 5.344592973589897, flat: 3.2579404041171074, pod: 51.78059005737305, loss: 60.38312339782715 
Train [9/11] | Epoch [31/160] |	nca: 4.960821680724621, flat: 3.3173334896564484, pod: 55.445290207862854, loss: 63.72344529628754 
Train [9/11] | Epoch [32/160] |	nca: 5.053889781236649, flat: 3.0346357002854347, pod: 51.44268357753754, loss: 59.53120934963226 
Train [9/11] | Epoch [33/160] |	nca: 4.78141512721777, flat: 2.968244731426239, pod: 50.82602643966675, loss: 58.57568633556366 
Train [9/11] | Epoch [34/160] |	nca: 4.815012291073799, flat: 3.033897764980793, pod: 50.68746268749237, loss: 58.536372661590576 
Train [9/11] | Epoch [35/160] |	nca: 5.0163953229784966, flat: 3.1638676151633263, pod: 52.19994032382965, loss: 60.38020300865173 
Train [9/11] | Epoch [36/160] |	nca: 5.567187964916229, flat: 3.336694300174713, pod: 52.78576993942261, loss: 61.68965196609497 
Train [9/11] | Epoch [37/160] |	nca: 5.0685639679431915, flat: 3.218031570315361, pod: 52.5105242729187, loss: 60.79711937904358 
Train [9/11] | Epoch [38/160] |	nca: 4.492595575749874, flat: 2.7722866162657738, pod: 47.67960214614868, loss: 54.94448435306549 
Train [9/11] | Epoch [39/160] |	nca: 4.6116945669054985, flat: 2.852148413658142, pod: 48.60844314098358, loss: 56.07228660583496 
Train [9/11] | Epoch [40/160] |	nca: 5.060749981552362, flat: 3.2319872602820396, pod: 52.324652671813965, loss: 60.61739003658295 
Train [9/11] | Epoch [41/160] |	nca: 4.446454130113125, flat: 2.8699258491396904, pod: 48.774367451667786, loss: 56.090747594833374 
Train [9/11] | Epoch [42/160] |	nca: 4.6163885444402695, flat: 2.8434285148978233, pod: 49.466519474983215, loss: 56.92633640766144 
Train [9/11] | Epoch [43/160] |	nca: 4.492754004895687, flat: 2.802124358713627, pod: 48.66411757469177, loss: 55.95899569988251 
Train [9/11] | Epoch [44/160] |	nca: 4.673542410135269, flat: 2.8154055550694466, pod: 47.21728503704071, loss: 54.7062326669693 
Train [9/11] | Epoch [45/160] |	nca: 4.8893530666828156, flat: 3.0004550144076347, pod: 50.181318044662476, loss: 58.071126222610474 
Train [9/11] | Epoch [46/160] |	nca: 4.999242044985294, flat: 3.011751711368561, pod: 50.72620177268982, loss: 58.73719525337219 
Train [9/11] | Epoch [47/160] |	nca: 4.358108893036842, flat: 2.8379310369491577, pod: 49.81014811992645, loss: 57.00618767738342 
Train [9/11] | Epoch [48/160] |	nca: 4.430192671716213, flat: 2.7939648032188416, pod: 48.41857087612152, loss: 55.642728090286255 
Train [9/11] | Epoch [49/160] |	nca: 4.272468343377113, flat: 2.8052148893475533, pod: 49.358853578567505, loss: 56.43653678894043 
Train [9/11] | Epoch [50/160] |	nca: 4.464528687298298, flat: 2.6584847941994667, pod: 47.20139753818512, loss: 54.324410915374756 
Train [9/11] | Epoch [51/160] |	nca: 4.551614947617054, flat: 2.8023034036159515, pod: 47.83066737651825, loss: 55.18458557128906 
Train [9/11] | Epoch [52/160] |	nca: 4.494824759662151, flat: 2.6189234629273415, pod: 46.88537037372589, loss: 53.99911844730377 
Train [9/11] | Epoch [53/160] |	nca: 4.6081694811582565, flat: 2.8268031924962997, pod: 48.68321132659912, loss: 56.118183732032776 
Train [9/11] | Epoch [54/160] |	nca: 4.111993663012981, flat: 2.6520825028419495, pod: 46.9006142616272, loss: 53.664690256118774 
Train [9/11] | Epoch [55/160] |	nca: 4.423577331006527, flat: 2.7505836337804794, pod: 47.42791140079498, loss: 54.60207259654999 
Train [9/11] | Epoch [56/160] |	nca: 4.245685838162899, flat: 2.713495008647442, pod: 47.312408089637756, loss: 54.271589040756226 
Train [9/11] | Epoch [57/160] |	nca: 4.343629375100136, flat: 2.5740940384566784, pod: 45.91178214550018, loss: 52.829505443573 
Train [9/11] | Epoch [58/160] |	nca: 4.499360293149948, flat: 2.6944033056497574, pod: 48.59270703792572, loss: 55.786471009254456 
Train [9/11] | Epoch [59/160] |	nca: 4.397201828658581, flat: 2.5980189852416515, pod: 46.717525482177734, loss: 53.712745785713196 
Train [9/11] | Epoch [60/160] |	nca: 5.004083000123501, flat: 3.1437250152230263, pod: 52.0147625207901, loss: 60.16257059574127 
Train [9/11] | Epoch [61/160] |	nca: 4.172007225453854, flat: 2.689137138426304, pod: 47.7554851770401, loss: 54.61662948131561 
Train [9/11] | Epoch [62/160] |	nca: 4.06719059497118, flat: 2.493839867413044, pod: 44.31096351146698, loss: 50.87199401855469 
Train [9/11] | Epoch [63/160] |	nca: 3.9869800359010696, flat: 2.376973059028387, pod: 44.239665269851685, loss: 50.60361838340759 
Train [9/11] | Epoch [64/160] |	nca: 4.057810261845589, flat: 2.3331181071698666, pod: 43.34614408016205, loss: 49.737072587013245 
Train [9/11] | Epoch [65/160] |	nca: 4.329917103052139, flat: 2.628705732524395, pod: 47.4224534034729, loss: 54.38107621669769 
Train [9/11] | Epoch [66/160] |	nca: 3.9953037947416306, flat: 2.3746186085045338, pod: 43.75800085067749, loss: 50.127923369407654 
Train [9/11] | Epoch [67/160] |	nca: 4.354737959802151, flat: 2.4979675747454166, pod: 45.96089541912079, loss: 52.813600897789 
Train [9/11] | Epoch [68/160] |	nca: 4.073137402534485, flat: 2.419500596821308, pod: 43.35824251174927, loss: 49.85088050365448 
Train [9/11] | Epoch [69/160] |	nca: 4.191413521766663, flat: 2.304516851902008, pod: 43.50547683238983, loss: 50.001407504081726 
Train [9/11] | Epoch [70/160] |	nca: 4.000957202166319, flat: 2.4256780929863453, pod: 45.50643575191498, loss: 51.93307101726532 
Train [9/11] | Epoch [71/160] |	nca: 3.955539435148239, flat: 2.4481593556702137, pod: 45.08351683616638, loss: 51.487215518951416 
Train [9/11] | Epoch [72/160] |	nca: 3.944285422563553, flat: 2.422977291047573, pod: 44.75808548927307, loss: 51.12534832954407 
Train [9/11] | Epoch [73/160] |	nca: 4.02176346629858, flat: 2.362192016094923, pod: 43.35793483257294, loss: 49.74189031124115 
Train [9/11] | Epoch [74/160] |	nca: 4.331149473786354, flat: 2.3520431108772755, pod: 42.632646322250366, loss: 49.3158392906189 
Train [9/11] | Epoch [75/160] |	nca: 4.131699375808239, flat: 2.482082974165678, pod: 45.06773555278778, loss: 51.681517481803894 
Train [9/11] | Epoch [76/160] |	nca: 4.1898303255438805, flat: 2.3507013209164143, pod: 43.65047514438629, loss: 50.19100737571716 
Train [9/11] | Epoch [77/160] |	nca: 3.75544024258852, flat: 2.198327448219061, pod: 42.21479678153992, loss: 48.168564319610596 
Train [9/11] | Epoch [78/160] |	nca: 4.040784053504467, flat: 2.127952676266432, pod: 41.7276349067688, loss: 47.896371603012085 
Train [9/11] | Epoch [79/160] |	nca: 3.976666286587715, flat: 2.2421830408275127, pod: 42.312357783317566, loss: 48.53120744228363 
Train [9/11] | Epoch [80/160] |	nca: 4.064097188413143, flat: 2.238314762711525, pod: 43.14610707759857, loss: 49.448519229888916 
Train [9/11] | Epoch [81/160] |	nca: 3.919356841593981, flat: 2.1726159527897835, pod: 41.132277846336365, loss: 47.22425067424774 
Train [9/11] | Epoch [82/160] |	nca: 3.7113227024674416, flat: 2.222960364073515, pod: 42.54630506038666, loss: 48.48058819770813 
Train [9/11] | Epoch [83/160] |	nca: 3.8430931493639946, flat: 2.2008574455976486, pod: 42.19866764545441, loss: 48.24261796474457 
Train [9/11] | Epoch [84/160] |	nca: 3.7559846714138985, flat: 2.056253779679537, pod: 41.01423382759094, loss: 46.82647204399109 
Train [9/11] | Epoch [85/160] |	nca: 3.7980427145957947, flat: 1.9183431640267372, pod: 38.74164044857025, loss: 44.45802628993988 
Train [9/11] | Epoch [86/160] |	nca: 3.8160536363720894, flat: 1.8725038208067417, pod: 37.462278008461, loss: 43.15083563327789 
Train [9/11] | Epoch [87/160] |	nca: 3.7921977639198303, flat: 1.9738306775689125, pod: 38.91969245672226, loss: 44.685720682144165 
Train [9/11] | Epoch [88/160] |	nca: 3.491928979754448, flat: 1.9001269936561584, pod: 38.44774353504181, loss: 43.839799880981445 
Train [9/11] | Epoch [89/160] |	nca: 3.686113640666008, flat: 1.8799523301422596, pod: 39.46208202838898, loss: 45.02814781665802 
Train [9/11] | Epoch [90/160] |	nca: 3.5969906970858574, flat: 1.876499742269516, pod: 38.21757835149765, loss: 43.69106864929199 
Train [9/11] | Epoch [91/160] |	nca: 3.7778141275048256, flat: 1.9291832968592644, pod: 39.846537470817566, loss: 45.55353486537933 
Train [9/11] | Epoch [92/160] |	nca: 3.6682416051626205, flat: 1.829993475228548, pod: 38.38188028335571, loss: 43.880115270614624 
Train [9/11] | Epoch [93/160] |	nca: 3.658566564321518, flat: 1.782087318599224, pod: 36.51680773496628, loss: 41.95746159553528 
Train [9/11] | Epoch [94/160] |	nca: 3.78729584813118, flat: 1.799457162618637, pod: 37.67381864786148, loss: 43.260571360588074 
Train [9/11] | Epoch [95/160] |	nca: 3.5908979326486588, flat: 1.7977395541965961, pod: 37.08826279640198, loss: 42.476900577545166 
Train [9/11] | Epoch [96/160] |	nca: 3.6400595381855965, flat: 1.7622851729393005, pod: 36.08172708749771, loss: 41.48407173156738 
Train [9/11] | Epoch [97/160] |	nca: 3.662502020597458, flat: 1.6987904943525791, pod: 36.14751219749451, loss: 41.50880467891693 
Train [9/11] | Epoch [98/160] |	nca: 3.359271578490734, flat: 1.5795087553560734, pod: 34.72048878669739, loss: 39.65926945209503 
Train [9/11] | Epoch [99/160] |	nca: 3.6900589615106583, flat: 1.7441571280360222, pod: 37.525023102760315, loss: 42.95923948287964 
Train [9/11] | Epoch [100/160] |	nca: 3.3984653055667877, flat: 1.5529444739222527, pod: 34.705047249794006, loss: 39.65645718574524 
Train [9/11] | Epoch [101/160] |	nca: 3.5216646566987038, flat: 1.7095673009753227, pod: 36.5497310757637, loss: 41.78096330165863 
Train [9/11] | Epoch [102/160] |	nca: 3.542800836265087, flat: 1.6681360006332397, pod: 35.75140917301178, loss: 40.96234607696533 
Train [9/11] | Epoch [103/160] |	nca: 3.6819987818598747, flat: 1.596175167709589, pod: 34.107840955257416, loss: 39.38601493835449 
Train [9/11] | Epoch [104/160] |	nca: 3.404792658984661, flat: 1.6221074536442757, pod: 34.9322292804718, loss: 39.95912957191467 
Train [9/11] | Epoch [105/160] |	nca: 3.6704401448369026, flat: 1.6536391824483871, pod: 35.52528929710388, loss: 40.84936881065369 
Train [9/11] | Epoch [106/160] |	nca: 3.4388027787208557, flat: 1.519483845680952, pod: 33.82760143280029, loss: 38.78588807582855 
Train [9/11] | Epoch [107/160] |	nca: 3.4142044335603714, flat: 1.5208104588091373, pod: 34.60933297872543, loss: 39.544347643852234 
Train [9/11] | Epoch [108/160] |	nca: 3.3867097795009613, flat: 1.5496445782482624, pod: 34.85988223552704, loss: 39.796236872673035 
Train [9/11] | Epoch [109/160] |	nca: 3.623758502304554, flat: 1.5375325754284859, pod: 33.77326583862305, loss: 38.93455719947815 
Train [9/11] | Epoch [110/160] |	nca: 3.3579908944666386, flat: 1.4684922844171524, pod: 34.11551934480667, loss: 38.94200271368027 
Train [9/11] | Epoch [111/160] |	nca: 3.562344767153263, flat: 1.443274226039648, pod: 33.057919681072235, loss: 38.063538551330566 
Train [9/11] | Epoch [112/160] |	nca: 3.5285866409540176, flat: 1.4871621429920197, pod: 33.43181359767914, loss: 38.44756233692169 
Train [9/11] | Epoch [113/160] |	nca: 3.4140903055667877, flat: 1.34068214148283, pod: 31.116938173770905, loss: 35.871710538864136 
Train [9/11] | Epoch [114/160] |	nca: 3.4937876164913177, flat: 1.3734729252755642, pod: 32.31999623775482, loss: 37.187256932258606 
Train [9/11] | Epoch [115/160] |	nca: 3.3514606952667236, flat: 1.3760631829500198, pod: 31.662878453731537, loss: 36.39040195941925 
Train [9/11] | Epoch [116/160] |	nca: 3.4247449040412903, flat: 1.3242683801800013, pod: 30.452972173690796, loss: 35.201985597610474 
Train [9/11] | Epoch [117/160] |	nca: 3.233036756515503, flat: 1.3083838783204556, pod: 31.12012779712677, loss: 35.66154831647873 
Train [9/11] | Epoch [118/160] |	nca: 3.6447125487029552, flat: 1.292179450392723, pod: 31.003225803375244, loss: 35.940117835998535 
Train [9/11] | Epoch [119/160] |	nca: 3.2645637914538383, flat: 1.2824227288365364, pod: 30.827660977840424, loss: 35.374647200107574 
Train [9/11] | Epoch [120/160] |	nca: 3.3816999793052673, flat: 1.1752143818885088, pod: 29.453202843666077, loss: 34.01011735200882 
Train [9/11] | Epoch [121/160] |	nca: 3.4336302764713764, flat: 1.2388933710753918, pod: 30.065702080726624, loss: 34.73822557926178 
Train [9/11] | Epoch [122/160] |	nca: 3.434964455664158, flat: 1.2325693611055613, pod: 29.642985582351685, loss: 34.31051957607269 
Train [9/11] | Epoch [123/160] |	nca: 3.302394710481167, flat: 1.1710493676364422, pod: 28.688110530376434, loss: 33.16155433654785 
Train [9/11] | Epoch [124/160] |	nca: 3.343364220112562, flat: 1.2357721757143736, pod: 30.15521115064621, loss: 34.734347462654114 
Train [9/11] | Epoch [125/160] |	nca: 3.1827979683876038, flat: 1.237563531845808, pod: 30.30629462003708, loss: 34.72665613889694 
Train [9/11] | Epoch [126/160] |	nca: 3.1676975712180138, flat: 1.197697812691331, pod: 29.544325053691864, loss: 33.90972018241882 
Train [9/11] | Epoch [127/160] |	nca: 3.322131685912609, flat: 1.111831046640873, pod: 28.48583424091339, loss: 32.91979676485062 
Train [9/11] | Epoch [128/160] |	nca: 3.295564651489258, flat: 1.0971366129815578, pod: 27.696296632289886, loss: 32.0889977812767 
Train [9/11] | Epoch [129/160] |	nca: 3.2377741001546383, flat: 1.0909244045615196, pod: 27.61569494009018, loss: 31.944393515586853 
Train [9/11] | Epoch [130/160] |	nca: 3.275058802217245, flat: 1.0570361353456974, pod: 27.09384113550186, loss: 31.425936222076416 
Train [9/11] | Epoch [131/160] |	nca: 3.2706379145383835, flat: 1.105023767799139, pod: 27.734380424022675, loss: 32.110042333602905 
Train [9/11] | Epoch [132/160] |	nca: 3.406222600489855, flat: 1.0394538268446922, pod: 26.479629278182983, loss: 30.925305604934692 
Train [9/11] | Epoch [133/160] |	nca: 3.1746355444192886, flat: 1.0173464734107256, pod: 27.171255946159363, loss: 31.363238096237183 
Train [9/11] | Epoch [134/160] |	nca: 3.25794468075037, flat: 1.0407407097518444, pod: 26.626240730285645, loss: 30.924926280975342 
Train [9/11] | Epoch [135/160] |	nca: 3.3460270166397095, flat: 1.0480279829353094, pod: 26.188127517700195, loss: 30.582182228565216 
Train [9/11] | Epoch [136/160] |	nca: 3.336587645113468, flat: 1.0104301758110523, pod: 26.417957305908203, loss: 30.764975130558014 
Train [9/11] | Epoch [137/160] |	nca: 3.1290044859051704, flat: 1.060408677905798, pod: 26.54992115497589, loss: 30.73933434486389 
Train [9/11] | Epoch [138/160] |	nca: 3.2895780950784683, flat: 1.0257841888815165, pod: 25.84486883878708, loss: 30.16023141145706 
Train [9/11] | Epoch [139/160] |	nca: 3.060435011982918, flat: 1.0156729631125927, pod: 25.79004818201065, loss: 29.866156101226807 
Train [9/11] | Epoch [140/160] |	nca: 3.4017219245433807, flat: 0.9976637400686741, pod: 26.41531389951706, loss: 30.81469976902008 
Train [9/11] | Epoch [141/160] |	nca: 3.2591186985373497, flat: 0.9567522741854191, pod: 25.20958536863327, loss: 29.42545634508133 
Train [9/11] | Epoch [142/160] |	nca: 3.0073828026652336, flat: 0.93823635391891, pod: 25.232736706733704, loss: 29.178355813026428 
Train [9/11] | Epoch [143/160] |	nca: 3.0984823554754257, flat: 0.9353645294904709, pod: 24.688937425613403, loss: 28.722784459590912 
Train [9/11] | Epoch [144/160] |	nca: 3.1406183540821075, flat: 0.9173763804137707, pod: 23.88578152656555, loss: 27.943776428699493 
Train [9/11] | Epoch [145/160] |	nca: 3.255538120865822, flat: 0.8592974562197924, pod: 23.34023231267929, loss: 27.455067932605743 
Train [9/11] | Epoch [146/160] |	nca: 3.1585236340761185, flat: 0.8945964407175779, pod: 23.831885516643524, loss: 27.885005474090576 
Train [9/11] | Epoch [147/160] |	nca: 3.1854956075549126, flat: 0.8647852428257465, pod: 23.481731176376343, loss: 27.532011926174164 
Train [9/11] | Epoch [148/160] |	nca: 3.2215512208640575, flat: 0.8947048429399729, pod: 23.78947412967682, loss: 27.90573024749756 
Train [9/11] | Epoch [149/160] |	nca: 3.0885794535279274, flat: 0.8834118843078613, pod: 23.348421216011047, loss: 27.320412755012512 
Train [9/11] | Epoch [150/160] |	nca: 3.1151606515049934, flat: 0.8576553203165531, pod: 23.029756903648376, loss: 27.00257283449173 
Train [9/11] | Epoch [151/160] |	nca: 2.9653800651431084, flat: 0.8164328522980213, pod: 22.346851468086243, loss: 26.128664314746857 
Train [9/11] | Epoch [152/160] |	nca: 3.2308396361768246, flat: 0.8800748363137245, pod: 23.460131227970123, loss: 27.571045637130737 
Train [9/11] | Epoch [153/160] |	nca: 3.0669943168759346, flat: 0.8433933444321156, pod: 22.64021933078766, loss: 26.550606966018677 
Train [9/11] | Epoch [154/160] |	nca: 3.06139999255538, flat: 0.8209984563291073, pod: 22.1114559173584, loss: 25.99385440349579 
Train [9/11] | Epoch [155/160] |	nca: 3.2016734927892685, flat: 0.8671701271086931, pod: 22.186655640602112, loss: 26.255499064922333 
Train [9/11] | Epoch [156/160] |	nca: 3.041545618325472, flat: 0.8366787526756525, pod: 21.896959602832794, loss: 25.77518379688263 
Train [9/11] | Epoch [157/160] |	nca: 3.023925095796585, flat: 0.7977137714624405, pod: 21.758292734622955, loss: 25.579931557178497 
Train [9/11] | Epoch [158/160] |	nca: 3.058776393532753, flat: 0.8740081693977118, pod: 23.167490541934967, loss: 27.100274980068207 
Train [9/11] | Epoch [159/160] |	nca: 3.234862670302391, flat: 0.8267736304551363, pod: 22.343536257743835, loss: 26.40517246723175 
Train [9/11] | Epoch [160/160] |	nca: 3.0953227505087852, flat: 0.8092288877815008, pod: 21.960091918706894, loss: 25.86464375257492 
Fine-tuning
Building & updating memory.
Train [9/11] | Epoch [161/180] |	nca: 1.9749497547745705, flat: 0.9996931664645672, pod: 18.522279739379883, loss: 21.496922731399536 
Train [9/11] | Epoch [162/180] |	nca: 2.455924589186907, flat: 1.2401967607438564, pod: 19.33751004934311, loss: 23.033631324768066 
Train [9/11] | Epoch [163/180] |	nca: 2.9440957233309746, flat: 1.025851245969534, pod: 18.62610650062561, loss: 22.59605371952057 
Train [9/11] | Epoch [164/180] |	nca: 2.3747388422489166, flat: 1.0881859809160233, pod: 18.78946143388748, loss: 22.252386212348938 
Train [9/11] | Epoch [165/180] |	nca: 2.1135585010051727, flat: 1.1149429753422737, pod: 19.00829404592514, loss: 22.23679554462433 
Train [9/11] | Epoch [166/180] |	nca: 2.1353174075484276, flat: 1.1576121412217617, pod: 19.60496687889099, loss: 22.897896647453308 
Train [9/11] | Epoch [167/180] |	nca: 1.9966368153691292, flat: 1.1101695001125336, pod: 19.159675538539886, loss: 22.266481757164 
Train [9/11] | Epoch [168/180] |	nca: 2.154966078698635, flat: 1.0454768687486649, pod: 18.782370924949646, loss: 21.982813715934753 
Train [9/11] | Epoch [169/180] |	nca: 2.311214290559292, flat: 1.0506679713726044, pod: 18.846386551856995, loss: 22.208268761634827 
Train [9/11] | Epoch [170/180] |	nca: 2.7425442561507225, flat: 1.095217291265726, pod: 18.924993813037872, loss: 22.762755274772644 
Train [9/11] | Epoch [171/180] |	nca: 2.89645504206419, flat: 1.0790880247950554, pod: 19.029239773750305, loss: 23.004782676696777 
Train [9/11] | Epoch [172/180] |	nca: 3.406461462378502, flat: 1.086803738027811, pod: 19.05510115623474, loss: 23.54836654663086 
Train [9/11] | Epoch [173/180] |	nca: 4.099189072847366, flat: 1.2043543308973312, pod: 19.79489141702652, loss: 25.098434805870056 
Train [9/11] | Epoch [174/180] |	nca: 2.5030784755945206, flat: 1.150252740830183, pod: 19.672212779521942, loss: 23.325543880462646 
Train [9/11] | Epoch [175/180] |	nca: 1.9281888976693153, flat: 1.0662602856755257, pod: 18.422255158424377, loss: 21.416704177856445 
Train [9/11] | Epoch [176/180] |	nca: 2.124648705124855, flat: 1.1001410111784935, pod: 19.08187687397003, loss: 22.306666612625122 
Train [9/11] | Epoch [177/180] |	nca: 2.107499696314335, flat: 1.133925300091505, pod: 18.984816789627075, loss: 22.226241946220398 
Train [9/11] | Epoch [178/180] |	nca: 2.019005388021469, flat: 1.0902778208255768, pod: 18.870870292186737, loss: 21.980153620243073 
Train [9/11] | Epoch [179/180] |	nca: 2.055779479444027, flat: 1.0720110349357128, pod: 19.052218198776245, loss: 22.18000864982605 
Train [9/11] | Epoch [180/180] |	nca: 1.425190806388855, flat: 1.004585888236761, pod: 18.00874936580658, loss: 20.438526153564453 
after task
Building & updating memory.
after task
Eval on 0->90.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6413333333333333.
Current acc: {'total': 0.563, '00-09': 0.656, '10-19': 0.564, '20-29': 0.484, '30-39': 0.533, '40-49': 0.587, '50-59': 0.569, '60-69': 0.48, '70-79': 0.572, '80-89': 0.622}.
Avg inc acc top5: 0.8808888888888888.
Current acc top5: {'total': 0.836}.
Forgetting: 0.13010000000000002.
Cord metric: 0.63.
Old accuracy: 0.56, mean: 0.63.
New accuracy: 0.66, mean: 0.65.
================Task 9 Start!================
Testing on False unseen tasks (max class = 95).
Set memory of size: 1800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 9 Training!================
The training samples number: 4300
Train on 90->95.
train task
nb 4300.
Train [10/11] | Epoch [1/160] |	nca: 34.79458636045456, flat: 10.552693538367748, pod: 88.42495602369308, loss: 133.7722363471985 
Train [10/11] | Epoch [2/160] |	nca: 31.422711789608, flat: 13.276788711547852, pod: 103.92473936080933, loss: 148.6242389678955 
Train [10/11] | Epoch [3/160] |	nca: 19.297307908535004, flat: 9.348153784871101, pod: 87.45305252075195, loss: 116.09851312637329 
Train [10/11] | Epoch [4/160] |	nca: 15.378364890813828, flat: 7.577886030077934, pod: 77.34405755996704, loss: 100.3003089427948 
Train [10/11] | Epoch [5/160] |	nca: 12.570657283067703, flat: 6.6561742424964905, pod: 73.19906222820282, loss: 92.42589378356934 
Train [10/11] | Epoch [6/160] |	nca: 11.033926397562027, flat: 5.78280708193779, pod: 68.88430047035217, loss: 85.70103430747986 
Train [10/11] | Epoch [7/160] |	nca: 10.427619889378548, flat: 5.2807072550058365, pod: 66.33490657806396, loss: 82.04323387145996 
Train [10/11] | Epoch [8/160] |	nca: 10.343723490834236, flat: 5.171415612101555, pod: 63.77529776096344, loss: 79.29043626785278 
Train [10/11] | Epoch [9/160] |	nca: 9.62386292219162, flat: 5.142913103103638, pod: 64.14826905727386, loss: 78.91504526138306 
Train [10/11] | Epoch [10/160] |	nca: 9.58541065454483, flat: 5.160730794072151, pod: 64.00022113323212, loss: 78.74636244773865 
Train [10/11] | Epoch [11/160] |	nca: 9.03331533074379, flat: 4.875298619270325, pod: 62.46837294101715, loss: 76.37698650360107 
Train [10/11] | Epoch [12/160] |	nca: 9.616867035627365, flat: 4.984205365180969, pod: 62.948755741119385, loss: 77.54982829093933 
Train [10/11] | Epoch [13/160] |	nca: 9.234585747122765, flat: 5.100064620375633, pod: 63.81096279621124, loss: 78.1456127166748 
Train [10/11] | Epoch [14/160] |	nca: 8.990806579589844, flat: 5.034512460231781, pod: 63.22955942153931, loss: 77.25487875938416 
Train [10/11] | Epoch [15/160] |	nca: 8.300094619393349, flat: 4.656365312635899, pod: 61.22203242778778, loss: 74.17849159240723 
Train [10/11] | Epoch [16/160] |	nca: 8.321076527237892, flat: 4.710265018045902, pod: 61.43931841850281, loss: 74.47065949440002 
Train [10/11] | Epoch [17/160] |	nca: 8.639493733644485, flat: 4.948763087391853, pod: 64.3557448387146, loss: 77.94400119781494 
Train [10/11] | Epoch [18/160] |	nca: 8.478711292147636, flat: 4.9250509440898895, pod: 61.893842339515686, loss: 75.29760479927063 
Train [10/11] | Epoch [19/160] |	nca: 8.448758393526077, flat: 4.967479258775711, pod: 64.1751948595047, loss: 77.59143209457397 
Train [10/11] | Epoch [20/160] |	nca: 7.952150031924248, flat: 4.653834916651249, pod: 61.16362953186035, loss: 73.7696144580841 
Train [10/11] | Epoch [21/160] |	nca: 8.48579615354538, flat: 4.771325975656509, pod: 61.59336721897125, loss: 74.85048961639404 
Train [10/11] | Epoch [22/160] |	nca: 7.464598715305328, flat: 4.649369418621063, pod: 60.086695313453674, loss: 72.20066368579865 
Train [10/11] | Epoch [23/160] |	nca: 7.029277473688126, flat: 4.1627031192183495, pod: 58.14436626434326, loss: 69.3363471031189 
Train [10/11] | Epoch [24/160] |	nca: 7.783057615160942, flat: 4.310707524418831, pod: 58.94933462142944, loss: 71.04309964179993 
Train [10/11] | Epoch [25/160] |	nca: 8.1715217679739, flat: 4.4395818039774895, pod: 58.664063453674316, loss: 71.27516710758209 
Train [10/11] | Epoch [26/160] |	nca: 7.6286928206682205, flat: 4.42998543381691, pod: 59.743823528289795, loss: 71.80250179767609 
Train [10/11] | Epoch [27/160] |	nca: 7.179113060235977, flat: 4.392624035477638, pod: 60.046958327293396, loss: 71.61869549751282 
Train [10/11] | Epoch [28/160] |	nca: 6.750147193670273, flat: 4.005473159253597, pod: 56.72785556316376, loss: 67.48347592353821 
Train [10/11] | Epoch [29/160] |	nca: 7.362098127603531, flat: 4.2634855061769485, pod: 59.10832178592682, loss: 70.73390543460846 
Train [10/11] | Epoch [30/160] |	nca: 7.19184285402298, flat: 4.23217286169529, pod: 59.011237382888794, loss: 70.43525242805481 
Train [10/11] | Epoch [31/160] |	nca: 7.406027153134346, flat: 4.413601830601692, pod: 58.907485604286194, loss: 70.7271146774292 
Train [10/11] | Epoch [32/160] |	nca: 6.941284671425819, flat: 4.1417419239878654, pod: 57.297972321510315, loss: 68.38099896907806 
Train [10/11] | Epoch [33/160] |	nca: 7.277488648891449, flat: 4.1318096071481705, pod: 57.930673122406006, loss: 69.33997142314911 
Train [10/11] | Epoch [34/160] |	nca: 7.1736191511154175, flat: 4.150248169898987, pod: 55.931472301483154, loss: 67.25533974170685 
Train [10/11] | Epoch [35/160] |	nca: 6.763364195823669, flat: 4.075616881251335, pod: 56.420992732048035, loss: 67.25997340679169 
Train [10/11] | Epoch [36/160] |	nca: 6.652751177549362, flat: 4.046852618455887, pod: 56.299850821495056, loss: 66.9994547367096 
Train [10/11] | Epoch [37/160] |	nca: 7.088465213775635, flat: 4.065743125975132, pod: 56.76988971233368, loss: 67.92409813404083 
Train [10/11] | Epoch [38/160] |	nca: 6.91664245724678, flat: 4.273176297545433, pod: 58.85792279243469, loss: 70.0477409362793 
Train [10/11] | Epoch [39/160] |	nca: 6.7067640870809555, flat: 3.9076919704675674, pod: 55.503581166267395, loss: 66.11803710460663 
Train [10/11] | Epoch [40/160] |	nca: 7.013553909957409, flat: 3.946645610034466, pod: 55.696025252342224, loss: 66.65622472763062 
Train [10/11] | Epoch [41/160] |	nca: 6.7316446751356125, flat: 4.0355231165885925, pod: 56.57106149196625, loss: 67.33822906017303 
Train [10/11] | Epoch [42/160] |	nca: 6.625761225819588, flat: 3.941814713180065, pod: 56.95045590400696, loss: 67.51803195476532 
Train [10/11] | Epoch [43/160] |	nca: 6.651935279369354, flat: 3.7354656159877777, pod: 54.23460495471954, loss: 64.6220053434372 
Train [10/11] | Epoch [44/160] |	nca: 6.964225217700005, flat: 4.142341643571854, pod: 56.855186343193054, loss: 67.9617532491684 
Train [10/11] | Epoch [45/160] |	nca: 6.569882780313492, flat: 3.7317532151937485, pod: 54.082608699798584, loss: 64.38424444198608 
Train [10/11] | Epoch [46/160] |	nca: 6.284062668681145, flat: 3.478452831506729, pod: 52.69573724269867, loss: 62.45825278759003 
Train [10/11] | Epoch [47/160] |	nca: 5.961390607059002, flat: 3.6519500762224197, pod: 53.560510754585266, loss: 63.17385149002075 
Train [10/11] | Epoch [48/160] |	nca: 6.1650135070085526, flat: 3.5979411751031876, pod: 53.54968559741974, loss: 63.31263995170593 
Train [10/11] | Epoch [49/160] |	nca: 6.3152064979076385, flat: 3.629018947482109, pod: 53.353068113327026, loss: 63.29729354381561 
Train [10/11] | Epoch [50/160] |	nca: 6.348225824534893, flat: 3.6063065826892853, pod: 52.27417278289795, loss: 62.228705644607544 
Train [10/11] | Epoch [51/160] |	nca: 6.4141232296824455, flat: 3.684862919151783, pod: 53.85643398761749, loss: 63.95542025566101 
Train [10/11] | Epoch [52/160] |	nca: 7.121859058737755, flat: 3.734888918697834, pod: 53.8888703584671, loss: 64.74561846256256 
Train [10/11] | Epoch [53/160] |	nca: 6.192219316959381, flat: 3.635471597313881, pod: 52.90309953689575, loss: 62.7307904958725 
Train [10/11] | Epoch [54/160] |	nca: 6.055500358343124, flat: 3.5092634856700897, pod: 52.079288840293884, loss: 61.644052624702454 
Train [10/11] | Epoch [55/160] |	nca: 6.202213078737259, flat: 3.445994183421135, pod: 52.57985162734985, loss: 62.22805893421173 
Train [10/11] | Epoch [56/160] |	nca: 5.759998366236687, flat: 3.4774164333939552, pod: 52.86965036392212, loss: 62.107064843177795 
Train [10/11] | Epoch [57/160] |	nca: 5.965809844434261, flat: 3.3658540844917297, pod: 51.62688171863556, loss: 60.95854568481445 
Train [10/11] | Epoch [58/160] |	nca: 6.108443006873131, flat: 3.309610977768898, pod: 49.57795822620392, loss: 58.99601209163666 
Train [10/11] | Epoch [59/160] |	nca: 5.889657691121101, flat: 3.32713782787323, pod: 50.16576159000397, loss: 59.3825569152832 
Train [10/11] | Epoch [60/160] |	nca: 6.383050665259361, flat: 3.4891601651906967, pod: 51.843613386154175, loss: 61.715824365615845 
Train [10/11] | Epoch [61/160] |	nca: 5.850149996578693, flat: 3.4636921882629395, pod: 51.97838580608368, loss: 61.29222798347473 
Train [10/11] | Epoch [62/160] |	nca: 5.511687196791172, flat: 3.1618694812059402, pod: 49.67510426044464, loss: 58.348660945892334 
Train [10/11] | Epoch [63/160] |	nca: 6.0654216185212135, flat: 3.315768525004387, pod: 50.0101500749588, loss: 59.391340255737305 
Train [10/11] | Epoch [64/160] |	nca: 5.663411967456341, flat: 3.1323882043361664, pod: 49.255441784858704, loss: 58.05124223232269 
Train [10/11] | Epoch [65/160] |	nca: 5.671645246446133, flat: 3.055112048983574, pod: 48.691168785095215, loss: 57.41792631149292 
Train [10/11] | Epoch [66/160] |	nca: 5.917226567864418, flat: 3.1777256578207016, pod: 49.835015654563904, loss: 58.92996799945831 
Train [10/11] | Epoch [67/160] |	nca: 5.797217547893524, flat: 3.2468287646770477, pod: 49.647560238838196, loss: 58.691606760025024 
Train [10/11] | Epoch [68/160] |	nca: 5.8820237666368484, flat: 3.0284618139266968, pod: 48.15240204334259, loss: 57.06288778781891 
Train [10/11] | Epoch [69/160] |	nca: 5.521561823785305, flat: 3.0496089830994606, pod: 47.902562499046326, loss: 56.47373342514038 
Train [10/11] | Epoch [70/160] |	nca: 5.7301958575844765, flat: 2.9458506405353546, pod: 46.81111407279968, loss: 55.48716056346893 
Train [10/11] | Epoch [71/160] |	nca: 5.734378628432751, flat: 3.0394162461161613, pod: 48.37542688846588, loss: 57.149221777915955 
Train [10/11] | Epoch [72/160] |	nca: 5.588040165603161, flat: 2.953477680683136, pod: 47.25872588157654, loss: 55.800243616104126 
Train [10/11] | Epoch [73/160] |	nca: 5.6236579939723015, flat: 3.059601955115795, pod: 47.90938210487366, loss: 56.592642068862915 
Train [10/11] | Epoch [74/160] |	nca: 5.332878366112709, flat: 3.016080856323242, pod: 48.85733377933502, loss: 57.20629298686981 
Train [10/11] | Epoch [75/160] |	nca: 5.667796991765499, flat: 3.0456705316901207, pod: 49.183584332466125, loss: 57.89705145359039 
Train [10/11] | Epoch [76/160] |	nca: 5.6058245450258255, flat: 2.899290695786476, pod: 47.42444670200348, loss: 55.92956209182739 
Train [10/11] | Epoch [77/160] |	nca: 5.074933744966984, flat: 2.7540012896060944, pod: 44.86736273765564, loss: 52.69629764556885 
Train [10/11] | Epoch [78/160] |	nca: 5.3328278586268425, flat: 2.7114527374505997, pod: 45.08963918685913, loss: 53.13391995429993 
Train [10/11] | Epoch [79/160] |	nca: 5.555439837276936, flat: 2.761645555496216, pod: 45.58266580104828, loss: 53.89975118637085 
Train [10/11] | Epoch [80/160] |	nca: 5.5274112448096275, flat: 2.855015017092228, pod: 46.12550163269043, loss: 54.507928013801575 
Train [10/11] | Epoch [81/160] |	nca: 5.331424735486507, flat: 2.646493047475815, pod: 45.00035309791565, loss: 52.97827100753784 
Train [10/11] | Epoch [82/160] |	nca: 5.161485455930233, flat: 2.6044575944542885, pod: 44.09368920326233, loss: 51.85963189601898 
Train [10/11] | Epoch [83/160] |	nca: 5.434798821806908, flat: 2.7479073256254196, pod: 45.67930042743683, loss: 53.86200666427612 
Train [10/11] | Epoch [84/160] |	nca: 5.067572996020317, flat: 2.6747850626707077, pod: 44.91230487823486, loss: 52.65466284751892 
Train [10/11] | Epoch [85/160] |	nca: 5.190903820097446, flat: 2.5370416790246964, pod: 42.39190447330475, loss: 50.11984968185425 
Train [10/11] | Epoch [86/160] |	nca: 4.943523809313774, flat: 2.4874536879360676, pod: 42.877882957458496, loss: 50.308860540390015 
Train [10/11] | Epoch [87/160] |	nca: 4.98703445494175, flat: 2.434426434338093, pod: 43.67910587787628, loss: 51.10056722164154 
Train [10/11] | Epoch [88/160] |	nca: 5.427909046411514, flat: 2.5860241428017616, pod: 44.27934110164642, loss: 52.29327416419983 
Train [10/11] | Epoch [89/160] |	nca: 5.044900141656399, flat: 2.519219495356083, pod: 43.93965709209442, loss: 51.50377655029297 
Train [10/11] | Epoch [90/160] |	nca: 5.177944257855415, flat: 2.556533519178629, pod: 43.78046488761902, loss: 51.51494264602661 
Train [10/11] | Epoch [91/160] |	nca: 5.180469013750553, flat: 2.484895057976246, pod: 42.759276390075684, loss: 50.42464017868042 
Train [10/11] | Epoch [92/160] |	nca: 4.95175102353096, flat: 2.3090093694627285, pod: 40.24372065067291, loss: 47.504480838775635 
Train [10/11] | Epoch [93/160] |	nca: 4.925665281713009, flat: 2.350967723876238, pod: 41.04430973529816, loss: 48.320942759513855 
Train [10/11] | Epoch [94/160] |	nca: 5.092595562338829, flat: 2.377721793949604, pod: 41.43048596382141, loss: 48.900803089141846 
Train [10/11] | Epoch [95/160] |	nca: 5.092918649315834, flat: 2.365543480962515, pod: 41.30042278766632, loss: 48.75888478755951 
Train [10/11] | Epoch [96/160] |	nca: 4.958710089325905, flat: 2.2383341006934643, pod: 40.0873829126358, loss: 47.28442692756653 
Train [10/11] | Epoch [97/160] |	nca: 4.715759426355362, flat: 2.0510420985519886, pod: 38.65736949443817, loss: 45.42417085170746 
Train [10/11] | Epoch [98/160] |	nca: 5.06239465624094, flat: 2.15928665548563, pod: 39.574472069740295, loss: 46.79615342617035 
Train [10/11] | Epoch [99/160] |	nca: 4.884625941514969, flat: 2.1737565621733665, pod: 39.21971952915192, loss: 46.27810192108154 
Train [10/11] | Epoch [100/160] |	nca: 4.664888441562653, flat: 2.0576573610305786, pod: 38.973520040512085, loss: 45.69606614112854 
Train [10/11] | Epoch [101/160] |	nca: 4.877702578902245, flat: 2.1639020889997482, pod: 40.05661427974701, loss: 47.09821879863739 
Train [10/11] | Epoch [102/160] |	nca: 4.788182705640793, flat: 2.182163268327713, pod: 40.95984899997711, loss: 47.93019497394562 
Train [10/11] | Epoch [103/160] |	nca: 4.838571734726429, flat: 2.0962799601256847, pod: 39.09970283508301, loss: 46.03455460071564 
Train [10/11] | Epoch [104/160] |	nca: 4.574634708464146, flat: 2.0193440914154053, pod: 37.995608150959015, loss: 44.58958673477173 
Train [10/11] | Epoch [105/160] |	nca: 4.683158256113529, flat: 1.9310161396861076, pod: 36.82985156774521, loss: 43.44402623176575 
Train [10/11] | Epoch [106/160] |	nca: 4.622292265295982, flat: 1.9342934973537922, pod: 37.28580451011658, loss: 43.842390179634094 
Train [10/11] | Epoch [107/160] |	nca: 4.8746435940265656, flat: 1.8471176140010357, pod: 35.555625796318054, loss: 42.277387261390686 
Train [10/11] | Epoch [108/160] |	nca: 4.656541608273983, flat: 1.8815792463719845, pod: 36.11449807882309, loss: 42.652618765830994 
Train [10/11] | Epoch [109/160] |	nca: 4.852646067738533, flat: 1.8259893171489239, pod: 35.660315990448, loss: 42.338951110839844 
Train [10/11] | Epoch [110/160] |	nca: 4.500816345214844, flat: 1.8820436336100101, pod: 35.66635978221893, loss: 42.049219727516174 
Train [10/11] | Epoch [111/160] |	nca: 4.485265739262104, flat: 1.7890499085187912, pod: 35.678941905498505, loss: 41.95325720310211 
Train [10/11] | Epoch [112/160] |	nca: 4.50905679166317, flat: 1.7628163322806358, pod: 35.404541969299316, loss: 41.67641520500183 
Train [10/11] | Epoch [113/160] |	nca: 4.365976832807064, flat: 1.6650521345436573, pod: 33.83867686986923, loss: 39.86970567703247 
Train [10/11] | Epoch [114/160] |	nca: 4.363922983407974, flat: 1.6481337435543537, pod: 33.74484968185425, loss: 39.756906509399414 
Train [10/11] | Epoch [115/160] |	nca: 4.602964825928211, flat: 1.6693552918732166, pod: 33.98316031694412, loss: 40.25548028945923 
Train [10/11] | Epoch [116/160] |	nca: 4.454380966722965, flat: 1.6681608520448208, pod: 33.856698870658875, loss: 39.97924089431763 
Train [10/11] | Epoch [117/160] |	nca: 4.599816739559174, flat: 1.746351532638073, pod: 35.17102110385895, loss: 41.517189264297485 
Train [10/11] | Epoch [118/160] |	nca: 4.561739943921566, flat: 1.7456979230046272, pod: 34.63665568828583, loss: 40.94409358501434 
Train [10/11] | Epoch [119/160] |	nca: 4.380059950053692, flat: 1.6162517108023167, pod: 32.310480296611786, loss: 38.30679166316986 
Train [10/11] | Epoch [120/160] |	nca: 4.353929311037064, flat: 1.5450645238161087, pod: 31.74986869096756, loss: 37.64886265993118 
Train [10/11] | Epoch [121/160] |	nca: 4.251201398670673, flat: 1.5368381552398205, pod: 31.508665084838867, loss: 37.29670476913452 
Train [10/11] | Epoch [122/160] |	nca: 4.630702719092369, flat: 1.490265604108572, pod: 31.047098994255066, loss: 37.168067276477814 
Train [10/11] | Epoch [123/160] |	nca: 4.3315903171896935, flat: 1.6122220493853092, pod: 33.59646052122116, loss: 39.54027307033539 
Train [10/11] | Epoch [124/160] |	nca: 4.423690557479858, flat: 1.5268472470343113, pod: 31.967339038848877, loss: 37.91787672042847 
Train [10/11] | Epoch [125/160] |	nca: 4.378490127623081, flat: 1.4014219678938389, pod: 30.054178476333618, loss: 35.834090650081635 
Train [10/11] | Epoch [126/160] |	nca: 4.477546267211437, flat: 1.5256364308297634, pod: 31.93869185447693, loss: 37.94187420606613 
Train [10/11] | Epoch [127/160] |	nca: 4.214372470974922, flat: 1.425049088895321, pod: 30.35857355594635, loss: 35.997995138168335 
Train [10/11] | Epoch [128/160] |	nca: 4.285553015768528, flat: 1.3698023781180382, pod: 30.27126806974411, loss: 35.92662364244461 
Train [10/11] | Epoch [129/160] |	nca: 4.321325957775116, flat: 1.3924633711576462, pod: 29.4776251912117, loss: 35.191414535045624 
Train [10/11] | Epoch [130/160] |	nca: 4.3866860419511795, flat: 1.418204490095377, pod: 29.61699616909027, loss: 35.421886920928955 
Train [10/11] | Epoch [131/160] |	nca: 4.422123394906521, flat: 1.3199316784739494, pod: 28.662505090236664, loss: 34.40455985069275 
Train [10/11] | Epoch [132/160] |	nca: 4.232901602983475, flat: 1.3457797765731812, pod: 28.782275021076202, loss: 34.36095613241196 
Train [10/11] | Epoch [133/160] |	nca: 4.548934601247311, flat: 1.3443078435957432, pod: 29.101525604724884, loss: 34.99476796388626 
Train [10/11] | Epoch [134/160] |	nca: 4.163190498948097, flat: 1.302022535353899, pod: 27.793979704380035, loss: 33.259192645549774 
Train [10/11] | Epoch [135/160] |	nca: 4.245147466659546, flat: 1.2929615564644337, pod: 28.410992860794067, loss: 33.94910192489624 
Train [10/11] | Epoch [136/160] |	nca: 4.4009948670864105, flat: 1.2886128854006529, pod: 28.568938076496124, loss: 34.25854569673538 
Train [10/11] | Epoch [137/160] |	nca: 4.159561865031719, flat: 1.1871332135051489, pod: 26.61817294359207, loss: 31.96486806869507 
Train [10/11] | Epoch [138/160] |	nca: 4.254818648099899, flat: 1.296687550842762, pod: 27.6448734998703, loss: 33.19637995958328 
Train [10/11] | Epoch [139/160] |	nca: 4.234968967735767, flat: 1.2152165193110704, pod: 27.201829612255096, loss: 32.65201497077942 
Train [10/11] | Epoch [140/160] |	nca: 4.2340618297457695, flat: 1.2558598406612873, pod: 27.119057714939117, loss: 32.60897916555405 
Train [10/11] | Epoch [141/160] |	nca: 4.204508751630783, flat: 1.1995082907378674, pod: 27.046389997005463, loss: 32.45040714740753 
Train [10/11] | Epoch [142/160] |	nca: 4.260553233325481, flat: 1.1949613746255636, pod: 26.14923131465912, loss: 31.604746103286743 
Train [10/11] | Epoch [143/160] |	nca: 4.323737367987633, flat: 1.1689544972032309, pod: 25.898215770721436, loss: 31.390907526016235 
Train [10/11] | Epoch [144/160] |	nca: 4.258301146328449, flat: 1.147844998165965, pod: 25.692333698272705, loss: 31.09847992658615 
Train [10/11] | Epoch [145/160] |	nca: 4.057691268622875, flat: 1.1299529019743204, pod: 26.091821432113647, loss: 31.279465675354004 
Train [10/11] | Epoch [146/160] |	nca: 4.128522731363773, flat: 1.1298728100955486, pod: 24.845485150814056, loss: 30.10388070344925 
Train [10/11] | Epoch [147/160] |	nca: 4.196207724511623, flat: 1.0983502957969904, pod: 25.260218918323517, loss: 30.554777085781097 
Train [10/11] | Epoch [148/160] |	nca: 4.198256820440292, flat: 1.1011876482516527, pod: 25.04910272359848, loss: 30.348547220230103 
Train [10/11] | Epoch [149/160] |	nca: 4.044014386832714, flat: 1.1155160889029503, pod: 25.37642753124237, loss: 30.535957872867584 
Train [10/11] | Epoch [150/160] |	nca: 4.251927249133587, flat: 1.073340268805623, pod: 24.619387805461884, loss: 29.94465547800064 
Train [10/11] | Epoch [151/160] |	nca: 4.099974073469639, flat: 1.1175669804215431, pod: 24.747227907180786, loss: 29.964768946170807 
Train [10/11] | Epoch [152/160] |	nca: 4.208118721842766, flat: 1.0898508224636316, pod: 24.516597032546997, loss: 29.814566671848297 
Train [10/11] | Epoch [153/160] |	nca: 4.001183032989502, flat: 1.092686202377081, pod: 24.86713695526123, loss: 29.961006224155426 
Train [10/11] | Epoch [154/160] |	nca: 4.216917850077152, flat: 1.104096682742238, pod: 24.54344016313553, loss: 29.864454686641693 
Train [10/11] | Epoch [155/160] |	nca: 4.01211129873991, flat: 1.0803878791630268, pod: 24.260561525821686, loss: 29.353060841560364 
Train [10/11] | Epoch [156/160] |	nca: 4.063682377338409, flat: 1.1258150432258844, pod: 24.729413151741028, loss: 29.918910682201385 
Train [10/11] | Epoch [157/160] |	nca: 4.207362249493599, flat: 1.1397194843739271, pod: 25.257295846939087, loss: 30.604377686977386 
Train [10/11] | Epoch [158/160] |	nca: 4.197730675339699, flat: 1.1007476821541786, pod: 24.723091423511505, loss: 30.021569669246674 
Train [10/11] | Epoch [159/160] |	nca: 4.105482950806618, flat: 1.0760049354285002, pod: 24.43875288963318, loss: 29.620240926742554 
Train [10/11] | Epoch [160/160] |	nca: 4.102026060223579, flat: 1.0913649685680866, pod: 24.475000500679016, loss: 29.668391585350037 
Fine-tuning
Building & updating memory.
Train [10/11] | Epoch [161/180] |	nca: 1.982735849916935, flat: 0.6350019685924053, pod: 12.477339446544647, loss: 15.095077216625214 
Train [10/11] | Epoch [162/180] |	nca: 1.3686017543077469, flat: 0.6405060663819313, pod: 12.353814661502838, loss: 14.362922370433807 
Train [10/11] | Epoch [163/180] |	nca: 1.097446747124195, flat: 0.6350722648203373, pod: 12.42785108089447, loss: 14.16036993265152 
Train [10/11] | Epoch [164/180] |	nca: 1.0070346780121326, flat: 0.6438322700560093, pod: 12.597551167011261, loss: 14.248418092727661 
Train [10/11] | Epoch [165/180] |	nca: 0.9811195693910122, flat: 0.6404845602810383, pod: 12.408716142177582, loss: 14.030320346355438 
Train [10/11] | Epoch [166/180] |	nca: 0.9802932478487492, flat: 0.6441380456089973, pod: 12.49439686536789, loss: 14.118828296661377 
Train [10/11] | Epoch [167/180] |	nca: 0.9024408683180809, flat: 0.6625778265297413, pod: 12.884071588516235, loss: 14.449090361595154 
Train [10/11] | Epoch [168/180] |	nca: 0.9112094342708588, flat: 0.6457686461508274, pod: 12.614225149154663, loss: 14.171203315258026 
Train [10/11] | Epoch [169/180] |	nca: 0.8977161385118961, flat: 0.6490985359996557, pod: 12.458365380764008, loss: 14.00518000125885 
Train [10/11] | Epoch [170/180] |	nca: 0.8389886058866978, flat: 0.6515178848057985, pod: 12.742949426174164, loss: 14.233455955982208 
Train [10/11] | Epoch [171/180] |	nca: 0.7717902697622776, flat: 0.644349217414856, pod: 12.864747405052185, loss: 14.280886948108673 
Train [10/11] | Epoch [172/180] |	nca: 0.7278131134808064, flat: 0.6272620223462582, pod: 12.456131756305695, loss: 13.811206758022308 
Train [10/11] | Epoch [173/180] |	nca: 0.7513977885246277, flat: 0.6573321670293808, pod: 12.559759080410004, loss: 13.968489050865173 
Train [10/11] | Epoch [174/180] |	nca: 0.758780013769865, flat: 0.6348429210484028, pod: 12.364295482635498, loss: 13.75791847705841 
Train [10/11] | Epoch [175/180] |	nca: 0.7412571832537651, flat: 0.6624632403254509, pod: 12.812488496303558, loss: 14.216208755970001 
Train [10/11] | Epoch [176/180] |	nca: 0.7293162234127522, flat: 0.6427246108651161, pod: 12.593861281871796, loss: 13.965902090072632 
Train [10/11] | Epoch [177/180] |	nca: 0.742075577378273, flat: 0.6568274348974228, pod: 12.4793022274971, loss: 13.878205299377441 
Train [10/11] | Epoch [178/180] |	nca: 0.7615820094943047, flat: 0.6471775583922863, pod: 12.360583662986755, loss: 13.769343137741089 
Train [10/11] | Epoch [179/180] |	nca: 0.7008318938314915, flat: 0.6539941318333149, pod: 12.686181902885437, loss: 14.041007936000824 
Train [10/11] | Epoch [180/180] |	nca: 0.7290611453354359, flat: 0.6602986566722393, pod: 12.915434956550598, loss: 14.304794728755951 
after task
Building & updating memory.
after task
Eval on 0->95.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6315.
Current acc: {'total': 0.543, '00-09': 0.638, '10-19': 0.547, '20-29': 0.464, '30-39': 0.522, '40-49': 0.564, '50-59': 0.557, '60-69': 0.456, '70-79': 0.544, '80-89': 0.604, '90-99': 0.532}.
Avg inc acc top5: 0.8760999999999999.
Current acc top5: {'total': 0.833}.
Forgetting: 0.08545454545454544.
Cord metric: 0.61.
Old accuracy: 0.54, mean: 0.62.
New accuracy: 0.53, mean: 0.64.
================Task 10 Start!================
Testing on False unseen tasks (max class = 100).
Set memory of size: 1900.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 10 Training!================
The training samples number: 4400
Train on 95->100.
train task
nb 4400.
Train [11/11] | Epoch [1/160] |	nca: 34.896218955516815, flat: 10.320150949060917, pod: 89.41523283720016, loss: 134.63160347938538 
Train [11/11] | Epoch [2/160] |	nca: 31.43739914894104, flat: 13.666198790073395, pod: 106.89429235458374, loss: 151.99789118766785 
Train [11/11] | Epoch [3/160] |	nca: 22.37295627593994, flat: 10.568890362977982, pod: 94.36446642875671, loss: 127.3063132762909 
Train [11/11] | Epoch [4/160] |	nca: 16.52964749932289, flat: 8.351330369710922, pod: 85.04134774208069, loss: 109.92232608795166 
Train [11/11] | Epoch [5/160] |	nca: 14.471465766429901, flat: 7.429150238633156, pod: 79.55099678039551, loss: 101.45161414146423 
Train [11/11] | Epoch [6/160] |	nca: 12.675326138734818, flat: 6.675975263118744, pod: 75.48127400875092, loss: 94.83257555961609 
Train [11/11] | Epoch [7/160] |	nca: 11.092235550284386, flat: 6.041515290737152, pod: 72.44891083240509, loss: 89.5826621055603 
Train [11/11] | Epoch [8/160] |	nca: 10.791624292731285, flat: 5.575273647904396, pod: 69.15143918991089, loss: 85.51833724975586 
Train [11/11] | Epoch [9/160] |	nca: 9.76253591477871, flat: 5.283029183745384, pod: 67.41527342796326, loss: 82.46083879470825 
Train [11/11] | Epoch [10/160] |	nca: 9.819554075598717, flat: 5.027803152799606, pod: 67.39882171154022, loss: 82.24617838859558 
Train [11/11] | Epoch [11/160] |	nca: 10.530846610665321, flat: 5.512564435601234, pod: 68.76844239234924, loss: 84.8118531703949 
Train [11/11] | Epoch [12/160] |	nca: 10.106796368956566, flat: 5.41499225795269, pod: 67.59159970283508, loss: 83.11338877677917 
Train [11/11] | Epoch [13/160] |	nca: 10.294136226177216, flat: 5.508399575948715, pod: 69.0356330871582, loss: 84.83816933631897 
Train [11/11] | Epoch [14/160] |	nca: 10.101067706942558, flat: 5.627906799316406, pod: 68.49220788478851, loss: 84.22118186950684 
Train [11/11] | Epoch [15/160] |	nca: 9.784787937998772, flat: 5.450713366270065, pod: 68.79558789730072, loss: 84.03108882904053 
Train [11/11] | Epoch [16/160] |	nca: 9.5728168040514, flat: 5.249150902032852, pod: 69.27409565448761, loss: 84.09606385231018 
Train [11/11] | Epoch [17/160] |	nca: 8.771263092756271, flat: 4.791020169854164, pod: 65.12247705459595, loss: 78.68476057052612 
Train [11/11] | Epoch [18/160] |	nca: 9.093791872262955, flat: 5.127415135502815, pod: 65.25260758399963, loss: 79.47381472587585 
Train [11/11] | Epoch [19/160] |	nca: 9.455608159303665, flat: 5.276568055152893, pod: 66.43338620662689, loss: 81.16556239128113 
Train [11/11] | Epoch [20/160] |	nca: 9.483093306422234, flat: 5.251760706305504, pod: 66.50190496444702, loss: 81.23675847053528 
Train [11/11] | Epoch [21/160] |	nca: 9.0742467045784, flat: 5.207631602883339, pod: 65.81366395950317, loss: 80.0955423116684 
Train [11/11] | Epoch [22/160] |	nca: 8.32667861878872, flat: 4.864059537649155, pod: 64.54911303520203, loss: 77.73985123634338 
Train [11/11] | Epoch [23/160] |	nca: 8.371489882469177, flat: 4.816998407244682, pod: 63.31588304042816, loss: 76.50437152385712 
Train [11/11] | Epoch [24/160] |	nca: 7.848131716251373, flat: 4.70691829174757, pod: 63.54882884025574, loss: 76.10387849807739 
Train [11/11] | Epoch [25/160] |	nca: 8.491170316934586, flat: 4.66597793251276, pod: 63.10665547847748, loss: 76.26380348205566 
Train [11/11] | Epoch [26/160] |	nca: 8.119676649570465, flat: 4.537668384611607, pod: 60.40344941616058, loss: 73.06079459190369 
Train [11/11] | Epoch [27/160] |	nca: 7.258575811982155, flat: 4.221571214497089, pod: 59.295754194259644, loss: 70.77590143680573 
Train [11/11] | Epoch [28/160] |	nca: 7.430804714560509, flat: 4.257674038410187, pod: 61.34790313243866, loss: 73.03638124465942 
Train [11/11] | Epoch [29/160] |	nca: 8.351203680038452, flat: 4.793587610125542, pod: 65.40461683273315, loss: 78.54940807819366 
Train [11/11] | Epoch [30/160] |	nca: 7.6321728229522705, flat: 4.273303277790546, pod: 59.76877522468567, loss: 71.6742513179779 
Train [11/11] | Epoch [31/160] |	nca: 8.53361152112484, flat: 4.673464477062225, pod: 62.804749488830566, loss: 76.01182651519775 
Train [11/11] | Epoch [32/160] |	nca: 9.1968232691288, flat: 5.09459150582552, pod: 64.80159282684326, loss: 79.09300756454468 
Train [11/11] | Epoch [33/160] |	nca: 8.277445375919342, flat: 4.844618357717991, pod: 62.98478555679321, loss: 76.10684895515442 
Train [11/11] | Epoch [34/160] |	nca: 6.999530151486397, flat: 4.220619857311249, pod: 61.56007719039917, loss: 72.7802265882492 
Train [11/11] | Epoch [35/160] |	nca: 7.515318870544434, flat: 4.296272985637188, pod: 59.9241886138916, loss: 71.7357804775238 
Train [11/11] | Epoch [36/160] |	nca: 8.029229834675789, flat: 4.805661454796791, pod: 63.959829211235046, loss: 76.79472076892853 
Train [11/11] | Epoch [37/160] |	nca: 7.210452862083912, flat: 4.252310782670975, pod: 60.90792274475098, loss: 72.37068569660187 
Train [11/11] | Epoch [38/160] |	nca: 7.678612411022186, flat: 4.498604193329811, pod: 61.864256858825684, loss: 74.04147362709045 
Train [11/11] | Epoch [39/160] |	nca: 8.32460242509842, flat: 4.684209354221821, pod: 62.387640833854675, loss: 75.39645195007324 
Train [11/11] | Epoch [40/160] |	nca: 7.925561860203743, flat: 4.619522742927074, pod: 61.623178601264954, loss: 74.16826319694519 
Train [11/11] | Epoch [41/160] |	nca: 7.752988517284393, flat: 4.620986111462116, pod: 61.91496682167053, loss: 74.2889415025711 
Train [11/11] | Epoch [42/160] |	nca: 6.893663719296455, flat: 4.170949779450893, pod: 59.647008657455444, loss: 70.71162140369415 
Train [11/11] | Epoch [43/160] |	nca: 8.216899365186691, flat: 4.364579536020756, pod: 59.94292604923248, loss: 72.52440512180328 
Train [11/11] | Epoch [44/160] |	nca: 7.631692864000797, flat: 4.44003576785326, pod: 60.8691645860672, loss: 72.94089353084564 
Train [11/11] | Epoch [45/160] |	nca: 7.214169964194298, flat: 4.169377118349075, pod: 59.78029453754425, loss: 71.1638411283493 
Train [11/11] | Epoch [46/160] |	nca: 6.554834395647049, flat: 3.903803586959839, pod: 57.29421818256378, loss: 67.75285625457764 
Train [11/11] | Epoch [47/160] |	nca: 6.960602954030037, flat: 4.046883508563042, pod: 59.26692473888397, loss: 70.27441167831421 
Train [11/11] | Epoch [48/160] |	nca: 6.5793866738677025, flat: 3.6062616631388664, pod: 54.51987636089325, loss: 64.70552480220795 
Train [11/11] | Epoch [49/160] |	nca: 7.1027856990695, flat: 3.9940153658390045, pod: 57.525588154792786, loss: 68.62238919734955 
Train [11/11] | Epoch [50/160] |	nca: 6.571829356253147, flat: 3.8049620762467384, pod: 56.70384478569031, loss: 67.08063578605652 
Train [11/11] | Epoch [51/160] |	nca: 6.653325505554676, flat: 3.7321814820170403, pod: 56.2032253742218, loss: 66.58873271942139 
Train [11/11] | Epoch [52/160] |	nca: 6.4588247165083885, flat: 3.620470680296421, pod: 55.688745737075806, loss: 65.76804101467133 
Train [11/11] | Epoch [53/160] |	nca: 6.904030948877335, flat: 3.7832796573638916, pod: 55.53046679496765, loss: 66.21777749061584 
Train [11/11] | Epoch [54/160] |	nca: 7.032959029078484, flat: 3.8375443667173386, pod: 56.37689185142517, loss: 67.24739503860474 
Train [11/11] | Epoch [55/160] |	nca: 6.473284505307674, flat: 3.6772587671875954, pod: 54.27610003948212, loss: 64.42664313316345 
Train [11/11] | Epoch [56/160] |	nca: 6.972882628440857, flat: 4.008648857474327, pod: 58.21568036079407, loss: 69.19721174240112 
Train [11/11] | Epoch [57/160] |	nca: 6.378049626946449, flat: 3.5810700356960297, pod: 54.70426285266876, loss: 64.66338264942169 
Train [11/11] | Epoch [58/160] |	nca: 6.359427519142628, flat: 3.481114350259304, pod: 54.300912380218506, loss: 64.14145457744598 
Train [11/11] | Epoch [59/160] |	nca: 6.888737075030804, flat: 3.4732171669602394, pod: 53.294578075408936, loss: 63.65653204917908 
Train [11/11] | Epoch [60/160] |	nca: 6.327405400574207, flat: 3.461228981614113, pod: 52.49079179763794, loss: 62.27942621707916 
Train [11/11] | Epoch [61/160] |	nca: 6.561852976679802, flat: 3.5981985852122307, pod: 55.17389941215515, loss: 65.33395111560822 
Train [11/11] | Epoch [62/160] |	nca: 6.011470817029476, flat: 3.508307561278343, pod: 55.395638942718506, loss: 64.91541755199432 
Train [11/11] | Epoch [63/160] |	nca: 6.148020826280117, flat: 3.1751434803009033, pod: 51.97985029220581, loss: 61.3030149936676 
Train [11/11] | Epoch [64/160] |	nca: 6.106056749820709, flat: 3.378236509859562, pod: 52.74282896518707, loss: 62.22712242603302 
Train [11/11] | Epoch [65/160] |	nca: 6.090183109045029, flat: 3.216058351099491, pod: 51.43975651264191, loss: 60.7459979057312 
Train [11/11] | Epoch [66/160] |	nca: 6.4908801689744, flat: 3.292195402085781, pod: 52.310524582862854, loss: 62.093600273132324 
Train [11/11] | Epoch [67/160] |	nca: 6.7137755155563354, flat: 3.4264905899763107, pod: 52.33580267429352, loss: 62.47606885433197 
Train [11/11] | Epoch [68/160] |	nca: 5.819983944296837, flat: 3.4046348333358765, pod: 51.95466887950897, loss: 61.17928767204285 
Train [11/11] | Epoch [69/160] |	nca: 5.93905932456255, flat: 3.0501622781157494, pod: 50.10912585258484, loss: 59.098347544670105 
Train [11/11] | Epoch [70/160] |	nca: 6.2290564477443695, flat: 3.3396454006433487, pod: 53.36228954792023, loss: 62.930991411209106 
Train [11/11] | Epoch [71/160] |	nca: 6.424070045351982, flat: 3.2587483301758766, pod: 51.42855668067932, loss: 61.111374855041504 
Train [11/11] | Epoch [72/160] |	nca: 6.02854211628437, flat: 3.248166263103485, pod: 51.794116854667664, loss: 61.07082521915436 
Train [11/11] | Epoch [73/160] |	nca: 5.579360373318195, flat: 3.088812731206417, pod: 49.70624351501465, loss: 58.37441658973694 
Train [11/11] | Epoch [74/160] |	nca: 5.937949605286121, flat: 3.0759662687778473, pod: 49.93171834945679, loss: 58.94563412666321 
Train [11/11] | Epoch [75/160] |	nca: 5.876862645149231, flat: 2.858056791126728, pod: 47.9353803396225, loss: 56.67029917240143 
Train [11/11] | Epoch [76/160] |	nca: 6.26190722733736, flat: 3.129388816654682, pod: 49.848918437957764, loss: 59.240214347839355 
Train [11/11] | Epoch [77/160] |	nca: 5.953325405716896, flat: 3.2079852893948555, pod: 50.05258297920227, loss: 59.21389400959015 
Train [11/11] | Epoch [78/160] |	nca: 5.402552530169487, flat: 2.8892108872532845, pod: 48.01637399196625, loss: 56.30813729763031 
Train [11/11] | Epoch [79/160] |	nca: 6.072335831820965, flat: 2.771102376282215, pod: 46.73832905292511, loss: 55.581767439842224 
Train [11/11] | Epoch [80/160] |	nca: 5.6023270934820175, flat: 2.884769193828106, pod: 48.33113646507263, loss: 56.81823265552521 
Train [11/11] | Epoch [81/160] |	nca: 5.571470990777016, flat: 2.791770026087761, pod: 47.183812856674194, loss: 55.54705357551575 
Train [11/11] | Epoch [82/160] |	nca: 5.666919104754925, flat: 2.745428889989853, pod: 47.49210476875305, loss: 55.90445291996002 
Train [11/11] | Epoch [83/160] |	nca: 5.9222739934921265, flat: 2.925542689859867, pod: 50.11487305164337, loss: 58.96268963813782 
Train [11/11] | Epoch [84/160] |	nca: 5.40101321041584, flat: 2.7742912992835045, pod: 47.80186367034912, loss: 55.97716820240021 
Train [11/11] | Epoch [85/160] |	nca: 5.18033292144537, flat: 2.4495336301624775, pod: 43.89782202243805, loss: 51.52768838405609 
Train [11/11] | Epoch [86/160] |	nca: 5.3043704852461815, flat: 2.5223338901996613, pod: 45.00257766246796, loss: 52.82928204536438 
Train [11/11] | Epoch [87/160] |	nca: 5.425862602889538, flat: 2.635529387742281, pod: 46.98604702949524, loss: 55.047438979148865 
Train [11/11] | Epoch [88/160] |	nca: 5.409781828522682, flat: 2.68209145963192, pod: 46.767041087150574, loss: 54.858914256095886 
Train [11/11] | Epoch [89/160] |	nca: 5.445783093571663, flat: 2.4866788014769554, pod: 43.887781262397766, loss: 51.82024300098419 
Train [11/11] | Epoch [90/160] |	nca: 5.695684380829334, flat: 2.6126263327896595, pod: 45.63120985031128, loss: 53.939520955085754 
Train [11/11] | Epoch [91/160] |	nca: 5.726988077163696, flat: 2.5988789051771164, pod: 46.07464873790741, loss: 54.40051555633545 
Train [11/11] | Epoch [92/160] |	nca: 5.101956412196159, flat: 2.4394625313580036, pod: 43.821547508239746, loss: 51.36296617984772 
Train [11/11] | Epoch [93/160] |	nca: 5.416126869618893, flat: 2.404054868966341, pod: 43.572949171066284, loss: 51.39313089847565 
Train [11/11] | Epoch [94/160] |	nca: 5.472902745008469, flat: 2.4810954555869102, pod: 44.373865842819214, loss: 52.32786440849304 
Train [11/11] | Epoch [95/160] |	nca: 5.510723799467087, flat: 2.318865578621626, pod: 43.18778479099274, loss: 51.017373919487 
Train [11/11] | Epoch [96/160] |	nca: 5.244470864534378, flat: 2.277803860604763, pod: 42.142000675201416, loss: 49.66427552700043 
Train [11/11] | Epoch [97/160] |	nca: 5.135032832622528, flat: 2.3631054647266865, pod: 43.098382115364075, loss: 50.59652054309845 
Train [11/11] | Epoch [98/160] |	nca: 5.525825150310993, flat: 2.2116912826895714, pod: 41.22133255004883, loss: 48.95884883403778 
Train [11/11] | Epoch [99/160] |	nca: 5.324772842228413, flat: 2.4518948048353195, pod: 43.11385750770569, loss: 50.890525102615356 
Train [11/11] | Epoch [100/160] |	nca: 5.020786739885807, flat: 2.2269300185143948, pod: 41.02472656965256, loss: 48.27244317531586 
Train [11/11] | Epoch [101/160] |	nca: 5.011806294322014, flat: 2.194131165742874, pod: 41.196343541145325, loss: 48.402281284332275 
Train [11/11] | Epoch [102/160] |	nca: 4.860524065792561, flat: 2.090690813958645, pod: 39.67332577705383, loss: 46.62454009056091 
Train [11/11] | Epoch [103/160] |	nca: 5.100063845515251, flat: 2.1234757900238037, pod: 40.554513692855835, loss: 47.778053283691406 
Train [11/11] | Epoch [104/160] |	nca: 5.083514869213104, flat: 2.137810565531254, pod: 41.03533184528351, loss: 48.25665736198425 
Train [11/11] | Epoch [105/160] |	nca: 4.95012441277504, flat: 2.017269864678383, pod: 39.57565641403198, loss: 46.5430508852005 
Train [11/11] | Epoch [106/160] |	nca: 5.12788899242878, flat: 2.003683418035507, pod: 38.609895050525665, loss: 45.7414675951004 
Train [11/11] | Epoch [107/160] |	nca: 5.0841246992349625, flat: 2.0546864084899426, pod: 39.18005108833313, loss: 46.318862199783325 
Train [11/11] | Epoch [108/160] |	nca: 4.795898154377937, flat: 1.9787258096039295, pod: 38.303891241550446, loss: 45.07851541042328 
Train [11/11] | Epoch [109/160] |	nca: 4.904757887125015, flat: 1.9407362937927246, pod: 38.20100671052933, loss: 45.0465008020401 
Train [11/11] | Epoch [110/160] |	nca: 4.807316035032272, flat: 1.8782019466161728, pod: 37.84984165430069, loss: 44.535359501838684 
Train [11/11] | Epoch [111/160] |	nca: 4.912695489823818, flat: 1.8869036994874477, pod: 38.60128062963486, loss: 45.400879859924316 
Train [11/11] | Epoch [112/160] |	nca: 4.823325514793396, flat: 1.8534926623106003, pod: 37.40655255317688, loss: 44.08337068557739 
Train [11/11] | Epoch [113/160] |	nca: 4.809912495315075, flat: 1.8795322440564632, pod: 36.36859089136124, loss: 43.058035373687744 
Train [11/11] | Epoch [114/160] |	nca: 4.644206993281841, flat: 1.8302761018276215, pod: 37.51474827528, loss: 43.98923134803772 
Train [11/11] | Epoch [115/160] |	nca: 4.710922345519066, flat: 1.8316336907446384, pod: 36.682920038700104, loss: 43.22547626495361 
Train [11/11] | Epoch [116/160] |	nca: 4.657894566655159, flat: 1.824524562805891, pod: 36.727665185928345, loss: 43.210084438323975 
Train [11/11] | Epoch [117/160] |	nca: 4.915316879749298, flat: 1.8094949536025524, pod: 36.95790219306946, loss: 43.682713747024536 
Train [11/11] | Epoch [118/160] |	nca: 4.6779516115784645, flat: 1.64870635420084, pod: 33.94441497325897, loss: 40.27107262611389 
Train [11/11] | Epoch [119/160] |	nca: 4.628795742988586, flat: 1.6587421335279942, pod: 34.89910328388214, loss: 41.18664109706879 
Train [11/11] | Epoch [120/160] |	nca: 4.5779044553637505, flat: 1.6213065348565578, pod: 33.89131361246109, loss: 40.09052491188049 
Train [11/11] | Epoch [121/160] |	nca: 4.536906458437443, flat: 1.6207358241081238, pod: 33.67745262384415, loss: 39.8350949883461 
Train [11/11] | Epoch [122/160] |	nca: 4.586553670465946, flat: 1.5355121567845345, pod: 32.924459517002106, loss: 39.04652559757233 
Train [11/11] | Epoch [123/160] |	nca: 4.60757939517498, flat: 1.6323085501790047, pod: 34.63341772556305, loss: 40.87330573797226 
Train [11/11] | Epoch [124/160] |	nca: 4.684718519449234, flat: 1.598450768738985, pod: 33.29505580663681, loss: 39.578224658966064 
Train [11/11] | Epoch [125/160] |	nca: 4.738301746547222, flat: 1.5802228599786758, pod: 33.80212676525116, loss: 40.12065130472183 
Train [11/11] | Epoch [126/160] |	nca: 4.396141842007637, flat: 1.5124408975243568, pod: 32.20178413391113, loss: 38.110367000103 
Train [11/11] | Epoch [127/160] |	nca: 4.660873264074326, flat: 1.5356599986553192, pod: 32.416462898254395, loss: 38.61299628019333 
Train [11/11] | Epoch [128/160] |	nca: 4.567393608391285, flat: 1.5375902727246284, pod: 33.3210763335228, loss: 39.42606037855148 
Train [11/11] | Epoch [129/160] |	nca: 4.453232318162918, flat: 1.4260602965950966, pod: 31.731570959091187, loss: 37.61086344718933 
Train [11/11] | Epoch [130/160] |	nca: 4.364422798156738, flat: 1.4111947529017925, pod: 30.629856169223785, loss: 36.405473589897156 
Train [11/11] | Epoch [131/160] |	nca: 4.3872580006718636, flat: 1.3998770974576473, pod: 31.02682590484619, loss: 36.81396108865738 
Train [11/11] | Epoch [132/160] |	nca: 4.607388831675053, flat: 1.360443614423275, pod: 30.636365175247192, loss: 36.60419750213623 
Train [11/11] | Epoch [133/160] |	nca: 4.799113303422928, flat: 1.4334472641348839, pod: 31.705403566360474, loss: 37.937964141368866 
Train [11/11] | Epoch [134/160] |	nca: 4.35327435284853, flat: 1.378013612702489, pod: 29.893484354019165, loss: 35.62477254867554 
Train [11/11] | Epoch [135/160] |	nca: 4.431808039546013, flat: 1.3729449398815632, pod: 30.134040772914886, loss: 35.938793659210205 
Train [11/11] | Epoch [136/160] |	nca: 4.6011990159749985, flat: 1.3645284790545702, pod: 29.985155820846558, loss: 35.95088326931 
Train [11/11] | Epoch [137/160] |	nca: 4.591971732676029, flat: 1.284032640978694, pod: 28.601487278938293, loss: 34.47749161720276 
Train [11/11] | Epoch [138/160] |	nca: 4.182690158486366, flat: 1.3375822585076094, pod: 29.613657295703888, loss: 35.133929669857025 
Train [11/11] | Epoch [139/160] |	nca: 4.348493903875351, flat: 1.2661624979227781, pod: 28.364526987075806, loss: 33.97918349504471 
Train [11/11] | Epoch [140/160] |	nca: 4.485595770180225, flat: 1.332330932840705, pod: 29.416294276714325, loss: 35.23422110080719 
Train [11/11] | Epoch [141/160] |	nca: 4.347841247916222, flat: 1.3012291882187128, pod: 28.369381427764893, loss: 34.01845192909241 
Train [11/11] | Epoch [142/160] |	nca: 4.346252679824829, flat: 1.1960359402000904, pod: 27.42891800403595, loss: 32.97120666503906 
Train [11/11] | Epoch [143/160] |	nca: 4.450004145503044, flat: 1.2612367775291204, pod: 28.076128721237183, loss: 33.78736960887909 
Train [11/11] | Epoch [144/160] |	nca: 4.350495852530003, flat: 1.196616504341364, pod: 27.185267329216003, loss: 32.732379615306854 
Train [11/11] | Epoch [145/160] |	nca: 4.299319572746754, flat: 1.2200331464409828, pod: 27.63100355863571, loss: 33.150356113910675 
Train [11/11] | Epoch [146/160] |	nca: 4.298313856124878, flat: 1.2349680457264185, pod: 27.52964824438095, loss: 33.0629301071167 
Train [11/11] | Epoch [147/160] |	nca: 4.492431592196226, flat: 1.2091766521334648, pod: 27.358939349651337, loss: 33.06054770946503 
Train [11/11] | Epoch [148/160] |	nca: 4.436521753668785, flat: 1.1500059273093939, pod: 26.542052149772644, loss: 32.12857973575592 
Train [11/11] | Epoch [149/160] |	nca: 4.398230105638504, flat: 1.1505903098732233, pod: 26.384664058685303, loss: 31.933484375476837 
Train [11/11] | Epoch [150/160] |	nca: 4.2708751037716866, flat: 1.0948851630091667, pod: 25.65312397480011, loss: 31.018884003162384 
Train [11/11] | Epoch [151/160] |	nca: 4.435710087418556, flat: 1.2009617257863283, pod: 26.5229589343071, loss: 32.159630835056305 
Train [11/11] | Epoch [152/160] |	nca: 4.457478307187557, flat: 1.14927713945508, pod: 26.544229567050934, loss: 32.150985062122345 
Train [11/11] | Epoch [153/160] |	nca: 4.217166677117348, flat: 1.1347918659448624, pod: 25.99429601430893, loss: 31.346254408359528 
Train [11/11] | Epoch [154/160] |	nca: 4.256906047463417, flat: 1.127539962530136, pod: 26.093822717666626, loss: 31.47826862335205 
Train [11/11] | Epoch [155/160] |	nca: 4.3109365329146385, flat: 1.131246492266655, pod: 25.965179979801178, loss: 31.407363057136536 
Train [11/11] | Epoch [156/160] |	nca: 4.39147911220789, flat: 1.1185075957328081, pod: 25.5993834733963, loss: 31.109370172023773 
Train [11/11] | Epoch [157/160] |	nca: 4.504472188651562, flat: 1.1425125878304243, pod: 26.19431960582733, loss: 31.84130436182022 
Train [11/11] | Epoch [158/160] |	nca: 4.33010483533144, flat: 1.133608303964138, pod: 25.639897346496582, loss: 31.103610396385193 
Train [11/11] | Epoch [159/160] |	nca: 4.325767770409584, flat: 1.1312244050204754, pod: 25.99316829442978, loss: 31.450160324573517 
Train [11/11] | Epoch [160/160] |	nca: 4.187821142375469, flat: 1.1388856526464224, pod: 26.268528044223785, loss: 31.595234811306 
Fine-tuning
Building & updating memory.
Train [11/11] | Epoch [161/180] |	nca: 2.096118986606598, flat: 0.7275623492896557, pod: 15.18503087759018, loss: 18.00871205329895 
Train [11/11] | Epoch [162/180] |	nca: 1.3708726055920124, flat: 0.7429785914719105, pod: 15.22923630475998, loss: 17.343087673187256 
Train [11/11] | Epoch [163/180] |	nca: 1.1650510765612125, flat: 0.7549225371330976, pod: 15.377529203891754, loss: 17.29750281572342 
Train [11/11] | Epoch [164/180] |	nca: 1.0607431903481483, flat: 0.7524698786437511, pod: 15.465781688690186, loss: 17.278995156288147 
Train [11/11] | Epoch [165/180] |	nca: 1.0173562429845333, flat: 0.7332665249705315, pod: 15.048809945583344, loss: 16.799432575702667 
Train [11/11] | Epoch [166/180] |	nca: 1.0740033015608788, flat: 0.7605982385575771, pod: 15.319020926952362, loss: 17.153622567653656 
Train [11/11] | Epoch [167/180] |	nca: 0.9383446983993053, flat: 0.7494937404990196, pod: 15.183174967765808, loss: 16.871013283729553 
Train [11/11] | Epoch [168/180] |	nca: 0.9210850186645985, flat: 0.7375334948301315, pod: 15.341802597045898, loss: 17.000421047210693 
Train [11/11] | Epoch [169/180] |	nca: 0.9205065183341503, flat: 0.7337556183338165, pod: 14.973593890666962, loss: 16.62785631418228 
Train [11/11] | Epoch [170/180] |	nca: 0.869577519595623, flat: 0.7320695146918297, pod: 14.88031816482544, loss: 16.48196530342102 
Train [11/11] | Epoch [171/180] |	nca: 0.9549187086522579, flat: 0.7688889540731907, pod: 15.599259972572327, loss: 17.323067367076874 
Train [11/11] | Epoch [172/180] |	nca: 0.860114324837923, flat: 0.765188854187727, pod: 15.827089965343475, loss: 17.452393054962158 
Train [11/11] | Epoch [173/180] |	nca: 0.8469706289470196, flat: 0.7270351573824883, pod: 14.819917798042297, loss: 16.393923819065094 
Train [11/11] | Epoch [174/180] |	nca: 0.8519674781709909, flat: 0.759438119828701, pod: 15.461413741111755, loss: 17.072819530963898 
Train [11/11] | Epoch [175/180] |	nca: 0.8327225111424923, flat: 0.7347810976207256, pod: 15.034451842308044, loss: 16.60195529460907 
Train [11/11] | Epoch [176/180] |	nca: 0.8846913315355778, flat: 0.7150863930583, pod: 14.621894180774689, loss: 16.22167205810547 
Train [11/11] | Epoch [177/180] |	nca: 0.7487646676599979, flat: 0.7351688556373119, pod: 15.046206414699554, loss: 16.530139923095703 
Train [11/11] | Epoch [178/180] |	nca: 0.85846146941185, flat: 0.7621771804988384, pod: 15.338663935661316, loss: 16.95930254459381 
Train [11/11] | Epoch [179/180] |	nca: 0.7947146333754063, flat: 0.7434670552611351, pod: 15.07774031162262, loss: 16.61592197418213 
Train [11/11] | Epoch [180/180] |	nca: 0.7254271507263184, flat: 0.7424012795090675, pod: 14.989352107048035, loss: 16.457180500030518 
after task
Building & updating memory.
after task
Saving model at results\dev\podnet\202401\week_1\20240102_podnet_nme_cifar100_10steps\net_0_task_10.pth.
Saving metadata at results\dev\podnet\202401\week_1\20240102_podnet_nme_cifar100_10steps\meta_0_task_10.pkl.
Eval on 0->100.
eval task
podnet_nme_cifar100_10steps
Avg inc acc: 0.6219090909090909.
Current acc: {'total': 0.526, '00-09': 0.624, '10-19': 0.532, '20-29': 0.443, '30-39': 0.506, '40-49': 0.563, '50-59': 0.527, '60-69': 0.449, '70-79': 0.526, '80-89': 0.58, '90-99': 0.509}.
Avg inc acc top5: 0.8706363636363637.
Current acc top5: {'total': 0.816}.
Forgetting: 0.14918181818181822.
Cord metric: 0.60.
Old accuracy: 0.53, mean: 0.61.
New accuracy: 0.53, mean: 0.63.
Average Incremental Accuracy: 0.6219090909090909.
Label was: podnet_nme_cifar100_10steps
Results done on 1 seeds: avg: 62.19, last: 52.6, forgetting: 14.92
Individual results avg: [62.19]
Individual results last: [52.6]
Individual results forget: [14.92]
Command was D:/go_to_D/ML/Final/LibContinual/run_trainer.py
Time cost :  8424.555960416794
