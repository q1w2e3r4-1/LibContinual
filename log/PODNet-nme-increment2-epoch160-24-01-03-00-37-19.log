Label: podnet_nme_cifar100_25steps
orders : None
{'model': 'podnet', 'convnet': 'rebuffi', 'dropout': 0.0, 'herding': None, 'memory_size': 2000, 'temperature': 1, 'fixed_memory': True, 'dataset': 'cifar100', 'increment': 2, 'batch_size': 128, 'workers': 0, 'threads': 1, 'validation': 0.0, 'random_classes': False, 'max_task': None, 'onehot': False, 'initial_increment': 50, 'sampler': None, 'data_path': '/data/douillard/', 'lr': 0.1, 'weight_decay': 0.0005, 'scheduling': 'cosine', 'lr_decay': 0.1, 'optimizer': 'sgd', 'epochs': 160, 'device': [0], 'label': 'podnet_nme_cifar100_25steps', 'autolabel': False, 'seed': [1], 'seed_range': None, 'options': None, 'save_model': 'last', 'dump_predictions': False, 'logging': 'info', 'resume': None, 'resume_first': False, 'recompute_meta': False, 'no_benchmark': False, 'detect_anomaly': False, 'dummy': 1, 'includes': ['headers/dummy.yaml'], 'data_root': 'D:/data/douillard/cifar100/cifar100', 'save_path': '.', 'eval_type': 'nme', 'backbone': {'name': 'resnet18'}, 'classifier': {'name': 'PODNet'}, 'classifier_config': {'type': 'cosine', 'proxy_per_class': 10, 'distance': 'neg_stable_cosine_distance'}, 'postprocessor_config': {'type': 'learned_scaling', 'initial_value': 1.0}, 'pod_flat': {'scheduled_factor': 1.0}, 'pod_spatial': {'scheduled_factor': 3.0, 'collapse_channels': 'spatial'}, 'nca': {'margin': 0.6, 'scale': 1.0, 'exclude_pos_denominator': True}, 'groupwise_factors': {'old_weights': 0.0}, 'finetuning_config': {'sampling': 'undersampling', 'tuning': 'classifier', 'lr': 0.05, 'epochs': 20, 'scaling': None}, 'proxy_per_class': 1, 'weight_generation': {'type': 'imprinted', 'multi_class_diff': 'kmeans'}, 'dataset_transforms': {'color_jitter': True}}
Launching run 1/1
Set seed 1
CUDA algos are determinists but very slow!
Files already downloaded and verified
Files already downloaded and verified
Dataset iCIFAR100: class ordering: [87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39].
Downsampling type stride
Using 10 proxies per class.
Model will be save at this rythm: last.
================Task 0 Start!================
Testing on False unseen tasks (max class = 50).
Before task
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 0 Training!================
The training samples number: 25000
Train on 0->50.
train task
nb 25000.
Train [1/26] | Epoch [1/160] |	nca: 713.351884841919, loss: 713.351884841919 
Train [1/26] | Epoch [2/160] |	nca: 628.6165583133698, loss: 628.6165583133698 
Train [1/26] | Epoch [3/160] |	nca: 578.6331541538239, loss: 578.6331541538239 
Train [1/26] | Epoch [4/160] |	nca: 530.7386615276337, loss: 530.7386615276337 
Train [1/26] | Epoch [5/160] |	nca: 479.500501871109, loss: 479.500501871109 
Train [1/26] | Epoch [6/160] |	nca: 435.3442208766937, loss: 435.3442208766937 
Train [1/26] | Epoch [7/160] |	nca: 401.26643419265747, loss: 401.26643419265747 
Train [1/26] | Epoch [8/160] |	nca: 375.8024117946625, loss: 375.8024117946625 
Train [1/26] | Epoch [9/160] |	nca: 354.27213966846466, loss: 354.27213966846466 
Train [1/26] | Epoch [10/160] |	nca: 336.8898422718048, loss: 336.8898422718048 
Train [1/26] | Epoch [11/160] |	nca: 320.44804549217224, loss: 320.44804549217224 
Train [1/26] | Epoch [12/160] |	nca: 305.83493304252625, loss: 305.83493304252625 
Train [1/26] | Epoch [13/160] |	nca: 294.6501029729843, loss: 294.6501029729843 
Train [1/26] | Epoch [14/160] |	nca: 282.2315227985382, loss: 282.2315227985382 
Train [1/26] | Epoch [15/160] |	nca: 274.926295876503, loss: 274.926295876503 
Train [1/26] | Epoch [16/160] |	nca: 266.0881495475769, loss: 266.0881495475769 
Train [1/26] | Epoch [17/160] |	nca: 259.16981571912766, loss: 259.16981571912766 
Train [1/26] | Epoch [18/160] |	nca: 254.72574758529663, loss: 254.72574758529663 
Train [1/26] | Epoch [19/160] |	nca: 248.95968079566956, loss: 248.95968079566956 
Train [1/26] | Epoch [20/160] |	nca: 243.20548540353775, loss: 243.20548540353775 
Train [1/26] | Epoch [21/160] |	nca: 239.14421570301056, loss: 239.14421570301056 
Train [1/26] | Epoch [22/160] |	nca: 231.69573068618774, loss: 231.69573068618774 
Train [1/26] | Epoch [23/160] |	nca: 230.83445185422897, loss: 230.83445185422897 
Train [1/26] | Epoch [24/160] |	nca: 224.39093899726868, loss: 224.39093899726868 
Train [1/26] | Epoch [25/160] |	nca: 223.75408631563187, loss: 223.75408631563187 
Train [1/26] | Epoch [26/160] |	nca: 220.56728547811508, loss: 220.56728547811508 
Train [1/26] | Epoch [27/160] |	nca: 217.50402510166168, loss: 217.50402510166168 
Train [1/26] | Epoch [28/160] |	nca: 214.038755774498, loss: 214.038755774498 
Train [1/26] | Epoch [29/160] |	nca: 211.85838121175766, loss: 211.85838121175766 
Train [1/26] | Epoch [30/160] |	nca: 209.0929234623909, loss: 209.0929234623909 
Train [1/26] | Epoch [31/160] |	nca: 204.9795206785202, loss: 204.9795206785202 
Train [1/26] | Epoch [32/160] |	nca: 206.8096480369568, loss: 206.8096480369568 
Train [1/26] | Epoch [33/160] |	nca: 204.11862134933472, loss: 204.11862134933472 
Train [1/26] | Epoch [34/160] |	nca: 200.40510100126266, loss: 200.40510100126266 
Train [1/26] | Epoch [35/160] |	nca: 198.49675315618515, loss: 198.49675315618515 
Train [1/26] | Epoch [36/160] |	nca: 196.67374467849731, loss: 196.67374467849731 
Train [1/26] | Epoch [37/160] |	nca: 194.41171395778656, loss: 194.41171395778656 
Train [1/26] | Epoch [38/160] |	nca: 191.68678677082062, loss: 191.68678677082062 
Train [1/26] | Epoch [39/160] |	nca: 192.71395355463028, loss: 192.71395355463028 
Train [1/26] | Epoch [40/160] |	nca: 190.81061494350433, loss: 190.81061494350433 
Train [1/26] | Epoch [41/160] |	nca: 189.1604282259941, loss: 189.1604282259941 
Train [1/26] | Epoch [42/160] |	nca: 186.20672190189362, loss: 186.20672190189362 
Train [1/26] | Epoch [43/160] |	nca: 186.92845010757446, loss: 186.92845010757446 
Train [1/26] | Epoch [44/160] |	nca: 181.49871999025345, loss: 181.49871999025345 
Train [1/26] | Epoch [45/160] |	nca: 181.77578687667847, loss: 181.77578687667847 
Train [1/26] | Epoch [46/160] |	nca: 181.2056167125702, loss: 181.2056167125702 
Train [1/26] | Epoch [47/160] |	nca: 181.16315454244614, loss: 181.16315454244614 
Train [1/26] | Epoch [48/160] |	nca: 178.53908595442772, loss: 178.53908595442772 
Train [1/26] | Epoch [49/160] |	nca: 175.36670005321503, loss: 175.36670005321503 
Train [1/26] | Epoch [50/160] |	nca: 174.0537033677101, loss: 174.0537033677101 
Train [1/26] | Epoch [51/160] |	nca: 171.19595915079117, loss: 171.19595915079117 
Train [1/26] | Epoch [52/160] |	nca: 172.69342017173767, loss: 172.69342017173767 
Train [1/26] | Epoch [53/160] |	nca: 168.82566076517105, loss: 168.82566076517105 
Train [1/26] | Epoch [54/160] |	nca: 167.9023533463478, loss: 167.9023533463478 
Train [1/26] | Epoch [55/160] |	nca: 167.24974232912064, loss: 167.24974232912064 
Train [1/26] | Epoch [56/160] |	nca: 165.85436302423477, loss: 165.85436302423477 
Train [1/26] | Epoch [57/160] |	nca: 165.5051113963127, loss: 165.5051113963127 
Train [1/26] | Epoch [58/160] |	nca: 164.60466295480728, loss: 164.60466295480728 
Train [1/26] | Epoch [59/160] |	nca: 160.6327401995659, loss: 160.6327401995659 
Train [1/26] | Epoch [60/160] |	nca: 162.23893290758133, loss: 162.23893290758133 
Train [1/26] | Epoch [61/160] |	nca: 157.18538808822632, loss: 157.18538808822632 
Train [1/26] | Epoch [62/160] |	nca: 156.47558665275574, loss: 156.47558665275574 
Train [1/26] | Epoch [63/160] |	nca: 154.64292865991592, loss: 154.64292865991592 
Train [1/26] | Epoch [64/160] |	nca: 155.6742660999298, loss: 155.6742660999298 
Train [1/26] | Epoch [65/160] |	nca: 149.62107729911804, loss: 149.62107729911804 
Train [1/26] | Epoch [66/160] |	nca: 153.21525579690933, loss: 153.21525579690933 
Train [1/26] | Epoch [67/160] |	nca: 147.12253135442734, loss: 147.12253135442734 
Train [1/26] | Epoch [68/160] |	nca: 146.77572679519653, loss: 146.77572679519653 
Train [1/26] | Epoch [69/160] |	nca: 147.21071964502335, loss: 147.21071964502335 
Train [1/26] | Epoch [70/160] |	nca: 143.65168660879135, loss: 143.65168660879135 
Train [1/26] | Epoch [71/160] |	nca: 145.1826254427433, loss: 145.1826254427433 
Train [1/26] | Epoch [72/160] |	nca: 140.94649094343185, loss: 140.94649094343185 
Train [1/26] | Epoch [73/160] |	nca: 136.1016357243061, loss: 136.1016357243061 
Train [1/26] | Epoch [74/160] |	nca: 136.10018265247345, loss: 136.10018265247345 
Train [1/26] | Epoch [75/160] |	nca: 137.39468535780907, loss: 137.39468535780907 
Train [1/26] | Epoch [76/160] |	nca: 134.91196206212044, loss: 134.91196206212044 
Train [1/26] | Epoch [77/160] |	nca: 133.55890649557114, loss: 133.55890649557114 
Train [1/26] | Epoch [78/160] |	nca: 130.7498186826706, loss: 130.7498186826706 
Train [1/26] | Epoch [79/160] |	nca: 129.03210878372192, loss: 129.03210878372192 
Train [1/26] | Epoch [80/160] |	nca: 127.07343074679375, loss: 127.07343074679375 
Train [1/26] | Epoch [81/160] |	nca: 126.50620111823082, loss: 126.50620111823082 
Train [1/26] | Epoch [82/160] |	nca: 125.5404884815216, loss: 125.5404884815216 
Train [1/26] | Epoch [83/160] |	nca: 121.37834912538528, loss: 121.37834912538528 
Train [1/26] | Epoch [84/160] |	nca: 120.21516990661621, loss: 120.21516990661621 
Train [1/26] | Epoch [85/160] |	nca: 118.00880980491638, loss: 118.00880980491638 
Train [1/26] | Epoch [86/160] |	nca: 122.26294612884521, loss: 122.26294612884521 
Train [1/26] | Epoch [87/160] |	nca: 114.48825865983963, loss: 114.48825865983963 
Train [1/26] | Epoch [88/160] |	nca: 112.44232502579689, loss: 112.44232502579689 
Train [1/26] | Epoch [89/160] |	nca: 113.65240815281868, loss: 113.65240815281868 
Train [1/26] | Epoch [90/160] |	nca: 108.59288465976715, loss: 108.59288465976715 
Train [1/26] | Epoch [91/160] |	nca: 107.31433835625648, loss: 107.31433835625648 
Train [1/26] | Epoch [92/160] |	nca: 106.03064024448395, loss: 106.03064024448395 
Train [1/26] | Epoch [93/160] |	nca: 104.8274872303009, loss: 104.8274872303009 
Train [1/26] | Epoch [94/160] |	nca: 99.3927595615387, loss: 99.3927595615387 
Train [1/26] | Epoch [95/160] |	nca: 98.01765170693398, loss: 98.01765170693398 
Train [1/26] | Epoch [96/160] |	nca: 98.72503092885017, loss: 98.72503092885017 
Train [1/26] | Epoch [97/160] |	nca: 92.91395708918571, loss: 92.91395708918571 
Train [1/26] | Epoch [98/160] |	nca: 94.99951711297035, loss: 94.99951711297035 
Train [1/26] | Epoch [99/160] |	nca: 90.99919417500496, loss: 90.99919417500496 
Train [1/26] | Epoch [100/160] |	nca: 89.08166259527206, loss: 89.08166259527206 
Train [1/26] | Epoch [101/160] |	nca: 87.35527998209, loss: 87.35527998209 
Train [1/26] | Epoch [102/160] |	nca: 84.42908239364624, loss: 84.42908239364624 
Train [1/26] | Epoch [103/160] |	nca: 81.95249280333519, loss: 81.95249280333519 
Train [1/26] | Epoch [104/160] |	nca: 78.56588837504387, loss: 78.56588837504387 
Train [1/26] | Epoch [105/160] |	nca: 77.78540995717049, loss: 77.78540995717049 
Train [1/26] | Epoch [106/160] |	nca: 77.76533743739128, loss: 77.76533743739128 
Train [1/26] | Epoch [107/160] |	nca: 73.34200575947762, loss: 73.34200575947762 
Train [1/26] | Epoch [108/160] |	nca: 67.52499675750732, loss: 67.52499675750732 
Train [1/26] | Epoch [109/160] |	nca: 67.94865590333939, loss: 67.94865590333939 
Train [1/26] | Epoch [110/160] |	nca: 68.80205161869526, loss: 68.80205161869526 
Train [1/26] | Epoch [111/160] |	nca: 63.13556386530399, loss: 63.13556386530399 
Train [1/26] | Epoch [112/160] |	nca: 63.32496574521065, loss: 63.32496574521065 
Train [1/26] | Epoch [113/160] |	nca: 57.91928431391716, loss: 57.91928431391716 
Train [1/26] | Epoch [114/160] |	nca: 58.13551875948906, loss: 58.13551875948906 
Train [1/26] | Epoch [115/160] |	nca: 55.22845076024532, loss: 55.22845076024532 
Train [1/26] | Epoch [116/160] |	nca: 51.329284861683846, loss: 51.329284861683846 
Train [1/26] | Epoch [117/160] |	nca: 46.37196624279022, loss: 46.37196624279022 
Train [1/26] | Epoch [118/160] |	nca: 45.11584118753672, loss: 45.11584118753672 
Train [1/26] | Epoch [119/160] |	nca: 44.9192823022604, loss: 44.9192823022604 
Train [1/26] | Epoch [120/160] |	nca: 41.42254064977169, loss: 41.42254064977169 
Train [1/26] | Epoch [121/160] |	nca: 37.90351743251085, loss: 37.90351743251085 
Train [1/26] | Epoch [122/160] |	nca: 37.02498168870807, loss: 37.02498168870807 
Train [1/26] | Epoch [123/160] |	nca: 37.104259222745895, loss: 37.104259222745895 
Train [1/26] | Epoch [124/160] |	nca: 32.7702416703105, loss: 32.7702416703105 
Train [1/26] | Epoch [125/160] |	nca: 30.432747825980186, loss: 30.432747825980186 
Train [1/26] | Epoch [126/160] |	nca: 28.43459513783455, loss: 28.43459513783455 
Train [1/26] | Epoch [127/160] |	nca: 26.454925294965506, loss: 26.454925294965506 
Train [1/26] | Epoch [128/160] |	nca: 24.065714728087187, loss: 24.065714728087187 
Train [1/26] | Epoch [129/160] |	nca: 23.70870105549693, loss: 23.70870105549693 
Train [1/26] | Epoch [130/160] |	nca: 21.023952335119247, loss: 21.023952335119247 
Train [1/26] | Epoch [131/160] |	nca: 19.12814335897565, loss: 19.12814335897565 
Train [1/26] | Epoch [132/160] |	nca: 17.830847334116697, loss: 17.830847334116697 
Train [1/26] | Epoch [133/160] |	nca: 16.285766765475273, loss: 16.285766765475273 
Train [1/26] | Epoch [134/160] |	nca: 14.202484237030149, loss: 14.202484237030149 
Train [1/26] | Epoch [135/160] |	nca: 13.40601178072393, loss: 13.40601178072393 
Train [1/26] | Epoch [136/160] |	nca: 12.08366908878088, loss: 12.08366908878088 
Train [1/26] | Epoch [137/160] |	nca: 11.904909536242485, loss: 11.904909536242485 
Train [1/26] | Epoch [138/160] |	nca: 10.581489497795701, loss: 10.581489497795701 
Train [1/26] | Epoch [139/160] |	nca: 9.774033959954977, loss: 9.774033959954977 
Train [1/26] | Epoch [140/160] |	nca: 9.209662212058902, loss: 9.209662212058902 
Train [1/26] | Epoch [141/160] |	nca: 8.856159476563334, loss: 8.856159476563334 
Train [1/26] | Epoch [142/160] |	nca: 7.608423316851258, loss: 7.608423316851258 
Train [1/26] | Epoch [143/160] |	nca: 7.30239122081548, loss: 7.30239122081548 
Train [1/26] | Epoch [144/160] |	nca: 7.472957908175886, loss: 7.472957908175886 
Train [1/26] | Epoch [145/160] |	nca: 6.936280506663024, loss: 6.936280506663024 
Train [1/26] | Epoch [146/160] |	nca: 6.2756683034822345, loss: 6.2756683034822345 
Train [1/26] | Epoch [147/160] |	nca: 6.389433943666518, loss: 6.389433943666518 
Train [1/26] | Epoch [148/160] |	nca: 6.155689801089466, loss: 6.155689801089466 
Train [1/26] | Epoch [149/160] |	nca: 6.098772035911679, loss: 6.098772035911679 
Train [1/26] | Epoch [150/160] |	nca: 5.655912977643311, loss: 5.655912977643311 
Train [1/26] | Epoch [151/160] |	nca: 5.426882187835872, loss: 5.426882187835872 
Train [1/26] | Epoch [152/160] |	nca: 5.37652182020247, loss: 5.37652182020247 
Train [1/26] | Epoch [153/160] |	nca: 5.289367562159896, loss: 5.289367562159896 
Train [1/26] | Epoch [154/160] |	nca: 5.042710347101092, loss: 5.042710347101092 
Train [1/26] | Epoch [155/160] |	nca: 5.120712922886014, loss: 5.120712922886014 
Train [1/26] | Epoch [156/160] |	nca: 4.793882131576538, loss: 4.793882131576538 
Train [1/26] | Epoch [157/160] |	nca: 5.144459698349237, loss: 5.144459698349237 
Train [1/26] | Epoch [158/160] |	nca: 4.835824086330831, loss: 4.835824086330831 
Train [1/26] | Epoch [159/160] |	nca: 5.0165546126663685, loss: 5.0165546126663685 
Train [1/26] | Epoch [160/160] |	nca: 4.910076605156064, loss: 4.910076605156064 
after task
Building & updating memory.
after task
Eval on 0->50.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.753.
Current acc: {'total': 0.753, '00-09': 0.789, '10-19': 0.779, '20-29': 0.706, '30-39': 0.725, '40-49': 0.768}.
Avg inc acc top5: 0.938.
Current acc top5: {'total': 0.938}.
Forgetting: 0.0.
Cord metric: 0.75.
================Task 1 Start!================
Testing on False unseen tasks (max class = 52).
Set memory of size: 1000.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 1 Training!================
The training samples number: 2000
Train on 50->52.
train task
nb 2000.
Train [2/26] | Epoch [1/160] |	nca: 26.56518018245697, flat: 32.40321904420853, pod: 126.820521235466, loss: 185.788920879364 
Train [2/26] | Epoch [2/160] |	nca: 19.660813868045807, flat: 31.72241735458374, pod: 120.84817552566528, loss: 172.23140811920166 
Train [2/26] | Epoch [3/160] |	nca: 12.560270607471466, flat: 25.71723198890686, pod: 104.39133834838867, loss: 142.6688413619995 
Train [2/26] | Epoch [4/160] |	nca: 6.904472172260284, flat: 20.135973930358887, pod: 92.12181568145752, loss: 119.16226196289062 
Train [2/26] | Epoch [5/160] |	nca: 4.753653347492218, flat: 16.659054279327393, pod: 83.48682880401611, loss: 104.89953756332397 
Train [2/26] | Epoch [6/160] |	nca: 3.259609431028366, flat: 14.08638733625412, pod: 77.59819030761719, loss: 94.94418621063232 
Train [2/26] | Epoch [7/160] |	nca: 2.9339537173509598, flat: 12.244483649730682, pod: 71.36723852157593, loss: 86.54567623138428 
Train [2/26] | Epoch [8/160] |	nca: 2.205301120877266, flat: 10.752207279205322, pod: 68.09491991996765, loss: 81.05242872238159 
Train [2/26] | Epoch [9/160] |	nca: 2.0641684159636497, flat: 9.735163807868958, pod: 64.92944145202637, loss: 76.72877407073975 
Train [2/26] | Epoch [10/160] |	nca: 1.902271680533886, flat: 9.10667371749878, pod: 64.1820559501648, loss: 75.19100141525269 
Train [2/26] | Epoch [11/160] |	nca: 1.9433075934648514, flat: 8.326532363891602, pod: 59.73600387573242, loss: 70.00584411621094 
Train [2/26] | Epoch [12/160] |	nca: 1.723787821829319, flat: 7.958377122879028, pod: 58.6589720249176, loss: 68.34113788604736 
Train [2/26] | Epoch [13/160] |	nca: 1.6885031498968601, flat: 7.309232622385025, pod: 56.82079458236694, loss: 65.81853103637695 
Train [2/26] | Epoch [14/160] |	nca: 2.0617082566022873, flat: 7.15385314822197, pod: 55.83755350112915, loss: 65.05311489105225 
Train [2/26] | Epoch [15/160] |	nca: 1.832879327237606, flat: 7.2378013134002686, pod: 55.64622783660889, loss: 64.71690893173218 
Train [2/26] | Epoch [16/160] |	nca: 1.490781046450138, flat: 7.037239849567413, pod: 55.39705157279968, loss: 63.92507290840149 
Train [2/26] | Epoch [17/160] |	nca: 1.4594448432326317, flat: 6.434417277574539, pod: 53.705233335494995, loss: 61.59909510612488 
Train [2/26] | Epoch [18/160] |	nca: 1.5316043235361576, flat: 6.184744209051132, pod: 51.3292133808136, loss: 59.04556155204773 
Train [2/26] | Epoch [19/160] |	nca: 1.7134951576590538, flat: 6.109678208827972, pod: 50.20492601394653, loss: 58.028099060058594 
Train [2/26] | Epoch [20/160] |	nca: 1.531319759786129, flat: 5.820512562990189, pod: 49.436257123947144, loss: 56.78808927536011 
Train [2/26] | Epoch [21/160] |	nca: 1.3023426309227943, flat: 6.012952834367752, pod: 50.40942406654358, loss: 57.724719524383545 
Train [2/26] | Epoch [22/160] |	nca: 1.6355502158403397, flat: 6.0967718064785, pod: 52.584311723709106, loss: 60.31663370132446 
Train [2/26] | Epoch [23/160] |	nca: 1.626612015068531, flat: 6.058194041252136, pod: 50.803847312927246, loss: 58.48865342140198 
Train [2/26] | Epoch [24/160] |	nca: 1.3873370103538036, flat: 5.613476574420929, pod: 49.013911485672, loss: 56.01472496986389 
Train [2/26] | Epoch [25/160] |	nca: 1.3281494304537773, flat: 5.553291022777557, pod: 49.409942626953125, loss: 56.291383028030396 
Train [2/26] | Epoch [26/160] |	nca: 1.5734142921864986, flat: 5.719902515411377, pod: 49.403143644332886, loss: 56.696460247039795 
Train [2/26] | Epoch [27/160] |	nca: 1.6733815409243107, flat: 6.076937764883041, pod: 51.19798707962036, loss: 58.94830656051636 
Train [2/26] | Epoch [28/160] |	nca: 1.563981518149376, flat: 5.769029527902603, pod: 49.34264945983887, loss: 56.675660371780396 
Train [2/26] | Epoch [29/160] |	nca: 1.3693268522620201, flat: 5.667157560586929, pod: 49.25783085823059, loss: 56.294315576553345 
Train [2/26] | Epoch [30/160] |	nca: 1.125551175326109, flat: 5.206992447376251, pod: 46.76359987258911, loss: 53.09614324569702 
Train [2/26] | Epoch [31/160] |	nca: 1.30027636885643, flat: 5.052917271852493, pod: 47.6441330909729, loss: 53.99732685089111 
Train [2/26] | Epoch [32/160] |	nca: 1.4258448630571365, flat: 5.278363883495331, pod: 48.38393497467041, loss: 55.088144063949585 
Train [2/26] | Epoch [33/160] |	nca: 1.2076035104691982, flat: 5.111842900514603, pod: 46.11027979850769, loss: 52.42972660064697 
Train [2/26] | Epoch [34/160] |	nca: 1.2632777839899063, flat: 4.964062660932541, pod: 45.6152081489563, loss: 51.84254860877991 
Train [2/26] | Epoch [35/160] |	nca: 1.3120055869221687, flat: 4.77171590924263, pod: 44.70904803276062, loss: 50.79276943206787 
Train [2/26] | Epoch [36/160] |	nca: 1.087832361459732, flat: 4.928774356842041, pod: 45.20964813232422, loss: 51.22625541687012 
Train [2/26] | Epoch [37/160] |	nca: 1.1294224634766579, flat: 4.661292493343353, pod: 44.96117067337036, loss: 50.75188612937927 
Train [2/26] | Epoch [38/160] |	nca: 1.4108943454921246, flat: 5.0545753836631775, pod: 46.29185104370117, loss: 52.75732111930847 
Train [2/26] | Epoch [39/160] |	nca: 1.2532158643007278, flat: 4.767500728368759, pod: 44.83122706413269, loss: 50.85194396972656 
Train [2/26] | Epoch [40/160] |	nca: 1.2512699998915195, flat: 4.537742614746094, pod: 42.6486496925354, loss: 48.43766236305237 
Train [2/26] | Epoch [41/160] |	nca: 1.3400697447359562, flat: 4.561912387609482, pod: 42.867767572402954, loss: 48.769750118255615 
Train [2/26] | Epoch [42/160] |	nca: 1.0758833065629005, flat: 4.544963479042053, pod: 43.6506826877594, loss: 49.27152919769287 
Train [2/26] | Epoch [43/160] |	nca: 1.0353829711675644, flat: 4.144693523645401, pod: 42.12537097930908, loss: 47.305447578430176 
Train [2/26] | Epoch [44/160] |	nca: 1.2432349175214767, flat: 4.2032932341098785, pod: 41.080960750579834, loss: 46.527488470077515 
Train [2/26] | Epoch [45/160] |	nca: 1.1655203104019165, flat: 4.186330065131187, pod: 42.210100173950195, loss: 47.56195092201233 
Train [2/26] | Epoch [46/160] |	nca: 0.9877431876957417, flat: 4.256416663527489, pod: 42.7262761592865, loss: 47.97043561935425 
Train [2/26] | Epoch [47/160] |	nca: 1.1098623499274254, flat: 4.0364218056201935, pod: 40.909674406051636, loss: 46.05595874786377 
Train [2/26] | Epoch [48/160] |	nca: 1.2591063231229782, flat: 4.162035569548607, pod: 41.93429470062256, loss: 47.35543632507324 
Train [2/26] | Epoch [49/160] |	nca: 1.5847628936171532, flat: 4.4261122941970825, pod: 43.25165128707886, loss: 49.262526512145996 
Train [2/26] | Epoch [50/160] |	nca: 1.3960936143994331, flat: 4.766637474298477, pod: 45.2247576713562, loss: 51.38748860359192 
Train [2/26] | Epoch [51/160] |	nca: 1.2843017764389515, flat: 4.506767109036446, pod: 42.52535557746887, loss: 48.31642460823059 
Train [2/26] | Epoch [52/160] |	nca: 1.203656978905201, flat: 4.206624001264572, pod: 41.65359020233154, loss: 47.06387138366699 
Train [2/26] | Epoch [53/160] |	nca: 1.0842120163142681, flat: 4.086645767092705, pod: 41.1794867515564, loss: 46.35034465789795 
Train [2/26] | Epoch [54/160] |	nca: 1.1480713300406933, flat: 4.136840522289276, pod: 41.17986512184143, loss: 46.46477651596069 
Train [2/26] | Epoch [55/160] |	nca: 1.1801754124462605, flat: 4.274726301431656, pod: 41.29394268989563, loss: 46.74884390830994 
Train [2/26] | Epoch [56/160] |	nca: 1.2667379658669233, flat: 4.023257717490196, pod: 40.98541593551636, loss: 46.27541184425354 
Train [2/26] | Epoch [57/160] |	nca: 1.103964351117611, flat: 3.991672918200493, pod: 40.24307608604431, loss: 45.33871364593506 
Train [2/26] | Epoch [58/160] |	nca: 1.1764975786209106, flat: 3.7608144879341125, pod: 38.75987911224365, loss: 43.69719099998474 
Train [2/26] | Epoch [59/160] |	nca: 1.0776076093316078, flat: 3.9016305059194565, pod: 39.93527340888977, loss: 44.91451168060303 
Train [2/26] | Epoch [60/160] |	nca: 1.3186615705490112, flat: 4.057329565286636, pod: 41.06451869010925, loss: 46.44050979614258 
Train [2/26] | Epoch [61/160] |	nca: 1.056857530027628, flat: 3.866906091570854, pod: 38.97587180137634, loss: 43.899635314941406 
Train [2/26] | Epoch [62/160] |	nca: 0.9866289123892784, flat: 3.8912866562604904, pod: 39.53368139266968, loss: 44.41159701347351 
Train [2/26] | Epoch [63/160] |	nca: 1.1900344286113977, flat: 3.583173155784607, pod: 37.6904034614563, loss: 42.463611125946045 
Train [2/26] | Epoch [64/160] |	nca: 1.1121667474508286, flat: 3.745212972164154, pod: 38.50327134132385, loss: 43.36065125465393 
Train [2/26] | Epoch [65/160] |	nca: 0.9286884851753712, flat: 3.5811511278152466, pod: 38.384016036987305, loss: 42.893855571746826 
Train [2/26] | Epoch [66/160] |	nca: 1.0181243531405926, flat: 3.49200601875782, pod: 37.809807777404785, loss: 42.31993865966797 
Train [2/26] | Epoch [67/160] |	nca: 1.04104895144701, flat: 3.469438821077347, pod: 37.58426213264465, loss: 42.09475040435791 
Train [2/26] | Epoch [68/160] |	nca: 1.0189349167048931, flat: 3.58757521212101, pod: 37.77750253677368, loss: 42.38401246070862 
Train [2/26] | Epoch [69/160] |	nca: 1.2355936840176582, flat: 3.608289882540703, pod: 39.48695468902588, loss: 44.330838203430176 
Train [2/26] | Epoch [70/160] |	nca: 1.036401566118002, flat: 3.6063520461320877, pod: 39.44362664222717, loss: 44.08638000488281 
Train [2/26] | Epoch [71/160] |	nca: 1.1174117363989353, flat: 3.6278809905052185, pod: 38.78331279754639, loss: 43.528605937957764 
Train [2/26] | Epoch [72/160] |	nca: 1.0111547745764256, flat: 3.3422177731990814, pod: 37.215736627578735, loss: 41.56910967826843 
Train [2/26] | Epoch [73/160] |	nca: 0.9797949753701687, flat: 3.307333469390869, pod: 38.07494044303894, loss: 42.36206912994385 
Train [2/26] | Epoch [74/160] |	nca: 1.04689122736454, flat: 3.2916448563337326, pod: 36.871164083480835, loss: 41.209699869155884 
Train [2/26] | Epoch [75/160] |	nca: 1.0857803486287594, flat: 3.210618630051613, pod: 36.504610776901245, loss: 40.8010094165802 
Train [2/26] | Epoch [76/160] |	nca: 0.9383594952523708, flat: 3.192715957760811, pod: 35.22204542160034, loss: 39.35312104225159 
Train [2/26] | Epoch [77/160] |	nca: 1.1040934659540653, flat: 3.1677808612585068, pod: 36.851940393447876, loss: 41.123815059661865 
Train [2/26] | Epoch [78/160] |	nca: 1.0057650059461594, flat: 3.1986126452684402, pod: 36.72777485847473, loss: 40.93215250968933 
Train [2/26] | Epoch [79/160] |	nca: 1.2571972124278545, flat: 3.3437518924474716, pod: 36.63801622390747, loss: 41.23896551132202 
Train [2/26] | Epoch [80/160] |	nca: 1.0221490319818258, flat: 3.3386058658361435, pod: 37.8328173160553, loss: 42.19357252120972 
Train [2/26] | Epoch [81/160] |	nca: 1.019707128405571, flat: 3.0830973237752914, pod: 34.93681812286377, loss: 39.03962230682373 
Train [2/26] | Epoch [82/160] |	nca: 1.2262261919677258, flat: 3.157614767551422, pod: 35.63307249546051, loss: 40.016913652420044 
Train [2/26] | Epoch [83/160] |	nca: 0.9316172488033772, flat: 2.986405700445175, pod: 34.16591536998749, loss: 38.083938121795654 
Train [2/26] | Epoch [84/160] |	nca: 1.1482549216598272, flat: 3.02716064453125, pod: 34.487038373947144, loss: 38.66245365142822 
Train [2/26] | Epoch [85/160] |	nca: 1.0072753559798002, flat: 3.05705164372921, pod: 34.82927370071411, loss: 38.89360046386719 
Train [2/26] | Epoch [86/160] |	nca: 1.1108685713261366, flat: 3.0974450558423996, pod: 34.28262257575989, loss: 38.490936279296875 
Train [2/26] | Epoch [87/160] |	nca: 0.9338835440576077, flat: 3.0160967260599136, pod: 34.58942925930023, loss: 38.53940939903259 
Train [2/26] | Epoch [88/160] |	nca: 0.8694464974105358, flat: 2.954661548137665, pod: 34.03056597709656, loss: 37.854674100875854 
Train [2/26] | Epoch [89/160] |	nca: 0.9311026055365801, flat: 2.7701483368873596, pod: 35.57958269119263, loss: 39.28083348274231 
Train [2/26] | Epoch [90/160] |	nca: 0.9055980481207371, flat: 3.045374408364296, pod: 35.35465145111084, loss: 39.30562353134155 
Train [2/26] | Epoch [91/160] |	nca: 0.9908271059393883, flat: 2.859071359038353, pod: 33.813966512680054, loss: 37.663864850997925 
Train [2/26] | Epoch [92/160] |	nca: 1.0447540655732155, flat: 2.675654023885727, pod: 33.02380895614624, loss: 36.74421715736389 
Train [2/26] | Epoch [93/160] |	nca: 0.9306379463523626, flat: 2.8663038462400436, pod: 34.7624785900116, loss: 38.559420347213745 
Train [2/26] | Epoch [94/160] |	nca: 1.013500016182661, flat: 2.7181315273046494, pod: 32.7368106842041, loss: 36.46844220161438 
Train [2/26] | Epoch [95/160] |	nca: 1.072521798312664, flat: 2.5686375200748444, pod: 31.712080717086792, loss: 35.35323977470398 
Train [2/26] | Epoch [96/160] |	nca: 0.9379784483462572, flat: 2.6393188685178757, pod: 31.504769682884216, loss: 35.082066774368286 
Train [2/26] | Epoch [97/160] |	nca: 0.9145119935274124, flat: 2.5961580872535706, pod: 31.852718114852905, loss: 35.36338829994202 
Train [2/26] | Epoch [98/160] |	nca: 0.9856145940721035, flat: 2.5743329524993896, pod: 31.440494298934937, loss: 35.000441551208496 
Train [2/26] | Epoch [99/160] |	nca: 0.9816068857908249, flat: 2.596608489751816, pod: 32.12866234779358, loss: 35.70687794685364 
Train [2/26] | Epoch [100/160] |	nca: 0.8938098251819611, flat: 2.51776160299778, pod: 32.004000782966614, loss: 35.41557228565216 
Train [2/26] | Epoch [101/160] |	nca: 0.9267784301191568, flat: 2.556767150759697, pod: 30.98372721672058, loss: 34.46727240085602 
Train [2/26] | Epoch [102/160] |	nca: 0.8854631893336773, flat: 2.494655132293701, pod: 31.024797916412354, loss: 34.40491580963135 
Train [2/26] | Epoch [103/160] |	nca: 0.9264627508819103, flat: 2.361746683716774, pod: 29.96455466747284, loss: 33.25276434421539 
Train [2/26] | Epoch [104/160] |	nca: 0.9934290200471878, flat: 2.4163730517029762, pod: 30.876717567443848, loss: 34.28651964664459 
Train [2/26] | Epoch [105/160] |	nca: 0.8838994055986404, flat: 2.357290104031563, pod: 30.2427339553833, loss: 33.48392391204834 
Train [2/26] | Epoch [106/160] |	nca: 0.9887633807957172, flat: 2.2323821038007736, pod: 28.73424470424652, loss: 31.955390214920044 
Train [2/26] | Epoch [107/160] |	nca: 0.9685406368225813, flat: 2.22187303006649, pod: 28.636970281600952, loss: 31.827383756637573 
Train [2/26] | Epoch [108/160] |	nca: 0.8356386870145798, flat: 2.283879205584526, pod: 29.771880745887756, loss: 32.891398668289185 
Train [2/26] | Epoch [109/160] |	nca: 0.9706763923168182, flat: 2.2488115429878235, pod: 29.758487701416016, loss: 32.977975606918335 
Train [2/26] | Epoch [110/160] |	nca: 1.0052857492119074, flat: 2.3527379482984543, pod: 29.962759852409363, loss: 33.320783495903015 
Train [2/26] | Epoch [111/160] |	nca: 0.8476916365325451, flat: 2.2532380670309067, pod: 28.80661392211914, loss: 31.907544016838074 
Train [2/26] | Epoch [112/160] |	nca: 1.0148849561810493, flat: 2.187425270676613, pod: 29.17326807975769, loss: 32.37557804584503 
Train [2/26] | Epoch [113/160] |	nca: 0.8476204928010702, flat: 2.2158345133066177, pod: 28.627692580223083, loss: 31.691147804260254 
Train [2/26] | Epoch [114/160] |	nca: 0.9211141876876354, flat: 2.1228113621473312, pod: 27.523240327835083, loss: 30.56716549396515 
Train [2/26] | Epoch [115/160] |	nca: 0.8906868547201157, flat: 2.0018168091773987, pod: 27.17857277393341, loss: 30.07107639312744 
Train [2/26] | Epoch [116/160] |	nca: 0.8574482537806034, flat: 2.1327586248517036, pod: 27.47906506061554, loss: 30.469271421432495 
Train [2/26] | Epoch [117/160] |	nca: 0.9146709516644478, flat: 2.0449594855308533, pod: 27.44768786430359, loss: 30.407318353652954 
Train [2/26] | Epoch [118/160] |	nca: 0.8731968402862549, flat: 2.0425078719854355, pod: 26.72869384288788, loss: 29.64439880847931 
Train [2/26] | Epoch [119/160] |	nca: 0.9854460088536143, flat: 2.0148933231830597, pod: 26.72039234638214, loss: 29.72073185443878 
Train [2/26] | Epoch [120/160] |	nca: 0.8130452558398247, flat: 1.899038091301918, pod: 26.382246732711792, loss: 29.094329953193665 
Train [2/26] | Epoch [121/160] |	nca: 0.9580805283039808, flat: 1.889869511127472, pod: 26.508161544799805, loss: 29.35611116886139 
Train [2/26] | Epoch [122/160] |	nca: 0.8818856161087751, flat: 1.9686490595340729, pod: 26.805948972702026, loss: 29.65648376941681 
Train [2/26] | Epoch [123/160] |	nca: 1.0065630842000246, flat: 1.9297510981559753, pod: 27.447049736976624, loss: 30.38336420059204 
Train [2/26] | Epoch [124/160] |	nca: 0.8232316449284554, flat: 1.9173340052366257, pod: 25.54177176952362, loss: 28.282337427139282 
Train [2/26] | Epoch [125/160] |	nca: 0.9780907295644283, flat: 1.9947554841637611, pod: 26.552464485168457, loss: 29.52531087398529 
Train [2/26] | Epoch [126/160] |	nca: 0.838437981903553, flat: 1.9274815618991852, pod: 26.78127884864807, loss: 29.54719829559326 
Train [2/26] | Epoch [127/160] |	nca: 0.8567463345825672, flat: 1.782410942018032, pod: 25.00649392604828, loss: 27.64565122127533 
Train [2/26] | Epoch [128/160] |	nca: 0.8038930054754019, flat: 1.8536527156829834, pod: 25.747352719306946, loss: 28.404898405075073 
Train [2/26] | Epoch [129/160] |	nca: 0.9673165157437325, flat: 1.7955007702112198, pod: 25.44905960559845, loss: 28.21187663078308 
Train [2/26] | Epoch [130/160] |	nca: 0.8768341317772865, flat: 1.8089133873581886, pod: 24.839706420898438, loss: 27.52545392513275 
Train [2/26] | Epoch [131/160] |	nca: 0.9789336919784546, flat: 1.866140402853489, pod: 25.384962558746338, loss: 28.230036735534668 
Train [2/26] | Epoch [132/160] |	nca: 0.9404697120189667, flat: 1.8467778861522675, pod: 24.792747616767883, loss: 27.579995155334473 
Train [2/26] | Epoch [133/160] |	nca: 0.9154275842010975, flat: 1.8307543024420738, pod: 24.286952137947083, loss: 27.03313422203064 
Train [2/26] | Epoch [134/160] |	nca: 0.9041707422584295, flat: 1.7726522162556648, pod: 24.343560576438904, loss: 27.020383596420288 
Train [2/26] | Epoch [135/160] |	nca: 0.9106748271733522, flat: 1.8336165249347687, pod: 24.84161138534546, loss: 27.58590292930603 
Train [2/26] | Epoch [136/160] |	nca: 0.9122894778847694, flat: 1.76096573472023, pod: 24.367198824882507, loss: 27.040453910827637 
Train [2/26] | Epoch [137/160] |	nca: 0.8060202971100807, flat: 1.7430551275610924, pod: 23.843701243400574, loss: 26.392776608467102 
Train [2/26] | Epoch [138/160] |	nca: 0.7964970991015434, flat: 1.7299469411373138, pod: 23.772180318832397, loss: 26.298624396324158 
Train [2/26] | Epoch [139/160] |	nca: 0.9344210736453533, flat: 1.685795322060585, pod: 24.007100224494934, loss: 26.62731659412384 
Train [2/26] | Epoch [140/160] |	nca: 0.8510982543230057, flat: 1.6753856390714645, pod: 23.32334017753601, loss: 25.849823832511902 
Train [2/26] | Epoch [141/160] |	nca: 0.9297229871153831, flat: 1.6277528032660484, pod: 22.959394574165344, loss: 25.516870379447937 
Train [2/26] | Epoch [142/160] |	nca: 0.8738970402628183, flat: 1.6035686954855919, pod: 22.761618733406067, loss: 25.239084601402283 
Train [2/26] | Epoch [143/160] |	nca: 0.8812222983688116, flat: 1.581764593720436, pod: 22.567296862602234, loss: 25.030283451080322 
Train [2/26] | Epoch [144/160] |	nca: 0.8760838881134987, flat: 1.6065670251846313, pod: 23.247389435768127, loss: 25.730040550231934 
Train [2/26] | Epoch [145/160] |	nca: 0.788317309692502, flat: 1.5768108442425728, pod: 22.534857630729675, loss: 24.899985909461975 
Train [2/26] | Epoch [146/160] |	nca: 0.941936019808054, flat: 1.6251668259501457, pod: 23.04758334159851, loss: 25.614685893058777 
Train [2/26] | Epoch [147/160] |	nca: 0.9094597771763802, flat: 1.576991692185402, pod: 22.561905026435852, loss: 25.048356533050537 
Train [2/26] | Epoch [148/160] |	nca: 0.8517516814172268, flat: 1.5707539469003677, pod: 22.76320171356201, loss: 25.185707330703735 
Train [2/26] | Epoch [149/160] |	nca: 0.9172130562365055, flat: 1.56445874273777, pod: 22.521134614944458, loss: 25.002806663513184 
Train [2/26] | Epoch [150/160] |	nca: 0.8793812356889248, flat: 1.5988679081201553, pod: 23.14233362674713, loss: 25.620582699775696 
Train [2/26] | Epoch [151/160] |	nca: 0.8613719344139099, flat: 1.596407100558281, pod: 22.659486293792725, loss: 25.117265105247498 
Train [2/26] | Epoch [152/160] |	nca: 0.9874187707901001, flat: 1.6489756926894188, pod: 23.46384108066559, loss: 26.10023546218872 
Train [2/26] | Epoch [153/160] |	nca: 0.8769074641168118, flat: 1.5495902374386787, pod: 22.557963490486145, loss: 24.984460949897766 
Train [2/26] | Epoch [154/160] |	nca: 0.8153637647628784, flat: 1.549332283437252, pod: 21.580649971961975, loss: 23.945345878601074 
Train [2/26] | Epoch [155/160] |	nca: 0.9175062850117683, flat: 1.544013261795044, pod: 21.542235255241394, loss: 24.00375497341156 
Train [2/26] | Epoch [156/160] |	nca: 0.8438900709152222, flat: 1.5982067361474037, pod: 22.14728558063507, loss: 24.58938241004944 
Train [2/26] | Epoch [157/160] |	nca: 0.8299236223101616, flat: 1.5904997289180756, pod: 21.900113940238953, loss: 24.320537328720093 
Train [2/26] | Epoch [158/160] |	nca: 0.8645826503634453, flat: 1.5670290514826775, pod: 22.26946985721588, loss: 24.7010817527771 
Train [2/26] | Epoch [159/160] |	nca: 0.9035343639552593, flat: 1.6352584287524223, pod: 22.302311420440674, loss: 24.84110391139984 
Train [2/26] | Epoch [160/160] |	nca: 0.9090749900788069, flat: 1.5939746052026749, pod: 22.09445869922638, loss: 24.597508549690247 
Fine-tuning
Building & updating memory.
Train [2/26] | Epoch [161/180] |	nca: 1.28769888356328, flat: 1.7864693403244019, pod: 17.518784284591675, loss: 20.592952489852905 
Train [2/26] | Epoch [162/180] |	nca: 1.4462732337415218, flat: 2.064653694629669, pod: 17.772698521614075, loss: 21.28362536430359 
Train [2/26] | Epoch [163/180] |	nca: 0.6059578992426395, flat: 1.7719973772764206, pod: 17.12061846256256, loss: 19.498573422431946 
Train [2/26] | Epoch [164/180] |	nca: 0.5019416846334934, flat: 1.7704102396965027, pod: 16.63147270679474, loss: 18.9038245677948 
Train [2/26] | Epoch [165/180] |	nca: 0.5340922363102436, flat: 1.6616031527519226, pod: 16.61177706718445, loss: 18.807472467422485 
Train [2/26] | Epoch [166/180] |	nca: 0.35157970152795315, flat: 1.6056880205869675, pod: 16.192954063415527, loss: 18.150221705436707 
Train [2/26] | Epoch [167/180] |	nca: 0.6173893846571445, flat: 1.7481518536806107, pod: 16.692637085914612, loss: 19.058178782463074 
Train [2/26] | Epoch [168/180] |	nca: 0.41209373250603676, flat: 1.8108279556035995, pod: 16.755478858947754, loss: 18.978400707244873 
Train [2/26] | Epoch [169/180] |	nca: 0.2921044956892729, flat: 1.6833361238241196, pod: 16.354239583015442, loss: 18.32968008518219 
Train [2/26] | Epoch [170/180] |	nca: 0.44007475674152374, flat: 1.7266544550657272, pod: 16.45529878139496, loss: 18.62202799320221 
Train [2/26] | Epoch [171/180] |	nca: 0.35314816422760487, flat: 1.661680519580841, pod: 16.60787808895111, loss: 18.62270677089691 
Train [2/26] | Epoch [172/180] |	nca: 0.22666621021926403, flat: 1.763209655880928, pod: 16.698863863945007, loss: 18.68873965740204 
Train [2/26] | Epoch [173/180] |	nca: 0.22249499708414078, flat: 1.6948464214801788, pod: 16.56166648864746, loss: 18.479007720947266 
Train [2/26] | Epoch [174/180] |	nca: 0.24613558314740658, flat: 1.714266374707222, pod: 17.17000949382782, loss: 19.130411386489868 
Train [2/26] | Epoch [175/180] |	nca: 0.3062102338299155, flat: 1.789070725440979, pod: 17.399290442466736, loss: 19.494571447372437 
Train [2/26] | Epoch [176/180] |	nca: 0.29638807475566864, flat: 1.8600617051124573, pod: 17.29339873790741, loss: 19.449848890304565 
Train [2/26] | Epoch [177/180] |	nca: 0.17335594817996025, flat: 1.7334544360637665, pod: 16.975570917129517, loss: 18.882381558418274 
Train [2/26] | Epoch [178/180] |	nca: 0.2071317145600915, flat: 1.7604969590902328, pod: 17.32813858985901, loss: 19.295767188072205 
Train [2/26] | Epoch [179/180] |	nca: 0.27307715453207493, flat: 1.7625055760145187, pod: 17.075791239738464, loss: 19.111374020576477 
Train [2/26] | Epoch [180/180] |	nca: 0.27078161761164665, flat: 1.819031298160553, pod: 16.77206015586853, loss: 18.861872911453247 
after task
Building & updating memory.
after task
Eval on 0->52.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.746.
Current acc: {'total': 0.739, '00-09': 0.788, '10-19': 0.767, '20-29': 0.692, '30-39': 0.7, '40-49': 0.754, '50-59': 0.71}.
Avg inc acc top5: 0.935.
Current acc top5: {'total': 0.932}.
Forgetting: -0.09199999999999998.
Cord metric: 0.75.
Old accuracy: 0.74, mean: 0.74.
New accuracy: 0.71, mean: 0.71.
================Task 2 Start!================
Testing on False unseen tasks (max class = 54).
Set memory of size: 1040.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 2 Training!================
The training samples number: 2040
Train on 52->54.
train task
nb 2040.
Train [3/26] | Epoch [1/160] |	nca: 7.2865269780159, flat: 5.630908764898777, pod: 47.3690881729126, loss: 60.286524295806885 
Train [3/26] | Epoch [2/160] |	nca: 4.446696877479553, flat: 6.907007157802582, pod: 52.627923250198364, loss: 63.981626749038696 
Train [3/26] | Epoch [3/160] |	nca: 3.2969628646969795, flat: 6.672761768102646, pod: 52.613569021224976, loss: 62.58329367637634 
Train [3/26] | Epoch [4/160] |	nca: 2.3950974866747856, flat: 5.524424195289612, pod: 49.36976504325867, loss: 57.289286851882935 
Train [3/26] | Epoch [5/160] |	nca: 2.423405922949314, flat: 4.783017635345459, pod: 46.16685700416565, loss: 53.37328100204468 
Train [3/26] | Epoch [6/160] |	nca: 2.1800417378544807, flat: 4.67633792757988, pod: 46.28550934791565, loss: 53.141889333724976 
Train [3/26] | Epoch [7/160] |	nca: 1.863684982061386, flat: 4.341620594263077, pod: 45.99407148361206, loss: 52.199376821517944 
Train [3/26] | Epoch [8/160] |	nca: 1.7627801597118378, flat: 3.995682790875435, pod: 41.93882870674133, loss: 47.69729161262512 
Train [3/26] | Epoch [9/160] |	nca: 1.8876022174954414, flat: 3.6835991591215134, pod: 40.40745258331299, loss: 45.97865390777588 
Train [3/26] | Epoch [10/160] |	nca: 1.953594408929348, flat: 4.000595331192017, pod: 42.698811531066895, loss: 48.65300107002258 
Train [3/26] | Epoch [11/160] |	nca: 2.100952796638012, flat: 3.8644352108240128, pod: 41.57526755332947, loss: 47.540656089782715 
Train [3/26] | Epoch [12/160] |	nca: 1.7975250594317913, flat: 3.8416854441165924, pod: 42.14565944671631, loss: 47.78487014770508 
Train [3/26] | Epoch [13/160] |	nca: 1.6536455005407333, flat: 3.7818759828805923, pod: 40.64348769187927, loss: 46.07900905609131 
Train [3/26] | Epoch [14/160] |	nca: 1.7841325849294662, flat: 3.788142442703247, pod: 39.844929933547974, loss: 45.41720533370972 
Train [3/26] | Epoch [15/160] |	nca: 1.739247389137745, flat: 3.522009551525116, pod: 38.830432653427124, loss: 44.091689348220825 
Train [3/26] | Epoch [16/160] |	nca: 1.7613659650087357, flat: 3.6033399552106857, pod: 39.68991279602051, loss: 45.05461883544922 
Train [3/26] | Epoch [17/160] |	nca: 1.702228620648384, flat: 3.7872558683156967, pod: 41.04220223426819, loss: 46.53168725967407 
Train [3/26] | Epoch [18/160] |	nca: 1.9334669038653374, flat: 3.741928443312645, pod: 40.701904296875, loss: 46.37730002403259 
Train [3/26] | Epoch [19/160] |	nca: 1.5359327346086502, flat: 3.7378042936325073, pod: 41.30740451812744, loss: 46.581141233444214 
Train [3/26] | Epoch [20/160] |	nca: 1.591490875929594, flat: 3.394940674304962, pod: 38.260501861572266, loss: 43.24693322181702 
Train [3/26] | Epoch [21/160] |	nca: 1.4980124346911907, flat: 3.344107508659363, pod: 38.92584776878357, loss: 43.76796793937683 
Train [3/26] | Epoch [22/160] |	nca: 1.688406340777874, flat: 3.226656422019005, pod: 37.204795837402344, loss: 42.119858503341675 
Train [3/26] | Epoch [23/160] |	nca: 1.5973727069795132, flat: 3.2566384971141815, pod: 37.84086608886719, loss: 42.69487714767456 
Train [3/26] | Epoch [24/160] |	nca: 1.7321243360638618, flat: 3.40636046230793, pod: 38.88611435890198, loss: 44.024598598480225 
Train [3/26] | Epoch [25/160] |	nca: 1.5156701281666756, flat: 3.322925493121147, pod: 37.84923219680786, loss: 42.687827348709106 
Train [3/26] | Epoch [26/160] |	nca: 1.8204671554267406, flat: 3.6338668018579483, pod: 40.358036518096924, loss: 45.81237006187439 
Train [3/26] | Epoch [27/160] |	nca: 1.4912703670561314, flat: 3.6526756286621094, pod: 39.778656005859375, loss: 44.92260193824768 
Train [3/26] | Epoch [28/160] |	nca: 1.415896151214838, flat: 3.223136156797409, pod: 37.5497944355011, loss: 42.18882656097412 
Train [3/26] | Epoch [29/160] |	nca: 1.4731552228331566, flat: 3.0695393830537796, pod: 36.47576904296875, loss: 41.01846385002136 
Train [3/26] | Epoch [30/160] |	nca: 1.566880438476801, flat: 3.139154613018036, pod: 36.10755753517151, loss: 40.8135929107666 
Train [3/26] | Epoch [31/160] |	nca: 1.6281505450606346, flat: 3.1252454817295074, pod: 36.432844161987305, loss: 41.18624019622803 
Train [3/26] | Epoch [32/160] |	nca: 1.5489566624164581, flat: 3.135801523923874, pod: 36.96529698371887, loss: 41.650054693222046 
Train [3/26] | Epoch [33/160] |	nca: 1.5388695001602173, flat: 3.251082718372345, pod: 38.50041675567627, loss: 43.2903687953949 
Train [3/26] | Epoch [34/160] |	nca: 1.6127061173319817, flat: 3.1612431406974792, pod: 36.84617352485657, loss: 41.62012267112732 
Train [3/26] | Epoch [35/160] |	nca: 1.3850105181336403, flat: 3.300851196050644, pod: 38.13179349899292, loss: 42.81765556335449 
Train [3/26] | Epoch [36/160] |	nca: 1.6170234978199005, flat: 3.013508588075638, pod: 35.140379190444946, loss: 39.77091097831726 
Train [3/26] | Epoch [37/160] |	nca: 1.5482523515820503, flat: 3.0184481739997864, pod: 35.90078544616699, loss: 40.467485427856445 
Train [3/26] | Epoch [38/160] |	nca: 1.416578996926546, flat: 3.1319080144166946, pod: 36.42704892158508, loss: 40.97553586959839 
Train [3/26] | Epoch [39/160] |	nca: 1.3997567258775234, flat: 3.171829715371132, pod: 37.709179162979126, loss: 42.280765533447266 
Train [3/26] | Epoch [40/160] |	nca: 1.5283910818397999, flat: 2.9812384843826294, pod: 36.16420245170593, loss: 40.673832178115845 
Train [3/26] | Epoch [41/160] |	nca: 1.4088066406548023, flat: 2.922155499458313, pod: 35.30612015724182, loss: 39.63708257675171 
Train [3/26] | Epoch [42/160] |	nca: 1.4087925106287003, flat: 2.9959176927804947, pod: 37.563681840896606, loss: 41.96839189529419 
Train [3/26] | Epoch [43/160] |	nca: 1.4343732297420502, flat: 3.0560728013515472, pod: 36.30113387107849, loss: 40.79158020019531 
Train [3/26] | Epoch [44/160] |	nca: 1.6800311170518398, flat: 3.1594942212104797, pod: 38.77837371826172, loss: 43.61789894104004 
Train [3/26] | Epoch [45/160] |	nca: 1.3833150826394558, flat: 3.08216355741024, pod: 36.73462462425232, loss: 41.20010280609131 
Train [3/26] | Epoch [46/160] |	nca: 1.527410827577114, flat: 2.9584556818008423, pod: 36.92951583862305, loss: 41.41538190841675 
Train [3/26] | Epoch [47/160] |	nca: 1.3378243148326874, flat: 2.9153301417827606, pod: 35.8186252117157, loss: 40.07177925109863 
Train [3/26] | Epoch [48/160] |	nca: 1.3673759512603283, flat: 2.86944280564785, pod: 36.04904246330261, loss: 40.28586173057556 
Train [3/26] | Epoch [49/160] |	nca: 1.310766763985157, flat: 2.8582894802093506, pod: 36.94191575050354, loss: 41.1109721660614 
Train [3/26] | Epoch [50/160] |	nca: 1.3300497829914093, flat: 2.910231500864029, pod: 35.754947900772095, loss: 39.9952290058136 
Train [3/26] | Epoch [51/160] |	nca: 1.5337732918560505, flat: 2.8954162150621414, pod: 34.835551619529724, loss: 39.26474094390869 
Train [3/26] | Epoch [52/160] |	nca: 1.586920440196991, flat: 2.846458852291107, pod: 35.202685952186584, loss: 39.6360650062561 
Train [3/26] | Epoch [53/160] |	nca: 1.405007354915142, flat: 2.9544325917959213, pod: 36.19117975234985, loss: 40.55062007904053 
Train [3/26] | Epoch [54/160] |	nca: 1.4802136719226837, flat: 2.8021873831748962, pod: 35.27846074104309, loss: 39.56086182594299 
Train [3/26] | Epoch [55/160] |	nca: 1.427779160439968, flat: 2.6773736029863358, pod: 34.610626459121704, loss: 38.71577978134155 
Train [3/26] | Epoch [56/160] |	nca: 1.2614856325089931, flat: 2.707081899046898, pod: 33.87128734588623, loss: 37.83985495567322 
Train [3/26] | Epoch [57/160] |	nca: 1.3142424412071705, flat: 2.8895840495824814, pod: 35.636420488357544, loss: 39.84024691581726 
Train [3/26] | Epoch [58/160] |	nca: 1.3463067598640919, flat: 2.594775825738907, pod: 33.56891858577728, loss: 37.51000094413757 
Train [3/26] | Epoch [59/160] |	nca: 1.6588904149830341, flat: 2.6790487468242645, pod: 33.792065382003784, loss: 38.1300048828125 
Train [3/26] | Epoch [60/160] |	nca: 1.303879126906395, flat: 2.7752372920513153, pod: 34.24634790420532, loss: 38.325464725494385 
Train [3/26] | Epoch [61/160] |	nca: 1.5116050094366074, flat: 2.5708534866571426, pod: 33.94789266586304, loss: 38.03035116195679 
Train [3/26] | Epoch [62/160] |	nca: 1.3250984512269497, flat: 2.662756234407425, pod: 34.23620367050171, loss: 38.22405815124512 
Train [3/26] | Epoch [63/160] |	nca: 1.315241176635027, flat: 2.4642578959465027, pod: 32.11442148685455, loss: 35.89392042160034 
Train [3/26] | Epoch [64/160] |	nca: 1.2424427829682827, flat: 2.4860050827264786, pod: 32.63153576850891, loss: 36.359983921051025 
Train [3/26] | Epoch [65/160] |	nca: 1.231342874467373, flat: 2.3889331221580505, pod: 32.64993667602539, loss: 36.27021288871765 
Train [3/26] | Epoch [66/160] |	nca: 1.3365823477506638, flat: 2.2979405522346497, pod: 31.62496531009674, loss: 35.259488105773926 
Train [3/26] | Epoch [67/160] |	nca: 1.3324825651943684, flat: 2.313694603741169, pod: 31.061899542808533, loss: 34.70807635784149 
Train [3/26] | Epoch [68/160] |	nca: 1.3932352662086487, flat: 2.484523206949234, pod: 33.03477191925049, loss: 36.91253042221069 
Train [3/26] | Epoch [69/160] |	nca: 1.260009203106165, flat: 2.4700023978948593, pod: 32.233240723609924, loss: 35.963252544403076 
Train [3/26] | Epoch [70/160] |	nca: 1.4544247463345528, flat: 2.439192533493042, pod: 33.097853779792786, loss: 36.99147129058838 
Train [3/26] | Epoch [71/160] |	nca: 1.436714880168438, flat: 2.306826911866665, pod: 31.514567017555237, loss: 35.25810885429382 
Train [3/26] | Epoch [72/160] |	nca: 1.0752029046416283, flat: 2.306893639266491, pod: 30.929303526878357, loss: 34.311400055885315 
Train [3/26] | Epoch [73/160] |	nca: 1.186523076146841, flat: 2.1179910451173782, pod: 29.852951288223267, loss: 33.15746557712555 
Train [3/26] | Epoch [74/160] |	nca: 1.3958478420972824, flat: 2.2494509667158127, pod: 30.47345769405365, loss: 34.11875641345978 
Train [3/26] | Epoch [75/160] |	nca: 1.268850315362215, flat: 2.2426812425255775, pod: 30.726155161857605, loss: 34.23768699169159 
Train [3/26] | Epoch [76/160] |	nca: 1.4119231179356575, flat: 2.2138391733169556, pod: 30.83833110332489, loss: 34.46409296989441 
Train [3/26] | Epoch [77/160] |	nca: 1.3258246518671513, flat: 2.354246437549591, pod: 33.702646374702454, loss: 37.38271737098694 
Train [3/26] | Epoch [78/160] |	nca: 1.320191901177168, flat: 2.2558016255497932, pod: 30.543854594230652, loss: 34.11984848976135 
Train [3/26] | Epoch [79/160] |	nca: 1.2134185209870338, flat: 2.322139009833336, pod: 31.51185417175293, loss: 35.04741191864014 
Train [3/26] | Epoch [80/160] |	nca: 1.2521213665604591, flat: 2.082549974322319, pod: 29.43293571472168, loss: 32.76760673522949 
Train [3/26] | Epoch [81/160] |	nca: 1.1411714442074299, flat: 1.9917046874761581, pod: 28.577953577041626, loss: 31.710829734802246 
Train [3/26] | Epoch [82/160] |	nca: 1.217257235199213, flat: 1.8407838717103004, pod: 28.081673741340637, loss: 31.13971495628357 
Train [3/26] | Epoch [83/160] |	nca: 1.374480988830328, flat: 2.1007696092128754, pod: 30.741654753684998, loss: 34.21690547466278 
Train [3/26] | Epoch [84/160] |	nca: 1.3228979222476482, flat: 2.093125469982624, pod: 29.937317848205566, loss: 33.353341579437256 
Train [3/26] | Epoch [85/160] |	nca: 1.1779556218534708, flat: 2.1306098327040672, pod: 29.41575789451599, loss: 32.7243230342865 
Train [3/26] | Epoch [86/160] |	nca: 1.4188271388411522, flat: 1.9395549073815346, pod: 28.91016447544098, loss: 32.26854646205902 
Train [3/26] | Epoch [87/160] |	nca: 1.1923238076269627, flat: 2.0594009086489677, pod: 29.373899817466736, loss: 32.62562429904938 
Train [3/26] | Epoch [88/160] |	nca: 1.209082916378975, flat: 2.062894068658352, pod: 29.540831208229065, loss: 32.81280791759491 
Train [3/26] | Epoch [89/160] |	nca: 1.2041518539190292, flat: 1.9332900866866112, pod: 28.521775722503662, loss: 31.659217596054077 
Train [3/26] | Epoch [90/160] |	nca: 1.30771504342556, flat: 1.97846669703722, pod: 28.565912127494812, loss: 31.852094054222107 
Train [3/26] | Epoch [91/160] |	nca: 1.2669709771871567, flat: 1.8691923767328262, pod: 27.47331738471985, loss: 30.60948073863983 
Train [3/26] | Epoch [92/160] |	nca: 1.2052429132163525, flat: 1.813249059021473, pod: 27.318269968032837, loss: 30.336761951446533 
Train [3/26] | Epoch [93/160] |	nca: 1.2425369247794151, flat: 1.9504135698080063, pod: 28.61618185043335, loss: 31.80913245677948 
Train [3/26] | Epoch [94/160] |	nca: 1.2112370803952217, flat: 1.837710328400135, pod: 27.07387149333954, loss: 30.1228187084198 
Train [3/26] | Epoch [95/160] |	nca: 1.312912467867136, flat: 1.6553333923220634, pod: 25.76252579689026, loss: 28.73077142238617 
Train [3/26] | Epoch [96/160] |	nca: 1.171560388058424, flat: 1.6825810819864273, pod: 26.067766070365906, loss: 28.921907544136047 
Train [3/26] | Epoch [97/160] |	nca: 1.2402974665164948, flat: 1.7751496881246567, pod: 26.960732102394104, loss: 29.976179361343384 
Train [3/26] | Epoch [98/160] |	nca: 1.1553879864513874, flat: 1.7307028025388718, pod: 26.427284002304077, loss: 29.313374757766724 
Train [3/26] | Epoch [99/160] |	nca: 1.145844705402851, flat: 1.580494150519371, pod: 24.6189022064209, loss: 27.3452410697937 
Train [3/26] | Epoch [100/160] |	nca: 1.307820837944746, flat: 1.7502856776118279, pod: 27.493539452552795, loss: 30.551645755767822 
Train [3/26] | Epoch [101/160] |	nca: 1.1760490387678146, flat: 1.7941554486751556, pod: 27.735263228416443, loss: 30.705467700958252 
Train [3/26] | Epoch [102/160] |	nca: 1.3384219147264957, flat: 1.72685918956995, pod: 27.07221794128418, loss: 30.13749933242798 
Train [3/26] | Epoch [103/160] |	nca: 1.1632377058267593, flat: 1.631032831966877, pod: 24.879852414131165, loss: 27.674123167991638 
Train [3/26] | Epoch [104/160] |	nca: 1.188247125595808, flat: 1.591438464820385, pod: 24.63763654232025, loss: 27.417322158813477 
Train [3/26] | Epoch [105/160] |	nca: 1.3651102408766747, flat: 1.5584048926830292, pod: 24.2922420501709, loss: 27.215757131576538 
Train [3/26] | Epoch [106/160] |	nca: 1.2397298403084278, flat: 1.5741173848509789, pod: 23.98042893409729, loss: 26.794276118278503 
Train [3/26] | Epoch [107/160] |	nca: 1.1439176388084888, flat: 1.604077234864235, pod: 25.568332195281982, loss: 28.31632697582245 
Train [3/26] | Epoch [108/160] |	nca: 1.3478813134133816, flat: 1.6545708402991295, pod: 25.697028160095215, loss: 28.699480533599854 
Train [3/26] | Epoch [109/160] |	nca: 1.1524436622858047, flat: 1.5429458022117615, pod: 25.61169731616974, loss: 28.3070867061615 
Train [3/26] | Epoch [110/160] |	nca: 1.3427141830325127, flat: 1.5020367130637169, pod: 24.956305861473083, loss: 27.801056742668152 
Train [3/26] | Epoch [111/160] |	nca: 1.1981874741613865, flat: 1.4568866416811943, pod: 23.374327301979065, loss: 26.029401302337646 
Train [3/26] | Epoch [112/160] |	nca: 1.2853342033922672, flat: 1.3928147777915, pod: 23.10063099861145, loss: 25.77877986431122 
Train [3/26] | Epoch [113/160] |	nca: 1.2019913084805012, flat: 1.455155722796917, pod: 23.609375834465027, loss: 26.266523003578186 
Train [3/26] | Epoch [114/160] |	nca: 1.3063410930335522, flat: 1.4568041265010834, pod: 24.232123494148254, loss: 26.99526858329773 
Train [3/26] | Epoch [115/160] |	nca: 1.1574669778347015, flat: 1.370755322277546, pod: 23.075283646583557, loss: 25.603505849838257 
Train [3/26] | Epoch [116/160] |	nca: 1.32729621976614, flat: 1.3592101708054543, pod: 21.99392807483673, loss: 24.680434346199036 
Train [3/26] | Epoch [117/160] |	nca: 1.2224208749830723, flat: 1.418239839375019, pod: 23.47006928920746, loss: 26.110729813575745 
Train [3/26] | Epoch [118/160] |	nca: 1.2033874653279781, flat: 1.405801385641098, pod: 23.402626276016235, loss: 26.011815071105957 
Train [3/26] | Epoch [119/160] |	nca: 1.1694016717374325, flat: 1.384668581187725, pod: 23.338294744491577, loss: 25.892364978790283 
Train [3/26] | Epoch [120/160] |	nca: 1.191720724105835, flat: 1.3694008961319923, pod: 22.186378955841064, loss: 24.74750065803528 
Train [3/26] | Epoch [121/160] |	nca: 1.1552855521440506, flat: 1.2210045382380486, pod: 20.964885234832764, loss: 23.341175317764282 
Train [3/26] | Epoch [122/160] |	nca: 1.0804505310952663, flat: 1.2580930516123772, pod: 22.162152647972107, loss: 24.500696301460266 
Train [3/26] | Epoch [123/160] |	nca: 1.254721686244011, flat: 1.2316529974341393, pod: 21.01369285583496, loss: 23.500067591667175 
Train [3/26] | Epoch [124/160] |	nca: 1.1218141913414001, flat: 1.1978093273937702, pod: 20.857003688812256, loss: 23.176627039909363 
Train [3/26] | Epoch [125/160] |	nca: 1.169448409229517, flat: 1.2198611460626125, pod: 20.64864754676819, loss: 23.037957072257996 
Train [3/26] | Epoch [126/160] |	nca: 1.31821533665061, flat: 1.2510913833975792, pod: 21.447465777397156, loss: 24.016772627830505 
Train [3/26] | Epoch [127/160] |	nca: 1.2111112214624882, flat: 1.2151260003447533, pod: 21.110148072242737, loss: 23.53638517856598 
Train [3/26] | Epoch [128/160] |	nca: 1.1266932226717472, flat: 1.1151352636516094, pod: 19.5080908536911, loss: 21.749919176101685 
Train [3/26] | Epoch [129/160] |	nca: 1.112772911787033, flat: 1.1405436471104622, pod: 19.958401322364807, loss: 22.21171808242798 
Train [3/26] | Epoch [130/160] |	nca: 1.175337065011263, flat: 1.0727761648595333, pod: 19.19824481010437, loss: 21.44635796546936 
Train [3/26] | Epoch [131/160] |	nca: 1.2098571807146072, flat: 1.1192917227745056, pod: 19.693862318992615, loss: 22.023011088371277 
Train [3/26] | Epoch [132/160] |	nca: 1.1533518582582474, flat: 1.1453099213540554, pod: 19.6235494017601, loss: 21.922211170196533 
Train [3/26] | Epoch [133/160] |	nca: 1.1864892914891243, flat: 1.078561831265688, pod: 18.726972937583923, loss: 20.992024302482605 
Train [3/26] | Epoch [134/160] |	nca: 1.138900026679039, flat: 1.0478713065385818, pod: 18.836897134780884, loss: 21.02366840839386 
Train [3/26] | Epoch [135/160] |	nca: 1.2064492255449295, flat: 1.0853469707071781, pod: 18.971687614917755, loss: 21.26348388195038 
Train [3/26] | Epoch [136/160] |	nca: 1.1053586937487125, flat: 1.062298908829689, pod: 18.943470358848572, loss: 21.111127972602844 
Train [3/26] | Epoch [137/160] |	nca: 1.1428822949528694, flat: 1.045023798942566, pod: 18.649433851242065, loss: 20.837339878082275 
Train [3/26] | Epoch [138/160] |	nca: 1.1478313691914082, flat: 1.0146275460720062, pod: 18.441690266132355, loss: 20.60414958000183 
Train [3/26] | Epoch [139/160] |	nca: 1.195486556738615, flat: 0.9947207123041153, pod: 18.029001235961914, loss: 20.219208240509033 
Train [3/26] | Epoch [140/160] |	nca: 1.1304519474506378, flat: 1.031250473111868, pod: 18.345370769500732, loss: 20.507073283195496 
Train [3/26] | Epoch [141/160] |	nca: 1.2930211573839188, flat: 0.9791649580001831, pod: 18.248816192150116, loss: 20.521002292633057 
Train [3/26] | Epoch [142/160] |	nca: 1.206954650580883, flat: 1.0234813056886196, pod: 18.065175414085388, loss: 20.29561138153076 
Train [3/26] | Epoch [143/160] |	nca: 1.1219927407801151, flat: 0.9930493123829365, pod: 17.994003415107727, loss: 20.109045386314392 
Train [3/26] | Epoch [144/160] |	nca: 1.1763041205704212, flat: 0.9929835870862007, pod: 18.127183735370636, loss: 20.29647159576416 
Train [3/26] | Epoch [145/160] |	nca: 1.1363224759697914, flat: 0.9609576091170311, pod: 17.000682294368744, loss: 19.09796231985092 
Train [3/26] | Epoch [146/160] |	nca: 1.1541913710534573, flat: 0.969318438321352, pod: 16.76691645383835, loss: 18.89042603969574 
Train [3/26] | Epoch [147/160] |	nca: 1.170084547251463, flat: 0.9768456369638443, pod: 17.35439831018448, loss: 19.501328349113464 
Train [3/26] | Epoch [148/160] |	nca: 1.189103938639164, flat: 0.9711899906396866, pod: 17.377781331539154, loss: 19.538075268268585 
Train [3/26] | Epoch [149/160] |	nca: 1.1372033320367336, flat: 0.9483426436781883, pod: 17.19978964328766, loss: 19.28533571958542 
Train [3/26] | Epoch [150/160] |	nca: 1.0957978069782257, flat: 0.8863465078175068, pod: 16.75222897529602, loss: 18.734373331069946 
Train [3/26] | Epoch [151/160] |	nca: 1.1794182024896145, flat: 0.9384247958660126, pod: 16.870954990386963, loss: 18.988798022270203 
Train [3/26] | Epoch [152/160] |	nca: 1.0845575630664825, flat: 0.8646039664745331, pod: 15.26891028881073, loss: 17.2180717587471 
Train [3/26] | Epoch [153/160] |	nca: 1.171717006713152, flat: 0.9589437134563923, pod: 17.015871584415436, loss: 19.1465322971344 
Train [3/26] | Epoch [154/160] |	nca: 1.1522580198943615, flat: 0.9651947692036629, pod: 17.781025290489197, loss: 19.898478269577026 
Train [3/26] | Epoch [155/160] |	nca: 1.277295857667923, flat: 0.9310799054801464, pod: 16.373703360557556, loss: 18.58207905292511 
Train [3/26] | Epoch [156/160] |	nca: 1.1986805237829685, flat: 0.8770301192998886, pod: 15.648896038532257, loss: 17.72460675239563 
Train [3/26] | Epoch [157/160] |	nca: 1.3753620348870754, flat: 0.9164960794150829, pod: 16.44054239988327, loss: 18.73240053653717 
Train [3/26] | Epoch [158/160] |	nca: 1.1707345433533192, flat: 0.8718382343649864, pod: 16.238277554512024, loss: 18.280850410461426 
Train [3/26] | Epoch [159/160] |	nca: 1.2742731124162674, flat: 0.9125176481902599, pod: 16.32865744829178, loss: 18.51544839143753 
Train [3/26] | Epoch [160/160] |	nca: 1.19099548086524, flat: 0.9336750991642475, pod: 16.33402693271637, loss: 18.45869755744934 
Fine-tuning
Building & updating memory.
Train [3/26] | Epoch [161/180] |	nca: 1.6485228165984154, flat: 1.3777800351381302, pod: 14.498934745788574, loss: 17.525237560272217 
Train [3/26] | Epoch [162/180] |	nca: 0.7612102217972279, flat: 1.397389993071556, pod: 14.833289623260498, loss: 16.991889595985413 
Train [3/26] | Epoch [163/180] |	nca: 0.5596085824072361, flat: 1.393289178609848, pod: 14.890284895896912, loss: 16.843182802200317 
Train [3/26] | Epoch [164/180] |	nca: 0.49074220657348633, flat: 1.433215782046318, pod: 14.913812041282654, loss: 16.837770104408264 
Train [3/26] | Epoch [165/180] |	nca: 0.40483920089900494, flat: 1.4172035157680511, pod: 15.05134105682373, loss: 16.87338376045227 
Train [3/26] | Epoch [166/180] |	nca: 0.3283413518220186, flat: 1.3729614168405533, pod: 14.658456683158875, loss: 16.35975968837738 
Train [3/26] | Epoch [167/180] |	nca: 0.3074058946222067, flat: 1.3768313974142075, pod: 14.786040544509888, loss: 16.470277905464172 
Train [3/26] | Epoch [168/180] |	nca: 0.3351125381886959, flat: 1.3876443058252335, pod: 14.775099754333496, loss: 16.497856497764587 
Train [3/26] | Epoch [169/180] |	nca: 0.3004745077341795, flat: 1.417327955365181, pod: 15.032031416893005, loss: 16.749833941459656 
Train [3/26] | Epoch [170/180] |	nca: 0.2889412958174944, flat: 1.4377842247486115, pod: 15.04066789150238, loss: 16.767393350601196 
Train [3/26] | Epoch [171/180] |	nca: 0.2954559251666069, flat: 1.38957679271698, pod: 14.759369611740112, loss: 16.44440245628357 
Train [3/26] | Epoch [172/180] |	nca: 0.27322378009557724, flat: 1.4568068236112595, pod: 15.139116048812866, loss: 16.869146585464478 
Train [3/26] | Epoch [173/180] |	nca: 0.31059782952070236, flat: 1.5256802141666412, pod: 15.744462490081787, loss: 17.580740451812744 
Train [3/26] | Epoch [174/180] |	nca: 0.2971206922084093, flat: 1.448445975780487, pod: 15.140657782554626, loss: 16.886224508285522 
Train [3/26] | Epoch [175/180] |	nca: 0.2663784809410572, flat: 1.4663773775100708, pod: 15.56056523323059, loss: 17.293321132659912 
Train [3/26] | Epoch [176/180] |	nca: 0.3445825222879648, flat: 1.4194293320178986, pod: 15.26179301738739, loss: 17.02580487728119 
Train [3/26] | Epoch [177/180] |	nca: 0.25679196789860725, flat: 1.4342918768525124, pod: 15.072571396827698, loss: 16.763655185699463 
Train [3/26] | Epoch [178/180] |	nca: 0.24445047415792942, flat: 1.4390002489089966, pod: 14.927891612052917, loss: 16.611342310905457 
Train [3/26] | Epoch [179/180] |	nca: 0.22950543835759163, flat: 1.4392763897776604, pod: 15.02522349357605, loss: 16.694005489349365 
Train [3/26] | Epoch [180/180] |	nca: 0.22300428058952093, flat: 1.4314176887273788, pod: 15.018058180809021, loss: 16.67247998714447 
after task
Building & updating memory.
after task
Eval on 0->54.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.7376666666666667.
Current acc: {'total': 0.721, '00-09': 0.778, '10-19': 0.761, '20-29': 0.649, '30-39': 0.692, '40-49': 0.754, '50-59': 0.652}.
Avg inc acc top5: 0.931.
Current acc top5: {'total': 0.923}.
Forgetting: 0.027285714285714278.
Cord metric: 0.73.
Old accuracy: 0.72, mean: 0.73.
New accuracy: 0.65, mean: 0.68.
================Task 3 Start!================
Testing on False unseen tasks (max class = 56).
Set memory of size: 1080.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 3 Training!================
The training samples number: 2080
Train on 54->56.
train task
nb 2080.
Train [4/26] | Epoch [1/160] |	nca: 6.6810949593782425, flat: 4.077324241399765, pod: 46.365269899368286, loss: 57.12368941307068 
Train [4/26] | Epoch [2/160] |	nca: 4.454232752323151, flat: 5.86714780330658, pod: 55.567017793655396, loss: 65.88839864730835 
Train [4/26] | Epoch [3/160] |	nca: 2.8325531855225563, flat: 4.937461167573929, pod: 49.143484592437744, loss: 56.91349911689758 
Train [4/26] | Epoch [4/160] |	nca: 2.950901612639427, flat: 4.1501783430576324, pod: 46.916001081466675, loss: 54.01708149909973 
Train [4/26] | Epoch [5/160] |	nca: 2.36369925737381, flat: 4.20920430123806, pod: 48.246620655059814, loss: 54.81952452659607 
Train [4/26] | Epoch [6/160] |	nca: 2.319880001246929, flat: 3.9838616400957108, pod: 47.210264444351196, loss: 53.51400566101074 
Train [4/26] | Epoch [7/160] |	nca: 2.536566324532032, flat: 4.019281774759293, pod: 46.07993149757385, loss: 52.63577890396118 
Train [4/26] | Epoch [8/160] |	nca: 2.1318456158041954, flat: 3.990493059158325, pod: 46.63085675239563, loss: 52.75319528579712 
Train [4/26] | Epoch [9/160] |	nca: 1.9224405065178871, flat: 3.6813211739063263, pod: 43.317038774490356, loss: 48.92080044746399 
Train [4/26] | Epoch [10/160] |	nca: 1.6619580388069153, flat: 3.334698736667633, pod: 42.26425242424011, loss: 47.26090908050537 
Train [4/26] | Epoch [11/160] |	nca: 1.853977382183075, flat: 3.307413801550865, pod: 42.007493019104004, loss: 47.16888427734375 
Train [4/26] | Epoch [12/160] |	nca: 1.9220723286271095, flat: 3.5035779178142548, pod: 43.432549476623535, loss: 48.85819959640503 
Train [4/26] | Epoch [13/160] |	nca: 1.7568149715662003, flat: 3.5711839348077774, pod: 44.632665157318115, loss: 49.96066427230835 
Train [4/26] | Epoch [14/160] |	nca: 2.0549919195473194, flat: 3.711263880133629, pod: 43.540966510772705, loss: 49.30722212791443 
Train [4/26] | Epoch [15/160] |	nca: 1.8030032515525818, flat: 3.4012269228696823, pod: 42.16825294494629, loss: 47.372482776641846 
Train [4/26] | Epoch [16/160] |	nca: 2.0570554807782173, flat: 3.457274228334427, pod: 43.14724898338318, loss: 48.6615788936615 
Train [4/26] | Epoch [17/160] |	nca: 1.9261691570281982, flat: 3.9432355761528015, pod: 46.6950421333313, loss: 52.56444716453552 
Train [4/26] | Epoch [18/160] |	nca: 1.893704704940319, flat: 3.8400230705738068, pod: 45.47884249687195, loss: 51.212570905685425 
Train [4/26] | Epoch [19/160] |	nca: 1.4918506368994713, flat: 3.2444686591625214, pod: 41.26210570335388, loss: 45.9984245300293 
Train [4/26] | Epoch [20/160] |	nca: 1.563531517982483, flat: 3.1671849489212036, pod: 42.157613039016724, loss: 46.88832902908325 
Train [4/26] | Epoch [21/160] |	nca: 1.625320240855217, flat: 3.2607602328062057, pod: 40.55007600784302, loss: 45.436156272888184 
Train [4/26] | Epoch [22/160] |	nca: 1.6115831956267357, flat: 3.172855645418167, pod: 42.00525760650635, loss: 46.78969621658325 
Train [4/26] | Epoch [23/160] |	nca: 1.7058070525527, flat: 3.5615430921316147, pod: 43.281996726989746, loss: 48.54934740066528 
Train [4/26] | Epoch [24/160] |	nca: 1.6495211124420166, flat: 3.3589794486761093, pod: 42.57990026473999, loss: 47.58840084075928 
Train [4/26] | Epoch [25/160] |	nca: 1.9796343371272087, flat: 3.51069276034832, pod: 43.182374477386475, loss: 48.672701597213745 
Train [4/26] | Epoch [26/160] |	nca: 1.8726619519293308, flat: 4.048952162265778, pod: 46.960031509399414, loss: 52.881645917892456 
Train [4/26] | Epoch [27/160] |	nca: 1.6285005249083042, flat: 3.1457138508558273, pod: 40.123268842697144, loss: 44.897483348846436 
Train [4/26] | Epoch [28/160] |	nca: 1.5981496535241604, flat: 3.192440003156662, pod: 41.00692915916443, loss: 45.79751920700073 
Train [4/26] | Epoch [29/160] |	nca: 1.5158158838748932, flat: 2.9786164611577988, pod: 39.55231285095215, loss: 44.04674577713013 
Train [4/26] | Epoch [30/160] |	nca: 1.8002655804157257, flat: 3.363921508193016, pod: 40.92612957954407, loss: 46.0903160572052 
Train [4/26] | Epoch [31/160] |	nca: 1.9489623010158539, flat: 3.5854634046554565, pod: 42.697514295578, loss: 48.231940031051636 
Train [4/26] | Epoch [32/160] |	nca: 1.5999487712979317, flat: 3.2091902047395706, pod: 39.83237147331238, loss: 44.64151072502136 
Train [4/26] | Epoch [33/160] |	nca: 1.6104015558958054, flat: 3.0622505992650986, pod: 40.13080978393555, loss: 44.803462266922 
Train [4/26] | Epoch [34/160] |	nca: 1.730062022805214, flat: 2.7871114164590836, pod: 37.51267433166504, loss: 42.02984809875488 
Train [4/26] | Epoch [35/160] |	nca: 1.649165090173483, flat: 3.2072838991880417, pod: 41.77156186103821, loss: 46.628010749816895 
Train [4/26] | Epoch [36/160] |	nca: 1.4975992664694786, flat: 3.0220056921243668, pod: 40.382397174835205, loss: 44.90200233459473 
Train [4/26] | Epoch [37/160] |	nca: 1.6760471314191818, flat: 3.002231642603874, pod: 40.0216600894928, loss: 44.69993877410889 
Train [4/26] | Epoch [38/160] |	nca: 1.5653969794511795, flat: 3.00566329061985, pod: 39.964627742767334, loss: 44.53568768501282 
Train [4/26] | Epoch [39/160] |	nca: 1.349623754620552, flat: 2.6955319344997406, pod: 36.84129250049591, loss: 40.88644790649414 
Train [4/26] | Epoch [40/160] |	nca: 1.3651621118187904, flat: 2.7535595297813416, pod: 36.433279156684875, loss: 40.552000999450684 
Train [4/26] | Epoch [41/160] |	nca: 1.6446740478277206, flat: 3.0174613296985626, pod: 39.67768716812134, loss: 44.33982253074646 
Train [4/26] | Epoch [42/160] |	nca: 1.5571388714015484, flat: 3.026045188307762, pod: 39.52745747566223, loss: 44.11064171791077 
Train [4/26] | Epoch [43/160] |	nca: 1.5547096617519855, flat: 2.7209283113479614, pod: 38.25869584083557, loss: 42.5343337059021 
Train [4/26] | Epoch [44/160] |	nca: 1.3977055810391903, flat: 2.9795695692300797, pod: 41.34234309196472, loss: 45.71961832046509 
Train [4/26] | Epoch [45/160] |	nca: 1.4341536350548267, flat: 2.92284294962883, pod: 39.63260006904602, loss: 43.9895966053009 
Train [4/26] | Epoch [46/160] |	nca: 1.6172531880438328, flat: 2.9230478554964066, pod: 38.89086425304413, loss: 43.43116521835327 
Train [4/26] | Epoch [47/160] |	nca: 1.636584062129259, flat: 3.052343040704727, pod: 39.10865068435669, loss: 43.79757785797119 
Train [4/26] | Epoch [48/160] |	nca: 1.5267614237964153, flat: 2.7861815094947815, pod: 38.07017254829407, loss: 42.38311576843262 
Train [4/26] | Epoch [49/160] |	nca: 1.4697718769311905, flat: 2.86807818710804, pod: 36.98682367801666, loss: 41.324673891067505 
Train [4/26] | Epoch [50/160] |	nca: 1.8736078813672066, flat: 3.300435170531273, pod: 41.2064094543457, loss: 46.380452156066895 
Train [4/26] | Epoch [51/160] |	nca: 1.5205860435962677, flat: 2.9900737404823303, pod: 39.77618408203125, loss: 44.28684401512146 
Train [4/26] | Epoch [52/160] |	nca: 1.230516940355301, flat: 2.6233306378126144, pod: 36.58563792705536, loss: 40.43948531150818 
Train [4/26] | Epoch [53/160] |	nca: 1.3624858893454075, flat: 2.5556807816028595, pod: 36.43159794807434, loss: 40.349764823913574 
Train [4/26] | Epoch [54/160] |	nca: 1.3615960255265236, flat: 2.730755567550659, pod: 38.68056523799896, loss: 42.77291679382324 
Train [4/26] | Epoch [55/160] |	nca: 1.5898258872330189, flat: 2.784103825688362, pod: 38.437538266181946, loss: 42.81146860122681 
Train [4/26] | Epoch [56/160] |	nca: 1.3851330056786537, flat: 2.643726944923401, pod: 37.03031277656555, loss: 41.05917263031006 
Train [4/26] | Epoch [57/160] |	nca: 1.5593947693705559, flat: 2.6014553010463715, pod: 35.542901396751404, loss: 39.70375156402588 
Train [4/26] | Epoch [58/160] |	nca: 1.549641665071249, flat: 2.418420284986496, pod: 34.86226761341095, loss: 38.83032965660095 
Train [4/26] | Epoch [59/160] |	nca: 1.4288844019174576, flat: 2.5054782181978226, pod: 35.932512640953064, loss: 39.86687517166138 
Train [4/26] | Epoch [60/160] |	nca: 1.2733813896775246, flat: 2.424985870718956, pod: 36.111826062202454, loss: 39.81019353866577 
Train [4/26] | Epoch [61/160] |	nca: 1.4350062534213066, flat: 2.382994592189789, pod: 35.00838220119476, loss: 38.826382875442505 
Train [4/26] | Epoch [62/160] |	nca: 1.4231510870158672, flat: 2.483030915260315, pod: 35.62082087993622, loss: 39.52700328826904 
Train [4/26] | Epoch [63/160] |	nca: 1.3529578410089016, flat: 2.406122073531151, pod: 35.341962933540344, loss: 39.10104274749756 
Train [4/26] | Epoch [64/160] |	nca: 1.3685284554958344, flat: 2.489683784544468, pod: 36.16425919532776, loss: 40.02247071266174 
Train [4/26] | Epoch [65/160] |	nca: 1.4345970340073109, flat: 2.5166384875774384, pod: 36.59802961349487, loss: 40.549264907836914 
Train [4/26] | Epoch [66/160] |	nca: 1.448784600943327, flat: 2.4550917223095894, pod: 34.841490626335144, loss: 38.74536728858948 
Train [4/26] | Epoch [67/160] |	nca: 1.1723397225141525, flat: 2.2161527946591377, pod: 33.85485637187958, loss: 37.243348836898804 
Train [4/26] | Epoch [68/160] |	nca: 1.2698989026248455, flat: 2.273552395403385, pod: 35.28339469432831, loss: 38.82684588432312 
Train [4/26] | Epoch [69/160] |	nca: 1.2595653496682644, flat: 2.1266738697886467, pod: 32.653130292892456, loss: 36.03936946392059 
Train [4/26] | Epoch [70/160] |	nca: 1.2475661858916283, flat: 2.12067973613739, pod: 32.567357778549194, loss: 35.93560338020325 
Train [4/26] | Epoch [71/160] |	nca: 1.2250875011086464, flat: 2.186944544315338, pod: 33.11249566078186, loss: 36.5245281457901 
Train [4/26] | Epoch [72/160] |	nca: 1.6047569625079632, flat: 2.198584996163845, pod: 33.95096302032471, loss: 37.754305362701416 
Train [4/26] | Epoch [73/160] |	nca: 1.4363598339259624, flat: 2.226051412522793, pod: 33.72290110588074, loss: 37.38531219959259 
Train [4/26] | Epoch [74/160] |	nca: 1.2232071049511433, flat: 2.0485449954867363, pod: 31.970391988754272, loss: 35.2421441078186 
Train [4/26] | Epoch [75/160] |	nca: 1.2639990858733654, flat: 1.9039336815476418, pod: 30.155147194862366, loss: 33.32308006286621 
Train [4/26] | Epoch [76/160] |	nca: 1.4284015335142612, flat: 2.154588058590889, pod: 33.18805968761444, loss: 36.77104961872101 
Train [4/26] | Epoch [77/160] |	nca: 1.2746292501688004, flat: 2.089710049331188, pod: 31.695343136787415, loss: 35.05968236923218 
Train [4/26] | Epoch [78/160] |	nca: 1.2356167249381542, flat: 2.1044858247041702, pod: 32.784964084625244, loss: 36.12506651878357 
Train [4/26] | Epoch [79/160] |	nca: 1.2115009278059006, flat: 1.9682524651288986, pod: 31.245275139808655, loss: 34.4250283241272 
Train [4/26] | Epoch [80/160] |	nca: 1.2558946050703526, flat: 1.9585939422249794, pod: 32.20333778858185, loss: 35.417826414108276 
Train [4/26] | Epoch [81/160] |	nca: 1.2414071299135685, flat: 1.9255751743912697, pod: 31.323363065719604, loss: 34.49034535884857 
Train [4/26] | Epoch [82/160] |	nca: 1.144802801311016, flat: 1.8616172522306442, pod: 30.661560893058777, loss: 33.667980909347534 
Train [4/26] | Epoch [83/160] |	nca: 1.338703665882349, flat: 1.9773709401488304, pod: 33.10206711292267, loss: 36.41814196109772 
Train [4/26] | Epoch [84/160] |	nca: 1.3799182251095772, flat: 2.1248052790760994, pod: 32.61513638496399, loss: 36.11986005306244 
Train [4/26] | Epoch [85/160] |	nca: 1.2685593403875828, flat: 2.0141625329852104, pod: 32.307820558547974, loss: 35.590542674064636 
Train [4/26] | Epoch [86/160] |	nca: 1.2200156040489674, flat: 1.9302709177136421, pod: 31.367560386657715, loss: 34.51784682273865 
Train [4/26] | Epoch [87/160] |	nca: 1.2230175137519836, flat: 1.8231848552823067, pod: 31.43105900287628, loss: 34.47726118564606 
Train [4/26] | Epoch [88/160] |	nca: 1.2599959671497345, flat: 1.8500708788633347, pod: 30.1936012506485, loss: 33.30366814136505 
Train [4/26] | Epoch [89/160] |	nca: 1.229234129190445, flat: 1.8642142117023468, pod: 31.587862253189087, loss: 34.681310296058655 
Train [4/26] | Epoch [90/160] |	nca: 1.1955366283655167, flat: 1.6931184157729149, pod: 29.172605991363525, loss: 32.06126117706299 
Train [4/26] | Epoch [91/160] |	nca: 1.289603404700756, flat: 1.7617148384451866, pod: 29.687578916549683, loss: 32.73889708518982 
Train [4/26] | Epoch [92/160] |	nca: 1.4059512987732887, flat: 1.8617196455597878, pod: 30.009759426116943, loss: 33.277430295944214 
Train [4/26] | Epoch [93/160] |	nca: 1.3195294477045536, flat: 1.7989422231912613, pod: 30.190494060516357, loss: 33.3089656829834 
Train [4/26] | Epoch [94/160] |	nca: 1.2560086250305176, flat: 1.7631538584828377, pod: 29.23533260822296, loss: 32.25449502468109 
Train [4/26] | Epoch [95/160] |	nca: 1.1309417709708214, flat: 1.5824542567133904, pod: 27.2895290851593, loss: 30.002925157546997 
Train [4/26] | Epoch [96/160] |	nca: 1.2299773544073105, flat: 1.6921458840370178, pod: 28.803714156150818, loss: 31.72583770751953 
Train [4/26] | Epoch [97/160] |	nca: 1.1030955091118813, flat: 1.5587775111198425, pod: 27.020325541496277, loss: 29.682198643684387 
Train [4/26] | Epoch [98/160] |	nca: 1.305836796760559, flat: 1.623699963092804, pod: 27.894671201705933, loss: 30.82420802116394 
Train [4/26] | Epoch [99/160] |	nca: 1.2613526657223701, flat: 1.5297248139977455, pod: 27.103697776794434, loss: 29.89477515220642 
Train [4/26] | Epoch [100/160] |	nca: 1.1453345827758312, flat: 1.5440865606069565, pod: 27.330965518951416, loss: 30.020386576652527 
Train [4/26] | Epoch [101/160] |	nca: 1.2634679600596428, flat: 1.4598028361797333, pod: 26.278860092163086, loss: 29.00213086605072 
Train [4/26] | Epoch [102/160] |	nca: 1.3081243336200714, flat: 1.509113386273384, pod: 26.8779878616333, loss: 29.695225596427917 
Train [4/26] | Epoch [103/160] |	nca: 1.2202430255711079, flat: 1.6190041229128838, pod: 27.801730751991272, loss: 30.64097797870636 
Train [4/26] | Epoch [104/160] |	nca: 1.3549340926110744, flat: 1.5343103855848312, pod: 27.62151038646698, loss: 30.510754942893982 
Train [4/26] | Epoch [105/160] |	nca: 1.287476934492588, flat: 1.4566801264882088, pod: 26.742039442062378, loss: 29.486196517944336 
Train [4/26] | Epoch [106/160] |	nca: 1.119020763784647, flat: 1.3658094368875027, pod: 25.223517656326294, loss: 27.70834791660309 
Train [4/26] | Epoch [107/160] |	nca: 1.268635168671608, flat: 1.3588078320026398, pod: 25.775856852531433, loss: 28.403299808502197 
Train [4/26] | Epoch [108/160] |	nca: 1.383164670318365, flat: 1.5918610766530037, pod: 29.34235644340515, loss: 32.31738209724426 
Train [4/26] | Epoch [109/160] |	nca: 1.2198072336614132, flat: 1.4159585908055305, pod: 26.642284631729126, loss: 29.278050541877747 
Train [4/26] | Epoch [110/160] |	nca: 1.176599059253931, flat: 1.3670556098222733, pod: 25.15505874156952, loss: 27.698713421821594 
Train [4/26] | Epoch [111/160] |	nca: 1.366516850888729, flat: 1.396420106291771, pod: 25.918755531311035, loss: 28.681692600250244 
Train [4/26] | Epoch [112/160] |	nca: 1.2562109753489494, flat: 1.3614297583699226, pod: 25.331079602241516, loss: 27.948720455169678 
Train [4/26] | Epoch [113/160] |	nca: 1.1438434720039368, flat: 1.2493071891367435, pod: 23.553854942321777, loss: 25.94700562953949 
Train [4/26] | Epoch [114/160] |	nca: 1.2230129316449165, flat: 1.2560226172208786, pod: 24.315999388694763, loss: 26.795034885406494 
Train [4/26] | Epoch [115/160] |	nca: 1.184664849191904, flat: 1.2436160631477833, pod: 23.937331080436707, loss: 26.365612030029297 
Train [4/26] | Epoch [116/160] |	nca: 1.1445910409092903, flat: 1.2002110704779625, pod: 23.218578457832336, loss: 25.56338059902191 
Train [4/26] | Epoch [117/160] |	nca: 1.4293358027935028, flat: 1.229516189545393, pod: 23.650538563728333, loss: 26.309390664100647 
Train [4/26] | Epoch [118/160] |	nca: 1.1151795201003551, flat: 1.1965172290802002, pod: 22.908893823623657, loss: 25.220590710639954 
Train [4/26] | Epoch [119/160] |	nca: 1.2910436391830444, flat: 1.2078433372080326, pod: 23.33234965801239, loss: 25.831236600875854 
Train [4/26] | Epoch [120/160] |	nca: 1.180990669876337, flat: 1.1673447489738464, pod: 22.678430199623108, loss: 25.02676570415497 
Train [4/26] | Epoch [121/160] |	nca: 1.212571818381548, flat: 1.2119652591645718, pod: 22.98932981491089, loss: 25.413866877555847 
Train [4/26] | Epoch [122/160] |	nca: 1.2110711820423603, flat: 1.224505640566349, pod: 23.26931881904602, loss: 25.704895853996277 
Train [4/26] | Epoch [123/160] |	nca: 1.1704067774116993, flat: 1.1593281254172325, pod: 23.670932054519653, loss: 26.000666975975037 
Train [4/26] | Epoch [124/160] |	nca: 1.237350519746542, flat: 1.0764935947954655, pod: 21.693254470825195, loss: 24.00709819793701 
Train [4/26] | Epoch [125/160] |	nca: 1.2292288169264793, flat: 1.0489174872636795, pod: 21.197306632995605, loss: 23.47545289993286 
Train [4/26] | Epoch [126/160] |	nca: 1.2601634562015533, flat: 1.1080408282577991, pod: 21.729647636413574, loss: 24.097851991653442 
Train [4/26] | Epoch [127/160] |	nca: 1.2941211014986038, flat: 1.0191859751939774, pod: 21.184193968772888, loss: 23.497500896453857 
Train [4/26] | Epoch [128/160] |	nca: 1.3003823533654213, flat: 1.064412735402584, pod: 21.33694040775299, loss: 23.701735615730286 
Train [4/26] | Epoch [129/160] |	nca: 1.1479333862662315, flat: 1.0054526627063751, pod: 20.623600602149963, loss: 22.776986479759216 
Train [4/26] | Epoch [130/160] |	nca: 1.1644187606871128, flat: 1.086215566843748, pod: 21.144388794898987, loss: 23.395023226737976 
Train [4/26] | Epoch [131/160] |	nca: 1.156593732535839, flat: 1.0367134101688862, pod: 20.47618329524994, loss: 22.669490456581116 
Train [4/26] | Epoch [132/160] |	nca: 1.1710089892148972, flat: 1.0262821801006794, pod: 21.22999656200409, loss: 23.427287817001343 
Train [4/26] | Epoch [133/160] |	nca: 1.234390452504158, flat: 1.0008767247200012, pod: 20.902769088745117, loss: 23.138036251068115 
Train [4/26] | Epoch [134/160] |	nca: 1.1274171844124794, flat: 0.9654455594718456, pod: 20.153842329978943, loss: 22.246704936027527 
Train [4/26] | Epoch [135/160] |	nca: 1.2923946678638458, flat: 1.0428248085081577, pod: 20.300321102142334, loss: 22.63554048538208 
Train [4/26] | Epoch [136/160] |	nca: 1.2625785246491432, flat: 1.07113566249609, pod: 21.44648551940918, loss: 23.780199885368347 
Train [4/26] | Epoch [137/160] |	nca: 1.2242095097899437, flat: 0.9935802146792412, pod: 19.844356298446655, loss: 22.06214588880539 
Train [4/26] | Epoch [138/160] |	nca: 1.2814048677682877, flat: 1.0101431906223297, pod: 20.17991429567337, loss: 22.47146224975586 
Train [4/26] | Epoch [139/160] |	nca: 1.257791195064783, flat: 0.9685636721551418, pod: 20.693642377853394, loss: 22.919997334480286 
Train [4/26] | Epoch [140/160] |	nca: 1.0728340074419975, flat: 0.8707418665289879, pod: 18.66241580247879, loss: 20.60599184036255 
Train [4/26] | Epoch [141/160] |	nca: 1.2620876766741276, flat: 0.927871897816658, pod: 18.87643724679947, loss: 21.06639665365219 
Train [4/26] | Epoch [142/160] |	nca: 1.0855065621435642, flat: 0.9102797769010067, pod: 19.349419116973877, loss: 21.345205307006836 
Train [4/26] | Epoch [143/160] |	nca: 1.3167595863342285, flat: 0.9102691859006882, pod: 18.98353284597397, loss: 21.210561633110046 
Train [4/26] | Epoch [144/160] |	nca: 1.1732431277632713, flat: 0.847548633813858, pod: 17.793095588684082, loss: 19.813887417316437 
Train [4/26] | Epoch [145/160] |	nca: 1.3328283093869686, flat: 0.8345623686909676, pod: 18.329449772834778, loss: 20.496840357780457 
Train [4/26] | Epoch [146/160] |	nca: 1.0978513471782207, flat: 0.8956701345741749, pod: 18.590875208377838, loss: 20.584396481513977 
Train [4/26] | Epoch [147/160] |	nca: 1.150320053100586, flat: 0.8638215474784374, pod: 18.608458995819092, loss: 20.622600376605988 
Train [4/26] | Epoch [148/160] |	nca: 1.231292001903057, flat: 0.9536768645048141, pod: 19.832933247089386, loss: 22.017902135849 
Train [4/26] | Epoch [149/160] |	nca: 1.2587455064058304, flat: 0.8425888940691948, pod: 17.259102940559387, loss: 19.36043745279312 
Train [4/26] | Epoch [150/160] |	nca: 1.0273318942636251, flat: 0.8259000554680824, pod: 17.659576952457428, loss: 19.512808978557587 
Train [4/26] | Epoch [151/160] |	nca: 1.1729459390044212, flat: 0.8141577802598476, pod: 17.220055043697357, loss: 19.207158625125885 
Train [4/26] | Epoch [152/160] |	nca: 1.1325461082160473, flat: 0.8235778510570526, pod: 18.025642096996307, loss: 19.98176634311676 
Train [4/26] | Epoch [153/160] |	nca: 1.1121840626001358, flat: 0.7917258813977242, pod: 17.706947684288025, loss: 19.610857605934143 
Train [4/26] | Epoch [154/160] |	nca: 1.1649371944367886, flat: 0.8310711197555065, pod: 17.018890500068665, loss: 19.014899134635925 
Train [4/26] | Epoch [155/160] |	nca: 1.0658105574548244, flat: 0.816763773560524, pod: 17.304745197296143, loss: 19.18731963634491 
Train [4/26] | Epoch [156/160] |	nca: 1.2836377322673798, flat: 0.8988455794751644, pod: 17.412913143634796, loss: 19.59539645910263 
Train [4/26] | Epoch [157/160] |	nca: 1.2494726479053497, flat: 0.8237376287579536, pod: 17.300375759601593, loss: 19.37358593940735 
Train [4/26] | Epoch [158/160] |	nca: 1.128762673586607, flat: 0.789273340255022, pod: 17.07240056991577, loss: 18.990436613559723 
Train [4/26] | Epoch [159/160] |	nca: 1.1569377966225147, flat: 0.8901768065989017, pod: 17.65620219707489, loss: 19.703316867351532 
Train [4/26] | Epoch [160/160] |	nca: 1.1280984692275524, flat: 0.8446741029620171, pod: 18.13259243965149, loss: 20.10536515712738 
Fine-tuning
Building & updating memory.
Train [4/26] | Epoch [161/180] |	nca: 3.91539566218853, flat: 2.3635680079460144, pod: 26.27745532989502, loss: 32.556418657302856 
Train [4/26] | Epoch [162/180] |	nca: 1.184975765645504, flat: 2.338096931576729, pod: 26.469781160354614, loss: 29.99285364151001 
Train [4/26] | Epoch [163/180] |	nca: 0.7714563794434071, flat: 2.3294641375541687, pod: 26.37844181060791, loss: 29.47936248779297 
Train [4/26] | Epoch [164/180] |	nca: 0.7183729521930218, flat: 2.3574508875608444, pod: 26.1798255443573, loss: 29.25564956665039 
Train [4/26] | Epoch [165/180] |	nca: 0.5607876628637314, flat: 2.330349698662758, pod: 26.02424454689026, loss: 28.91538166999817 
Train [4/26] | Epoch [166/180] |	nca: 0.4865783751010895, flat: 2.2690210789442062, pod: 25.8372323513031, loss: 28.59283208847046 
Train [4/26] | Epoch [167/180] |	nca: 0.5067589245736599, flat: 2.2975875437259674, pod: 26.082732915878296, loss: 28.88707971572876 
Train [4/26] | Epoch [168/180] |	nca: 0.4568192660808563, flat: 2.3736050873994827, pod: 26.577154874801636, loss: 29.40757966041565 
Train [4/26] | Epoch [169/180] |	nca: 0.5414625070989132, flat: 2.331475645303726, pod: 26.377711057662964, loss: 29.25064969062805 
Train [4/26] | Epoch [170/180] |	nca: 0.46496615558862686, flat: 2.376669481396675, pod: 26.55181050300598, loss: 29.39344596862793 
Train [4/26] | Epoch [171/180] |	nca: 0.39762704260647297, flat: 2.3105495125055313, pod: 26.07942032814026, loss: 28.787597179412842 
Train [4/26] | Epoch [172/180] |	nca: 0.40265458822250366, flat: 2.344725266098976, pod: 26.241189002990723, loss: 28.988568782806396 
Train [4/26] | Epoch [173/180] |	nca: 0.3965653069317341, flat: 2.368777856230736, pod: 26.53620457649231, loss: 29.301547527313232 
Train [4/26] | Epoch [174/180] |	nca: 0.4003402888774872, flat: 2.3347248435020447, pod: 26.25802254676819, loss: 28.993087768554688 
Train [4/26] | Epoch [175/180] |	nca: 0.405665785074234, flat: 2.3036085665225983, pod: 26.37860369682312, loss: 29.087877988815308 
Train [4/26] | Epoch [176/180] |	nca: 0.4061006046831608, flat: 2.3490528762340546, pod: 26.2884464263916, loss: 29.043599605560303 
Train [4/26] | Epoch [177/180] |	nca: 0.3755900841206312, flat: 2.40627358853817, pod: 26.79266667366028, loss: 29.574530363082886 
Train [4/26] | Epoch [178/180] |	nca: 0.37934147007763386, flat: 2.28975947201252, pod: 26.285907983779907, loss: 28.955008506774902 
Train [4/26] | Epoch [179/180] |	nca: 0.37118582241237164, flat: 2.3899221420288086, pod: 26.65083932876587, loss: 29.411947011947632 
Train [4/26] | Epoch [180/180] |	nca: 0.4109180085361004, flat: 2.351889729499817, pod: 26.819842100143433, loss: 29.58264994621277 
after task
Building & updating memory.
after task
Eval on 0->56.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.7250000000000001.
Current acc: {'total': 0.687, '00-09': 0.754, '10-19': 0.699, '20-29': 0.634, '30-39': 0.661, '40-49': 0.706, '50-59': 0.655}.
Avg inc acc top5: 0.923.
Current acc top5: {'total': 0.899}.
Forgetting: 0.05257142857142857.
Cord metric: 0.72.
Old accuracy: 0.68, mean: 0.72.
New accuracy: 0.79, mean: 0.71.
================Task 4 Start!================
Testing on False unseen tasks (max class = 58).
Set memory of size: 1120.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 4 Training!================
The training samples number: 2120
Train on 56->58.
train task
nb 2120.
Train [5/26] | Epoch [1/160] |	nca: 4.865972921252251, flat: 2.962940528988838, pod: 39.75645923614502, loss: 47.58537292480469 
Train [5/26] | Epoch [2/160] |	nca: 3.135031081736088, flat: 4.022975742816925, pod: 48.07739996910095, loss: 55.23540687561035 
Train [5/26] | Epoch [3/160] |	nca: 2.676277816295624, flat: 3.9466301798820496, pod: 47.52514433860779, loss: 54.14805197715759 
Train [5/26] | Epoch [4/160] |	nca: 2.222271613776684, flat: 3.695854678750038, pod: 46.95806097984314, loss: 52.87618708610535 
Train [5/26] | Epoch [5/160] |	nca: 2.0936169028282166, flat: 3.2320473939180374, pod: 43.46726870536804, loss: 48.792932987213135 
Train [5/26] | Epoch [6/160] |	nca: 2.3521256744861603, flat: 3.7592222690582275, pod: 46.768776178359985, loss: 52.88012385368347 
Train [5/26] | Epoch [7/160] |	nca: 2.056853085756302, flat: 3.5020038336515427, pod: 45.82339668273926, loss: 51.38225340843201 
Train [5/26] | Epoch [8/160] |	nca: 2.013252053409815, flat: 3.3078954368829727, pod: 44.63617706298828, loss: 49.957324504852295 
Train [5/26] | Epoch [9/160] |	nca: 1.5332909226417542, flat: 2.948819011449814, pod: 41.344393491744995, loss: 45.82650279998779 
Train [5/26] | Epoch [10/160] |	nca: 1.7458692640066147, flat: 2.9951646476984024, pod: 43.36599802970886, loss: 48.10703182220459 
Train [5/26] | Epoch [11/160] |	nca: 1.785198725759983, flat: 3.020922377705574, pod: 42.82684922218323, loss: 47.632970571517944 
Train [5/26] | Epoch [12/160] |	nca: 1.5613852627575397, flat: 2.7612157464027405, pod: 39.69797134399414, loss: 44.020572662353516 
Train [5/26] | Epoch [13/160] |	nca: 1.81276261433959, flat: 2.7508816868066788, pod: 40.20217704772949, loss: 44.76582169532776 
Train [5/26] | Epoch [14/160] |	nca: 1.5292377211153507, flat: 2.9444659650325775, pod: 43.31536364555359, loss: 47.78906750679016 
Train [5/26] | Epoch [15/160] |	nca: 1.4961956702172756, flat: 2.812897205352783, pod: 41.220685720443726, loss: 45.529778718948364 
Train [5/26] | Epoch [16/160] |	nca: 1.5013190992176533, flat: 2.747080445289612, pod: 41.182292461395264, loss: 45.430691719055176 
Train [5/26] | Epoch [17/160] |	nca: 1.7981188669800758, flat: 3.051013171672821, pod: 43.239046573638916, loss: 48.088178634643555 
Train [5/26] | Epoch [18/160] |	nca: 1.8553286269307137, flat: 3.0268227607011795, pod: 42.51425862312317, loss: 47.39641046524048 
Train [5/26] | Epoch [19/160] |	nca: 1.4026238024234772, flat: 2.883788913488388, pod: 42.710461139678955, loss: 46.99687385559082 
Train [5/26] | Epoch [20/160] |	nca: 1.433833584189415, flat: 2.6082812398672104, pod: 38.84032416343689, loss: 42.88243889808655 
Train [5/26] | Epoch [21/160] |	nca: 1.4024012088775635, flat: 2.664205387234688, pod: 39.587902545928955, loss: 43.65450978279114 
Train [5/26] | Epoch [22/160] |	nca: 1.4791009351611137, flat: 2.5318137258291245, pod: 39.545576095581055, loss: 43.5564911365509 
Train [5/26] | Epoch [23/160] |	nca: 1.6251771412789822, flat: 2.6968685537576675, pod: 40.70768117904663, loss: 45.02972674369812 
Train [5/26] | Epoch [24/160] |	nca: 1.6051576174795628, flat: 2.750296652317047, pod: 40.39792799949646, loss: 44.75338268280029 
Train [5/26] | Epoch [25/160] |	nca: 1.5034773834049702, flat: 2.7998540699481964, pod: 42.19720268249512, loss: 46.500534534454346 
Train [5/26] | Epoch [26/160] |	nca: 1.450407549738884, flat: 2.684285670518875, pod: 39.7495698928833, loss: 43.88426351547241 
Train [5/26] | Epoch [27/160] |	nca: 1.3580311313271523, flat: 2.428318239748478, pod: 37.1537389755249, loss: 40.940088510513306 
Train [5/26] | Epoch [28/160] |	nca: 1.5783690810203552, flat: 2.570148602128029, pod: 39.59961199760437, loss: 43.74812984466553 
Train [5/26] | Epoch [29/160] |	nca: 1.6744720339775085, flat: 2.833331510424614, pod: 41.252668142318726, loss: 45.7604718208313 
Train [5/26] | Epoch [30/160] |	nca: 1.416169699281454, flat: 2.655502960085869, pod: 40.110556840896606, loss: 44.1822292804718 
Train [5/26] | Epoch [31/160] |	nca: 1.2457608468830585, flat: 2.5128098726272583, pod: 39.63707184791565, loss: 43.39564275741577 
Train [5/26] | Epoch [32/160] |	nca: 1.3440589979290962, flat: 2.353419706225395, pod: 37.051433086395264, loss: 40.74891209602356 
Train [5/26] | Epoch [33/160] |	nca: 1.3590709455311298, flat: 2.420224405825138, pod: 38.25778818130493, loss: 42.03708338737488 
Train [5/26] | Epoch [34/160] |	nca: 1.3279096819460392, flat: 2.322734758257866, pod: 36.69999325275421, loss: 40.350637435913086 
Train [5/26] | Epoch [35/160] |	nca: 1.4014114029705524, flat: 2.5062964409589767, pod: 38.69613170623779, loss: 42.60383939743042 
Train [5/26] | Epoch [36/160] |	nca: 1.5035797208547592, flat: 2.509672410786152, pod: 38.005340695381165, loss: 42.01859259605408 
Train [5/26] | Epoch [37/160] |	nca: 1.3541848100721836, flat: 2.510515436530113, pod: 39.13867235183716, loss: 43.00337243080139 
Train [5/26] | Epoch [38/160] |	nca: 1.2284056767821312, flat: 2.4055092334747314, pod: 38.26458168029785, loss: 41.89849662780762 
Train [5/26] | Epoch [39/160] |	nca: 1.274920828640461, flat: 2.465822219848633, pod: 38.287542939186096, loss: 42.02828598022461 
Train [5/26] | Epoch [40/160] |	nca: 1.4325669035315514, flat: 2.390517011284828, pod: 36.90483617782593, loss: 40.727920055389404 
Train [5/26] | Epoch [41/160] |	nca: 1.2494953647255898, flat: 2.227973200380802, pod: 37.30895721912384, loss: 40.786426067352295 
Train [5/26] | Epoch [42/160] |	nca: 1.5256068706512451, flat: 2.3436388596892357, pod: 37.09532928466797, loss: 40.96457481384277 
Train [5/26] | Epoch [43/160] |	nca: 1.2407710254192352, flat: 2.294958084821701, pod: 37.64150810241699, loss: 41.17723774909973 
Train [5/26] | Epoch [44/160] |	nca: 1.2656965851783752, flat: 2.3511475771665573, pod: 37.632694721221924, loss: 41.24953866004944 
Train [5/26] | Epoch [45/160] |	nca: 1.2908580526709557, flat: 2.288384571671486, pod: 37.41905605792999, loss: 40.99829864501953 
Train [5/26] | Epoch [46/160] |	nca: 1.4954846128821373, flat: 2.2936438992619514, pod: 37.15697169303894, loss: 40.94609999656677 
Train [5/26] | Epoch [47/160] |	nca: 1.3611886091530323, flat: 2.329357624053955, pod: 36.65473973751068, loss: 40.34528565406799 
Train [5/26] | Epoch [48/160] |	nca: 1.4738207086920738, flat: 2.3962620943784714, pod: 37.59985423088074, loss: 41.469937324523926 
Train [5/26] | Epoch [49/160] |	nca: 1.574039675295353, flat: 2.550614431500435, pod: 39.38866066932678, loss: 43.513314723968506 
Train [5/26] | Epoch [50/160] |	nca: 1.5975845344364643, flat: 2.626559257507324, pod: 39.77374267578125, loss: 43.997885942459106 
Train [5/26] | Epoch [51/160] |	nca: 1.293869536370039, flat: 2.4723896831274033, pod: 38.30065846443176, loss: 42.06691765785217 
Train [5/26] | Epoch [52/160] |	nca: 1.163298338651657, flat: 2.0706886872649193, pod: 34.7190797328949, loss: 37.95306658744812 
Train [5/26] | Epoch [53/160] |	nca: 1.3223255202174187, flat: 2.13905943185091, pod: 36.21052420139313, loss: 39.67190933227539 
Train [5/26] | Epoch [54/160] |	nca: 1.1933818738907576, flat: 2.1454904600977898, pod: 35.7153285741806, loss: 39.054200649261475 
Train [5/26] | Epoch [55/160] |	nca: 1.1565614081919193, flat: 2.169334463775158, pod: 36.471250891685486, loss: 39.7971465587616 
Train [5/26] | Epoch [56/160] |	nca: 1.543928861618042, flat: 2.1303114220499992, pod: 36.484416246414185, loss: 40.15865635871887 
Train [5/26] | Epoch [57/160] |	nca: 1.4623042345046997, flat: 2.2417173609137535, pod: 36.467540979385376, loss: 40.17156267166138 
Train [5/26] | Epoch [58/160] |	nca: 1.2120666727423668, flat: 2.3527988344430923, pod: 37.68499207496643, loss: 41.249857902526855 
Train [5/26] | Epoch [59/160] |	nca: 1.3451728112995625, flat: 2.285423181951046, pod: 38.1546356678009, loss: 41.785231590270996 
Train [5/26] | Epoch [60/160] |	nca: 1.3430578224360943, flat: 1.9963847696781158, pod: 34.026248812675476, loss: 37.36569130420685 
Train [5/26] | Epoch [61/160] |	nca: 1.153125036507845, flat: 2.043110117316246, pod: 34.802040696144104, loss: 37.99827527999878 
Train [5/26] | Epoch [62/160] |	nca: 1.21086685359478, flat: 1.9442460387945175, pod: 34.10064494609833, loss: 37.25575792789459 
Train [5/26] | Epoch [63/160] |	nca: 1.318997085094452, flat: 1.9377330988645554, pod: 33.30067193508148, loss: 36.55740237236023 
Train [5/26] | Epoch [64/160] |	nca: 1.2816586084663868, flat: 2.0432307347655296, pod: 35.428863644599915, loss: 38.75375270843506 
Train [5/26] | Epoch [65/160] |	nca: 1.2054564617574215, flat: 2.1338999792933464, pod: 36.059929728507996, loss: 39.39928650856018 
Train [5/26] | Epoch [66/160] |	nca: 1.4446347393095493, flat: 2.1007151380181313, pod: 36.38093090057373, loss: 39.92628073692322 
Train [5/26] | Epoch [67/160] |	nca: 1.2194864340126514, flat: 2.0360700488090515, pod: 34.623101115226746, loss: 37.878657817840576 
Train [5/26] | Epoch [68/160] |	nca: 1.3273824453353882, flat: 2.114157311618328, pod: 36.33367609977722, loss: 39.7752161026001 
Train [5/26] | Epoch [69/160] |	nca: 1.1525115184485912, flat: 2.01774013787508, pod: 33.461063623428345, loss: 36.63131487369537 
Train [5/26] | Epoch [70/160] |	nca: 1.2528351433575153, flat: 1.8401402160525322, pod: 32.74984133243561, loss: 35.8428168296814 
Train [5/26] | Epoch [71/160] |	nca: 1.1230660304427147, flat: 1.6949774473905563, pod: 31.93545699119568, loss: 34.75350081920624 
Train [5/26] | Epoch [72/160] |	nca: 1.1938613504171371, flat: 1.864515632390976, pod: 34.09552752971649, loss: 37.15390431880951 
Train [5/26] | Epoch [73/160] |	nca: 1.3278443366289139, flat: 1.9248021319508553, pod: 33.93908190727234, loss: 37.1917290687561 
Train [5/26] | Epoch [74/160] |	nca: 1.1136562898755074, flat: 1.8523496612906456, pod: 32.278250336647034, loss: 35.24425649642944 
Train [5/26] | Epoch [75/160] |	nca: 1.2237410433590412, flat: 1.8581179901957512, pod: 32.63323640823364, loss: 35.71509552001953 
Train [5/26] | Epoch [76/160] |	nca: 1.1008605137467384, flat: 1.6658273488283157, pod: 31.56702697277069, loss: 34.333714842796326 
Train [5/26] | Epoch [77/160] |	nca: 1.2481336779892445, flat: 1.6605149134993553, pod: 31.492720007896423, loss: 34.40136897563934 
Train [5/26] | Epoch [78/160] |	nca: 1.1188917234539986, flat: 1.8419341668486595, pod: 34.58074367046356, loss: 37.54156947135925 
Train [5/26] | Epoch [79/160] |	nca: 1.1992466002702713, flat: 1.847923882305622, pod: 33.21479535102844, loss: 36.26196587085724 
Train [5/26] | Epoch [80/160] |	nca: 1.1724474914371967, flat: 1.8002122640609741, pod: 32.42233169078827, loss: 35.39499127864838 
Train [5/26] | Epoch [81/160] |	nca: 1.3536170236766338, flat: 1.6677009984850883, pod: 31.349188089370728, loss: 34.370506167411804 
Train [5/26] | Epoch [82/160] |	nca: 1.124283343553543, flat: 1.6967506408691406, pod: 31.43568444252014, loss: 34.25671851634979 
Train [5/26] | Epoch [83/160] |	nca: 1.2104557044804096, flat: 1.587908960878849, pod: 30.24708318710327, loss: 33.04544818401337 
Train [5/26] | Epoch [84/160] |	nca: 1.0815715715289116, flat: 1.549651101231575, pod: 30.968860983848572, loss: 33.60008370876312 
Train [5/26] | Epoch [85/160] |	nca: 1.1377993300557137, flat: 1.5185173153877258, pod: 30.12992525100708, loss: 32.78624176979065 
Train [5/26] | Epoch [86/160] |	nca: 1.0192157924175262, flat: 1.439653292298317, pod: 28.07745373249054, loss: 30.536323070526123 
Train [5/26] | Epoch [87/160] |	nca: 1.255721740424633, flat: 1.5018782690167427, pod: 28.75445246696472, loss: 31.512052297592163 
Train [5/26] | Epoch [88/160] |	nca: 1.2244294174015522, flat: 1.4860683903098106, pod: 30.15567445755005, loss: 32.866172432899475 
Train [5/26] | Epoch [89/160] |	nca: 1.1095353811979294, flat: 1.5311909019947052, pod: 30.162558555603027, loss: 32.803284883499146 
Train [5/26] | Epoch [90/160] |	nca: 1.3090606518089771, flat: 1.6797584742307663, pod: 31.09628677368164, loss: 34.085105657577515 
Train [5/26] | Epoch [91/160] |	nca: 1.190782692283392, flat: 1.454787127673626, pod: 29.115912079811096, loss: 31.761481642723083 
Train [5/26] | Epoch [92/160] |	nca: 1.1459007561206818, flat: 1.53580342233181, pod: 29.499160885810852, loss: 32.18086493015289 
Train [5/26] | Epoch [93/160] |	nca: 1.210768599063158, flat: 1.4727345034480095, pod: 29.573346734046936, loss: 32.25684976577759 
Train [5/26] | Epoch [94/160] |	nca: 1.1548631899058819, flat: 1.4493239596486092, pod: 28.84742760658264, loss: 31.45161473751068 
Train [5/26] | Epoch [95/160] |	nca: 1.0877708066254854, flat: 1.4193848296999931, pod: 29.16741693019867, loss: 31.674572587013245 
Train [5/26] | Epoch [96/160] |	nca: 1.0760734230279922, flat: 1.4961472898721695, pod: 29.361688256263733, loss: 31.93390929698944 
Train [5/26] | Epoch [97/160] |	nca: 1.067401446402073, flat: 1.3643714860081673, pod: 28.402884006500244, loss: 30.834656715393066 
Train [5/26] | Epoch [98/160] |	nca: 1.1817155294120312, flat: 1.3848681151866913, pod: 26.889873504638672, loss: 29.456457257270813 
Train [5/26] | Epoch [99/160] |	nca: 1.0726963616907597, flat: 1.328553695231676, pod: 27.352795243263245, loss: 29.754045248031616 
Train [5/26] | Epoch [100/160] |	nca: 1.0365167260169983, flat: 1.22633982822299, pod: 25.511975526809692, loss: 27.774832010269165 
Train [5/26] | Epoch [101/160] |	nca: 0.991759430617094, flat: 1.2017648220062256, pod: 25.701096534729004, loss: 27.894620895385742 
Train [5/26] | Epoch [102/160] |	nca: 1.2562230192124844, flat: 1.2740072757005692, pod: 26.96847891807556, loss: 29.498709201812744 
Train [5/26] | Epoch [103/160] |	nca: 1.0465194769203663, flat: 1.2223453111946583, pod: 26.554881811141968, loss: 28.8237464427948 
Train [5/26] | Epoch [104/160] |	nca: 1.0619756020605564, flat: 1.1691293753683567, pod: 25.264678359031677, loss: 27.49578320980072 
Train [5/26] | Epoch [105/160] |	nca: 1.2566498182713985, flat: 1.2468094229698181, pod: 26.233150005340576, loss: 28.73660945892334 
Train [5/26] | Epoch [106/160] |	nca: 1.0515078008174896, flat: 1.1918348371982574, pod: 26.164026141166687, loss: 28.407368898391724 
Train [5/26] | Epoch [107/160] |	nca: 1.0171399042010307, flat: 1.122928399592638, pod: 25.581002831459045, loss: 27.721071124076843 
Train [5/26] | Epoch [108/160] |	nca: 1.0868106372654438, flat: 1.112757097929716, pod: 24.974101662635803, loss: 27.173669457435608 
Train [5/26] | Epoch [109/160] |	nca: 1.0313336104154587, flat: 1.1910245306789875, pod: 26.79194140434265, loss: 29.014299511909485 
Train [5/26] | Epoch [110/160] |	nca: 1.1566544584929943, flat: 1.1503762602806091, pod: 25.63578975200653, loss: 27.94282066822052 
Train [5/26] | Epoch [111/160] |	nca: 1.0654752887785435, flat: 1.110344659537077, pod: 25.293398141860962, loss: 27.469218134880066 
Train [5/26] | Epoch [112/160] |	nca: 1.0846351459622383, flat: 1.1334242895245552, pod: 26.151500701904297, loss: 28.36956036090851 
Train [5/26] | Epoch [113/160] |	nca: 1.1072397343814373, flat: 1.0852752849459648, pod: 24.947449445724487, loss: 27.13996434211731 
Train [5/26] | Epoch [114/160] |	nca: 1.0329641588032246, flat: 1.1222869977355003, pod: 24.89036989212036, loss: 27.045621156692505 
Train [5/26] | Epoch [115/160] |	nca: 1.1900140456855297, flat: 1.0340425744652748, pod: 23.694438815116882, loss: 25.918495416641235 
Train [5/26] | Epoch [116/160] |	nca: 1.0894230864942074, flat: 0.9736205562949181, pod: 23.55029571056366, loss: 25.61333954334259 
Train [5/26] | Epoch [117/160] |	nca: 1.0225498229265213, flat: 0.9698526374995708, pod: 22.365023374557495, loss: 24.357425808906555 
Train [5/26] | Epoch [118/160] |	nca: 1.1663890704512596, flat: 1.0129210762679577, pod: 23.772330284118652, loss: 25.951640486717224 
Train [5/26] | Epoch [119/160] |	nca: 1.0703576747328043, flat: 0.9903748817741871, pod: 23.030290007591248, loss: 25.091022729873657 
Train [5/26] | Epoch [120/160] |	nca: 1.1397960111498833, flat: 0.9781675338745117, pod: 22.270925045013428, loss: 24.388888478279114 
Train [5/26] | Epoch [121/160] |	nca: 1.1170016825199127, flat: 0.940081350505352, pod: 22.343272924423218, loss: 24.40035593509674 
Train [5/26] | Epoch [122/160] |	nca: 1.016556166112423, flat: 1.0281588397920132, pod: 23.795907616615295, loss: 25.840622663497925 
Train [5/26] | Epoch [123/160] |	nca: 1.0234851576387882, flat: 0.9080523513257504, pod: 22.718869924545288, loss: 24.650407552719116 
Train [5/26] | Epoch [124/160] |	nca: 1.0352798253297806, flat: 0.9145551025867462, pod: 22.534347534179688, loss: 24.484182715415955 
Train [5/26] | Epoch [125/160] |	nca: 1.161299455910921, flat: 0.9429172985255718, pod: 22.44002616405487, loss: 24.54424285888672 
Train [5/26] | Epoch [126/160] |	nca: 1.0135882310569286, flat: 0.9046860001981258, pod: 22.04579246044159, loss: 23.96406650543213 
Train [5/26] | Epoch [127/160] |	nca: 1.0501513965427876, flat: 0.8465376012027264, pod: 21.52128517627716, loss: 23.41797435283661 
Train [5/26] | Epoch [128/160] |	nca: 0.9789417609572411, flat: 0.804331585764885, pod: 19.722906410694122, loss: 21.506179690361023 
Train [5/26] | Epoch [129/160] |	nca: 1.0948480144143105, flat: 0.845609150826931, pod: 21.42772912979126, loss: 23.368186116218567 
Train [5/26] | Epoch [130/160] |	nca: 1.0444168411195278, flat: 0.8567907884716988, pod: 22.092236280441284, loss: 23.993443846702576 
Train [5/26] | Epoch [131/160] |	nca: 1.0852717012166977, flat: 0.7889732234179974, pod: 20.180902779102325, loss: 22.055147647857666 
Train [5/26] | Epoch [132/160] |	nca: 1.080370344221592, flat: 0.8398249335587025, pod: 21.48354434967041, loss: 23.40373957157135 
Train [5/26] | Epoch [133/160] |	nca: 1.0828244909644127, flat: 0.8660134896636009, pod: 21.86981964111328, loss: 23.818657636642456 
Train [5/26] | Epoch [134/160] |	nca: 1.04210652038455, flat: 0.8120396547019482, pod: 20.566633224487305, loss: 22.420779585838318 
Train [5/26] | Epoch [135/160] |	nca: 1.0039981678128242, flat: 0.7860657311975956, pod: 20.075047552585602, loss: 21.865111470222473 
Train [5/26] | Epoch [136/160] |	nca: 1.063463769853115, flat: 0.8093746937811375, pod: 20.4065762758255, loss: 22.279414653778076 
Train [5/26] | Epoch [137/160] |	nca: 0.9734788537025452, flat: 0.7156375125050545, pod: 19.562530159950256, loss: 21.251646637916565 
Train [5/26] | Epoch [138/160] |	nca: 0.982286561280489, flat: 0.7792472317814827, pod: 19.327954053878784, loss: 21.08948791027069 
Train [5/26] | Epoch [139/160] |	nca: 1.089749500155449, flat: 0.7820821180939674, pod: 19.63444983959198, loss: 21.50628161430359 
Train [5/26] | Epoch [140/160] |	nca: 1.1134599708020687, flat: 0.7332996018230915, pod: 18.913860261440277, loss: 20.76061975955963 
Train [5/26] | Epoch [141/160] |	nca: 1.0649961940944195, flat: 0.752346720546484, pod: 19.3937286734581, loss: 21.211071372032166 
Train [5/26] | Epoch [142/160] |	nca: 1.0063737109303474, flat: 0.742595512419939, pod: 19.288953483104706, loss: 21.037922620773315 
Train [5/26] | Epoch [143/160] |	nca: 1.0578562542796135, flat: 0.7344188615679741, pod: 18.282714784145355, loss: 20.074989914894104 
Train [5/26] | Epoch [144/160] |	nca: 1.0022988244891167, flat: 0.7184533812105656, pod: 18.96272772550583, loss: 20.683480083942413 
Train [5/26] | Epoch [145/160] |	nca: 1.045864850282669, flat: 0.6798557005822659, pod: 18.431395173072815, loss: 20.157115936279297 
Train [5/26] | Epoch [146/160] |	nca: 1.10597138479352, flat: 0.6651228945702314, pod: 17.936919271945953, loss: 19.708013832569122 
Train [5/26] | Epoch [147/160] |	nca: 1.0660299845039845, flat: 0.6692642830312252, pod: 18.023704409599304, loss: 19.758998572826385 
Train [5/26] | Epoch [148/160] |	nca: 0.97155387327075, flat: 0.661802789196372, pod: 17.477034211158752, loss: 19.110390782356262 
Train [5/26] | Epoch [149/160] |	nca: 1.073806345462799, flat: 0.6703575439751148, pod: 17.603603065013885, loss: 19.34776681661606 
Train [5/26] | Epoch [150/160] |	nca: 1.0124954655766487, flat: 0.6425640247762203, pod: 17.137304663658142, loss: 18.792364239692688 
Train [5/26] | Epoch [151/160] |	nca: 1.048525620251894, flat: 0.6427135039120913, pod: 17.282191574573517, loss: 18.9734308719635 
Train [5/26] | Epoch [152/160] |	nca: 1.0158446356654167, flat: 0.6384158488363028, pod: 17.261594533920288, loss: 18.915854930877686 
Train [5/26] | Epoch [153/160] |	nca: 0.9847624599933624, flat: 0.6092767808586359, pod: 16.49052208662033, loss: 18.08456128835678 
Train [5/26] | Epoch [154/160] |	nca: 1.0552131682634354, flat: 0.7386246919631958, pod: 18.477243721485138, loss: 20.271081566810608 
Train [5/26] | Epoch [155/160] |	nca: 0.981026217341423, flat: 0.6181821338832378, pod: 17.24045979976654, loss: 18.839668095111847 
Train [5/26] | Epoch [156/160] |	nca: 0.9891218803822994, flat: 0.6194809898734093, pod: 16.50210726261139, loss: 18.110709965229034 
Train [5/26] | Epoch [157/160] |	nca: 1.0220538787543774, flat: 0.6532740779221058, pod: 16.675469875335693, loss: 18.350797832012177 
Train [5/26] | Epoch [158/160] |	nca: 1.0341692715883255, flat: 0.6343573722988367, pod: 16.388889253139496, loss: 18.05741596221924 
Train [5/26] | Epoch [159/160] |	nca: 1.0037051551043987, flat: 0.6208677385002375, pod: 16.52094829082489, loss: 18.145521461963654 
Train [5/26] | Epoch [160/160] |	nca: 1.0095825754106045, flat: 0.640714580193162, pod: 17.22812396287918, loss: 18.878421247005463 
Fine-tuning
Building & updating memory.
Train [5/26] | Epoch [161/180] |	nca: 2.578943081200123, flat: 2.085916191339493, pod: 24.164451360702515, loss: 28.829310417175293 
Train [5/26] | Epoch [162/180] |	nca: 2.4337360709905624, flat: 2.360339939594269, pod: 24.74778985977173, loss: 29.541866064071655 
Train [5/26] | Epoch [163/180] |	nca: 2.229848973453045, flat: 1.9495275914669037, pod: 23.678290843963623, loss: 27.857667684555054 
Train [5/26] | Epoch [164/180] |	nca: 2.0331911593675613, flat: 2.198392629623413, pod: 23.938641905784607, loss: 28.170225620269775 
Train [5/26] | Epoch [165/180] |	nca: 1.839181788265705, flat: 2.008127361536026, pod: 23.96695590019226, loss: 27.81426501274109 
Train [5/26] | Epoch [166/180] |	nca: 1.3247640654444695, flat: 2.1375052630901337, pod: 24.670228004455566, loss: 28.132497310638428 
Train [5/26] | Epoch [167/180] |	nca: 2.1529010608792305, flat: 2.5637055188417435, pod: 27.200999855995178, loss: 31.917606592178345 
Train [5/26] | Epoch [168/180] |	nca: 1.6143342107534409, flat: 2.361738607287407, pod: 24.469356775283813, loss: 28.445429801940918 
Train [5/26] | Epoch [169/180] |	nca: 1.7831857800483704, flat: 2.2918800711631775, pod: 25.405166625976562, loss: 29.48023247718811 
Train [5/26] | Epoch [170/180] |	nca: 1.456611379981041, flat: 2.2039872258901596, pod: 24.18800687789917, loss: 27.848605632781982 
Train [5/26] | Epoch [171/180] |	nca: 1.4035101383924484, flat: 2.333332911133766, pod: 25.04201650619507, loss: 28.77885937690735 
Train [5/26] | Epoch [172/180] |	nca: 1.3843815997242928, flat: 2.072304055094719, pod: 24.5511257648468, loss: 28.007811069488525 
Train [5/26] | Epoch [173/180] |	nca: 1.7239233031868935, flat: 2.34864142537117, pod: 24.354188442230225, loss: 28.426753044128418 
Train [5/26] | Epoch [174/180] |	nca: 1.9068752750754356, flat: 2.558755747973919, pod: 25.348910808563232, loss: 29.814541578292847 
Train [5/26] | Epoch [175/180] |	nca: 1.730651244521141, flat: 2.1449815034866333, pod: 24.72806692123413, loss: 28.603699922561646 
Train [5/26] | Epoch [176/180] |	nca: 1.885070376098156, flat: 2.063813492655754, pod: 24.507773876190186, loss: 28.456657886505127 
Train [5/26] | Epoch [177/180] |	nca: 1.6390134319663048, flat: 2.0266769230365753, pod: 24.02631449699402, loss: 27.692005395889282 
Train [5/26] | Epoch [178/180] |	nca: 1.2108183354139328, flat: 2.377801150083542, pod: 25.28187918663025, loss: 28.870498657226562 
Train [5/26] | Epoch [179/180] |	nca: 1.7862739488482475, flat: 2.299339681863785, pod: 25.01726472377777, loss: 29.10287857055664 
Train [5/26] | Epoch [180/180] |	nca: 1.306537352502346, flat: 2.3968138098716736, pod: 25.765867352485657, loss: 29.469218254089355 
after task
Building & updating memory.
after task
Eval on 0->58.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.7116.
Current acc: {'total': 0.658, '00-09': 0.71, '10-19': 0.668, '20-29': 0.61, '30-39': 0.624, '40-49': 0.691, '50-59': 0.644}.
Avg inc acc top5: 0.9152000000000001.
Current acc top5: {'total': 0.884}.
Forgetting: 0.07571428571428572.
Cord metric: 0.71.
Old accuracy: 0.66, mean: 0.70.
New accuracy: 0.69, mean: 0.71.
================Task 5 Start!================
Testing on False unseen tasks (max class = 60).
Set memory of size: 1160.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 5 Training!================
The training samples number: 2160
Train on 58->60.
train task
nb 2160.
Train [6/26] | Epoch [1/160] |	nca: 7.001505583524704, flat: 3.7350914254784584, pod: 43.10654330253601, loss: 53.843141198158264 
Train [6/26] | Epoch [2/160] |	nca: 4.876686707139015, flat: 5.47979211807251, pod: 51.949158906936646, loss: 62.30563759803772 
Train [6/26] | Epoch [3/160] |	nca: 4.021677792072296, flat: 5.347157388925552, pod: 53.314141035079956, loss: 62.68297600746155 
Train [6/26] | Epoch [4/160] |	nca: 2.8129043728113174, flat: 4.64742149412632, pod: 48.876922369003296, loss: 56.33724784851074 
Train [6/26] | Epoch [5/160] |	nca: 3.088845692574978, flat: 4.2469721138477325, pod: 48.604586362838745, loss: 55.94040393829346 
Train [6/26] | Epoch [6/160] |	nca: 2.5152892656624317, flat: 4.082773923873901, pod: 46.81309771537781, loss: 53.41116118431091 
Train [6/26] | Epoch [7/160] |	nca: 2.5507842525839806, flat: 3.7905034124851227, pod: 44.6340696811676, loss: 50.97535729408264 
Train [6/26] | Epoch [8/160] |	nca: 2.2873840928077698, flat: 3.6305747777223587, pod: 44.062963008880615, loss: 49.980921268463135 
Train [6/26] | Epoch [9/160] |	nca: 2.2068127915263176, flat: 3.67139108479023, pod: 44.792603731155396, loss: 50.67080760002136 
Train [6/26] | Epoch [10/160] |	nca: 2.201977491378784, flat: 3.4132087528705597, pod: 42.906594038009644, loss: 48.521780490875244 
Train [6/26] | Epoch [11/160] |	nca: 1.9721130281686783, flat: 3.1114103198051453, pod: 40.72966551780701, loss: 45.813188791275024 
Train [6/26] | Epoch [12/160] |	nca: 2.0561644211411476, flat: 3.0516387671232224, pod: 40.16062331199646, loss: 45.26842641830444 
Train [6/26] | Epoch [13/160] |	nca: 2.084501050412655, flat: 3.2346321046352386, pod: 42.44962215423584, loss: 47.768755197525024 
Train [6/26] | Epoch [14/160] |	nca: 2.184909638017416, flat: 3.4202927947044373, pod: 43.382906675338745, loss: 48.98810911178589 
Train [6/26] | Epoch [15/160] |	nca: 2.2329971194267273, flat: 3.4227082580327988, pod: 43.50267052650452, loss: 49.15837574005127 
Train [6/26] | Epoch [16/160] |	nca: 2.175878554582596, flat: 3.420267015695572, pod: 43.66645336151123, loss: 49.26259922981262 
Train [6/26] | Epoch [17/160] |	nca: 2.0092702209949493, flat: 3.211717650294304, pod: 41.28736400604248, loss: 46.50835204124451 
Train [6/26] | Epoch [18/160] |	nca: 2.1114501506090164, flat: 3.0301646888256073, pod: 40.116851568222046, loss: 45.2584662437439 
Train [6/26] | Epoch [19/160] |	nca: 2.006117321550846, flat: 2.956636667251587, pod: 39.939507484436035, loss: 44.90226173400879 
Train [6/26] | Epoch [20/160] |	nca: 1.8363099619746208, flat: 2.9842585772275925, pod: 40.72832918167114, loss: 45.5488977432251 
Train [6/26] | Epoch [21/160] |	nca: 2.284159153699875, flat: 3.108486518263817, pod: 40.87723755836487, loss: 46.269882678985596 
Train [6/26] | Epoch [22/160] |	nca: 1.6870607286691666, flat: 3.114985778927803, pod: 41.50053524971008, loss: 46.30258131027222 
Train [6/26] | Epoch [23/160] |	nca: 1.8315143585205078, flat: 2.766678676009178, pod: 38.40063977241516, loss: 42.99883317947388 
Train [6/26] | Epoch [24/160] |	nca: 1.8638998344540596, flat: 2.9756221920251846, pod: 40.24684190750122, loss: 45.08636426925659 
Train [6/26] | Epoch [25/160] |	nca: 1.937767818570137, flat: 3.003561854362488, pod: 40.53236269950867, loss: 45.473692178726196 
Train [6/26] | Epoch [26/160] |	nca: 1.8452631384134293, flat: 2.8445740044116974, pod: 39.1198296546936, loss: 43.809667110443115 
Train [6/26] | Epoch [27/160] |	nca: 1.5475665181875229, flat: 2.5547654181718826, pod: 36.35055065155029, loss: 40.452882289886475 
Train [6/26] | Epoch [28/160] |	nca: 1.5217070430517197, flat: 2.550082504749298, pod: 36.742605686187744, loss: 40.81439542770386 
Train [6/26] | Epoch [29/160] |	nca: 1.8130737394094467, flat: 2.762477323412895, pod: 40.209330558776855, loss: 44.784881591796875 
Train [6/26] | Epoch [30/160] |	nca: 1.8932113870978355, flat: 2.719532787799835, pod: 37.35721576213837, loss: 41.96995973587036 
Train [6/26] | Epoch [31/160] |	nca: 1.8470268100500107, flat: 2.917447119951248, pod: 38.62191414833069, loss: 43.38638782501221 
Train [6/26] | Epoch [32/160] |	nca: 1.693936325609684, flat: 2.8298370391130447, pod: 39.82322931289673, loss: 44.34700298309326 
Train [6/26] | Epoch [33/160] |	nca: 1.6694591417908669, flat: 2.660367175936699, pod: 38.17768359184265, loss: 42.50750970840454 
Train [6/26] | Epoch [34/160] |	nca: 1.7195546329021454, flat: 2.8919732123613358, pod: 40.58198523521423, loss: 45.19351291656494 
Train [6/26] | Epoch [35/160] |	nca: 1.5911008417606354, flat: 2.6226505637168884, pod: 37.66329312324524, loss: 41.87704515457153 
Train [6/26] | Epoch [36/160] |	nca: 1.7392575480043888, flat: 2.630228668451309, pod: 38.124879360198975, loss: 42.494365215301514 
Train [6/26] | Epoch [37/160] |	nca: 1.8495931588113308, flat: 2.7770423889160156, pod: 39.22360157966614, loss: 43.850237131118774 
Train [6/26] | Epoch [38/160] |	nca: 1.7914593070745468, flat: 2.866980627179146, pod: 39.514159202575684, loss: 44.17259931564331 
Train [6/26] | Epoch [39/160] |	nca: 1.701195016503334, flat: 2.6927239894866943, pod: 37.91704845428467, loss: 42.31096792221069 
Train [6/26] | Epoch [40/160] |	nca: 1.6345615684986115, flat: 2.6352095752954483, pod: 37.48520064353943, loss: 41.75497221946716 
Train [6/26] | Epoch [41/160] |	nca: 1.7209189608693123, flat: 2.8855247646570206, pod: 40.45928692817688, loss: 45.065730571746826 
Train [6/26] | Epoch [42/160] |	nca: 1.7736122012138367, flat: 2.899376168847084, pod: 40.78021836280823, loss: 45.453206300735474 
Train [6/26] | Epoch [43/160] |	nca: 1.950460933148861, flat: 2.902310937643051, pod: 40.16221570968628, loss: 45.01498818397522 
Train [6/26] | Epoch [44/160] |	nca: 1.7271301187574863, flat: 2.7601601779460907, pod: 38.48970556259155, loss: 42.97699546813965 
Train [6/26] | Epoch [45/160] |	nca: 1.6662348955869675, flat: 2.5949874371290207, pod: 37.35342240333557, loss: 41.6146445274353 
Train [6/26] | Epoch [46/160] |	nca: 1.762488279491663, flat: 2.5235380828380585, pod: 37.09008252620697, loss: 41.37610864639282 
Train [6/26] | Epoch [47/160] |	nca: 1.4658018797636032, flat: 2.476163625717163, pod: 36.46777284145355, loss: 40.409738302230835 
Train [6/26] | Epoch [48/160] |	nca: 1.5727684311568737, flat: 2.4522811993956566, pod: 37.22673428058624, loss: 41.251784324645996 
Train [6/26] | Epoch [49/160] |	nca: 1.4955089837312698, flat: 2.3711310774087906, pod: 35.516879200935364, loss: 39.383519649505615 
Train [6/26] | Epoch [50/160] |	nca: 1.536765493452549, flat: 2.4133722335100174, pod: 36.39339244365692, loss: 40.34352993965149 
Train [6/26] | Epoch [51/160] |	nca: 1.52558171749115, flat: 2.3855935111641884, pod: 35.649420738220215, loss: 39.56059646606445 
Train [6/26] | Epoch [52/160] |	nca: 1.6056897900998592, flat: 2.3751216530799866, pod: 35.06779110431671, loss: 39.04860210418701 
Train [6/26] | Epoch [53/160] |	nca: 1.6251536943018436, flat: 2.3060621172189713, pod: 36.11184573173523, loss: 40.04306173324585 
Train [6/26] | Epoch [54/160] |	nca: 1.4468860030174255, flat: 2.3574555963277817, pod: 35.67304515838623, loss: 39.477386474609375 
Train [6/26] | Epoch [55/160] |	nca: 1.4971886649727821, flat: 2.294117286801338, pod: 34.41051971912384, loss: 38.20182549953461 
Train [6/26] | Epoch [56/160] |	nca: 1.707273080945015, flat: 2.3249664530158043, pod: 35.38652968406677, loss: 39.418769121170044 
Train [6/26] | Epoch [57/160] |	nca: 1.505937471985817, flat: 2.404985949397087, pod: 35.985780477523804, loss: 39.89670419692993 
Train [6/26] | Epoch [58/160] |	nca: 1.5125631503760815, flat: 2.277994431555271, pod: 35.52113091945648, loss: 39.31168866157532 
Train [6/26] | Epoch [59/160] |	nca: 1.621583852916956, flat: 2.2523389384150505, pod: 34.49366319179535, loss: 38.3675856590271 
Train [6/26] | Epoch [60/160] |	nca: 1.657686971127987, flat: 2.198981687426567, pod: 34.39179027080536, loss: 38.24845886230469 
Train [6/26] | Epoch [61/160] |	nca: 1.6293067745864391, flat: 2.153984986245632, pod: 34.12552034854889, loss: 37.90881276130676 
Train [6/26] | Epoch [62/160] |	nca: 1.3735391162335873, flat: 2.1860247626900673, pod: 34.19156742095947, loss: 37.751131772994995 
Train [6/26] | Epoch [63/160] |	nca: 1.7318594455718994, flat: 2.322477973997593, pod: 36.57788121700287, loss: 40.63221836090088 
Train [6/26] | Epoch [64/160] |	nca: 1.518710970878601, flat: 2.2781548127532005, pod: 35.27878499031067, loss: 39.075650453567505 
Train [6/26] | Epoch [65/160] |	nca: 1.4977406710386276, flat: 2.0354763716459274, pod: 32.49478852748871, loss: 36.02800536155701 
Train [6/26] | Epoch [66/160] |	nca: 1.634611837565899, flat: 2.4321595281362534, pod: 37.21389150619507, loss: 41.28066277503967 
Train [6/26] | Epoch [67/160] |	nca: 1.7087320387363434, flat: 2.361952528357506, pod: 36.39846074581146, loss: 40.46914482116699 
Train [6/26] | Epoch [68/160] |	nca: 1.500655896961689, flat: 2.3211963698267937, pod: 35.94981276988983, loss: 39.77166509628296 
Train [6/26] | Epoch [69/160] |	nca: 1.403812687844038, flat: 2.1320657059550285, pod: 33.924341797828674, loss: 37.46022033691406 
Train [6/26] | Epoch [70/160] |	nca: 1.456561129540205, flat: 1.9805569127202034, pod: 32.220924615859985, loss: 35.658042311668396 
Train [6/26] | Epoch [71/160] |	nca: 1.4071925655007362, flat: 1.9939140677452087, pod: 32.79587543010712, loss: 36.19698238372803 
Train [6/26] | Epoch [72/160] |	nca: 1.3720777817070484, flat: 2.056284435093403, pod: 33.17749464511871, loss: 36.60585701465607 
Train [6/26] | Epoch [73/160] |	nca: 1.504140391945839, flat: 1.9749997556209564, pod: 31.937296867370605, loss: 35.41643702983856 
Train [6/26] | Epoch [74/160] |	nca: 1.325820304453373, flat: 1.866489440202713, pod: 31.48861801624298, loss: 34.680928111076355 
Train [6/26] | Epoch [75/160] |	nca: 1.6838535815477371, flat: 1.9539115205407143, pod: 32.30195462703705, loss: 35.939719915390015 
Train [6/26] | Epoch [76/160] |	nca: 1.564496073871851, flat: 2.0163136795163155, pod: 32.285144686698914, loss: 35.86595416069031 
Train [6/26] | Epoch [77/160] |	nca: 1.4576698802411556, flat: 1.8257722780108452, pod: 30.672776579856873, loss: 33.956218957901 
Train [6/26] | Epoch [78/160] |	nca: 1.700398501008749, flat: 1.8134022504091263, pod: 30.887116074562073, loss: 34.40091693401337 
Train [6/26] | Epoch [79/160] |	nca: 1.4725445173680782, flat: 1.8259711563587189, pod: 31.165262579917908, loss: 34.463778257369995 
Train [6/26] | Epoch [80/160] |	nca: 1.455180637538433, flat: 1.8237455636262894, pod: 31.084555983543396, loss: 34.3634819984436 
Train [6/26] | Epoch [81/160] |	nca: 1.4581689052283764, flat: 1.9754967465996742, pod: 32.41257882118225, loss: 35.84624457359314 
Train [6/26] | Epoch [82/160] |	nca: 1.3873443081974983, flat: 1.852550096809864, pod: 30.63531231880188, loss: 33.87520694732666 
Train [6/26] | Epoch [83/160] |	nca: 1.3690701685845852, flat: 1.7461613714694977, pod: 29.3401095867157, loss: 32.45534133911133 
Train [6/26] | Epoch [84/160] |	nca: 1.381690938025713, flat: 1.6664562970399857, pod: 29.284927129745483, loss: 32.33307421207428 
Train [6/26] | Epoch [85/160] |	nca: 1.6261524707078934, flat: 1.8412349373102188, pod: 30.402233004570007, loss: 33.86962020397186 
Train [6/26] | Epoch [86/160] |	nca: 1.4662588611245155, flat: 1.8149859011173248, pod: 30.54376709461212, loss: 33.82501173019409 
Train [6/26] | Epoch [87/160] |	nca: 1.4814896434545517, flat: 1.8742132633924484, pod: 32.917389154434204, loss: 36.27309191226959 
Train [6/26] | Epoch [88/160] |	nca: 1.6299973204731941, flat: 1.7635239735245705, pod: 31.135581135749817, loss: 34.52910244464874 
Train [6/26] | Epoch [89/160] |	nca: 1.4583266489207745, flat: 1.8645464554429054, pod: 32.10331070423126, loss: 35.42618381977081 
Train [6/26] | Epoch [90/160] |	nca: 1.3815450444817543, flat: 1.6513908877968788, pod: 29.43280839920044, loss: 32.4657438993454 
Train [6/26] | Epoch [91/160] |	nca: 1.3438253216445446, flat: 1.603980392217636, pod: 29.22308385372162, loss: 32.17088961601257 
Train [6/26] | Epoch [92/160] |	nca: 1.4812620766460896, flat: 1.6524654999375343, pod: 30.065478444099426, loss: 33.19920563697815 
Train [6/26] | Epoch [93/160] |	nca: 1.4226628690958023, flat: 1.658166080713272, pod: 29.35307765007019, loss: 32.43390643596649 
Train [6/26] | Epoch [94/160] |	nca: 1.424226351082325, flat: 1.572834551334381, pod: 28.85018241405487, loss: 31.847243189811707 
Train [6/26] | Epoch [95/160] |	nca: 1.2785345688462257, flat: 1.5975772440433502, pod: 29.167462706565857, loss: 32.04357469081879 
Train [6/26] | Epoch [96/160] |	nca: 1.4192107282578945, flat: 1.4982324242591858, pod: 28.005778193473816, loss: 30.923221349716187 
Train [6/26] | Epoch [97/160] |	nca: 1.4434509053826332, flat: 1.4749186858534813, pod: 27.53662884235382, loss: 30.454998254776 
Train [6/26] | Epoch [98/160] |	nca: 1.35293959826231, flat: 1.42132980376482, pod: 26.89193320274353, loss: 29.666202902793884 
Train [6/26] | Epoch [99/160] |	nca: 1.380860734730959, flat: 1.4704379513859749, pod: 27.295096516609192, loss: 30.146395444869995 
Train [6/26] | Epoch [100/160] |	nca: 1.3754640817642212, flat: 1.4599460139870644, pod: 26.757179737091064, loss: 29.592589735984802 
Train [6/26] | Epoch [101/160] |	nca: 1.3580844588577747, flat: 1.4461716189980507, pod: 27.501317381858826, loss: 30.305573225021362 
Train [6/26] | Epoch [102/160] |	nca: 1.3339142203330994, flat: 1.4295197948813438, pod: 27.975533962249756, loss: 30.738968014717102 
Train [6/26] | Epoch [103/160] |	nca: 1.423098310828209, flat: 1.4316177368164062, pod: 27.357581734657288, loss: 30.212297677993774 
Train [6/26] | Epoch [104/160] |	nca: 1.3304112255573273, flat: 1.3604109585285187, pod: 26.495310068130493, loss: 29.186132073402405 
Train [6/26] | Epoch [105/160] |	nca: 1.2360782660543919, flat: 1.2586356289684772, pod: 25.243356466293335, loss: 27.738070249557495 
Train [6/26] | Epoch [106/160] |	nca: 1.3928757943212986, flat: 1.3187083080410957, pod: 25.70383632183075, loss: 28.415420532226562 
Train [6/26] | Epoch [107/160] |	nca: 1.3155297338962555, flat: 1.2540095150470734, pod: 25.767627835273743, loss: 28.337166905403137 
Train [6/26] | Epoch [108/160] |	nca: 1.4608652666211128, flat: 1.356993980705738, pod: 26.269057035446167, loss: 29.086916208267212 
Train [6/26] | Epoch [109/160] |	nca: 1.2910435199737549, flat: 1.3243170231580734, pod: 25.384009957313538, loss: 27.999370574951172 
Train [6/26] | Epoch [110/160] |	nca: 1.3899424485862255, flat: 1.2713047228753567, pod: 24.790315866470337, loss: 27.451563000679016 
Train [6/26] | Epoch [111/160] |	nca: 1.534060101956129, flat: 1.2133113630115986, pod: 24.10551416873932, loss: 26.852885961532593 
Train [6/26] | Epoch [112/160] |	nca: 1.2713948376476765, flat: 1.1454002037644386, pod: 22.559046268463135, loss: 24.975841522216797 
Train [6/26] | Epoch [113/160] |	nca: 1.3463379330933094, flat: 1.1149244979023933, pod: 22.809739351272583, loss: 25.27100169658661 
Train [6/26] | Epoch [114/160] |	nca: 1.4139405116438866, flat: 1.1502650901675224, pod: 23.080109119415283, loss: 25.644314646720886 
Train [6/26] | Epoch [115/160] |	nca: 1.3608260080218315, flat: 1.2458331063389778, pod: 25.449530363082886, loss: 28.05618929862976 
Train [6/26] | Epoch [116/160] |	nca: 1.3245834410190582, flat: 1.155087761580944, pod: 23.913840413093567, loss: 26.393511533737183 
Train [6/26] | Epoch [117/160] |	nca: 1.3414743691682816, flat: 1.2095269374549389, pod: 24.61272883415222, loss: 27.1637305021286 
Train [6/26] | Epoch [118/160] |	nca: 1.3216426111757755, flat: 1.132566835731268, pod: 23.37883949279785, loss: 25.833049058914185 
Train [6/26] | Epoch [119/160] |	nca: 1.3558809533715248, flat: 1.1195995323359966, pod: 22.998002648353577, loss: 25.473483204841614 
Train [6/26] | Epoch [120/160] |	nca: 1.375827681273222, flat: 1.164785373955965, pod: 23.85256278514862, loss: 26.393175721168518 
Train [6/26] | Epoch [121/160] |	nca: 1.4848815314471722, flat: 1.1347247324883938, pod: 22.69760489463806, loss: 25.317211031913757 
Train [6/26] | Epoch [122/160] |	nca: 1.3414628468453884, flat: 1.0560785457491875, pod: 21.87062120437622, loss: 24.268162488937378 
Train [6/26] | Epoch [123/160] |	nca: 1.3317359872162342, flat: 1.0657776072621346, pod: 22.760807514190674, loss: 25.158321380615234 
Train [6/26] | Epoch [124/160] |	nca: 1.343630611896515, flat: 1.0359383448958397, pod: 21.837018489837646, loss: 24.21658766269684 
Train [6/26] | Epoch [125/160] |	nca: 1.4223289154469967, flat: 1.0609958991408348, pod: 22.803112030029297, loss: 25.286437153816223 
Train [6/26] | Epoch [126/160] |	nca: 1.2702987417578697, flat: 1.054837927222252, pod: 22.716116905212402, loss: 25.041253328323364 
Train [6/26] | Epoch [127/160] |	nca: 1.197760384529829, flat: 0.9524540863931179, pod: 21.09605062007904, loss: 23.246265292167664 
Train [6/26] | Epoch [128/160] |	nca: 1.256662242114544, flat: 0.9687295481562614, pod: 21.714224219322205, loss: 23.939615964889526 
Train [6/26] | Epoch [129/160] |	nca: 1.353765107691288, flat: 0.880060363560915, pod: 20.100736558437347, loss: 22.334562301635742 
Train [6/26] | Epoch [130/160] |	nca: 1.374403040856123, flat: 0.9031364843249321, pod: 20.13577961921692, loss: 22.41331923007965 
Train [6/26] | Epoch [131/160] |	nca: 1.3458160683512688, flat: 0.8953339383006096, pod: 19.689541399478912, loss: 21.930691361427307 
Train [6/26] | Epoch [132/160] |	nca: 1.3179842792451382, flat: 0.9513942375779152, pod: 20.264985978603363, loss: 22.534364461898804 
Train [6/26] | Epoch [133/160] |	nca: 1.3856921903789043, flat: 0.9553178995847702, pod: 20.62678849697113, loss: 22.967798590660095 
Train [6/26] | Epoch [134/160] |	nca: 1.2454637922346592, flat: 0.933866735547781, pod: 21.033645629882812, loss: 23.212976217269897 
Train [6/26] | Epoch [135/160] |	nca: 1.2349947392940521, flat: 0.8674758113920689, pod: 19.146481156349182, loss: 21.24895179271698 
Train [6/26] | Epoch [136/160] |	nca: 1.3184375166893005, flat: 0.8731594681739807, pod: 19.307166576385498, loss: 21.4987633228302 
Train [6/26] | Epoch [137/160] |	nca: 1.3038941510021687, flat: 0.8612370528280735, pod: 20.424145817756653, loss: 22.589277029037476 
Train [6/26] | Epoch [138/160] |	nca: 1.3211549408733845, flat: 0.8430317305028439, pod: 18.91951686143875, loss: 21.08370351791382 
Train [6/26] | Epoch [139/160] |	nca: 1.4275779910385609, flat: 0.8277663215994835, pod: 18.714555978775024, loss: 20.969900250434875 
Train [6/26] | Epoch [140/160] |	nca: 1.3140732273459435, flat: 0.8020192068070173, pod: 18.68167555332184, loss: 20.7977676987648 
Train [6/26] | Epoch [141/160] |	nca: 1.331177819520235, flat: 0.8332037627696991, pod: 18.484511494636536, loss: 20.648893237113953 
Train [6/26] | Epoch [142/160] |	nca: 1.3397256061434746, flat: 0.8154617473483086, pod: 18.81490522623062, loss: 20.97009241580963 
Train [6/26] | Epoch [143/160] |	nca: 1.3263408616185188, flat: 0.8209403119981289, pod: 19.433242440223694, loss: 21.58052372932434 
Train [6/26] | Epoch [144/160] |	nca: 1.4007700607180595, flat: 0.9069205336272717, pod: 20.05500453710556, loss: 22.362695038318634 
Train [6/26] | Epoch [145/160] |	nca: 1.2348111681640148, flat: 0.8125944286584854, pod: 18.870288372039795, loss: 20.917693972587585 
Train [6/26] | Epoch [146/160] |	nca: 1.315631203353405, flat: 0.8159364014863968, pod: 18.46847903728485, loss: 20.600046515464783 
Train [6/26] | Epoch [147/160] |	nca: 1.2855426892638206, flat: 0.7785509862005711, pod: 18.23738169670105, loss: 20.30147534608841 
Train [6/26] | Epoch [148/160] |	nca: 1.2889711037278175, flat: 0.7393254637718201, pod: 17.715707540512085, loss: 19.744004130363464 
Train [6/26] | Epoch [149/160] |	nca: 1.3256626091897488, flat: 0.7899152487516403, pod: 18.443404972553253, loss: 20.558982849121094 
Train [6/26] | Epoch [150/160] |	nca: 1.3889515586197376, flat: 0.7593004778027534, pod: 17.519379258155823, loss: 19.66763138771057 
Train [6/26] | Epoch [151/160] |	nca: 1.499115876853466, flat: 0.8054983206093311, pod: 18.05001664161682, loss: 20.354630708694458 
Train [6/26] | Epoch [152/160] |	nca: 1.2803208492696285, flat: 0.738059975206852, pod: 17.139678716659546, loss: 19.158059656620026 
Train [6/26] | Epoch [153/160] |	nca: 1.3194711655378342, flat: 0.7647546119987965, pod: 17.814981043338776, loss: 19.89920663833618 
Train [6/26] | Epoch [154/160] |	nca: 1.3231093883514404, flat: 0.7845283932983875, pod: 17.737426698207855, loss: 19.845064401626587 
Train [6/26] | Epoch [155/160] |	nca: 1.3245752342045307, flat: 0.7669517509639263, pod: 17.3894185423851, loss: 19.48094552755356 
Train [6/26] | Epoch [156/160] |	nca: 1.3289509154856205, flat: 0.7814381532371044, pod: 17.477838456630707, loss: 19.58822739124298 
Train [6/26] | Epoch [157/160] |	nca: 1.3744110837578773, flat: 0.8397225439548492, pod: 19.200928568840027, loss: 21.415062189102173 
Train [6/26] | Epoch [158/160] |	nca: 1.3040120862424374, flat: 0.7546607963740826, pod: 16.78226524591446, loss: 18.840938210487366 
Train [6/26] | Epoch [159/160] |	nca: 1.2386252656579018, flat: 0.7514433637261391, pod: 17.30832815170288, loss: 19.298396706581116 
Train [6/26] | Epoch [160/160] |	nca: 1.3812936134636402, flat: 0.7844287194311619, pod: 17.539446353912354, loss: 19.705168843269348 
Fine-tuning
Building & updating memory.
Train [6/26] | Epoch [161/180] |	nca: 1.6162926778197289, flat: 1.1606714650988579, pod: 18.341381192207336, loss: 21.118345260620117 
Train [6/26] | Epoch [162/180] |	nca: 0.5615320783108473, flat: 1.229249581694603, pod: 19.37233293056488, loss: 21.16311466693878 
Train [6/26] | Epoch [163/180] |	nca: 0.5959638562053442, flat: 1.1994787976145744, pod: 19.119691848754883, loss: 20.91513431072235 
Train [6/26] | Epoch [164/180] |	nca: 0.5108351111412048, flat: 1.2132771462202072, pod: 18.662403345108032, loss: 20.386515617370605 
Train [6/26] | Epoch [165/180] |	nca: 0.41082289442420006, flat: 1.1504384726285934, pod: 18.3117458820343, loss: 19.87300741672516 
Train [6/26] | Epoch [166/180] |	nca: 0.4798950180411339, flat: 1.15526831895113, pod: 18.597591519355774, loss: 20.232754707336426 
Train [6/26] | Epoch [167/180] |	nca: 0.37149452790617943, flat: 1.189316675066948, pod: 18.97902524471283, loss: 20.539836287498474 
Train [6/26] | Epoch [168/180] |	nca: 0.43218497559428215, flat: 1.1840932816267014, pod: 18.813145518302917, loss: 20.429423451423645 
Train [6/26] | Epoch [169/180] |	nca: 0.3770835530012846, flat: 1.1901515051722527, pod: 18.96639585494995, loss: 20.533630847930908 
Train [6/26] | Epoch [170/180] |	nca: 0.35445091500878334, flat: 1.2057663202285767, pod: 19.15974986553192, loss: 20.719967365264893 
Train [6/26] | Epoch [171/180] |	nca: 0.3973454236984253, flat: 1.1843397691845894, pod: 18.81937885284424, loss: 20.401064038276672 
Train [6/26] | Epoch [172/180] |	nca: 0.3273032009601593, flat: 1.1957866549491882, pod: 19.174922466278076, loss: 20.698012590408325 
Train [6/26] | Epoch [173/180] |	nca: 0.3237955179065466, flat: 1.1756276935338974, pod: 19.07345974445343, loss: 20.572882771492004 
Train [6/26] | Epoch [174/180] |	nca: 0.3211657330393791, flat: 1.1951055899262428, pod: 18.882654786109924, loss: 20.39892601966858 
Train [6/26] | Epoch [175/180] |	nca: 0.3648000489920378, flat: 1.1707926467061043, pod: 18.557472229003906, loss: 20.09306502342224 
Train [6/26] | Epoch [176/180] |	nca: 0.33523343317210674, flat: 1.1370496228337288, pod: 18.566745400428772, loss: 20.039028763771057 
Train [6/26] | Epoch [177/180] |	nca: 0.3858474176377058, flat: 1.1793388724327087, pod: 18.906144380569458, loss: 20.471330881118774 
Train [6/26] | Epoch [178/180] |	nca: 0.321951350197196, flat: 1.1534148380160332, pod: 18.460580825805664, loss: 19.935946941375732 
Train [6/26] | Epoch [179/180] |	nca: 0.301381915807724, flat: 1.183255061507225, pod: 19.149474620819092, loss: 20.634111762046814 
Train [6/26] | Epoch [180/180] |	nca: 0.2811813745647669, flat: 1.1476072296500206, pod: 18.5368173122406, loss: 19.965606093406677 
after task
Building & updating memory.
after task
Eval on 0->60.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.7028333333333334.
Current acc: {'total': 0.659, '00-09': 0.707, '10-19': 0.663, '20-29': 0.613, '30-39': 0.617, '40-49': 0.682, '50-59': 0.673}.
Avg inc acc top5: 0.9106666666666667.
Current acc top5: {'total': 0.888}.
Forgetting: 0.07457142857142855.
Cord metric: 0.70.
Old accuracy: 0.66, mean: 0.69.
New accuracy: 0.68, mean: 0.70.
================Task 6 Start!================
Testing on False unseen tasks (max class = 62).
Set memory of size: 1200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 6 Training!================
The training samples number: 2200
Train on 60->62.
train task
nb 2200.
Train [7/26] | Epoch [1/160] |	nca: 6.5527218878269196, flat: 3.1834852918982506, pod: 40.961610555648804, loss: 50.69781827926636 
Train [7/26] | Epoch [2/160] |	nca: 5.90417654812336, flat: 5.848916411399841, pod: 57.44802522659302, loss: 69.20111799240112 
Train [7/26] | Epoch [3/160] |	nca: 7.012232631444931, flat: 7.723761826753616, pod: 64.22335124015808, loss: 78.9593448638916 
Train [7/26] | Epoch [4/160] |	nca: 6.290871895849705, flat: 7.779329001903534, pod: 64.61281204223633, loss: 78.68301343917847 
Train [7/26] | Epoch [5/160] |	nca: 4.251263722777367, flat: 5.974615603685379, pod: 57.65196084976196, loss: 67.87784051895142 
Train [7/26] | Epoch [6/160] |	nca: 5.620071351528168, flat: 6.012705951929092, pod: 58.2231011390686, loss: 69.85587811470032 
Train [7/26] | Epoch [7/160] |	nca: 3.0144782327115536, flat: 5.0653417855501175, pod: 55.43565583229065, loss: 63.51547646522522 
Train [7/26] | Epoch [8/160] |	nca: 2.5228887498378754, flat: 4.100105568766594, pod: 48.70822072029114, loss: 55.331215381622314 
Train [7/26] | Epoch [9/160] |	nca: 2.0932255536317825, flat: 3.806304156780243, pod: 47.16781806945801, loss: 53.06734776496887 
Train [7/26] | Epoch [10/160] |	nca: 2.111262172460556, flat: 3.5461794584989548, pod: 48.297390937805176, loss: 53.954832315444946 
Train [7/26] | Epoch [11/160] |	nca: 2.260984070599079, flat: 3.32619509100914, pod: 45.556067943573, loss: 51.14324688911438 
Train [7/26] | Epoch [12/160] |	nca: 2.714683324098587, flat: 3.9580614864826202, pod: 49.01208972930908, loss: 55.6848349571228 
Train [7/26] | Epoch [13/160] |	nca: 2.1320793740451336, flat: 3.794983208179474, pod: 47.249492168426514, loss: 53.176555156707764 
Train [7/26] | Epoch [14/160] |	nca: 2.2269477769732475, flat: 3.439274698495865, pod: 45.35227036476135, loss: 51.018492221832275 
Train [7/26] | Epoch [15/160] |	nca: 3.118248648941517, flat: 4.137994676828384, pod: 52.12992596626282, loss: 59.38616919517517 
Train [7/26] | Epoch [16/160] |	nca: 3.0739127323031425, flat: 4.467520460486412, pod: 52.33254671096802, loss: 59.873979568481445 
Train [7/26] | Epoch [17/160] |	nca: 3.14368062466383, flat: 4.2560830265283585, pod: 49.877596616744995, loss: 57.27736043930054 
Train [7/26] | Epoch [18/160] |	nca: 2.92452123016119, flat: 4.646128818392754, pod: 53.116366386413574, loss: 60.687016248703 
Train [7/26] | Epoch [19/160] |	nca: 2.210869051516056, flat: 3.8968490809202194, pod: 47.85649299621582, loss: 53.96421146392822 
Train [7/26] | Epoch [20/160] |	nca: 1.957786601036787, flat: 3.347577214241028, pod: 45.21607708930969, loss: 50.52144169807434 
Train [7/26] | Epoch [21/160] |	nca: 1.9881206825375557, flat: 3.277122125029564, pod: 45.6886088848114, loss: 50.95385193824768 
Train [7/26] | Epoch [22/160] |	nca: 2.3590236231684685, flat: 3.0871749818325043, pod: 43.90540933609009, loss: 49.35160827636719 
Train [7/26] | Epoch [23/160] |	nca: 2.951343573629856, flat: 3.7444039434194565, pod: 45.962531328201294, loss: 52.658278942108154 
Train [7/26] | Epoch [24/160] |	nca: 2.1968491673469543, flat: 3.289450466632843, pod: 43.55942749977112, loss: 49.04572677612305 
Train [7/26] | Epoch [25/160] |	nca: 1.9078037291765213, flat: 3.237846314907074, pod: 43.8403217792511, loss: 48.98597192764282 
Train [7/26] | Epoch [26/160] |	nca: 1.9001530148088932, flat: 2.983548656105995, pod: 42.98471808433533, loss: 47.868420124053955 
Train [7/26] | Epoch [27/160] |	nca: 1.9232499673962593, flat: 3.100325420498848, pod: 43.816385984420776, loss: 48.839961528778076 
Train [7/26] | Epoch [28/160] |	nca: 2.125918924808502, flat: 3.170677065849304, pod: 43.64133596420288, loss: 48.93793225288391 
Train [7/26] | Epoch [29/160] |	nca: 2.513707421720028, flat: 3.7743301689624786, pod: 46.8510947227478, loss: 53.139132499694824 
Train [7/26] | Epoch [30/160] |	nca: 2.3298311829566956, flat: 3.562615007162094, pod: 46.744898319244385, loss: 52.63734459877014 
Train [7/26] | Epoch [31/160] |	nca: 2.1622825264930725, flat: 3.45426407456398, pod: 45.18700313568115, loss: 50.80354928970337 
Train [7/26] | Epoch [32/160] |	nca: 2.038892090320587, flat: 3.5013928562402725, pod: 46.93265128135681, loss: 52.47293663024902 
Train [7/26] | Epoch [33/160] |	nca: 1.9011845737695694, flat: 3.278169348835945, pod: 43.60800337791443, loss: 48.78735709190369 
Train [7/26] | Epoch [34/160] |	nca: 1.9484626203775406, flat: 3.175062358379364, pod: 42.92043137550354, loss: 48.04395604133606 
Train [7/26] | Epoch [35/160] |	nca: 2.0017387829720974, flat: 3.336747422814369, pod: 45.56760334968567, loss: 50.906089067459106 
Train [7/26] | Epoch [36/160] |	nca: 2.2283844724297523, flat: 3.2147895991802216, pod: 44.10794734954834, loss: 49.55112171173096 
Train [7/26] | Epoch [37/160] |	nca: 2.077561043202877, flat: 3.2038550972938538, pod: 44.03067898750305, loss: 49.312095165252686 
Train [7/26] | Epoch [38/160] |	nca: 1.9584727510809898, flat: 2.923789218068123, pod: 40.999613761901855, loss: 45.88187575340271 
Train [7/26] | Epoch [39/160] |	nca: 2.0720486864447594, flat: 3.0109431445598602, pod: 40.79156255722046, loss: 45.87455439567566 
Train [7/26] | Epoch [40/160] |	nca: 2.081678032875061, flat: 3.0447158813476562, pod: 42.98609948158264, loss: 48.11249351501465 
Train [7/26] | Epoch [41/160] |	nca: 1.9099203683435917, flat: 2.9708377718925476, pod: 40.35294961929321, loss: 45.233707904815674 
Train [7/26] | Epoch [42/160] |	nca: 2.2810028940439224, flat: 3.5372387021780014, pod: 44.01461577415466, loss: 49.83285737037659 
Train [7/26] | Epoch [43/160] |	nca: 1.9311207234859467, flat: 3.090845212340355, pod: 41.33910536766052, loss: 46.36107134819031 
Train [7/26] | Epoch [44/160] |	nca: 1.9057534225285053, flat: 2.552685394883156, pod: 38.07101500034332, loss: 42.52945375442505 
Train [7/26] | Epoch [45/160] |	nca: 2.325126312673092, flat: 3.1187001168727875, pod: 42.10003995895386, loss: 47.54386615753174 
Train [7/26] | Epoch [46/160] |	nca: 2.502241477370262, flat: 3.444367751479149, pod: 42.786620140075684, loss: 48.73322916030884 
Train [7/26] | Epoch [47/160] |	nca: 1.9124164432287216, flat: 2.9681453853845596, pod: 41.21535301208496, loss: 46.09591460227966 
Train [7/26] | Epoch [48/160] |	nca: 1.4905479550361633, flat: 2.7473520189523697, pod: 39.84499382972717, loss: 44.08289361000061 
Train [7/26] | Epoch [49/160] |	nca: 1.6368501037359238, flat: 2.5170320123434067, pod: 38.76400804519653, loss: 42.917890310287476 
Train [7/26] | Epoch [50/160] |	nca: 1.8153827711939812, flat: 2.5548654347658157, pod: 38.136547684669495, loss: 42.50679588317871 
Train [7/26] | Epoch [51/160] |	nca: 1.864416316151619, flat: 2.873236432671547, pod: 41.08934307098389, loss: 45.826996088027954 
Train [7/26] | Epoch [52/160] |	nca: 1.83645761013031, flat: 2.8177038058638573, pod: 40.39051127433777, loss: 45.04467272758484 
Train [7/26] | Epoch [53/160] |	nca: 2.3172852247953415, flat: 2.898551866412163, pod: 40.68726086616516, loss: 45.903098344802856 
Train [7/26] | Epoch [54/160] |	nca: 1.533703051507473, flat: 2.597937859594822, pod: 39.564924478530884, loss: 43.69656562805176 
Train [7/26] | Epoch [55/160] |	nca: 1.628470554947853, flat: 2.453296445310116, pod: 39.71059310436249, loss: 43.792360067367554 
Train [7/26] | Epoch [56/160] |	nca: 1.70202262327075, flat: 2.5096743404865265, pod: 39.00958728790283, loss: 43.22128391265869 
Train [7/26] | Epoch [57/160] |	nca: 1.6816474758088589, flat: 2.579221948981285, pod: 39.46113848686218, loss: 43.72200798988342 
Train [7/26] | Epoch [58/160] |	nca: 1.7288190722465515, flat: 2.618487700819969, pod: 39.640411019325256, loss: 43.987717628479004 
Train [7/26] | Epoch [59/160] |	nca: 1.4916833508759737, flat: 2.6134493201971054, pod: 40.34517979621887, loss: 44.45031261444092 
Train [7/26] | Epoch [60/160] |	nca: 1.5418983064591885, flat: 2.4774518609046936, pod: 39.22412133216858, loss: 43.24347138404846 
Train [7/26] | Epoch [61/160] |	nca: 1.7185726016759872, flat: 2.4967616125941277, pod: 39.95851945877075, loss: 44.173853397369385 
Train [7/26] | Epoch [62/160] |	nca: 1.9768999367952347, flat: 2.4404491409659386, pod: 38.96735501289368, loss: 43.38470435142517 
Train [7/26] | Epoch [63/160] |	nca: 1.9917703047394753, flat: 2.9265214055776596, pod: 40.09094595909119, loss: 45.00923728942871 
Train [7/26] | Epoch [64/160] |	nca: 2.068539835512638, flat: 2.872392423450947, pod: 39.584877133369446, loss: 44.52581000328064 
Train [7/26] | Epoch [65/160] |	nca: 1.761737436056137, flat: 2.6195110380649567, pod: 38.282655000686646, loss: 42.66390347480774 
Train [7/26] | Epoch [66/160] |	nca: 1.5074387975037098, flat: 2.4371536523103714, pod: 38.05692434310913, loss: 42.00151610374451 
Train [7/26] | Epoch [67/160] |	nca: 1.4800474718213081, flat: 2.1382518112659454, pod: 35.70014405250549, loss: 39.31844341754913 
Train [7/26] | Epoch [68/160] |	nca: 1.5452792719006538, flat: 2.2315003648400307, pod: 35.462886452674866, loss: 39.23966634273529 
Train [7/26] | Epoch [69/160] |	nca: 1.48678158223629, flat: 2.124451629817486, pod: 35.34826600551605, loss: 38.95949864387512 
Train [7/26] | Epoch [70/160] |	nca: 1.764468215405941, flat: 2.3224792554974556, pod: 37.248671889305115, loss: 41.3356192111969 
Train [7/26] | Epoch [71/160] |	nca: 1.5192631781101227, flat: 2.1142668649554253, pod: 35.9025799036026, loss: 39.53610944747925 
Train [7/26] | Epoch [72/160] |	nca: 1.6554313898086548, flat: 2.081963136792183, pod: 34.93560600280762, loss: 38.67300081253052 
Train [7/26] | Epoch [73/160] |	nca: 1.510921400040388, flat: 2.1591592505574226, pod: 35.738789200782776, loss: 39.408870220184326 
Train [7/26] | Epoch [74/160] |	nca: 1.800092987716198, flat: 2.306052088737488, pod: 37.79691195487976, loss: 41.903056621551514 
Train [7/26] | Epoch [75/160] |	nca: 1.7055076695978642, flat: 2.2004065066576004, pod: 35.64483630657196, loss: 39.55074989795685 
Train [7/26] | Epoch [76/160] |	nca: 1.5256058275699615, flat: 2.2132961824536324, pod: 35.95154070854187, loss: 39.69044303894043 
Train [7/26] | Epoch [77/160] |	nca: 1.467432264238596, flat: 1.992255337536335, pod: 33.91208791732788, loss: 37.37177550792694 
Train [7/26] | Epoch [78/160] |	nca: 1.7898328974843025, flat: 2.2979834005236626, pod: 35.540621519088745, loss: 39.628437519073486 
Train [7/26] | Epoch [79/160] |	nca: 1.7056767269968987, flat: 2.1758248284459114, pod: 34.52219772338867, loss: 38.40369915962219 
Train [7/26] | Epoch [80/160] |	nca: 1.6117286495864391, flat: 2.239266984164715, pod: 35.05517876148224, loss: 38.906174063682556 
Train [7/26] | Epoch [81/160] |	nca: 1.8758260756731033, flat: 2.3849890306591988, pod: 36.358073115348816, loss: 40.61888813972473 
Train [7/26] | Epoch [82/160] |	nca: 1.7607377469539642, flat: 2.3906103894114494, pod: 36.47971725463867, loss: 40.6310658454895 
Train [7/26] | Epoch [83/160] |	nca: 1.406944002956152, flat: 2.012069270014763, pod: 33.37252926826477, loss: 36.791542410850525 
Train [7/26] | Epoch [84/160] |	nca: 1.8976165056228638, flat: 1.8248250931501389, pod: 31.749902367591858, loss: 35.47234392166138 
Train [7/26] | Epoch [85/160] |	nca: 1.8912749998271465, flat: 2.4124993830919266, pod: 38.10031795501709, loss: 42.40409231185913 
Train [7/26] | Epoch [86/160] |	nca: 1.379771202802658, flat: 2.024192914366722, pod: 34.28433847427368, loss: 37.688302636146545 
Train [7/26] | Epoch [87/160] |	nca: 1.466866958886385, flat: 1.9383883848786354, pod: 34.46724772453308, loss: 37.87250304222107 
Train [7/26] | Epoch [88/160] |	nca: 1.3987222537398338, flat: 1.8580743819475174, pod: 33.252938628196716, loss: 36.50973582267761 
Train [7/26] | Epoch [89/160] |	nca: 1.5216920003294945, flat: 1.6546582728624344, pod: 30.332064986228943, loss: 33.50841522216797 
Train [7/26] | Epoch [90/160] |	nca: 1.6291419193148613, flat: 1.7969421967864037, pod: 31.81311786174774, loss: 35.23920226097107 
Train [7/26] | Epoch [91/160] |	nca: 1.5914673283696175, flat: 1.9356804937124252, pod: 33.42135155200958, loss: 36.94849932193756 
Train [7/26] | Epoch [92/160] |	nca: 1.572583220899105, flat: 1.9096344709396362, pod: 32.4546172618866, loss: 35.936834931373596 
Train [7/26] | Epoch [93/160] |	nca: 1.4497140385210514, flat: 1.7143592610955238, pod: 30.350784063339233, loss: 33.514857053756714 
Train [7/26] | Epoch [94/160] |	nca: 1.5244719833135605, flat: 1.638240933418274, pod: 30.605142951011658, loss: 33.76785588264465 
Train [7/26] | Epoch [95/160] |	nca: 1.4534277990460396, flat: 1.634637787938118, pod: 30.850120067596436, loss: 33.93818557262421 
Train [7/26] | Epoch [96/160] |	nca: 1.747921697795391, flat: 1.6998675018548965, pod: 31.032897353172302, loss: 34.48068654537201 
Train [7/26] | Epoch [97/160] |	nca: 1.675092302262783, flat: 1.778986617922783, pod: 30.886927366256714, loss: 34.34100651741028 
Train [7/26] | Epoch [98/160] |	nca: 1.5736988708376884, flat: 1.992193080484867, pod: 32.124494433403015, loss: 35.69038641452789 
Train [7/26] | Epoch [99/160] |	nca: 1.494390681385994, flat: 1.6484726592898369, pod: 30.64699101448059, loss: 33.789854288101196 
Train [7/26] | Epoch [100/160] |	nca: 1.4384505935013294, flat: 1.5379943922162056, pod: 29.515885949134827, loss: 32.49233090877533 
Train [7/26] | Epoch [101/160] |	nca: 1.3151827342808247, flat: 1.576347678899765, pod: 29.31629192829132, loss: 32.20782244205475 
Train [7/26] | Epoch [102/160] |	nca: 1.5067275054752827, flat: 1.5152301043272018, pod: 28.18458580970764, loss: 31.206543564796448 
Train [7/26] | Epoch [103/160] |	nca: 1.3769653886556625, flat: 1.6660854816436768, pod: 29.654916167259216, loss: 32.69796693325043 
Train [7/26] | Epoch [104/160] |	nca: 1.4295699670910835, flat: 1.494324803352356, pod: 28.884326100349426, loss: 31.808221101760864 
Train [7/26] | Epoch [105/160] |	nca: 1.3246892131865025, flat: 1.522451888769865, pod: 28.4629887342453, loss: 31.310129404067993 
Train [7/26] | Epoch [106/160] |	nca: 1.3969717659056187, flat: 1.337102010846138, pod: 27.656363010406494, loss: 30.39043688774109 
Train [7/26] | Epoch [107/160] |	nca: 1.3634785376489162, flat: 1.4554782882332802, pod: 28.16558277606964, loss: 30.98453938961029 
Train [7/26] | Epoch [108/160] |	nca: 1.3716255463659763, flat: 1.4598492234945297, pod: 28.540541648864746, loss: 31.372016191482544 
Train [7/26] | Epoch [109/160] |	nca: 1.423012312501669, flat: 1.398868903517723, pod: 27.674030303955078, loss: 30.495911598205566 
Train [7/26] | Epoch [110/160] |	nca: 1.3999222666025162, flat: 1.4391006380319595, pod: 28.78095853328705, loss: 31.6199814081192 
Train [7/26] | Epoch [111/160] |	nca: 1.4698464088141918, flat: 1.358563743531704, pod: 26.945661067962646, loss: 29.774071097373962 
Train [7/26] | Epoch [112/160] |	nca: 1.465044755488634, flat: 1.31354271620512, pod: 25.895304083824158, loss: 28.6738920211792 
Train [7/26] | Epoch [113/160] |	nca: 1.2557607740163803, flat: 1.333331298083067, pod: 26.575191855430603, loss: 29.164283990859985 
Train [7/26] | Epoch [114/160] |	nca: 1.4113935865461826, flat: 1.2450926043093204, pod: 25.546728134155273, loss: 28.203214406967163 
Train [7/26] | Epoch [115/160] |	nca: 1.5222103856503963, flat: 1.2991563193500042, pod: 26.19203507900238, loss: 29.013401746749878 
Train [7/26] | Epoch [116/160] |	nca: 1.438125129789114, flat: 1.4614575952291489, pod: 28.73523712158203, loss: 31.634820103645325 
Train [7/26] | Epoch [117/160] |	nca: 1.5457568019628525, flat: 1.3869484439492226, pod: 26.385072231292725, loss: 29.31777811050415 
Train [7/26] | Epoch [118/160] |	nca: 1.3977957367897034, flat: 1.308766569942236, pod: 25.183875799179077, loss: 27.890438199043274 
Train [7/26] | Epoch [119/160] |	nca: 1.347603663802147, flat: 1.3982796519994736, pod: 27.62825655937195, loss: 30.37414002418518 
Train [7/26] | Epoch [120/160] |	nca: 1.3768692687153816, flat: 1.2218810357153416, pod: 24.868762969970703, loss: 27.46751296520233 
Train [7/26] | Epoch [121/160] |	nca: 1.3658363111317158, flat: 1.218354471027851, pod: 25.817598700523376, loss: 28.40178918838501 
Train [7/26] | Epoch [122/160] |	nca: 1.4028520621359348, flat: 1.2205965034663677, pod: 24.54124128818512, loss: 27.164689779281616 
Train [7/26] | Epoch [123/160] |	nca: 1.3296746276319027, flat: 1.1148102469742298, pod: 23.41362965106964, loss: 25.85811471939087 
Train [7/26] | Epoch [124/160] |	nca: 1.420028768479824, flat: 1.2159205563366413, pod: 24.248181581497192, loss: 26.884130597114563 
Train [7/26] | Epoch [125/160] |	nca: 1.5350925587117672, flat: 1.1190876215696335, pod: 23.4081814289093, loss: 26.06236183643341 
Train [7/26] | Epoch [126/160] |	nca: 1.4479568786919117, flat: 1.2298721075057983, pod: 24.88830077648163, loss: 27.566129684448242 
Train [7/26] | Epoch [127/160] |	nca: 1.4957418888807297, flat: 1.1646024212241173, pod: 22.89040958881378, loss: 25.550753831863403 
Train [7/26] | Epoch [128/160] |	nca: 1.3565604574978352, flat: 1.1718320176005363, pod: 23.681139707565308, loss: 26.209532141685486 
Train [7/26] | Epoch [129/160] |	nca: 1.380316372960806, flat: 1.0310584492981434, pod: 22.895371437072754, loss: 25.306746244430542 
Train [7/26] | Epoch [130/160] |	nca: 1.4203386045992374, flat: 1.1368118189275265, pod: 23.497814536094666, loss: 26.054965019226074 
Train [7/26] | Epoch [131/160] |	nca: 1.3255482763051987, flat: 1.1802429556846619, pod: 24.448169827461243, loss: 26.95396137237549 
Train [7/26] | Epoch [132/160] |	nca: 1.3475620597600937, flat: 1.067947380244732, pod: 22.85613125562668, loss: 25.2716406583786 
Train [7/26] | Epoch [133/160] |	nca: 1.533365000039339, flat: 1.051792100071907, pod: 21.324907958507538, loss: 23.910064935684204 
Train [7/26] | Epoch [134/160] |	nca: 1.2721966430544853, flat: 1.080335184931755, pod: 22.33627998828888, loss: 24.688811659812927 
Train [7/26] | Epoch [135/160] |	nca: 1.25904044136405, flat: 1.0274473614990711, pod: 21.939680635929108, loss: 24.226168274879456 
Train [7/26] | Epoch [136/160] |	nca: 1.5436351113021374, flat: 1.021607369184494, pod: 21.51374441385269, loss: 24.078986763954163 
Train [7/26] | Epoch [137/160] |	nca: 1.4201080910861492, flat: 1.0432857125997543, pod: 21.790901720523834, loss: 24.254295587539673 
Train [7/26] | Epoch [138/160] |	nca: 1.477655615657568, flat: 1.0371725112199783, pod: 22.009536385536194, loss: 24.524364113807678 
Train [7/26] | Epoch [139/160] |	nca: 1.432363785803318, flat: 1.0644392743706703, pod: 22.213964223861694, loss: 24.710767149925232 
Train [7/26] | Epoch [140/160] |	nca: 1.3590399287641048, flat: 0.9830896854400635, pod: 21.265463888645172, loss: 23.607593417167664 
Train [7/26] | Epoch [141/160] |	nca: 1.3333199471235275, flat: 0.9977897852659225, pod: 21.484363317489624, loss: 23.815472960472107 
Train [7/26] | Epoch [142/160] |	nca: 1.32199290022254, flat: 1.0141877494752407, pod: 21.078598737716675, loss: 23.41477942466736 
Train [7/26] | Epoch [143/160] |	nca: 1.2509013824164867, flat: 0.9657049961388111, pod: 21.120302200317383, loss: 23.33690845966339 
Train [7/26] | Epoch [144/160] |	nca: 1.3542171083390713, flat: 0.9567962922155857, pod: 21.039113461971283, loss: 23.35012674331665 
Train [7/26] | Epoch [145/160] |	nca: 1.157043356448412, flat: 0.9329008311033249, pod: 20.20587247610092, loss: 22.295816659927368 
Train [7/26] | Epoch [146/160] |	nca: 1.3298962526023388, flat: 0.938492264598608, pod: 19.966082394123077, loss: 22.23447072505951 
Train [7/26] | Epoch [147/160] |	nca: 1.4419635869562626, flat: 0.9757311046123505, pod: 20.946539044380188, loss: 23.36423373222351 
Train [7/26] | Epoch [148/160] |	nca: 1.385998360812664, flat: 0.9316749051213264, pod: 20.284386217594147, loss: 22.602059483528137 
Train [7/26] | Epoch [149/160] |	nca: 1.4380819201469421, flat: 0.951218131929636, pod: 21.161836326122284, loss: 23.551136374473572 
Train [7/26] | Epoch [150/160] |	nca: 1.381361223757267, flat: 0.9074282199144363, pod: 19.935145020484924, loss: 22.223934412002563 
Train [7/26] | Epoch [151/160] |	nca: 1.4419161714613438, flat: 0.9741861410439014, pod: 20.92812192440033, loss: 23.344224214553833 
Train [7/26] | Epoch [152/160] |	nca: 1.406663067638874, flat: 0.9536461792886257, pod: 19.620968639850616, loss: 21.98127806186676 
Train [7/26] | Epoch [153/160] |	nca: 1.3431376703083515, flat: 0.9091266319155693, pod: 19.873518228530884, loss: 22.12578248977661 
Train [7/26] | Epoch [154/160] |	nca: 1.3330176584422588, flat: 0.8591513708233833, pod: 18.75082951784134, loss: 20.94299840927124 
Train [7/26] | Epoch [155/160] |	nca: 1.3656392022967339, flat: 0.8460874333977699, pod: 18.807347416877747, loss: 21.019074201583862 
Train [7/26] | Epoch [156/160] |	nca: 1.3657626137137413, flat: 0.8860562965273857, pod: 19.646149575710297, loss: 21.897968530654907 
Train [7/26] | Epoch [157/160] |	nca: 1.2723316811025143, flat: 0.9102339223027229, pod: 19.407362282276154, loss: 21.589927971363068 
Train [7/26] | Epoch [158/160] |	nca: 1.3808062225580215, flat: 0.9583613835275173, pod: 20.216708779335022, loss: 22.55587649345398 
Train [7/26] | Epoch [159/160] |	nca: 1.3365283980965614, flat: 0.9368194304406643, pod: 20.31689751148224, loss: 22.590245187282562 
Train [7/26] | Epoch [160/160] |	nca: 1.35895224660635, flat: 0.949410904198885, pod: 19.826162815093994, loss: 22.134525954723358 
Fine-tuning
Building & updating memory.
Train [7/26] | Epoch [161/180] |	nca: 1.5899967327713966, flat: 1.2415874674916267, pod: 18.481481552124023, loss: 21.313066005706787 
Train [7/26] | Epoch [162/180] |	nca: 0.5967446379363537, flat: 1.2409393638372421, pod: 18.831804275512695, loss: 20.669488072395325 
Train [7/26] | Epoch [163/180] |	nca: 0.49958598613739014, flat: 1.2105694189667702, pod: 18.484858751296997, loss: 20.195013999938965 
Train [7/26] | Epoch [164/180] |	nca: 0.5103032942861319, flat: 1.1878316476941109, pod: 18.097826838493347, loss: 19.79596173763275 
Train [7/26] | Epoch [165/180] |	nca: 0.39293581806123257, flat: 1.2274256646633148, pod: 18.577085375785828, loss: 20.197446703910828 
Train [7/26] | Epoch [166/180] |	nca: 0.4450436942279339, flat: 1.2163080647587776, pod: 18.421685576438904, loss: 20.083037614822388 
Train [7/26] | Epoch [167/180] |	nca: 0.37688994966447353, flat: 1.1647162809967995, pod: 18.003787875175476, loss: 19.54539442062378 
Train [7/26] | Epoch [168/180] |	nca: 0.32550124637782574, flat: 1.2474215477705002, pod: 18.88344669342041, loss: 20.456369400024414 
Train [7/26] | Epoch [169/180] |	nca: 0.33556448481976986, flat: 1.2074824795126915, pod: 17.932986855506897, loss: 19.47603416442871 
Train [7/26] | Epoch [170/180] |	nca: 0.33144673332571983, flat: 1.2612671554088593, pod: 18.881815552711487, loss: 20.474529504776 
Train [7/26] | Epoch [171/180] |	nca: 0.33813125640153885, flat: 1.2410090789198875, pod: 18.32851254940033, loss: 19.907652974128723 
Train [7/26] | Epoch [172/180] |	nca: 0.31173757277429104, flat: 1.2137262597680092, pod: 18.525625467300415, loss: 20.05108916759491 
Train [7/26] | Epoch [173/180] |	nca: 0.34367584250867367, flat: 1.2446768283843994, pod: 18.62173068523407, loss: 20.21008312702179 
Train [7/26] | Epoch [174/180] |	nca: 0.34216026961803436, flat: 1.2485933899879456, pod: 18.644795894622803, loss: 20.235549688339233 
Train [7/26] | Epoch [175/180] |	nca: 0.35852883011102676, flat: 1.2270088121294975, pod: 18.05671763420105, loss: 19.642255306243896 
Train [7/26] | Epoch [176/180] |	nca: 0.30600493773818016, flat: 1.2544140592217445, pod: 18.636574745178223, loss: 20.196993947029114 
Train [7/26] | Epoch [177/180] |	nca: 0.2938853334635496, flat: 1.2063595727086067, pod: 18.196404218673706, loss: 19.696649193763733 
Train [7/26] | Epoch [178/180] |	nca: 0.3075417298823595, flat: 1.2150684967637062, pod: 18.838327407836914, loss: 20.360937476158142 
Train [7/26] | Epoch [179/180] |	nca: 0.2994159869849682, flat: 1.217259481549263, pod: 18.369754672050476, loss: 19.886430144309998 
Train [7/26] | Epoch [180/180] |	nca: 0.3013537507504225, flat: 1.2194893583655357, pod: 18.618203163146973, loss: 20.13904643058777 
after task
Building & updating memory.
after task
Eval on 0->62.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6947142857142857.
Current acc: {'total': 0.646, '00-09': 0.7, '10-19': 0.667, '20-29': 0.593, '30-39': 0.62, '40-49': 0.658, '50-59': 0.667, '60-69': 0.515}.
Avg inc acc top5: 0.907.
Current acc top5: {'total': 0.885}.
Forgetting: 0.0071249999999999925.
Cord metric: 0.69.
Old accuracy: 0.65, mean: 0.69.
New accuracy: 0.52, mean: 0.67.
================Task 7 Start!================
Testing on False unseen tasks (max class = 64).
Set memory of size: 1240.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 7 Training!================
The training samples number: 2240
Train on 62->64.
train task
nb 2240.
Train [8/26] | Epoch [1/160] |	nca: 7.826771140098572, flat: 3.154911182820797, pod: 42.02599012851715, loss: 53.00767254829407 
Train [8/26] | Epoch [2/160] |	nca: 6.189842998981476, flat: 4.449290230870247, pod: 51.9113450050354, loss: 62.55047845840454 
Train [8/26] | Epoch [3/160] |	nca: 4.005988135933876, flat: 4.159023344516754, pod: 51.75178265571594, loss: 59.91679406166077 
Train [8/26] | Epoch [4/160] |	nca: 3.1257734820246696, flat: 3.5222657918930054, pod: 48.616101026535034, loss: 55.264140367507935 
Train [8/26] | Epoch [5/160] |	nca: 3.0175667330622673, flat: 3.2931382954120636, pod: 46.749666929244995, loss: 53.06037211418152 
Train [8/26] | Epoch [6/160] |	nca: 3.0864943489432335, flat: 3.2268355041742325, pod: 45.54290723800659, loss: 51.856237173080444 
Train [8/26] | Epoch [7/160] |	nca: 3.171003110706806, flat: 3.236436113715172, pod: 45.253000259399414, loss: 51.66043972969055 
Train [8/26] | Epoch [8/160] |	nca: 2.719572827219963, flat: 3.079259917140007, pod: 44.09932994842529, loss: 49.898162603378296 
Train [8/26] | Epoch [9/160] |	nca: 2.710967533290386, flat: 3.109300896525383, pod: 44.85405778884888, loss: 50.67432641983032 
Train [8/26] | Epoch [10/160] |	nca: 2.583394877612591, flat: 2.853332683444023, pod: 43.6785831451416, loss: 49.11531066894531 
Train [8/26] | Epoch [11/160] |	nca: 2.9671378135681152, flat: 3.291507050395012, pod: 45.8552360534668, loss: 52.11388087272644 
Train [8/26] | Epoch [12/160] |	nca: 2.9564303308725357, flat: 3.093622386455536, pod: 44.302820920944214, loss: 50.35287356376648 
Train [8/26] | Epoch [13/160] |	nca: 2.2520765513181686, flat: 2.8540416806936264, pod: 44.12020421028137, loss: 49.226322174072266 
Train [8/26] | Epoch [14/160] |	nca: 2.780585989356041, flat: 3.0893745124340057, pod: 45.6844265460968, loss: 51.55438733100891 
Train [8/26] | Epoch [15/160] |	nca: 2.275019906461239, flat: 2.7910818830132484, pod: 43.646188735961914, loss: 48.71229028701782 
Train [8/26] | Epoch [16/160] |	nca: 2.2624016255140305, flat: 2.747312217950821, pod: 42.64526414871216, loss: 47.65497803688049 
Train [8/26] | Epoch [17/160] |	nca: 2.243309162557125, flat: 2.6448948681354523, pod: 41.203450202941895, loss: 46.0916543006897 
Train [8/26] | Epoch [18/160] |	nca: 2.289080634713173, flat: 2.718694254755974, pod: 41.0625262260437, loss: 46.07030153274536 
Train [8/26] | Epoch [19/160] |	nca: 2.434735454618931, flat: 2.759853094816208, pod: 43.54959011077881, loss: 48.74417805671692 
Train [8/26] | Epoch [20/160] |	nca: 2.138030491769314, flat: 2.769659399986267, pod: 43.71959924697876, loss: 48.62728929519653 
Train [8/26] | Epoch [21/160] |	nca: 2.3902884051203728, flat: 2.6736762821674347, pod: 41.67054295539856, loss: 46.73450779914856 
Train [8/26] | Epoch [22/160] |	nca: 1.9838031232357025, flat: 2.667517438530922, pod: 41.890997886657715, loss: 46.54231882095337 
Train [8/26] | Epoch [23/160] |	nca: 2.0689704343676567, flat: 2.5198308005928993, pod: 41.64407205581665, loss: 46.23287343978882 
Train [8/26] | Epoch [24/160] |	nca: 2.1340756565332413, flat: 2.593873009085655, pod: 41.00889325141907, loss: 45.736841678619385 
Train [8/26] | Epoch [25/160] |	nca: 2.558426223695278, flat: 2.716268911957741, pod: 42.03932738304138, loss: 47.31402254104614 
Train [8/26] | Epoch [26/160] |	nca: 2.5604003965854645, flat: 2.8082185089588165, pod: 43.12245225906372, loss: 48.49107098579407 
Train [8/26] | Epoch [27/160] |	nca: 2.21868933737278, flat: 2.9123214185237885, pod: 42.794007539749146, loss: 47.92501878738403 
Train [8/26] | Epoch [28/160] |	nca: 1.8054861053824425, flat: 2.5070194751024246, pod: 41.14167308807373, loss: 45.45417857170105 
Train [8/26] | Epoch [29/160] |	nca: 1.9055246636271477, flat: 2.3795089200139046, pod: 39.91378057003021, loss: 44.198814392089844 
Train [8/26] | Epoch [30/160] |	nca: 1.909994125366211, flat: 2.353894427418709, pod: 40.43019711971283, loss: 44.69408559799194 
Train [8/26] | Epoch [31/160] |	nca: 2.044303737580776, flat: 2.3116279914975166, pod: 39.3325777053833, loss: 43.68850922584534 
Train [8/26] | Epoch [32/160] |	nca: 2.1119463369250298, flat: 2.2946073189377785, pod: 38.454651832580566, loss: 42.86120581626892 
Train [8/26] | Epoch [33/160] |	nca: 2.211543932557106, flat: 2.4492682069540024, pod: 40.040632247924805, loss: 44.701444149017334 
Train [8/26] | Epoch [34/160] |	nca: 2.0245645120739937, flat: 2.4396328777074814, pod: 40.31697487831116, loss: 44.781172037124634 
Train [8/26] | Epoch [35/160] |	nca: 1.9984302334487438, flat: 2.307098776102066, pod: 39.21102976799011, loss: 43.51655840873718 
Train [8/26] | Epoch [36/160] |	nca: 1.9366676658391953, flat: 2.4040691554546356, pod: 40.13690781593323, loss: 44.477644205093384 
Train [8/26] | Epoch [37/160] |	nca: 2.1389027759432793, flat: 2.514180764555931, pod: 40.927472829818726, loss: 45.580557107925415 
Train [8/26] | Epoch [38/160] |	nca: 2.084720004349947, flat: 2.584088735282421, pod: 42.06560277938843, loss: 46.73441195487976 
Train [8/26] | Epoch [39/160] |	nca: 2.142930954694748, flat: 2.35147375613451, pod: 38.918479919433594, loss: 43.4128851890564 
Train [8/26] | Epoch [40/160] |	nca: 2.230651006102562, flat: 2.433802530169487, pod: 40.02389597892761, loss: 44.6883487701416 
Train [8/26] | Epoch [41/160] |	nca: 2.020436480641365, flat: 2.5406752675771713, pod: 39.99670958518982, loss: 44.55782151222229 
Train [8/26] | Epoch [42/160] |	nca: 1.9195010177791119, flat: 2.4079418554902077, pod: 39.96716129779816, loss: 44.29460430145264 
Train [8/26] | Epoch [43/160] |	nca: 2.0401222817599773, flat: 2.5077113956212997, pod: 39.34297168254852, loss: 43.8908052444458 
Train [8/26] | Epoch [44/160] |	nca: 2.060689926147461, flat: 2.355782151222229, pod: 39.455679178237915, loss: 43.872151136398315 
Train [8/26] | Epoch [45/160] |	nca: 1.8251035623252392, flat: 2.52041407674551, pod: 43.81363272666931, loss: 48.15915012359619 
Train [8/26] | Epoch [46/160] |	nca: 1.9962877817451954, flat: 2.307663470506668, pod: 39.639877796173096, loss: 43.94382929801941 
Train [8/26] | Epoch [47/160] |	nca: 2.078992336988449, flat: 2.5203181728720665, pod: 42.15125131607056, loss: 46.75056171417236 
Train [8/26] | Epoch [48/160] |	nca: 2.0385720059275627, flat: 2.4489688873291016, pod: 40.109758138656616, loss: 44.597299337387085 
Train [8/26] | Epoch [49/160] |	nca: 1.9413663372397423, flat: 2.2494807094335556, pod: 37.47100639343262, loss: 41.661853313446045 
Train [8/26] | Epoch [50/160] |	nca: 2.013732135295868, flat: 2.2611229345202446, pod: 37.52283072471619, loss: 41.797685861587524 
Train [8/26] | Epoch [51/160] |	nca: 1.6397001966834068, flat: 2.0481304675340652, pod: 37.231101393699646, loss: 40.91893219947815 
Train [8/26] | Epoch [52/160] |	nca: 1.7817635647952557, flat: 2.0138943642377853, pod: 36.53196370601654, loss: 40.32762169837952 
Train [8/26] | Epoch [53/160] |	nca: 1.797387957572937, flat: 2.010766454041004, pod: 35.372865319252014, loss: 39.1810200214386 
Train [8/26] | Epoch [54/160] |	nca: 1.95869929343462, flat: 2.089929796755314, pod: 36.9075448513031, loss: 40.95617425441742 
Train [8/26] | Epoch [55/160] |	nca: 1.7179736718535423, flat: 1.9841061010956764, pod: 35.84782111644745, loss: 39.5499005317688 
Train [8/26] | Epoch [56/160] |	nca: 1.584707386791706, flat: 1.8389780893921852, pod: 34.89707601070404, loss: 38.32076144218445 
Train [8/26] | Epoch [57/160] |	nca: 1.7524625696241856, flat: 1.8603629097342491, pod: 34.53704643249512, loss: 38.149871945381165 
Train [8/26] | Epoch [58/160] |	nca: 1.7266463115811348, flat: 1.8300738856196404, pod: 35.001190423965454, loss: 38.55791091918945 
Train [8/26] | Epoch [59/160] |	nca: 1.8221772611141205, flat: 2.055273152887821, pod: 37.264413595199585, loss: 41.14186382293701 
Train [8/26] | Epoch [60/160] |	nca: 1.8594288788735867, flat: 2.0931639298796654, pod: 37.11327660083771, loss: 41.06586980819702 
Train [8/26] | Epoch [61/160] |	nca: 1.717858947813511, flat: 2.1559789180755615, pod: 38.575669050216675, loss: 42.449506998062134 
Train [8/26] | Epoch [62/160] |	nca: 2.136362560093403, flat: 2.047472156584263, pod: 36.53065514564514, loss: 40.71448993682861 
Train [8/26] | Epoch [63/160] |	nca: 1.884575828909874, flat: 2.0634662434458733, pod: 36.578723311424255, loss: 40.52676558494568 
Train [8/26] | Epoch [64/160] |	nca: 1.6743468269705772, flat: 1.9187858179211617, pod: 35.493088722229004, loss: 39.08622121810913 
Train [8/26] | Epoch [65/160] |	nca: 1.5849178358912468, flat: 1.8081662878394127, pod: 34.900962114334106, loss: 38.29404628276825 
Train [8/26] | Epoch [66/160] |	nca: 1.6514404341578484, flat: 1.7546189278364182, pod: 34.41340446472168, loss: 37.81946396827698 
Train [8/26] | Epoch [67/160] |	nca: 1.8747954964637756, flat: 1.9970284700393677, pod: 36.92909073829651, loss: 40.8009147644043 
Train [8/26] | Epoch [68/160] |	nca: 1.6609121337532997, flat: 1.8930443599820137, pod: 35.271435141563416, loss: 38.82539165019989 
Train [8/26] | Epoch [69/160] |	nca: 1.7608315497636795, flat: 1.802106149494648, pod: 33.761905789375305, loss: 37.32484316825867 
Train [8/26] | Epoch [70/160] |	nca: 1.6148008033633232, flat: 1.7777433320879936, pod: 33.85618805885315, loss: 37.24873208999634 
Train [8/26] | Epoch [71/160] |	nca: 1.7726900465786457, flat: 1.7611668482422829, pod: 34.49706721305847, loss: 38.03092384338379 
Train [8/26] | Epoch [72/160] |	nca: 1.699168462306261, flat: 1.7489212900400162, pod: 33.0332567691803, loss: 36.48134672641754 
Train [8/26] | Epoch [73/160] |	nca: 1.6179746352136135, flat: 1.7213780730962753, pod: 33.534764528274536, loss: 36.874117493629456 
Train [8/26] | Epoch [74/160] |	nca: 1.6703405976295471, flat: 1.692502997815609, pod: 32.59066116809845, loss: 35.95350456237793 
Train [8/26] | Epoch [75/160] |	nca: 1.8577502146363258, flat: 1.830476313829422, pod: 33.80070149898529, loss: 37.48892831802368 
Train [8/26] | Epoch [76/160] |	nca: 1.6440168768167496, flat: 1.657472550868988, pod: 31.860559821128845, loss: 35.16204917430878 
Train [8/26] | Epoch [77/160] |	nca: 1.7109018340706825, flat: 1.6566517427563667, pod: 32.022093296051025, loss: 35.389646887779236 
Train [8/26] | Epoch [78/160] |	nca: 1.7119349986314774, flat: 1.7085361704230309, pod: 33.50757670402527, loss: 36.92804801464081 
Train [8/26] | Epoch [79/160] |	nca: 1.7839553654193878, flat: 1.652747631072998, pod: 33.356261014938354, loss: 36.79296374320984 
Train [8/26] | Epoch [80/160] |	nca: 1.644274264574051, flat: 1.6250567138195038, pod: 32.21298933029175, loss: 35.48232066631317 
Train [8/26] | Epoch [81/160] |	nca: 1.643490545451641, flat: 1.623344548046589, pod: 33.83103382587433, loss: 37.09786903858185 
Train [8/26] | Epoch [82/160] |	nca: 1.6855560094118118, flat: 1.6880196183919907, pod: 33.46604573726654, loss: 36.83962094783783 
Train [8/26] | Epoch [83/160] |	nca: 1.8706489130854607, flat: 1.699832633137703, pod: 33.3527889251709, loss: 36.9232702255249 
Train [8/26] | Epoch [84/160] |	nca: 1.7073531560599804, flat: 1.5528396517038345, pod: 31.91140365600586, loss: 35.17159652709961 
Train [8/26] | Epoch [85/160] |	nca: 1.7371365949511528, flat: 1.5269509851932526, pod: 31.51365828514099, loss: 34.777745723724365 
Train [8/26] | Epoch [86/160] |	nca: 1.5574249550700188, flat: 1.4246504977345467, pod: 30.460302472114563, loss: 33.44237792491913 
Train [8/26] | Epoch [87/160] |	nca: 1.689618468284607, flat: 1.4970626384019852, pod: 31.07467246055603, loss: 34.261353850364685 
Train [8/26] | Epoch [88/160] |	nca: 1.653688222169876, flat: 1.5356291085481644, pod: 31.920966744422913, loss: 35.110284090042114 
Train [8/26] | Epoch [89/160] |	nca: 1.6776919178664684, flat: 1.4464589729905128, pod: 29.785382509231567, loss: 32.90953326225281 
Train [8/26] | Epoch [90/160] |	nca: 1.7658696323633194, flat: 1.5179357379674911, pod: 31.696069359779358, loss: 34.97987496852875 
Train [8/26] | Epoch [91/160] |	nca: 1.6622859090566635, flat: 1.4669178649783134, pod: 30.610594749450684, loss: 33.73979878425598 
Train [8/26] | Epoch [92/160] |	nca: 1.5347331948578358, flat: 1.417420744895935, pod: 30.352365493774414, loss: 33.30451989173889 
Train [8/26] | Epoch [93/160] |	nca: 1.6596608981490135, flat: 1.3142749518156052, pod: 28.11443316936493, loss: 31.088368892669678 
Train [8/26] | Epoch [94/160] |	nca: 1.5268701761960983, flat: 1.2528230585157871, pod: 27.86120331287384, loss: 30.640896677970886 
Train [8/26] | Epoch [95/160] |	nca: 1.6013009920716286, flat: 1.3440711684525013, pod: 28.57136058807373, loss: 31.516732811927795 
Train [8/26] | Epoch [96/160] |	nca: 1.6697366572916508, flat: 1.3351517468690872, pod: 28.290565371513367, loss: 31.295453906059265 
Train [8/26] | Epoch [97/160] |	nca: 1.4703326188027859, flat: 1.3550252988934517, pod: 29.12418293952942, loss: 31.949541211128235 
Train [8/26] | Epoch [98/160] |	nca: 1.6458069533109665, flat: 1.430395182222128, pod: 30.26898443698883, loss: 33.3451863527298 
Train [8/26] | Epoch [99/160] |	nca: 1.5721513964235783, flat: 1.2828605212271214, pod: 28.021403551101685, loss: 30.876415491104126 
Train [8/26] | Epoch [100/160] |	nca: 1.643370658159256, flat: 1.2988266050815582, pod: 28.608238339424133, loss: 31.550435543060303 
Train [8/26] | Epoch [101/160] |	nca: 1.58667116984725, flat: 1.321496780961752, pod: 28.91426956653595, loss: 31.822437286376953 
Train [8/26] | Epoch [102/160] |	nca: 1.4954658523201942, flat: 1.277709260582924, pod: 27.800014853477478, loss: 30.573189973831177 
Train [8/26] | Epoch [103/160] |	nca: 1.67367796972394, flat: 1.3230610229074955, pod: 29.75545585155487, loss: 32.75219476222992 
Train [8/26] | Epoch [104/160] |	nca: 1.746766835451126, flat: 1.3366516381502151, pod: 29.228838205337524, loss: 32.31225657463074 
Train [8/26] | Epoch [105/160] |	nca: 1.3948416337370872, flat: 1.2468466199934483, pod: 27.304277420043945, loss: 29.94596564769745 
Train [8/26] | Epoch [106/160] |	nca: 1.533965591341257, flat: 1.1001267693936825, pod: 25.378023624420166, loss: 28.012116312980652 
Train [8/26] | Epoch [107/160] |	nca: 1.7729187943041325, flat: 1.1345221251249313, pod: 25.839127898216248, loss: 28.74656879901886 
Train [8/26] | Epoch [108/160] |	nca: 1.5396916568279266, flat: 1.047023132443428, pod: 24.633208990097046, loss: 27.219923734664917 
Train [8/26] | Epoch [109/160] |	nca: 1.531152743846178, flat: 1.1233961060643196, pod: 26.40477180480957, loss: 29.05932056903839 
Train [8/26] | Epoch [110/160] |	nca: 1.4280140660703182, flat: 1.0370361730456352, pod: 24.966623067855835, loss: 27.431673288345337 
Train [8/26] | Epoch [111/160] |	nca: 1.4822149649262428, flat: 1.2083618082106113, pod: 27.425978422164917, loss: 30.116554975509644 
Train [8/26] | Epoch [112/160] |	nca: 1.6097290590405464, flat: 1.1841202564537525, pod: 26.501496076583862, loss: 29.295345544815063 
Train [8/26] | Epoch [113/160] |	nca: 1.6027814373373985, flat: 1.1136010400950909, pod: 25.635374188423157, loss: 28.35175633430481 
Train [8/26] | Epoch [114/160] |	nca: 1.4162285029888153, flat: 1.0658522844314575, pod: 25.48911225795746, loss: 27.971192836761475 
Train [8/26] | Epoch [115/160] |	nca: 1.6706925295293331, flat: 0.9702529013156891, pod: 23.805332899093628, loss: 26.44627845287323 
Train [8/26] | Epoch [116/160] |	nca: 1.452611356973648, flat: 1.0367409773170948, pod: 23.976268410682678, loss: 26.46562087535858 
Train [8/26] | Epoch [117/160] |	nca: 1.5078592859208584, flat: 0.9333932548761368, pod: 23.245967268943787, loss: 25.687219619750977 
Train [8/26] | Epoch [118/160] |	nca: 1.5543982982635498, flat: 0.9624042548239231, pod: 23.65278732776642, loss: 26.169589638710022 
Train [8/26] | Epoch [119/160] |	nca: 1.4669922329485416, flat: 0.9625204019248486, pod: 24.337621927261353, loss: 26.76713466644287 
Train [8/26] | Epoch [120/160] |	nca: 1.6464445926249027, flat: 0.9160771146416664, pod: 22.82062005996704, loss: 25.38314199447632 
Train [8/26] | Epoch [121/160] |	nca: 1.6446930952370167, flat: 0.9914201274514198, pod: 23.980085253715515, loss: 26.616198301315308 
Train [8/26] | Epoch [122/160] |	nca: 1.572643592953682, flat: 0.9654787667095661, pod: 23.41812574863434, loss: 25.95624828338623 
Train [8/26] | Epoch [123/160] |	nca: 1.4409890808165073, flat: 0.9208372607827187, pod: 23.382055163383484, loss: 25.743881702423096 
Train [8/26] | Epoch [124/160] |	nca: 1.4702478423714638, flat: 0.8570221588015556, pod: 21.890926599502563, loss: 24.218196392059326 
Train [8/26] | Epoch [125/160] |	nca: 1.4792172871530056, flat: 0.8764885067939758, pod: 22.096964716911316, loss: 24.452670574188232 
Train [8/26] | Epoch [126/160] |	nca: 1.5692366249859333, flat: 0.7965598851442337, pod: 21.437784552574158, loss: 23.80358099937439 
Train [8/26] | Epoch [127/160] |	nca: 1.4035691358149052, flat: 0.8148114494979382, pod: 20.993940591812134, loss: 23.212321162223816 
Train [8/26] | Epoch [128/160] |	nca: 1.4599302262067795, flat: 0.8779068775475025, pod: 21.949441075325012, loss: 24.287278413772583 
Train [8/26] | Epoch [129/160] |	nca: 1.4754928313195705, flat: 0.8179546799510717, pod: 20.948652744293213, loss: 23.24210023880005 
Train [8/26] | Epoch [130/160] |	nca: 1.3388185650110245, flat: 0.8645277097821236, pod: 21.194082736968994, loss: 23.39742910861969 
Train [8/26] | Epoch [131/160] |	nca: 1.5047854743897915, flat: 0.8406010381877422, pod: 21.321642220020294, loss: 23.667028546333313 
Train [8/26] | Epoch [132/160] |	nca: 1.4549321345984936, flat: 0.7973806727677584, pod: 20.28226363658905, loss: 22.534576177597046 
Train [8/26] | Epoch [133/160] |	nca: 1.561390232294798, flat: 0.7622311040759087, pod: 20.93204641342163, loss: 23.255667805671692 
Train [8/26] | Epoch [134/160] |	nca: 1.5070576444268227, flat: 0.7980694696307182, pod: 21.172415852546692, loss: 23.477542877197266 
Train [8/26] | Epoch [135/160] |	nca: 1.4428123496472836, flat: 0.7897005211561918, pod: 20.955092132091522, loss: 23.187605023384094 
Train [8/26] | Epoch [136/160] |	nca: 1.6390530355274677, flat: 0.8259145729243755, pod: 20.463836193084717, loss: 22.92880415916443 
Train [8/26] | Epoch [137/160] |	nca: 1.4300714060664177, flat: 0.7351769674569368, pod: 19.61178731918335, loss: 21.777035653591156 
Train [8/26] | Epoch [138/160] |	nca: 1.4534081667661667, flat: 0.7652479857206345, pod: 19.884272933006287, loss: 22.10292899608612 
Train [8/26] | Epoch [139/160] |	nca: 1.4814395569264889, flat: 0.7241570297628641, pod: 20.25096744298935, loss: 22.45656383037567 
Train [8/26] | Epoch [140/160] |	nca: 1.4219354800879955, flat: 0.7762945108115673, pod: 20.679702043533325, loss: 22.87793219089508 
Train [8/26] | Epoch [141/160] |	nca: 1.4863143563270569, flat: 0.6783596444875002, pod: 18.30390602350235, loss: 20.46857976913452 
Train [8/26] | Epoch [142/160] |	nca: 1.5721512362360954, flat: 0.7395424880087376, pod: 19.841930389404297, loss: 22.153624057769775 
Train [8/26] | Epoch [143/160] |	nca: 1.548097413033247, flat: 0.6937109846621752, pod: 18.321142435073853, loss: 20.562950909137726 
Train [8/26] | Epoch [144/160] |	nca: 1.4533461891114712, flat: 0.7360834162682295, pod: 19.988151729106903, loss: 22.177581429481506 
Train [8/26] | Epoch [145/160] |	nca: 1.382118809968233, flat: 0.6986960619688034, pod: 19.27154839038849, loss: 21.352363348007202 
Train [8/26] | Epoch [146/160] |	nca: 1.4626609273254871, flat: 0.694600272923708, pod: 18.83939003944397, loss: 20.996650874614716 
Train [8/26] | Epoch [147/160] |	nca: 1.3773865699768066, flat: 0.6906439308077097, pod: 18.944548189640045, loss: 21.0125789642334 
Train [8/26] | Epoch [148/160] |	nca: 1.4152467027306557, flat: 0.7303613554686308, pod: 18.945175290107727, loss: 21.090783417224884 
Train [8/26] | Epoch [149/160] |	nca: 1.4850918650627136, flat: 0.7049441542476416, pod: 18.655552864074707, loss: 20.84558916091919 
Train [8/26] | Epoch [150/160] |	nca: 1.392695564776659, flat: 0.6960691642016172, pod: 17.843369126319885, loss: 19.93213403224945 
Train [8/26] | Epoch [151/160] |	nca: 1.4557438418269157, flat: 0.7077994551509619, pod: 17.878202319145203, loss: 20.0417457818985 
Train [8/26] | Epoch [152/160] |	nca: 1.4921138361096382, flat: 0.6377988308668137, pod: 17.435283303260803, loss: 19.565195858478546 
Train [8/26] | Epoch [153/160] |	nca: 1.3488110974431038, flat: 0.6937917433679104, pod: 18.27523946762085, loss: 20.317842304706573 
Train [8/26] | Epoch [154/160] |	nca: 1.4850803799927235, flat: 0.6502340119332075, pod: 17.763181626796722, loss: 19.89849603176117 
Train [8/26] | Epoch [155/160] |	nca: 1.3683114908635616, flat: 0.5905134808272123, pod: 16.914104223251343, loss: 18.872929334640503 
Train [8/26] | Epoch [156/160] |	nca: 1.3749230206012726, flat: 0.6452177166938782, pod: 17.2400985956192, loss: 19.26023906469345 
Train [8/26] | Epoch [157/160] |	nca: 1.536974936723709, flat: 0.653581541031599, pod: 18.036898136138916, loss: 20.227454483509064 
Train [8/26] | Epoch [158/160] |	nca: 1.5048722885549068, flat: 0.6630199775099754, pod: 17.87300157546997, loss: 20.040893852710724 
Train [8/26] | Epoch [159/160] |	nca: 1.5280994549393654, flat: 0.6853133402764797, pod: 18.50726628303528, loss: 20.720678865909576 
Train [8/26] | Epoch [160/160] |	nca: 1.4232483245432377, flat: 0.6286366209387779, pod: 17.153161108493805, loss: 19.20504605770111 
Fine-tuning
Building & updating memory.
Train [8/26] | Epoch [161/180] |	nca: 1.75699894875288, flat: 1.1720543429255486, pod: 18.548848390579224, loss: 21.477902054786682 
Train [8/26] | Epoch [162/180] |	nca: 0.8421454280614853, flat: 1.1812073439359665, pod: 18.608521819114685, loss: 20.631874442100525 
Train [8/26] | Epoch [163/180] |	nca: 0.6711594797670841, flat: 1.1882513761520386, pod: 18.80000627040863, loss: 20.659416794776917 
Train [8/26] | Epoch [164/180] |	nca: 0.5244939625263214, flat: 1.171412616968155, pod: 18.591933012008667, loss: 20.287839770317078 
Train [8/26] | Epoch [165/180] |	nca: 0.5299728214740753, flat: 1.1839330941438675, pod: 18.587817549705505, loss: 20.30172348022461 
Train [8/26] | Epoch [166/180] |	nca: 0.4657556749880314, flat: 1.12819654494524, pod: 18.096674919128418, loss: 19.690626859664917 
Train [8/26] | Epoch [167/180] |	nca: 0.47361457347869873, flat: 1.181131087243557, pod: 18.95056986808777, loss: 20.605315566062927 
Train [8/26] | Epoch [168/180] |	nca: 0.46822498738765717, flat: 1.1799015626311302, pod: 18.578359723091125, loss: 20.226486206054688 
Train [8/26] | Epoch [169/180] |	nca: 0.40982799604535103, flat: 1.1779981181025505, pod: 18.73833191394806, loss: 20.326158046722412 
Train [8/26] | Epoch [170/180] |	nca: 0.39583473838865757, flat: 1.1945548579096794, pod: 18.827213287353516, loss: 20.41760289669037 
Train [8/26] | Epoch [171/180] |	nca: 0.41062650829553604, flat: 1.1871862038969994, pod: 18.76602566242218, loss: 20.36383819580078 
Train [8/26] | Epoch [172/180] |	nca: 0.3974865786731243, flat: 1.1939716190099716, pod: 18.932427525520325, loss: 20.523885846138 
Train [8/26] | Epoch [173/180] |	nca: 0.4364282973110676, flat: 1.1980148330330849, pod: 18.805841088294983, loss: 20.44028401374817 
Train [8/26] | Epoch [174/180] |	nca: 0.41698378697037697, flat: 1.1750494614243507, pod: 18.4588383436203, loss: 20.05087149143219 
Train [8/26] | Epoch [175/180] |	nca: 0.438373327255249, flat: 1.1339634656906128, pod: 18.325350165367126, loss: 19.897687077522278 
Train [8/26] | Epoch [176/180] |	nca: 0.34367344714701176, flat: 1.1569370478391647, pod: 18.410330772399902, loss: 19.91094136238098 
Train [8/26] | Epoch [177/180] |	nca: 0.36875044740736485, flat: 1.1533699184656143, pod: 18.510947704315186, loss: 20.03306806087494 
Train [8/26] | Epoch [178/180] |	nca: 0.36494498886168003, flat: 1.1830591410398483, pod: 18.715019702911377, loss: 20.263023734092712 
Train [8/26] | Epoch [179/180] |	nca: 0.35440830513834953, flat: 1.1554346680641174, pod: 18.80606520175934, loss: 20.315908193588257 
Train [8/26] | Epoch [180/180] |	nca: 0.3400131966918707, flat: 1.1733315587043762, pod: 18.36088800430298, loss: 19.87423276901245 
after task
Building & updating memory.
after task
Eval on 0->64.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.686.
Current acc: {'total': 0.625, '00-09': 0.673, '10-19': 0.663, '20-29': 0.551, '30-39': 0.593, '40-49': 0.638, '50-59': 0.66, '60-69': 0.562}.
Avg inc acc top5: 0.90275.
Current acc top5: {'total': 0.873}.
Forgetting: 0.08149999999999998.
Cord metric: 0.68.
Old accuracy: 0.62, mean: 0.68.
New accuracy: 0.65, mean: 0.67.
================Task 8 Start!================
Testing on False unseen tasks (max class = 66).
Set memory of size: 1280.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 8 Training!================
The training samples number: 2280
Train on 64->66.
train task
nb 2280.
Train [9/26] | Epoch [1/160] |	nca: 7.89812359213829, flat: 3.274533312767744, pod: 42.61053800582886, loss: 53.78319501876831 
Train [9/26] | Epoch [2/160] |	nca: 5.526506215333939, flat: 4.449973404407501, pod: 50.62122631072998, loss: 60.59770631790161 
Train [9/26] | Epoch [3/160] |	nca: 4.5358332842588425, flat: 4.402245178818703, pod: 50.775259256362915, loss: 59.713337898254395 
Train [9/26] | Epoch [4/160] |	nca: 3.4800485521554947, flat: 3.761402666568756, pod: 47.99577307701111, loss: 55.23722457885742 
Train [9/26] | Epoch [5/160] |	nca: 3.283678263425827, flat: 3.3880419433116913, pod: 45.47578811645508, loss: 52.14750814437866 
Train [9/26] | Epoch [6/160] |	nca: 2.823495991528034, flat: 3.0174735486507416, pod: 43.608073472976685, loss: 49.4490430355072 
Train [9/26] | Epoch [7/160] |	nca: 2.365090288221836, flat: 2.8960124254226685, pod: 44.20338225364685, loss: 49.46448493003845 
Train [9/26] | Epoch [8/160] |	nca: 2.5807429924607277, flat: 2.640696570277214, pod: 41.52992558479309, loss: 46.751364946365356 
Train [9/26] | Epoch [9/160] |	nca: 2.304998107254505, flat: 2.6332211270928383, pod: 40.382699489593506, loss: 45.320918560028076 
Train [9/26] | Epoch [10/160] |	nca: 2.9849523156881332, flat: 2.8279767483472824, pod: 41.53450155258179, loss: 47.34743118286133 
Train [9/26] | Epoch [11/160] |	nca: 2.6143603399395943, flat: 2.882507711648941, pod: 42.69296479225159, loss: 48.18983268737793 
Train [9/26] | Epoch [12/160] |	nca: 2.271646924316883, flat: 2.6702273339033127, pod: 41.49729919433594, loss: 46.43917393684387 
Train [9/26] | Epoch [13/160] |	nca: 2.3881950601935387, flat: 2.7291232496500015, pod: 41.86298322677612, loss: 46.98030233383179 
Train [9/26] | Epoch [14/160] |	nca: 2.3822930827736855, flat: 2.688361272215843, pod: 40.617597579956055, loss: 45.688252449035645 
Train [9/26] | Epoch [15/160] |	nca: 2.2331963032484055, flat: 2.574587866663933, pod: 40.43220257759094, loss: 45.23998689651489 
Train [9/26] | Epoch [16/160] |	nca: 2.534747928380966, flat: 2.543631114065647, pod: 40.795461654663086, loss: 45.87384104728699 
Train [9/26] | Epoch [17/160] |	nca: 2.1078761406242847, flat: 2.4447903260588646, pod: 40.781676054000854, loss: 45.33434271812439 
Train [9/26] | Epoch [18/160] |	nca: 2.2559665367007256, flat: 2.496176779270172, pod: 40.1021785736084, loss: 44.85432195663452 
Train [9/26] | Epoch [19/160] |	nca: 2.086446724832058, flat: 2.4718447029590607, pod: 41.34001064300537, loss: 45.89830207824707 
Train [9/26] | Epoch [20/160] |	nca: 1.958785817027092, flat: 2.4087692573666573, pod: 39.69892501831055, loss: 44.06647992134094 
Train [9/26] | Epoch [21/160] |	nca: 2.023240379989147, flat: 2.32688008248806, pod: 39.59495520591736, loss: 43.94507551193237 
Train [9/26] | Epoch [22/160] |	nca: 1.9534050561487675, flat: 2.4095205664634705, pod: 38.87734317779541, loss: 43.24026870727539 
Train [9/26] | Epoch [23/160] |	nca: 2.132956311106682, flat: 2.375650092959404, pod: 39.06045317649841, loss: 43.56906008720398 
Train [9/26] | Epoch [24/160] |	nca: 1.998552367091179, flat: 2.3575660660862923, pod: 38.47350716590881, loss: 42.829625606536865 
Train [9/26] | Epoch [25/160] |	nca: 2.0655524358153343, flat: 2.411195822060108, pod: 40.12737989425659, loss: 44.60412836074829 
Train [9/26] | Epoch [26/160] |	nca: 2.1455743238329887, flat: 2.6787600964307785, pod: 41.995553493499756, loss: 46.81988787651062 
Train [9/26] | Epoch [27/160] |	nca: 2.1256076022982597, flat: 2.542611353099346, pod: 40.84044599533081, loss: 45.50866484642029 
Train [9/26] | Epoch [28/160] |	nca: 1.879396852105856, flat: 2.4015802294015884, pod: 39.8175733089447, loss: 44.09855031967163 
Train [9/26] | Epoch [29/160] |	nca: 1.90352214127779, flat: 2.1496231481432915, pod: 37.0859637260437, loss: 41.13910889625549 
Train [9/26] | Epoch [30/160] |	nca: 2.1518524065613747, flat: 2.407386898994446, pod: 38.67913556098938, loss: 43.23837471008301 
Train [9/26] | Epoch [31/160] |	nca: 1.8679027259349823, flat: 2.34945647418499, pod: 38.48858380317688, loss: 42.7059428691864 
Train [9/26] | Epoch [32/160] |	nca: 1.8269523307681084, flat: 2.3686537072062492, pod: 39.104047775268555, loss: 43.29965424537659 
Train [9/26] | Epoch [33/160] |	nca: 1.8303475007414818, flat: 2.2860502898693085, pod: 38.68964469432831, loss: 42.806042194366455 
Train [9/26] | Epoch [34/160] |	nca: 1.8417394571006298, flat: 2.3004272878170013, pod: 38.25346100330353, loss: 42.395628213882446 
Train [9/26] | Epoch [35/160] |	nca: 1.9348843544721603, flat: 2.2100437954068184, pod: 38.72228026390076, loss: 42.8672080039978 
Train [9/26] | Epoch [36/160] |	nca: 1.9746854454278946, flat: 2.2411361187696457, pod: 38.13055098056793, loss: 42.346372842788696 
Train [9/26] | Epoch [37/160] |	nca: 1.9239706248044968, flat: 2.1440994441509247, pod: 36.083173990249634, loss: 40.15124440193176 
Train [9/26] | Epoch [38/160] |	nca: 1.7309306859970093, flat: 2.0884646251797676, pod: 36.122161626815796, loss: 39.94155716896057 
Train [9/26] | Epoch [39/160] |	nca: 2.2503286227583885, flat: 2.4211528822779655, pod: 39.1275315284729, loss: 43.799012660980225 
Train [9/26] | Epoch [40/160] |	nca: 1.9162025675177574, flat: 2.2251427471637726, pod: 37.131149768829346, loss: 41.27249479293823 
Train [9/26] | Epoch [41/160] |	nca: 1.8780114725232124, flat: 2.212609201669693, pod: 37.10670518875122, loss: 41.197325706481934 
Train [9/26] | Epoch [42/160] |	nca: 1.7751283682882786, flat: 2.1880476772785187, pod: 36.29092562198639, loss: 40.25410175323486 
Train [9/26] | Epoch [43/160] |	nca: 1.7014366686344147, flat: 2.1863185688853264, pod: 37.61042582988739, loss: 41.498180866241455 
Train [9/26] | Epoch [44/160] |	nca: 1.8558278046548367, flat: 2.169159896671772, pod: 38.0158725976944, loss: 42.040860176086426 
Train [9/26] | Epoch [45/160] |	nca: 1.8016071394085884, flat: 2.01187601685524, pod: 36.0733847618103, loss: 39.88686752319336 
Train [9/26] | Epoch [46/160] |	nca: 1.9645055495202541, flat: 2.082898363471031, pod: 36.105364203453064, loss: 40.15276789665222 
Train [9/26] | Epoch [47/160] |	nca: 1.8248257413506508, flat: 2.031263552606106, pod: 35.4945650100708, loss: 39.35065460205078 
Train [9/26] | Epoch [48/160] |	nca: 1.7053196728229523, flat: 1.9525580927729607, pod: 36.54637956619263, loss: 40.20425748825073 
Train [9/26] | Epoch [49/160] |	nca: 1.7881755158305168, flat: 2.0871168226003647, pod: 36.59479379653931, loss: 40.47008657455444 
Train [9/26] | Epoch [50/160] |	nca: 1.8878134526312351, flat: 2.0393674969673157, pod: 36.02563738822937, loss: 39.952818512916565 
Train [9/26] | Epoch [51/160] |	nca: 1.6881421506404877, flat: 1.9162817671895027, pod: 34.79506528377533, loss: 38.39948868751526 
Train [9/26] | Epoch [52/160] |	nca: 1.7016558423638344, flat: 1.9796055778861046, pod: 35.1175240278244, loss: 38.79878556728363 
Train [9/26] | Epoch [53/160] |	nca: 1.7020915299654007, flat: 1.8794786632061005, pod: 34.232417345047, loss: 37.813987493515015 
Train [9/26] | Epoch [54/160] |	nca: 1.6291259080171585, flat: 1.9983401447534561, pod: 35.40539300441742, loss: 39.032859086990356 
Train [9/26] | Epoch [55/160] |	nca: 1.7623222395777702, flat: 1.9687956869602203, pod: 35.76381027698517, loss: 39.49492847919464 
Train [9/26] | Epoch [56/160] |	nca: 1.7117310613393784, flat: 1.8776695728302002, pod: 35.07759118080139, loss: 38.66699182987213 
Train [9/26] | Epoch [57/160] |	nca: 1.7246433719992638, flat: 1.8076694384217262, pod: 33.98031771183014, loss: 37.512630581855774 
Train [9/26] | Epoch [58/160] |	nca: 1.6956078670918941, flat: 1.981999509036541, pod: 37.12796437740326, loss: 40.80557179450989 
Train [9/26] | Epoch [59/160] |	nca: 1.6394801810383797, flat: 1.7876569107174873, pod: 34.0680216550827, loss: 37.495158672332764 
Train [9/26] | Epoch [60/160] |	nca: 1.6558368131518364, flat: 1.7233584076166153, pod: 32.64111661911011, loss: 36.02031147480011 
Train [9/26] | Epoch [61/160] |	nca: 1.6862004473805428, flat: 1.773979790508747, pod: 33.715601086616516, loss: 37.17578148841858 
Train [9/26] | Epoch [62/160] |	nca: 1.859332449734211, flat: 1.9327768608927727, pod: 35.100229144096375, loss: 38.892338275909424 
Train [9/26] | Epoch [63/160] |	nca: 1.654764223843813, flat: 1.8024352341890335, pod: 34.26924216747284, loss: 37.72644126415253 
Train [9/26] | Epoch [64/160] |	nca: 1.6799611523747444, flat: 1.8585614636540413, pod: 33.92431604862213, loss: 37.46283841133118 
Train [9/26] | Epoch [65/160] |	nca: 1.7358610406517982, flat: 1.9247120022773743, pod: 34.839741945266724, loss: 38.50031495094299 
Train [9/26] | Epoch [66/160] |	nca: 1.667013805359602, flat: 1.8576852157711983, pod: 35.096038699150085, loss: 38.6207377910614 
Train [9/26] | Epoch [67/160] |	nca: 1.7519489228725433, flat: 1.6923327073454857, pod: 32.17018473148346, loss: 35.61446666717529 
Train [9/26] | Epoch [68/160] |	nca: 1.5615038238465786, flat: 1.693544365465641, pod: 31.484780430793762, loss: 34.73982894420624 
Train [9/26] | Epoch [69/160] |	nca: 1.695006612688303, flat: 1.7673852816224098, pod: 33.34723460674286, loss: 36.80962598323822 
Train [9/26] | Epoch [70/160] |	nca: 1.6050603948533535, flat: 1.7188119739294052, pod: 32.33587658405304, loss: 35.659748911857605 
Train [9/26] | Epoch [71/160] |	nca: 1.7053389064967632, flat: 1.6958936527371407, pod: 32.22602319717407, loss: 35.62725555896759 
Train [9/26] | Epoch [72/160] |	nca: 1.5951142609119415, flat: 1.7020561918616295, pod: 33.14897036552429, loss: 36.44614064693451 
Train [9/26] | Epoch [73/160] |	nca: 1.6840641498565674, flat: 1.6962799951434135, pod: 32.18524873256683, loss: 35.565592885017395 
Train [9/26] | Epoch [74/160] |	nca: 1.7060246020555496, flat: 1.6581018269062042, pod: 32.21193265914917, loss: 35.576059103012085 
Train [9/26] | Epoch [75/160] |	nca: 1.6066936366260052, flat: 1.6503971815109253, pod: 32.15198254585266, loss: 35.40907323360443 
Train [9/26] | Epoch [76/160] |	nca: 1.584011249244213, flat: 1.6257758662104607, pod: 32.04318678379059, loss: 35.252974152565 
Train [9/26] | Epoch [77/160] |	nca: 1.6413656994700432, flat: 1.5710166841745377, pod: 31.272382736206055, loss: 34.4847651720047 
Train [9/26] | Epoch [78/160] |	nca: 1.8244388028979301, flat: 1.664097085595131, pod: 31.730347752571106, loss: 35.218883633613586 
Train [9/26] | Epoch [79/160] |	nca: 1.5521830841898918, flat: 1.6012812405824661, pod: 31.07976794242859, loss: 34.233232259750366 
Train [9/26] | Epoch [80/160] |	nca: 1.6121692657470703, flat: 1.5624455213546753, pod: 30.898951411247253, loss: 34.07356631755829 
Train [9/26] | Epoch [81/160] |	nca: 1.4888531528413296, flat: 1.5257346853613853, pod: 32.258697390556335, loss: 35.273285269737244 
Train [9/26] | Epoch [82/160] |	nca: 1.4654801934957504, flat: 1.5160105600953102, pod: 30.5416921377182, loss: 33.5231831073761 
Train [9/26] | Epoch [83/160] |	nca: 1.5787990167737007, flat: 1.4270270019769669, pod: 29.225755095481873, loss: 32.2315810918808 
Train [9/26] | Epoch [84/160] |	nca: 1.4671635366976261, flat: 1.4141231589019299, pod: 29.30173623561859, loss: 32.1830233335495 
Train [9/26] | Epoch [85/160] |	nca: 1.4330456629395485, flat: 1.4119050279259682, pod: 30.16647696495056, loss: 33.01142752170563 
Train [9/26] | Epoch [86/160] |	nca: 1.5429766550660133, flat: 1.4287943467497826, pod: 29.697618007659912, loss: 32.66938889026642 
Train [9/26] | Epoch [87/160] |	nca: 1.5684247240424156, flat: 1.4080389067530632, pod: 29.55095410346985, loss: 32.52741765975952 
Train [9/26] | Epoch [88/160] |	nca: 1.5311194099485874, flat: 1.3295606598258018, pod: 28.926786422729492, loss: 31.787466526031494 
Train [9/26] | Epoch [89/160] |	nca: 1.4690081030130386, flat: 1.3554411232471466, pod: 28.430310606956482, loss: 31.254760026931763 
Train [9/26] | Epoch [90/160] |	nca: 1.5211312770843506, flat: 1.4301465675234795, pod: 30.975955486297607, loss: 33.92723321914673 
Train [9/26] | Epoch [91/160] |	nca: 1.4986985959112644, flat: 1.3881127573549747, pod: 29.27491056919098, loss: 32.16172182559967 
Train [9/26] | Epoch [92/160] |	nca: 1.594755832105875, flat: 1.290144294500351, pod: 27.434487104415894, loss: 30.319387316703796 
Train [9/26] | Epoch [93/160] |	nca: 1.4480497874319553, flat: 1.2842668741941452, pod: 27.467103719711304, loss: 30.19942045211792 
Train [9/26] | Epoch [94/160] |	nca: 1.4401313103735447, flat: 1.2465078011155128, pod: 26.961760878562927, loss: 29.648399829864502 
Train [9/26] | Epoch [95/160] |	nca: 1.5463511906564236, flat: 1.2182553112506866, pod: 26.965810418128967, loss: 29.730416536331177 
Train [9/26] | Epoch [96/160] |	nca: 1.6330152973532677, flat: 1.3698789104819298, pod: 28.821020364761353, loss: 31.823914527893066 
Train [9/26] | Epoch [97/160] |	nca: 1.4275027699768543, flat: 1.2759928777813911, pod: 28.513340711593628, loss: 31.21683621406555 
Train [9/26] | Epoch [98/160] |	nca: 1.4213949888944626, flat: 1.2470029145479202, pod: 28.195534586906433, loss: 30.863932371139526 
Train [9/26] | Epoch [99/160] |	nca: 1.4142528362572193, flat: 1.1990155652165413, pod: 27.737323880195618, loss: 30.350592374801636 
Train [9/26] | Epoch [100/160] |	nca: 1.4445207118988037, flat: 1.1193481385707855, pod: 25.390483736991882, loss: 27.954352736473083 
Train [9/26] | Epoch [101/160] |	nca: 1.5515737272799015, flat: 1.1359292455017567, pod: 26.287873148918152, loss: 28.97537612915039 
Train [9/26] | Epoch [102/160] |	nca: 1.5161361917853355, flat: 1.1495560631155968, pod: 26.859952926635742, loss: 29.52564525604248 
Train [9/26] | Epoch [103/160] |	nca: 1.6604543402791023, flat: 1.1518452651798725, pod: 25.660162568092346, loss: 28.47246217727661 
Train [9/26] | Epoch [104/160] |	nca: 1.4462316669523716, flat: 1.1700691916048527, pod: 26.07968282699585, loss: 28.69598364830017 
Train [9/26] | Epoch [105/160] |	nca: 1.573522686958313, flat: 1.2290675044059753, pod: 26.97655701637268, loss: 29.779147028923035 
Train [9/26] | Epoch [106/160] |	nca: 1.3602013997733593, flat: 1.0146002061665058, pod: 24.255895256996155, loss: 26.630696892738342 
Train [9/26] | Epoch [107/160] |	nca: 1.4770408757030964, flat: 1.0949267968535423, pod: 25.85968029499054, loss: 28.431647896766663 
Train [9/26] | Epoch [108/160] |	nca: 1.53868667781353, flat: 1.0878808312118053, pod: 25.183810472488403, loss: 27.810378074645996 
Train [9/26] | Epoch [109/160] |	nca: 1.4254823997616768, flat: 1.1056918539106846, pod: 25.556159496307373, loss: 28.08733367919922 
Train [9/26] | Epoch [110/160] |	nca: 1.3753060139715672, flat: 0.9770060442388058, pod: 23.451793313026428, loss: 25.804105401039124 
Train [9/26] | Epoch [111/160] |	nca: 1.606363132596016, flat: 1.063676506280899, pod: 23.879962682724, loss: 26.550002098083496 
Train [9/26] | Epoch [112/160] |	nca: 1.5261208415031433, flat: 1.0282910130918026, pod: 24.01068353652954, loss: 26.56509554386139 
Train [9/26] | Epoch [113/160] |	nca: 1.576940968632698, flat: 0.9915703311562538, pod: 22.991984128952026, loss: 25.560495376586914 
Train [9/26] | Epoch [114/160] |	nca: 1.3927379921078682, flat: 0.9540020674467087, pod: 23.231924057006836, loss: 25.57866406440735 
Train [9/26] | Epoch [115/160] |	nca: 1.4062956273555756, flat: 1.0102668963372707, pod: 23.914982557296753, loss: 26.331545114517212 
Train [9/26] | Epoch [116/160] |	nca: 1.443767286837101, flat: 0.9110423065721989, pod: 21.96372127532959, loss: 24.318530678749084 
Train [9/26] | Epoch [117/160] |	nca: 1.389866717159748, flat: 0.9759064801037312, pod: 23.6661559343338, loss: 26.03192913532257 
Train [9/26] | Epoch [118/160] |	nca: 1.3366914987564087, flat: 0.9718198105692863, pod: 23.196849465370178, loss: 25.50536072254181 
Train [9/26] | Epoch [119/160] |	nca: 1.452723789960146, flat: 0.8692231252789497, pod: 21.513699531555176, loss: 23.835646629333496 
Train [9/26] | Epoch [120/160] |	nca: 1.416836354881525, flat: 0.8349188379943371, pod: 21.47395670413971, loss: 23.725711941719055 
Train [9/26] | Epoch [121/160] |	nca: 1.4634478092193604, flat: 0.9253906980156898, pod: 22.64139187335968, loss: 25.030230402946472 
Train [9/26] | Epoch [122/160] |	nca: 1.4360029511153698, flat: 0.9793161861598492, pod: 23.00000500679016, loss: 25.415324091911316 
Train [9/26] | Epoch [123/160] |	nca: 1.2497466690838337, flat: 0.8705447018146515, pod: 22.051836252212524, loss: 24.17212748527527 
Train [9/26] | Epoch [124/160] |	nca: 1.412368282675743, flat: 0.9230508096516132, pod: 23.345932960510254, loss: 25.68135178089142 
Train [9/26] | Epoch [125/160] |	nca: 1.4468841440975666, flat: 0.8321443274617195, pod: 21.90550208091736, loss: 24.18453073501587 
Train [9/26] | Epoch [126/160] |	nca: 1.4708644673228264, flat: 0.8837692923843861, pod: 21.86112093925476, loss: 24.215754508972168 
Train [9/26] | Epoch [127/160] |	nca: 1.4185045771300793, flat: 0.8542578183114529, pod: 21.864805936813354, loss: 24.13756811618805 
Train [9/26] | Epoch [128/160] |	nca: 1.4421173855662346, flat: 0.8117516711354256, pod: 20.21280211210251, loss: 22.46667128801346 
Train [9/26] | Epoch [129/160] |	nca: 1.4140861555933952, flat: 0.8355027511715889, pod: 20.702771365642548, loss: 22.952360153198242 
Train [9/26] | Epoch [130/160] |	nca: 1.3978068232536316, flat: 0.8261416889727116, pod: 21.595021188259125, loss: 23.81896984577179 
Train [9/26] | Epoch [131/160] |	nca: 1.4276748038828373, flat: 0.7853867709636688, pod: 20.614973545074463, loss: 22.82803523540497 
Train [9/26] | Epoch [132/160] |	nca: 1.374574363231659, flat: 0.7567549496889114, pod: 19.76572847366333, loss: 21.89705777168274 
Train [9/26] | Epoch [133/160] |	nca: 1.3231859467923641, flat: 0.7355814799666405, pod: 19.017454206943512, loss: 21.076221704483032 
Train [9/26] | Epoch [134/160] |	nca: 1.3331796266138554, flat: 0.7652082107961178, pod: 19.268015801906586, loss: 21.366403698921204 
Train [9/26] | Epoch [135/160] |	nca: 1.375359132885933, flat: 0.7988884747028351, pod: 20.83801132440567, loss: 23.012259006500244 
Train [9/26] | Epoch [136/160] |	nca: 1.3993473760783672, flat: 0.7137523572891951, pod: 18.803342163562775, loss: 20.916441917419434 
Train [9/26] | Epoch [137/160] |	nca: 1.3986962959170341, flat: 0.7157608382403851, pod: 18.906372845172882, loss: 21.020829916000366 
Train [9/26] | Epoch [138/160] |	nca: 1.3472218587994576, flat: 0.7342225573956966, pod: 19.627794563770294, loss: 21.70923900604248 
Train [9/26] | Epoch [139/160] |	nca: 1.3987243995070457, flat: 0.687202962115407, pod: 18.692215144634247, loss: 20.778142631053925 
Train [9/26] | Epoch [140/160] |	nca: 1.3641574531793594, flat: 0.7336841635406017, pod: 19.113410592079163, loss: 21.21125227212906 
Train [9/26] | Epoch [141/160] |	nca: 1.3769504316151142, flat: 0.6981260646134615, pod: 18.7723228931427, loss: 20.847399592399597 
Train [9/26] | Epoch [142/160] |	nca: 1.4514341279864311, flat: 0.7320346646010876, pod: 18.796651542186737, loss: 20.980120301246643 
Train [9/26] | Epoch [143/160] |	nca: 1.45913552865386, flat: 0.6691591832786798, pod: 17.911337971687317, loss: 20.039632558822632 
Train [9/26] | Epoch [144/160] |	nca: 1.361023798584938, flat: 0.7082688063383102, pod: 18.43500030040741, loss: 20.50429278612137 
Train [9/26] | Epoch [145/160] |	nca: 1.3616516552865505, flat: 0.635222913697362, pod: 17.755951285362244, loss: 19.752825915813446 
Train [9/26] | Epoch [146/160] |	nca: 1.3578029610216618, flat: 0.6273125410079956, pod: 17.33160310983658, loss: 19.316718578338623 
Train [9/26] | Epoch [147/160] |	nca: 1.4347602650523186, flat: 0.6481541339308023, pod: 17.350822031497955, loss: 19.433736264705658 
Train [9/26] | Epoch [148/160] |	nca: 1.3161855451762676, flat: 0.6609406657516956, pod: 17.34646636247635, loss: 19.323592483997345 
Train [9/26] | Epoch [149/160] |	nca: 1.4484073892235756, flat: 0.6421300265938044, pod: 17.38267344236374, loss: 19.47321105003357 
Train [9/26] | Epoch [150/160] |	nca: 1.4206173494458199, flat: 0.6331020817160606, pod: 16.774355053901672, loss: 18.828074514865875 
Train [9/26] | Epoch [151/160] |	nca: 1.4288702346384525, flat: 0.632057836279273, pod: 16.70832920074463, loss: 18.769257485866547 
Train [9/26] | Epoch [152/160] |	nca: 1.3117175921797752, flat: 0.6515934746712446, pod: 16.75648009777069, loss: 18.71979123353958 
Train [9/26] | Epoch [153/160] |	nca: 1.22169903293252, flat: 0.5999088492244482, pod: 16.279198586940765, loss: 18.10080635547638 
Train [9/26] | Epoch [154/160] |	nca: 1.4019283391535282, flat: 0.5994448736310005, pod: 16.647254645824432, loss: 18.648627877235413 
Train [9/26] | Epoch [155/160] |	nca: 1.49373072758317, flat: 0.6304555591195822, pod: 16.775542378425598, loss: 18.899728417396545 
Train [9/26] | Epoch [156/160] |	nca: 1.3200753591954708, flat: 0.6278754696249962, pod: 16.9218248128891, loss: 18.869775652885437 
Train [9/26] | Epoch [157/160] |	nca: 1.3579555228352547, flat: 0.6325339078903198, pod: 16.87150549888611, loss: 18.861994802951813 
Train [9/26] | Epoch [158/160] |	nca: 1.3589341416954994, flat: 0.6298192553222179, pod: 17.139685213565826, loss: 19.128438651561737 
Train [9/26] | Epoch [159/160] |	nca: 1.3398418128490448, flat: 0.5952109154313803, pod: 16.336489498615265, loss: 18.271542489528656 
Train [9/26] | Epoch [160/160] |	nca: 1.4171887151896954, flat: 0.5863806325942278, pod: 16.09156233072281, loss: 18.095131635665894 
Fine-tuning
Building & updating memory.
Train [9/26] | Epoch [161/180] |	nca: 1.1225063502788544, flat: 0.7877211384475231, pod: 14.838335752487183, loss: 16.748563408851624 
Train [9/26] | Epoch [162/180] |	nca: 0.6228738129138947, flat: 0.8222764134407043, pod: 15.080386519432068, loss: 16.52553677558899 
Train [9/26] | Epoch [163/180] |	nca: 0.5828488320112228, flat: 0.8020893633365631, pod: 14.98366630077362, loss: 16.36860430240631 
Train [9/26] | Epoch [164/180] |	nca: 0.4847048781812191, flat: 0.8002885803580284, pod: 14.831353425979614, loss: 16.116346836090088 
Train [9/26] | Epoch [165/180] |	nca: 0.5823708493262529, flat: 0.8158434443175793, pod: 15.049724340438843, loss: 16.447938442230225 
Train [9/26] | Epoch [166/180] |	nca: 0.48516679368913174, flat: 0.8012270703911781, pod: 14.874743103981018, loss: 16.161137104034424 
Train [9/26] | Epoch [167/180] |	nca: 0.4604750778526068, flat: 0.7786143608391285, pod: 14.962905406951904, loss: 16.20199477672577 
Train [9/26] | Epoch [168/180] |	nca: 0.38233367167413235, flat: 0.7841536700725555, pod: 14.86316180229187, loss: 16.029649138450623 
Train [9/26] | Epoch [169/180] |	nca: 0.38853769190609455, flat: 0.8005155362188816, pod: 15.074931383132935, loss: 16.263984441757202 
Train [9/26] | Epoch [170/180] |	nca: 0.4240961857140064, flat: 0.8105919770896435, pod: 14.797084927558899, loss: 16.03177309036255 
Train [9/26] | Epoch [171/180] |	nca: 0.47528891265392303, flat: 0.7995253764092922, pod: 15.337453484535217, loss: 16.61226773262024 
Train [9/26] | Epoch [172/180] |	nca: 0.43769580125808716, flat: 0.8681648895144463, pod: 15.540699005126953, loss: 16.846559643745422 
Train [9/26] | Epoch [173/180] |	nca: 0.4747402109205723, flat: 0.8065831325948238, pod: 15.190271735191345, loss: 16.47159504890442 
Train [9/26] | Epoch [174/180] |	nca: 0.41587649285793304, flat: 0.7976397052407265, pod: 14.903028130531311, loss: 16.116544365882874 
Train [9/26] | Epoch [175/180] |	nca: 0.37943199649453163, flat: 0.8069982193410397, pod: 14.911424040794373, loss: 16.097854137420654 
Train [9/26] | Epoch [176/180] |	nca: 0.46834060177206993, flat: 0.8277404494583607, pod: 15.395407557487488, loss: 16.69148874282837 
Train [9/26] | Epoch [177/180] |	nca: 0.3689184654504061, flat: 0.8005492202937603, pod: 14.699566125869751, loss: 15.869033694267273 
Train [9/26] | Epoch [178/180] |	nca: 0.3938591741025448, flat: 0.7822110429406166, pod: 14.810489296913147, loss: 15.986559510231018 
Train [9/26] | Epoch [179/180] |	nca: 0.4568468816578388, flat: 0.850946456193924, pod: 15.361311316490173, loss: 16.66910457611084 
Train [9/26] | Epoch [180/180] |	nca: 0.35908476263284683, flat: 0.793047334998846, pod: 15.016884088516235, loss: 16.169016003608704 
after task
Building & updating memory.
after task
Eval on 0->66.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6777777777777778.
Current acc: {'total': 0.612, '00-09': 0.651, '10-19': 0.64, '20-29': 0.548, '30-39': 0.585, '40-49': 0.634, '50-59': 0.672, '60-69': 0.517}.
Avg inc acc top5: 0.8988888888888888.
Current acc top5: {'total': 0.868}.
Forgetting: 0.09899999999999999.
Cord metric: 0.66.
Old accuracy: 0.61, mean: 0.67.
New accuracy: 0.51, mean: 0.65.
================Task 9 Start!================
Testing on False unseen tasks (max class = 68).
Set memory of size: 1320.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 9 Training!================
The training samples number: 2320
Train on 66->68.
train task
nb 2320.
Train [10/26] | Epoch [1/160] |	nca: 6.961518585681915, flat: 2.907315455377102, pod: 41.81275010108948, loss: 51.68158483505249 
Train [10/26] | Epoch [2/160] |	nca: 7.9935926496982574, flat: 6.114838182926178, pod: 61.51182699203491, loss: 75.62025856971741 
Train [10/26] | Epoch [3/160] |	nca: 7.222693890333176, flat: 6.897119224071503, pod: 65.77840924263, loss: 79.89822292327881 
Train [10/26] | Epoch [4/160] |	nca: 6.414055056869984, flat: 6.5460759699344635, pod: 64.51825404167175, loss: 77.47838497161865 
Train [10/26] | Epoch [5/160] |	nca: 4.270674146711826, flat: 4.746253505349159, pod: 55.55678844451904, loss: 64.57371616363525 
Train [10/26] | Epoch [6/160] |	nca: 4.996341556310654, flat: 5.51255239546299, pod: 58.84067463874817, loss: 69.34956860542297 
Train [10/26] | Epoch [7/160] |	nca: 4.807274714112282, flat: 5.310782223939896, pod: 60.63201689720154, loss: 70.75007390975952 
Train [10/26] | Epoch [8/160] |	nca: 6.0179573148489, flat: 6.170089155435562, pod: 64.599858045578, loss: 76.78790426254272 
Train [10/26] | Epoch [9/160] |	nca: 5.029523774981499, flat: 5.786738902330399, pod: 59.908973932266235, loss: 70.7252368927002 
Train [10/26] | Epoch [10/160] |	nca: 3.7629605531692505, flat: 4.897583231329918, pod: 56.26134181022644, loss: 64.92188549041748 
Train [10/26] | Epoch [11/160] |	nca: 2.9477589651942253, flat: 3.8833815455436707, pod: 50.89948534965515, loss: 57.730626583099365 
Train [10/26] | Epoch [12/160] |	nca: 2.8811369612812996, flat: 3.5423412024974823, pod: 48.608702421188354, loss: 55.032180309295654 
Train [10/26] | Epoch [13/160] |	nca: 2.5885327458381653, flat: 3.55543851852417, pod: 50.74264478683472, loss: 56.886616230010986 
Train [10/26] | Epoch [14/160] |	nca: 2.305271215736866, flat: 3.005347415804863, pod: 46.75175166130066, loss: 52.06237053871155 
Train [10/26] | Epoch [15/160] |	nca: 2.372211091220379, flat: 3.0516490787267685, pod: 46.326581716537476, loss: 51.750441789627075 
Train [10/26] | Epoch [16/160] |	nca: 2.0416675433516502, flat: 2.786425158381462, pod: 45.02972936630249, loss: 49.85782170295715 
Train [10/26] | Epoch [17/160] |	nca: 2.3698884695768356, flat: 2.8649424612522125, pod: 45.083577156066895, loss: 50.31840801239014 
Train [10/26] | Epoch [18/160] |	nca: 3.018470861017704, flat: 3.7533643692731857, pod: 50.23578500747681, loss: 57.007619857788086 
Train [10/26] | Epoch [19/160] |	nca: 3.1728771701455116, flat: 3.4328210800886154, pod: 48.29062843322754, loss: 54.896326303482056 
Train [10/26] | Epoch [20/160] |	nca: 4.2333507761359215, flat: 4.435106322169304, pod: 53.10700273513794, loss: 61.7754602432251 
Train [10/26] | Epoch [21/160] |	nca: 3.024155877530575, flat: 4.252708077430725, pod: 51.944522857666016, loss: 59.221386671066284 
Train [10/26] | Epoch [22/160] |	nca: 3.015131562948227, flat: 3.769136667251587, pod: 49.18114161491394, loss: 55.96540975570679 
Train [10/26] | Epoch [23/160] |	nca: 2.3958468288183212, flat: 3.737755388021469, pod: 48.58004140853882, loss: 54.7136435508728 
Train [10/26] | Epoch [24/160] |	nca: 2.2248263880610466, flat: 2.9434168338775635, pod: 45.28621697425842, loss: 50.45445990562439 
Train [10/26] | Epoch [25/160] |	nca: 2.450399287045002, flat: 3.0365714877843857, pod: 46.14508271217346, loss: 51.6320538520813 
Train [10/26] | Epoch [26/160] |	nca: 2.996032789349556, flat: 3.400387689471245, pod: 45.42169761657715, loss: 51.81811738014221 
Train [10/26] | Epoch [27/160] |	nca: 2.896882139146328, flat: 3.2581095695495605, pod: 46.601999282836914, loss: 52.75699067115784 
Train [10/26] | Epoch [28/160] |	nca: 2.9204914271831512, flat: 3.956882983446121, pod: 50.86564373970032, loss: 57.74301791191101 
Train [10/26] | Epoch [29/160] |	nca: 2.890691079199314, flat: 3.1045078337192535, pod: 46.961270809173584, loss: 52.956470012664795 
Train [10/26] | Epoch [30/160] |	nca: 3.8663277626037598, flat: 4.244394347071648, pod: 53.917784452438354, loss: 62.02850604057312 
Train [10/26] | Epoch [31/160] |	nca: 2.508977472782135, flat: 3.488646164536476, pod: 47.15514135360718, loss: 53.15276527404785 
Train [10/26] | Epoch [32/160] |	nca: 1.9563156217336655, flat: 2.8723506927490234, pod: 44.144577503204346, loss: 48.97324347496033 
Train [10/26] | Epoch [33/160] |	nca: 1.6053815372288227, flat: 2.3329510614275932, pod: 39.99556350708008, loss: 43.93389558792114 
Train [10/26] | Epoch [34/160] |	nca: 1.6758985817432404, flat: 2.423816353082657, pod: 42.76487958431244, loss: 46.86459422111511 
Train [10/26] | Epoch [35/160] |	nca: 1.791541501879692, flat: 2.2619926929473877, pod: 40.91324746608734, loss: 44.96678137779236 
Train [10/26] | Epoch [36/160] |	nca: 1.9410480633378029, flat: 2.5478610768914223, pod: 41.224015951156616, loss: 45.71292519569397 
Train [10/26] | Epoch [37/160] |	nca: 2.574325665831566, flat: 2.7094677537679672, pod: 42.28909349441528, loss: 47.57288718223572 
Train [10/26] | Epoch [38/160] |	nca: 3.3890888541936874, flat: 3.610731393098831, pod: 47.33689856529236, loss: 54.33671855926514 
Train [10/26] | Epoch [39/160] |	nca: 2.9878250285983086, flat: 3.7213694602251053, pod: 48.1150176525116, loss: 54.824212074279785 
Train [10/26] | Epoch [40/160] |	nca: 2.273356653749943, flat: 3.3473555147647858, pod: 48.224698543548584, loss: 53.8454110622406 
Train [10/26] | Epoch [41/160] |	nca: 2.0944214537739754, flat: 3.060620829463005, pod: 45.15447211265564, loss: 50.30951404571533 
Train [10/26] | Epoch [42/160] |	nca: 2.108498729765415, flat: 2.7939123660326004, pod: 43.03006398677826, loss: 47.932475328445435 
Train [10/26] | Epoch [43/160] |	nca: 2.145874284207821, flat: 2.698923073709011, pod: 43.83647608757019, loss: 48.681273221969604 
Train [10/26] | Epoch [44/160] |	nca: 2.01765239238739, flat: 2.7044458240270615, pod: 42.46188187599182, loss: 47.1839804649353 
Train [10/26] | Epoch [45/160] |	nca: 1.6222378686070442, flat: 2.2957416400313377, pod: 40.60651659965515, loss: 44.52449607849121 
Train [10/26] | Epoch [46/160] |	nca: 2.261243812739849, flat: 2.1936721056699753, pod: 39.72961211204529, loss: 44.1845281124115 
Train [10/26] | Epoch [47/160] |	nca: 3.2364854142069817, flat: 3.6494124084711075, pod: 46.057212829589844, loss: 52.943111181259155 
Train [10/26] | Epoch [48/160] |	nca: 2.263168103992939, flat: 2.8956040740013123, pod: 44.75411653518677, loss: 49.91288876533508 
Train [10/26] | Epoch [49/160] |	nca: 2.0021296814084053, flat: 2.6592078506946564, pod: 41.81123495101929, loss: 46.47257208824158 
Train [10/26] | Epoch [50/160] |	nca: 1.691934835165739, flat: 2.335001051425934, pod: 40.59270000457764, loss: 44.619635820388794 
Train [10/26] | Epoch [51/160] |	nca: 2.0153542421758175, flat: 2.3995364755392075, pod: 40.893988251686096, loss: 45.308879137039185 
Train [10/26] | Epoch [52/160] |	nca: 1.7255448251962662, flat: 2.3249163776636124, pod: 40.268173813819885, loss: 44.31863522529602 
Train [10/26] | Epoch [53/160] |	nca: 1.8985517285764217, flat: 2.160991556942463, pod: 38.93887555599213, loss: 42.99841856956482 
Train [10/26] | Epoch [54/160] |	nca: 1.7283829525113106, flat: 2.1640445962548256, pod: 38.223956823349, loss: 42.11638379096985 
Train [10/26] | Epoch [55/160] |	nca: 2.162597604095936, flat: 2.6850762590765953, pod: 42.12766098976135, loss: 46.97533440589905 
Train [10/26] | Epoch [56/160] |	nca: 2.823080465197563, flat: 2.607278972864151, pod: 41.07944321632385, loss: 46.50980281829834 
Train [10/26] | Epoch [57/160] |	nca: 2.7585454881191254, flat: 3.448298826813698, pod: 45.75559592247009, loss: 51.9624400138855 
Train [10/26] | Epoch [58/160] |	nca: 2.0913174152374268, flat: 2.785905532538891, pod: 43.07628893852234, loss: 47.95351266860962 
Train [10/26] | Epoch [59/160] |	nca: 2.083942722529173, flat: 2.452727660536766, pod: 41.856449246406555, loss: 46.39311981201172 
Train [10/26] | Epoch [60/160] |	nca: 2.3379009813070297, flat: 2.7024885937571526, pod: 42.44928503036499, loss: 47.48967480659485 
Train [10/26] | Epoch [61/160] |	nca: 2.098603807389736, flat: 2.8891381472349167, pod: 43.84788537025452, loss: 48.83562707901001 
Train [10/26] | Epoch [62/160] |	nca: 1.7895360440015793, flat: 2.346991702914238, pod: 40.34368574619293, loss: 44.480212688446045 
Train [10/26] | Epoch [63/160] |	nca: 1.8255292177200317, flat: 2.17383174598217, pod: 37.84476590156555, loss: 41.84412658214569 
Train [10/26] | Epoch [64/160] |	nca: 1.94838947057724, flat: 2.2985895574092865, pod: 38.355553150177, loss: 42.602532505989075 
Train [10/26] | Epoch [65/160] |	nca: 1.7378958612680435, flat: 2.0724239125847816, pod: 36.5343234539032, loss: 40.344643354415894 
Train [10/26] | Epoch [66/160] |	nca: 1.8203607834875584, flat: 1.897466205060482, pod: 36.30335354804993, loss: 40.021180629730225 
Train [10/26] | Epoch [67/160] |	nca: 1.7322439290583134, flat: 2.1086044162511826, pod: 38.32063102722168, loss: 42.161479473114014 
Train [10/26] | Epoch [68/160] |	nca: 1.8020807765424252, flat: 2.1439739763736725, pod: 38.62629544734955, loss: 42.57234966754913 
Train [10/26] | Epoch [69/160] |	nca: 1.6330974735319614, flat: 2.083993189036846, pod: 38.86025309562683, loss: 42.577343344688416 
Train [10/26] | Epoch [70/160] |	nca: 1.6832712106406689, flat: 1.8044765070080757, pod: 35.71301591396332, loss: 39.20076382160187 
Train [10/26] | Epoch [71/160] |	nca: 1.6778759509325027, flat: 1.766779139637947, pod: 35.72722351551056, loss: 39.1718784570694 
Train [10/26] | Epoch [72/160] |	nca: 1.7965897172689438, flat: 1.798837810754776, pod: 34.91109621524811, loss: 38.506523847579956 
Train [10/26] | Epoch [73/160] |	nca: 1.731205128133297, flat: 1.9633527472615242, pod: 37.024399757385254, loss: 40.71895742416382 
Train [10/26] | Epoch [74/160] |	nca: 1.5797752849757671, flat: 1.9067955166101456, pod: 35.99010908603668, loss: 39.47667968273163 
Train [10/26] | Epoch [75/160] |	nca: 1.497869472950697, flat: 1.7905889376997948, pod: 34.876038670539856, loss: 38.16449701786041 
Train [10/26] | Epoch [76/160] |	nca: 1.7775053270161152, flat: 1.9142431020736694, pod: 35.442911982536316, loss: 39.134660601615906 
Train [10/26] | Epoch [77/160] |	nca: 1.734004184603691, flat: 1.7974552437663078, pod: 33.673893213272095, loss: 37.205352783203125 
Train [10/26] | Epoch [78/160] |	nca: 1.7905688397586346, flat: 1.6647552326321602, pod: 33.25018906593323, loss: 36.70551323890686 
Train [10/26] | Epoch [79/160] |	nca: 1.8839684799313545, flat: 1.9153700768947601, pod: 34.872361063957214, loss: 38.67169976234436 
Train [10/26] | Epoch [80/160] |	nca: 1.7227888219058514, flat: 1.8617510125041008, pod: 34.144599199295044, loss: 37.72913885116577 
Train [10/26] | Epoch [81/160] |	nca: 1.622783400118351, flat: 1.7743365466594696, pod: 34.80521070957184, loss: 38.20233070850372 
Train [10/26] | Epoch [82/160] |	nca: 1.594038411974907, flat: 1.5924094468355179, pod: 32.940714597702026, loss: 36.12716269493103 
Train [10/26] | Epoch [83/160] |	nca: 1.5551271624863148, flat: 1.7271691635251045, pod: 33.181610345840454, loss: 36.46390676498413 
Train [10/26] | Epoch [84/160] |	nca: 1.8265713341534138, flat: 1.567695513367653, pod: 32.06901252269745, loss: 35.463279485702515 
Train [10/26] | Epoch [85/160] |	nca: 1.8234711550176144, flat: 1.6836250722408295, pod: 33.52054214477539, loss: 37.02763819694519 
Train [10/26] | Epoch [86/160] |	nca: 1.8875469081103802, flat: 1.7202216163277626, pod: 32.96245086193085, loss: 36.57021915912628 
Train [10/26] | Epoch [87/160] |	nca: 1.8562614768743515, flat: 1.8366686552762985, pod: 34.30849838256836, loss: 38.00142824649811 
Train [10/26] | Epoch [88/160] |	nca: 2.0365387350320816, flat: 1.8739797696471214, pod: 33.983301877975464, loss: 37.89382040500641 
Train [10/26] | Epoch [89/160] |	nca: 1.9711288809776306, flat: 1.7925821393728256, pod: 33.871795773506165, loss: 37.635506987571716 
Train [10/26] | Epoch [90/160] |	nca: 1.7189867608249187, flat: 1.7391961514949799, pod: 32.62451410293579, loss: 36.08269667625427 
Train [10/26] | Epoch [91/160] |	nca: 1.7052343115210533, flat: 1.6827910020947456, pod: 32.35061490535736, loss: 35.73864018917084 
Train [10/26] | Epoch [92/160] |	nca: 1.7639959305524826, flat: 1.6632611006498337, pod: 32.232943177223206, loss: 35.660200357437134 
Train [10/26] | Epoch [93/160] |	nca: 1.8601273968815804, flat: 1.699863612651825, pod: 34.99904406070709, loss: 38.55903494358063 
Train [10/26] | Epoch [94/160] |	nca: 1.59042065218091, flat: 1.6526039242744446, pod: 33.47718822956085, loss: 36.72021293640137 
Train [10/26] | Epoch [95/160] |	nca: 1.5964322425425053, flat: 1.5178074091672897, pod: 31.606894373893738, loss: 34.72113382816315 
Train [10/26] | Epoch [96/160] |	nca: 1.4815035872161388, flat: 1.6681669056415558, pod: 32.23119103908539, loss: 35.38086152076721 
Train [10/26] | Epoch [97/160] |	nca: 2.0930127166211605, flat: 1.6014454625546932, pod: 32.94915819168091, loss: 36.64361643791199 
Train [10/26] | Epoch [98/160] |	nca: 1.8509869910776615, flat: 1.6540229432284832, pod: 32.236243724823, loss: 35.74125397205353 
Train [10/26] | Epoch [99/160] |	nca: 1.410192921757698, flat: 1.3223180063068867, pod: 29.24522602558136, loss: 31.977736711502075 
Train [10/26] | Epoch [100/160] |	nca: 1.8460279442369938, flat: 1.3577721118927002, pod: 29.222491145133972, loss: 32.42629110813141 
Train [10/26] | Epoch [101/160] |	nca: 1.67541129514575, flat: 1.407788697630167, pod: 30.536077737808228, loss: 33.619277596473694 
Train [10/26] | Epoch [102/160] |	nca: 1.6957221254706383, flat: 1.4082681350409985, pod: 29.636897802352905, loss: 32.74088799953461 
Train [10/26] | Epoch [103/160] |	nca: 1.6375263929367065, flat: 1.423322957009077, pod: 29.829441905021667, loss: 32.89029121398926 
Train [10/26] | Epoch [104/160] |	nca: 1.6736539341509342, flat: 1.425741907209158, pod: 29.96882390975952, loss: 33.06821954250336 
Train [10/26] | Epoch [105/160] |	nca: 2.2051495984196663, flat: 1.434574417769909, pod: 29.455296993255615, loss: 33.09502112865448 
Train [10/26] | Epoch [106/160] |	nca: 1.6205255053937435, flat: 1.356498658657074, pod: 28.386863112449646, loss: 31.363887190818787 
Train [10/26] | Epoch [107/160] |	nca: 1.371340449899435, flat: 1.3061247877776623, pod: 28.681743144989014, loss: 31.359208345413208 
Train [10/26] | Epoch [108/160] |	nca: 1.6377301588654518, flat: 1.3230566121637821, pod: 28.009174704551697, loss: 30.969961285591125 
Train [10/26] | Epoch [109/160] |	nca: 1.394617646932602, flat: 1.4035122990608215, pod: 28.801088333129883, loss: 31.599218487739563 
Train [10/26] | Epoch [110/160] |	nca: 1.7151885628700256, flat: 1.2349675074219704, pod: 27.275739908218384, loss: 30.22589600086212 
Train [10/26] | Epoch [111/160] |	nca: 1.4780806116759777, flat: 1.2578693963587284, pod: 27.159536838531494, loss: 29.89548695087433 
Train [10/26] | Epoch [112/160] |	nca: 1.5754521079361439, flat: 1.1727420128881931, pod: 25.63278079032898, loss: 28.380974769592285 
Train [10/26] | Epoch [113/160] |	nca: 1.396902333945036, flat: 1.297518502920866, pod: 27.186289191246033, loss: 29.880710005760193 
Train [10/26] | Epoch [114/160] |	nca: 1.585499957203865, flat: 1.1716791689395905, pod: 27.23140239715576, loss: 29.98858153820038 
Train [10/26] | Epoch [115/160] |	nca: 1.5878570713102818, flat: 1.1984054557979107, pod: 28.017914652824402, loss: 30.804177284240723 
Train [10/26] | Epoch [116/160] |	nca: 1.4536162950098515, flat: 1.1634329669177532, pod: 26.42238759994507, loss: 29.03943657875061 
Train [10/26] | Epoch [117/160] |	nca: 1.3377825915813446, flat: 1.0609562695026398, pod: 24.404743671417236, loss: 26.80348253250122 
Train [10/26] | Epoch [118/160] |	nca: 1.7486719451844692, flat: 1.1133960895240307, pod: 25.655001044273376, loss: 28.51706898212433 
Train [10/26] | Epoch [119/160] |	nca: 1.6155891194939613, flat: 1.1343907788395882, pod: 25.801868796348572, loss: 28.551848769187927 
Train [10/26] | Epoch [120/160] |	nca: 1.8203400559723377, flat: 1.1860508508980274, pod: 25.81544268131256, loss: 28.821833729743958 
Train [10/26] | Epoch [121/160] |	nca: 1.4459549337625504, flat: 1.039158497005701, pod: 23.91598343849182, loss: 26.40109694004059 
Train [10/26] | Epoch [122/160] |	nca: 1.493509005755186, flat: 1.0189065225422382, pod: 23.960057854652405, loss: 26.47247338294983 
Train [10/26] | Epoch [123/160] |	nca: 1.4192617535591125, flat: 1.0824164263904095, pod: 25.023356914520264, loss: 27.52503514289856 
Train [10/26] | Epoch [124/160] |	nca: 1.7633198127150536, flat: 0.9712157770991325, pod: 23.30346655845642, loss: 26.038001894950867 
Train [10/26] | Epoch [125/160] |	nca: 1.4509446062147617, flat: 1.0367937609553337, pod: 23.544089436531067, loss: 26.031827807426453 
Train [10/26] | Epoch [126/160] |	nca: 1.4234269112348557, flat: 1.0853697918355465, pod: 25.41261577606201, loss: 27.921412348747253 
Train [10/26] | Epoch [127/160] |	nca: 1.9678292386233807, flat: 1.1394296176731586, pod: 24.23984980583191, loss: 27.347108840942383 
Train [10/26] | Epoch [128/160] |	nca: 1.9365731738507748, flat: 1.2509061060845852, pod: 25.265156626701355, loss: 28.452636003494263 
Train [10/26] | Epoch [129/160] |	nca: 1.4520130269229412, flat: 1.2541595064103603, pod: 24.622902512550354, loss: 27.32907509803772 
Train [10/26] | Epoch [130/160] |	nca: 1.4567402936518192, flat: 0.9654181562364101, pod: 22.311068415641785, loss: 24.733226776123047 
Train [10/26] | Epoch [131/160] |	nca: 1.5818538814783096, flat: 0.9624956510961056, pod: 22.287482738494873, loss: 24.83183228969574 
Train [10/26] | Epoch [132/160] |	nca: 1.5572241060435772, flat: 1.07063340395689, pod: 22.91633516550064, loss: 25.54419255256653 
Train [10/26] | Epoch [133/160] |	nca: 1.4343756437301636, flat: 0.9291042983531952, pod: 22.224752068519592, loss: 24.588231801986694 
Train [10/26] | Epoch [134/160] |	nca: 1.3796271421015263, flat: 0.8613638356328011, pod: 21.17437320947647, loss: 23.415363907814026 
Train [10/26] | Epoch [135/160] |	nca: 1.33244913443923, flat: 0.9159774482250214, pod: 21.92506515979767, loss: 24.173491835594177 
Train [10/26] | Epoch [136/160] |	nca: 1.5242979601025581, flat: 0.8978111371397972, pod: 21.106397211551666, loss: 23.52850639820099 
Train [10/26] | Epoch [137/160] |	nca: 1.5521500557661057, flat: 0.9270531237125397, pod: 21.140655159950256, loss: 23.619858145713806 
Train [10/26] | Epoch [138/160] |	nca: 1.6666508466005325, flat: 0.8747098743915558, pod: 20.718958616256714, loss: 23.260319471359253 
Train [10/26] | Epoch [139/160] |	nca: 1.3409973420202732, flat: 0.8255324978381395, pod: 20.26533168554306, loss: 22.431861639022827 
Train [10/26] | Epoch [140/160] |	nca: 1.2885093875229359, flat: 0.8479726295918226, pod: 20.024518132209778, loss: 22.161000072956085 
Train [10/26] | Epoch [141/160] |	nca: 1.3699812293052673, flat: 0.8269207086414099, pod: 20.248792469501495, loss: 22.44569420814514 
Train [10/26] | Epoch [142/160] |	nca: 1.3365336544811726, flat: 0.8107109535485506, pod: 19.673659563064575, loss: 21.82090413570404 
Train [10/26] | Epoch [143/160] |	nca: 1.5268770977854729, flat: 0.8380684293806553, pod: 20.41976511478424, loss: 22.784710705280304 
Train [10/26] | Epoch [144/160] |	nca: 1.5964465253055096, flat: 0.8280442953109741, pod: 19.340974152088165, loss: 21.765464961528778 
Train [10/26] | Epoch [145/160] |	nca: 1.4616716504096985, flat: 0.8239671923220158, pod: 20.59973233938217, loss: 22.885371506214142 
Train [10/26] | Epoch [146/160] |	nca: 1.3532667234539986, flat: 0.8279601335525513, pod: 20.412174701690674, loss: 22.593401432037354 
Train [10/26] | Epoch [147/160] |	nca: 1.3973094187676907, flat: 0.7517689224332571, pod: 19.939954340457916, loss: 22.089032649993896 
Train [10/26] | Epoch [148/160] |	nca: 1.4086001217365265, flat: 0.8644142653793097, pod: 19.38646709918976, loss: 21.659481406211853 
Train [10/26] | Epoch [149/160] |	nca: 1.4160356484353542, flat: 0.7398347221314907, pod: 19.427218735218048, loss: 21.58308917284012 
Train [10/26] | Epoch [150/160] |	nca: 1.4194867461919785, flat: 0.6910499408841133, pod: 18.280665397644043, loss: 20.391202211380005 
Train [10/26] | Epoch [151/160] |	nca: 1.303130391985178, flat: 0.8166588582098484, pod: 19.506533980369568, loss: 21.626323342323303 
Train [10/26] | Epoch [152/160] |	nca: 1.42098793014884, flat: 0.8777570500969887, pod: 18.62624102830887, loss: 20.924986004829407 
Train [10/26] | Epoch [153/160] |	nca: 1.6958702467381954, flat: 0.8960327990353107, pod: 19.169845819473267, loss: 21.761748909950256 
Train [10/26] | Epoch [154/160] |	nca: 1.4115151762962341, flat: 0.7850143760442734, pod: 19.094911634922028, loss: 21.291441023349762 
Train [10/26] | Epoch [155/160] |	nca: 1.3558559902012348, flat: 0.875662924721837, pod: 20.134144365787506, loss: 22.365663170814514 
Train [10/26] | Epoch [156/160] |	nca: 1.306133657693863, flat: 0.718396371230483, pod: 18.425582826137543, loss: 20.45011281967163 
Train [10/26] | Epoch [157/160] |	nca: 1.2894304990768433, flat: 0.7665975335985422, pod: 18.444933354854584, loss: 20.500961184501648 
Train [10/26] | Epoch [158/160] |	nca: 1.55810209736228, flat: 0.8544581383466721, pod: 19.122890770435333, loss: 21.535450875759125 
Train [10/26] | Epoch [159/160] |	nca: 1.4523286297917366, flat: 0.7136894036084414, pod: 17.41839236021042, loss: 19.58441036939621 
Train [10/26] | Epoch [160/160] |	nca: 1.3537731803953648, flat: 0.786117410287261, pod: 18.98498111963272, loss: 21.124871730804443 
Fine-tuning
Building & updating memory.
Train [10/26] | Epoch [161/180] |	nca: 1.2943210005760193, flat: 0.8800018280744553, pod: 14.888827681541443, loss: 17.06315052509308 
Train [10/26] | Epoch [162/180] |	nca: 0.723646555095911, flat: 0.8691841885447502, pod: 14.864099383354187, loss: 16.456929922103882 
Train [10/26] | Epoch [163/180] |	nca: 0.7119692787528038, flat: 0.8953016065061092, pod: 14.99783170223236, loss: 16.6051025390625 
Train [10/26] | Epoch [164/180] |	nca: 0.6318029426038265, flat: 0.9055708199739456, pod: 15.206547975540161, loss: 16.743921875953674 
Train [10/26] | Epoch [165/180] |	nca: 0.5310576446354389, flat: 0.8981040418148041, pod: 15.337953805923462, loss: 16.767115473747253 
Train [10/26] | Epoch [166/180] |	nca: 0.47937286645174026, flat: 0.881919089704752, pod: 14.947990536689758, loss: 16.309282541275024 
Train [10/26] | Epoch [167/180] |	nca: 0.4815319310873747, flat: 0.8804736658930779, pod: 15.008520603179932, loss: 16.37052619457245 
Train [10/26] | Epoch [168/180] |	nca: 0.46041152253746986, flat: 0.8669371493160725, pod: 14.531646132469177, loss: 15.858995079994202 
Train [10/26] | Epoch [169/180] |	nca: 0.4463004805147648, flat: 0.860389094799757, pod: 14.831689715385437, loss: 16.138379335403442 
Train [10/26] | Epoch [170/180] |	nca: 0.4525010511279106, flat: 0.8659743182361126, pod: 15.017826080322266, loss: 16.336301445961 
Train [10/26] | Epoch [171/180] |	nca: 0.4477590471506119, flat: 0.8582444339990616, pod: 14.866378545761108, loss: 16.17238211631775 
Train [10/26] | Epoch [172/180] |	nca: 0.5102563630789518, flat: 0.8706173561513424, pod: 14.755117177963257, loss: 16.135990977287292 
Train [10/26] | Epoch [173/180] |	nca: 0.44131309166550636, flat: 0.8820948377251625, pod: 14.71176016330719, loss: 16.035168051719666 
Train [10/26] | Epoch [174/180] |	nca: 0.45911828614771366, flat: 0.8790111765265465, pod: 15.059506058692932, loss: 16.39763569831848 
Train [10/26] | Epoch [175/180] |	nca: 0.44318127632141113, flat: 0.9002465978264809, pod: 15.035858631134033, loss: 16.379286527633667 
Train [10/26] | Epoch [176/180] |	nca: 0.45315135084092617, flat: 0.9004663750529289, pod: 15.182761549949646, loss: 16.5363792181015 
Train [10/26] | Epoch [177/180] |	nca: 0.45389800518751144, flat: 0.8785294890403748, pod: 14.99923026561737, loss: 16.331657886505127 
Train [10/26] | Epoch [178/180] |	nca: 0.41077846847474575, flat: 0.8930790610611439, pod: 14.907552003860474, loss: 16.21140968799591 
Train [10/26] | Epoch [179/180] |	nca: 0.42985289730131626, flat: 0.8846081867814064, pod: 15.039051532745361, loss: 16.35351264476776 
Train [10/26] | Epoch [180/180] |	nca: 0.4346322938799858, flat: 0.8846344761550426, pod: 15.112494707107544, loss: 16.431761384010315 
after task
Building & updating memory.
after task
Eval on 0->68.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6695.
Current acc: {'total': 0.595, '00-09': 0.648, '10-19': 0.616, '20-29': 0.535, '30-39': 0.562, '40-49': 0.625, '50-59': 0.641, '60-69': 0.524}.
Avg inc acc top5: 0.8943.
Current acc top5: {'total': 0.853}.
Forgetting: 0.11099999999999999.
Cord metric: 0.65.
Old accuracy: 0.59, mean: 0.66.
New accuracy: 0.59, mean: 0.64.
================Task 10 Start!================
Testing on False unseen tasks (max class = 70).
Set memory of size: 1360.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 10 Training!================
The training samples number: 2360
Train on 68->70.
train task
nb 2360.
Train [11/26] | Epoch [1/160] |	nca: 6.89148174226284, flat: 2.8403021320700645, pod: 40.25130844116211, loss: 49.983091831207275 
Train [11/26] | Epoch [2/160] |	nca: 4.379933804273605, flat: 3.2971202582120895, pod: 48.78372550010681, loss: 56.460779905319214 
Train [11/26] | Epoch [3/160] |	nca: 3.020357199013233, flat: 2.85439233481884, pod: 45.597107887268066, loss: 51.47185730934143 
Train [11/26] | Epoch [4/160] |	nca: 3.084290511906147, flat: 2.7279804050922394, pod: 45.263978242874146, loss: 51.07624936103821 
Train [11/26] | Epoch [5/160] |	nca: 2.5697741210460663, flat: 2.562940016388893, pod: 43.869637966156006, loss: 49.002352476119995 
Train [11/26] | Epoch [6/160] |	nca: 2.4156981632113457, flat: 2.354147031903267, pod: 43.6693217754364, loss: 48.43916726112366 
Train [11/26] | Epoch [7/160] |	nca: 2.609726905822754, flat: 2.553715132176876, pod: 45.13836216926575, loss: 50.30180382728577 
Train [11/26] | Epoch [8/160] |	nca: 2.352460741996765, flat: 2.6432196497917175, pod: 45.552841901779175, loss: 50.548521995544434 
Train [11/26] | Epoch [9/160] |	nca: 2.308092273771763, flat: 2.547652043402195, pod: 45.207462549209595, loss: 50.06320667266846 
Train [11/26] | Epoch [10/160] |	nca: 2.1045504063367844, flat: 2.284451775252819, pod: 41.55173397064209, loss: 45.940736293792725 
Train [11/26] | Epoch [11/160] |	nca: 2.31192734092474, flat: 2.111114926636219, pod: 40.56382083892822, loss: 44.98686337471008 
Train [11/26] | Epoch [12/160] |	nca: 2.161234486848116, flat: 2.1618004366755486, pod: 39.49689185619354, loss: 43.819926023483276 
Train [11/26] | Epoch [13/160] |	nca: 2.494131002575159, flat: 2.4450405314564705, pod: 43.72109293937683, loss: 48.66026496887207 
Train [11/26] | Epoch [14/160] |	nca: 2.346313200891018, flat: 2.3226026445627213, pod: 42.416024684906006, loss: 47.0849404335022 
Train [11/26] | Epoch [15/160] |	nca: 2.083705686032772, flat: 2.138861283659935, pod: 40.44154942035675, loss: 44.66411590576172 
Train [11/26] | Epoch [16/160] |	nca: 2.2646668404340744, flat: 2.195117361843586, pod: 41.450533628463745, loss: 45.91031789779663 
Train [11/26] | Epoch [17/160] |	nca: 2.132758103311062, flat: 2.1108816862106323, pod: 39.35624158382416, loss: 43.599881649017334 
Train [11/26] | Epoch [18/160] |	nca: 2.2122186794877052, flat: 2.113270081579685, pod: 39.84714496135712, loss: 44.17263340950012 
Train [11/26] | Epoch [19/160] |	nca: 2.100612796843052, flat: 2.1265349090099335, pod: 39.62656390666962, loss: 43.85371160507202 
Train [11/26] | Epoch [20/160] |	nca: 2.073012851178646, flat: 2.1383264288306236, pod: 41.60525894165039, loss: 45.816598415374756 
Train [11/26] | Epoch [21/160] |	nca: 1.8555810824036598, flat: 2.0096593126654625, pod: 39.49684715270996, loss: 43.36208724975586 
Train [11/26] | Epoch [22/160] |	nca: 1.9801007807254791, flat: 2.006754621863365, pod: 38.74385869503021, loss: 42.73071336746216 
Train [11/26] | Epoch [23/160] |	nca: 2.2128911912441254, flat: 2.261984996497631, pod: 40.35576677322388, loss: 44.83064293861389 
Train [11/26] | Epoch [24/160] |	nca: 2.1486511677503586, flat: 2.4373024106025696, pod: 41.86647963523865, loss: 46.45243310928345 
Train [11/26] | Epoch [25/160] |	nca: 2.099184215068817, flat: 2.109117865562439, pod: 39.97578227519989, loss: 44.18408393859863 
Train [11/26] | Epoch [26/160] |	nca: 1.930576778948307, flat: 1.9283462390303612, pod: 38.33636808395386, loss: 42.19529104232788 
Train [11/26] | Epoch [27/160] |	nca: 1.9334666877985, flat: 2.1798550710082054, pod: 40.73232173919678, loss: 44.845643281936646 
Train [11/26] | Epoch [28/160] |	nca: 2.22678579390049, flat: 2.2268107011914253, pod: 41.7558228969574, loss: 46.20941925048828 
Train [11/26] | Epoch [29/160] |	nca: 1.887134775519371, flat: 2.1313432157039642, pod: 39.93789088726044, loss: 43.956368923187256 
Train [11/26] | Epoch [30/160] |	nca: 1.7695586532354355, flat: 1.9114390537142754, pod: 38.075222849845886, loss: 41.75622034072876 
Train [11/26] | Epoch [31/160] |	nca: 1.9733254164457321, flat: 2.0093714371323586, pod: 39.33807837963104, loss: 43.320775270462036 
Train [11/26] | Epoch [32/160] |	nca: 1.8273258730769157, flat: 2.0231409072875977, pod: 38.81599020957947, loss: 42.666457176208496 
Train [11/26] | Epoch [33/160] |	nca: 2.148868143558502, flat: 2.1094513908028603, pod: 40.85698068141937, loss: 45.11529994010925 
Train [11/26] | Epoch [34/160] |	nca: 2.120181567966938, flat: 2.3139920458197594, pod: 42.40792667865753, loss: 46.842100381851196 
Train [11/26] | Epoch [35/160] |	nca: 1.923076592385769, flat: 2.101928301155567, pod: 39.62465262413025, loss: 43.649657011032104 
Train [11/26] | Epoch [36/160] |	nca: 2.041211858391762, flat: 2.0836940929293633, pod: 40.010313272476196, loss: 44.13521933555603 
Train [11/26] | Epoch [37/160] |	nca: 1.9274033904075623, flat: 2.048807315528393, pod: 38.64469051361084, loss: 42.620900988578796 
Train [11/26] | Epoch [38/160] |	nca: 1.795445255935192, flat: 2.0209995433688164, pod: 38.40587592124939, loss: 42.222320556640625 
Train [11/26] | Epoch [39/160] |	nca: 1.8351642973721027, flat: 1.9163496866822243, pod: 37.87178182601929, loss: 41.62329578399658 
Train [11/26] | Epoch [40/160] |	nca: 1.8517531491816044, flat: 1.7743772715330124, pod: 36.146528840065, loss: 39.77265918254852 
Train [11/26] | Epoch [41/160] |	nca: 1.709227293729782, flat: 1.8777450993657112, pod: 37.71684169769287, loss: 41.30381417274475 
Train [11/26] | Epoch [42/160] |	nca: 1.972553327679634, flat: 1.8656317666172981, pod: 37.33342957496643, loss: 41.1716148853302 
Train [11/26] | Epoch [43/160] |	nca: 1.6798367127776146, flat: 1.8354720398783684, pod: 36.94867563247681, loss: 40.46398460865021 
Train [11/26] | Epoch [44/160] |	nca: 1.778452541679144, flat: 1.8616263419389725, pod: 38.12738394737244, loss: 41.767462491989136 
Train [11/26] | Epoch [45/160] |	nca: 1.784715436398983, flat: 1.8151482567191124, pod: 37.82869803905487, loss: 41.42856240272522 
Train [11/26] | Epoch [46/160] |	nca: 1.8702059611678123, flat: 2.085633732378483, pod: 39.266485810279846, loss: 43.222325801849365 
Train [11/26] | Epoch [47/160] |	nca: 1.6590798422694206, flat: 1.768286369740963, pod: 36.239825963974, loss: 39.667192220687866 
Train [11/26] | Epoch [48/160] |	nca: 1.7010525092482567, flat: 1.629196397960186, pod: 34.93227183818817, loss: 38.26252043247223 
Train [11/26] | Epoch [49/160] |	nca: 1.740236021578312, flat: 1.7251270413398743, pod: 35.27885127067566, loss: 38.74421405792236 
Train [11/26] | Epoch [50/160] |	nca: 1.902234185487032, flat: 1.8812780901789665, pod: 37.08635234832764, loss: 40.86986446380615 
Train [11/26] | Epoch [51/160] |	nca: 1.6114977411925793, flat: 1.7874819338321686, pod: 36.935659408569336, loss: 40.33463907241821 
Train [11/26] | Epoch [52/160] |	nca: 1.7867036499083042, flat: 1.6860839053988457, pod: 35.50816750526428, loss: 38.98095500469208 
Train [11/26] | Epoch [53/160] |	nca: 1.8200982138514519, flat: 1.6669365987181664, pod: 34.6508332490921, loss: 38.13786828517914 
Train [11/26] | Epoch [54/160] |	nca: 1.7030085697770119, flat: 1.7450787052512169, pod: 36.958091259002686, loss: 40.40617787837982 
Train [11/26] | Epoch [55/160] |	nca: 1.977518618106842, flat: 1.8480829000473022, pod: 37.65772616863251, loss: 41.48332750797272 
Train [11/26] | Epoch [56/160] |	nca: 1.810459055006504, flat: 1.9036769419908524, pod: 38.13669264316559, loss: 41.850828647613525 
Train [11/26] | Epoch [57/160] |	nca: 1.9019572958350182, flat: 1.657324567437172, pod: 34.16137742996216, loss: 37.7206597328186 
Train [11/26] | Epoch [58/160] |	nca: 1.675659529864788, flat: 1.6455054581165314, pod: 34.140233635902405, loss: 37.46139848232269 
Train [11/26] | Epoch [59/160] |	nca: 1.8943413645029068, flat: 1.7336538583040237, pod: 36.110326170921326, loss: 39.73832142353058 
Train [11/26] | Epoch [60/160] |	nca: 1.561061978340149, flat: 1.6609835997223854, pod: 35.67864537239075, loss: 38.90069127082825 
Train [11/26] | Epoch [61/160] |	nca: 1.7308333739638329, flat: 1.540227748453617, pod: 33.89185905456543, loss: 37.1629204750061 
Train [11/26] | Epoch [62/160] |	nca: 1.7701239064335823, flat: 1.6628203839063644, pod: 34.00901758670807, loss: 37.44196176528931 
Train [11/26] | Epoch [63/160] |	nca: 1.743408314883709, flat: 1.5966643318533897, pod: 33.638169169425964, loss: 36.97824168205261 
Train [11/26] | Epoch [64/160] |	nca: 1.6413950026035309, flat: 1.576041154563427, pod: 32.63504993915558, loss: 35.85248601436615 
Train [11/26] | Epoch [65/160] |	nca: 1.6950840204954147, flat: 1.5535437166690826, pod: 34.73261642456055, loss: 37.98124420642853 
Train [11/26] | Epoch [66/160] |	nca: 1.7483924068510532, flat: 1.614660918712616, pod: 34.493969321250916, loss: 37.857022643089294 
Train [11/26] | Epoch [67/160] |	nca: 1.7551523484289646, flat: 1.5803995952010155, pod: 34.85134673118591, loss: 38.186898827552795 
Train [11/26] | Epoch [68/160] |	nca: 1.536724030971527, flat: 1.4537317156791687, pod: 34.15971052646637, loss: 37.1501659154892 
Train [11/26] | Epoch [69/160] |	nca: 1.652326624840498, flat: 1.5049398355185986, pod: 33.00873363018036, loss: 36.16599988937378 
Train [11/26] | Epoch [70/160] |	nca: 1.7189816311001778, flat: 1.483579345047474, pod: 33.71982955932617, loss: 36.92239022254944 
Train [11/26] | Epoch [71/160] |	nca: 1.6164094991981983, flat: 1.7311698719859123, pod: 36.32011961936951, loss: 39.667699337005615 
Train [11/26] | Epoch [72/160] |	nca: 1.5779738239943981, flat: 1.5164212882518768, pod: 34.04056227207184, loss: 37.13495719432831 
Train [11/26] | Epoch [73/160] |	nca: 1.7712613604962826, flat: 1.5828651040792465, pod: 34.260249853134155, loss: 37.614376068115234 
Train [11/26] | Epoch [74/160] |	nca: 1.4704339765012264, flat: 1.3970257304608822, pod: 31.44775629043579, loss: 34.315216183662415 
Train [11/26] | Epoch [75/160] |	nca: 1.539326962083578, flat: 1.4693847298622131, pod: 32.46494209766388, loss: 35.47365403175354 
Train [11/26] | Epoch [76/160] |	nca: 1.6283612176775932, flat: 1.4241971597075462, pod: 33.19109511375427, loss: 36.243653416633606 
Train [11/26] | Epoch [77/160] |	nca: 1.6360547356307507, flat: 1.4622387290000916, pod: 33.07851684093475, loss: 36.17681038379669 
Train [11/26] | Epoch [78/160] |	nca: 1.595864299684763, flat: 1.4614226073026657, pod: 33.19620954990387, loss: 36.2534966468811 
Train [11/26] | Epoch [79/160] |	nca: 1.5894439034163952, flat: 1.3863524869084358, pod: 32.798388600349426, loss: 35.77418518066406 
Train [11/26] | Epoch [80/160] |	nca: 1.4451099820435047, flat: 1.3386475518345833, pod: 32.11696791648865, loss: 34.90072560310364 
Train [11/26] | Epoch [81/160] |	nca: 1.5273475758731365, flat: 1.197725884616375, pod: 30.04664945602417, loss: 32.7717227935791 
Train [11/26] | Epoch [82/160] |	nca: 1.5520912520587444, flat: 1.242278341203928, pod: 30.553597569465637, loss: 33.34796702861786 
Train [11/26] | Epoch [83/160] |	nca: 1.4531843736767769, flat: 1.2407422959804535, pod: 29.510733485221863, loss: 32.204660058021545 
Train [11/26] | Epoch [84/160] |	nca: 1.5814032666385174, flat: 1.2172627560794353, pod: 29.858162879943848, loss: 32.65682888031006 
Train [11/26] | Epoch [85/160] |	nca: 1.7030537724494934, flat: 1.2710922323167324, pod: 30.06899642944336, loss: 33.043142437934875 
Train [11/26] | Epoch [86/160] |	nca: 1.5452484413981438, flat: 1.170472327619791, pod: 28.281317234039307, loss: 30.997037887573242 
Train [11/26] | Epoch [87/160] |	nca: 1.482812687754631, flat: 1.3343045450747013, pod: 30.989115238189697, loss: 33.80623245239258 
Train [11/26] | Epoch [88/160] |	nca: 1.6264866925776005, flat: 1.3408726528286934, pod: 30.978719115257263, loss: 33.946078419685364 
Train [11/26] | Epoch [89/160] |	nca: 1.4956635273993015, flat: 1.2395683079957962, pod: 29.897017121315002, loss: 32.632248878479004 
Train [11/26] | Epoch [90/160] |	nca: 1.5133324787020683, flat: 1.2725991420447826, pod: 30.32309591770172, loss: 33.10902762413025 
Train [11/26] | Epoch [91/160] |	nca: 1.5665420517325401, flat: 1.23685834556818, pod: 29.53137731552124, loss: 32.33477759361267 
Train [11/26] | Epoch [92/160] |	nca: 1.5788554325699806, flat: 1.1826598718762398, pod: 28.1981281042099, loss: 30.959643483161926 
Train [11/26] | Epoch [93/160] |	nca: 1.7207428365945816, flat: 1.1909097209572792, pod: 28.555385947227478, loss: 31.46703863143921 
Train [11/26] | Epoch [94/160] |	nca: 1.5154707431793213, flat: 1.088659405708313, pod: 27.70271372795105, loss: 30.306843876838684 
Train [11/26] | Epoch [95/160] |	nca: 1.5300611108541489, flat: 1.192023016512394, pod: 28.613543391227722, loss: 31.33562743663788 
Train [11/26] | Epoch [96/160] |	nca: 1.5912872850894928, flat: 1.174345426261425, pod: 29.078663110733032, loss: 31.844295740127563 
Train [11/26] | Epoch [97/160] |	nca: 1.7210501171648502, flat: 1.098095130175352, pod: 26.749470233917236, loss: 29.568615555763245 
Train [11/26] | Epoch [98/160] |	nca: 1.5628137737512589, flat: 1.255155973136425, pod: 29.471749901771545, loss: 32.289719581604004 
Train [11/26] | Epoch [99/160] |	nca: 1.6195226833224297, flat: 1.118130911141634, pod: 28.218106031417847, loss: 30.955759644508362 
Train [11/26] | Epoch [100/160] |	nca: 1.5712199211120605, flat: 1.1726794429123402, pod: 28.440256714820862, loss: 31.18415606021881 
Train [11/26] | Epoch [101/160] |	nca: 1.587812889367342, flat: 1.1767676696181297, pod: 28.68294632434845, loss: 31.447526812553406 
Train [11/26] | Epoch [102/160] |	nca: 1.431858729571104, flat: 1.1332597620785236, pod: 27.604515075683594, loss: 30.169633626937866 
Train [11/26] | Epoch [103/160] |	nca: 1.4373380094766617, flat: 1.083727978169918, pod: 27.507306694984436, loss: 30.028372645378113 
Train [11/26] | Epoch [104/160] |	nca: 1.439429510384798, flat: 1.0295014455914497, pod: 27.56467831134796, loss: 30.0336092710495 
Train [11/26] | Epoch [105/160] |	nca: 1.4398113749921322, flat: 0.9651988409459591, pod: 25.599432945251465, loss: 28.004442930221558 
Train [11/26] | Epoch [106/160] |	nca: 1.5197284296154976, flat: 0.9933813959360123, pod: 24.830636143684387, loss: 27.343745827674866 
Train [11/26] | Epoch [107/160] |	nca: 1.5988963805139065, flat: 0.9533754363656044, pod: 25.054839372634888, loss: 27.60711109638214 
Train [11/26] | Epoch [108/160] |	nca: 1.4918586984276772, flat: 0.983252689242363, pod: 26.000921964645386, loss: 28.476033449172974 
Train [11/26] | Epoch [109/160] |	nca: 1.5630325302481651, flat: 0.9682579562067986, pod: 24.54230511188507, loss: 27.073595643043518 
Train [11/26] | Epoch [110/160] |	nca: 1.4283210299909115, flat: 0.978374544531107, pod: 25.320460438728333, loss: 27.727156043052673 
Train [11/26] | Epoch [111/160] |	nca: 1.3463429138064384, flat: 0.8789917454123497, pod: 24.51816952228546, loss: 26.74350416660309 
Train [11/26] | Epoch [112/160] |	nca: 1.4060424491763115, flat: 0.8520242869853973, pod: 24.019233465194702, loss: 26.277300238609314 
Train [11/26] | Epoch [113/160] |	nca: 1.519688457250595, flat: 0.842020783573389, pod: 24.46151101589203, loss: 26.823220133781433 
Train [11/26] | Epoch [114/160] |	nca: 1.4844365380704403, flat: 0.8703182972967625, pod: 24.165350437164307, loss: 26.520105242729187 
Train [11/26] | Epoch [115/160] |	nca: 1.4021529294550419, flat: 0.8650501295924187, pod: 23.548014402389526, loss: 25.8152174949646 
Train [11/26] | Epoch [116/160] |	nca: 1.5292981937527657, flat: 0.8548461869359016, pod: 23.321540117263794, loss: 25.705684542655945 
Train [11/26] | Epoch [117/160] |	nca: 1.3880912475287914, flat: 0.8597162179648876, pod: 23.68797206878662, loss: 25.935779452323914 
Train [11/26] | Epoch [118/160] |	nca: 1.4840529635548592, flat: 0.8743453286588192, pod: 24.098626971244812, loss: 26.457025170326233 
Train [11/26] | Epoch [119/160] |	nca: 1.424934260547161, flat: 0.8440561555325985, pod: 23.46881103515625, loss: 25.737801432609558 
Train [11/26] | Epoch [120/160] |	nca: 1.3877964168787003, flat: 0.7925337441265583, pod: 21.988708436489105, loss: 24.169038772583008 
Train [11/26] | Epoch [121/160] |	nca: 1.5598518140614033, flat: 0.8148877117782831, pod: 22.800636291503906, loss: 25.175375938415527 
Train [11/26] | Epoch [122/160] |	nca: 1.4643757939338684, flat: 0.7932009063661098, pod: 22.73681378364563, loss: 24.994390726089478 
Train [11/26] | Epoch [123/160] |	nca: 1.4864563308656216, flat: 0.7891219276934862, pod: 22.19458019733429, loss: 24.470158576965332 
Train [11/26] | Epoch [124/160] |	nca: 1.4259699881076813, flat: 0.7844436522573233, pod: 22.269043743610382, loss: 24.47945725917816 
Train [11/26] | Epoch [125/160] |	nca: 1.4763936288654804, flat: 0.7929651029407978, pod: 22.996004104614258, loss: 25.26536250114441 
Train [11/26] | Epoch [126/160] |	nca: 1.3689689971506596, flat: 0.7663597632199526, pod: 21.684746503829956, loss: 23.820075511932373 
Train [11/26] | Epoch [127/160] |	nca: 1.4566831961274147, flat: 0.779050761833787, pod: 22.21931082010269, loss: 24.455044865608215 
Train [11/26] | Epoch [128/160] |	nca: 1.3846982792019844, flat: 0.7017028275877237, pod: 21.052562475204468, loss: 23.13896358013153 
Train [11/26] | Epoch [129/160] |	nca: 1.4421928338706493, flat: 0.7418886199593544, pod: 21.145474910736084, loss: 23.32955628633499 
Train [11/26] | Epoch [130/160] |	nca: 1.4334547258913517, flat: 0.7420102469623089, pod: 20.8791064620018, loss: 23.054571509361267 
Train [11/26] | Epoch [131/160] |	nca: 1.3565402664244175, flat: 0.6700989007949829, pod: 20.039820432662964, loss: 22.06645977497101 
Train [11/26] | Epoch [132/160] |	nca: 1.4012922644615173, flat: 0.72066880017519, pod: 20.580621242523193, loss: 22.70258218050003 
Train [11/26] | Epoch [133/160] |	nca: 1.3170770332217216, flat: 0.645230308175087, pod: 19.12270498275757, loss: 21.08501249551773 
Train [11/26] | Epoch [134/160] |	nca: 1.3929386921226978, flat: 0.659024516120553, pod: 19.237416326999664, loss: 21.28937965631485 
Train [11/26] | Epoch [135/160] |	nca: 1.4691454246640205, flat: 0.6251855101436377, pod: 18.878709375858307, loss: 20.973040342330933 
Train [11/26] | Epoch [136/160] |	nca: 1.391924425959587, flat: 0.6328027416020632, pod: 18.864021062850952, loss: 20.888748228549957 
Train [11/26] | Epoch [137/160] |	nca: 1.4559329487383366, flat: 0.6167577989399433, pod: 18.19585210084915, loss: 20.268542766571045 
Train [11/26] | Epoch [138/160] |	nca: 1.5016369074583054, flat: 0.654461394995451, pod: 19.140749752521515, loss: 21.296848118305206 
Train [11/26] | Epoch [139/160] |	nca: 1.3790085390210152, flat: 0.6287408173084259, pod: 19.026564061641693, loss: 21.034313678741455 
Train [11/26] | Epoch [140/160] |	nca: 1.471933577209711, flat: 0.6274113394320011, pod: 18.400126039981842, loss: 20.499471068382263 
Train [11/26] | Epoch [141/160] |	nca: 1.3023580014705658, flat: 0.6344287190586329, pod: 18.146115481853485, loss: 20.082902193069458 
Train [11/26] | Epoch [142/160] |	nca: 1.4150509983301163, flat: 0.632957311347127, pod: 18.99095207452774, loss: 21.038960337638855 
Train [11/26] | Epoch [143/160] |	nca: 1.4134282618761063, flat: 0.5775603372603655, pod: 18.084909439086914, loss: 20.075898230075836 
Train [11/26] | Epoch [144/160] |	nca: 1.4514792375266552, flat: 0.5983903761953115, pod: 18.6633403301239, loss: 20.713209807872772 
Train [11/26] | Epoch [145/160] |	nca: 1.3982791937887669, flat: 0.6356822326779366, pod: 18.560497999191284, loss: 20.594459533691406 
Train [11/26] | Epoch [146/160] |	nca: 1.4404223524034023, flat: 0.625761104747653, pod: 18.153406977653503, loss: 20.219590306282043 
Train [11/26] | Epoch [147/160] |	nca: 1.4459476694464684, flat: 0.5573427323251963, pod: 17.370564818382263, loss: 19.373855113983154 
Train [11/26] | Epoch [148/160] |	nca: 1.4591073021292686, flat: 0.5843253526836634, pod: 16.984184682369232, loss: 19.027617394924164 
Train [11/26] | Epoch [149/160] |	nca: 1.3315138928592205, flat: 0.5341706331819296, pod: 16.294699907302856, loss: 18.160384356975555 
Train [11/26] | Epoch [150/160] |	nca: 1.3410613909363747, flat: 0.5834465101361275, pod: 17.764931440353394, loss: 19.689439475536346 
Train [11/26] | Epoch [151/160] |	nca: 1.502452615648508, flat: 0.5902656894177198, pod: 17.748584389686584, loss: 19.841302812099457 
Train [11/26] | Epoch [152/160] |	nca: 1.4144884981215, flat: 0.5160114075988531, pod: 15.96388590335846, loss: 17.894385993480682 
Train [11/26] | Epoch [153/160] |	nca: 1.3550901263952255, flat: 0.5223559215664864, pod: 15.993104875087738, loss: 17.87055093050003 
Train [11/26] | Epoch [154/160] |	nca: 1.4279787316918373, flat: 0.597265699878335, pod: 17.263316571712494, loss: 19.28856122493744 
Train [11/26] | Epoch [155/160] |	nca: 1.426475252956152, flat: 0.5552532244473696, pod: 16.90212595462799, loss: 18.88385432958603 
Train [11/26] | Epoch [156/160] |	nca: 1.3325412422418594, flat: 0.529285741969943, pod: 16.446269690990448, loss: 18.308096706867218 
Train [11/26] | Epoch [157/160] |	nca: 1.4518191665410995, flat: 0.5772126391530037, pod: 16.3489790558815, loss: 18.378010988235474 
Train [11/26] | Epoch [158/160] |	nca: 1.4252592623233795, flat: 0.556238666176796, pod: 16.768988370895386, loss: 18.750486195087433 
Train [11/26] | Epoch [159/160] |	nca: 1.468517929315567, flat: 0.5562953855842352, pod: 16.80637264251709, loss: 18.83118611574173 
Train [11/26] | Epoch [160/160] |	nca: 1.4594793990254402, flat: 0.5762799978256226, pod: 17.15511465072632, loss: 19.19087415933609 
Fine-tuning
Building & updating memory.
Train [11/26] | Epoch [161/180] |	nca: 1.2759417481720448, flat: 0.7677632607519627, pod: 14.170451641082764, loss: 16.21415686607361 
Train [11/26] | Epoch [162/180] |	nca: 0.8909937925636768, flat: 0.7728130891919136, pod: 14.172108888626099, loss: 15.835915684700012 
Train [11/26] | Epoch [163/180] |	nca: 0.6402231492102146, flat: 0.7688890472054482, pod: 14.315128207206726, loss: 15.72424042224884 
Train [11/26] | Epoch [164/180] |	nca: 0.5484611950814724, flat: 0.7731278836727142, pod: 13.769291639328003, loss: 15.090880870819092 
Train [11/26] | Epoch [165/180] |	nca: 0.5423564799129963, flat: 0.7941200509667397, pod: 14.604437947273254, loss: 15.940914392471313 
Train [11/26] | Epoch [166/180] |	nca: 0.5135126151144505, flat: 0.7643155083060265, pod: 14.119080364704132, loss: 15.396908521652222 
Train [11/26] | Epoch [167/180] |	nca: 0.4695739205926657, flat: 0.771090142428875, pod: 14.366566181182861, loss: 15.607230186462402 
Train [11/26] | Epoch [168/180] |	nca: 0.504031827673316, flat: 0.7602790109813213, pod: 14.198337316513062, loss: 15.462648272514343 
Train [11/26] | Epoch [169/180] |	nca: 0.47568143531680107, flat: 0.7694041915237904, pod: 13.932582318782806, loss: 15.17766797542572 
Train [11/26] | Epoch [170/180] |	nca: 0.4643193781375885, flat: 0.7491424567997456, pod: 13.947885036468506, loss: 15.161346912384033 
Train [11/26] | Epoch [171/180] |	nca: 0.4658353701233864, flat: 0.7502375692129135, pod: 14.055410504341125, loss: 15.271483421325684 
Train [11/26] | Epoch [172/180] |	nca: 0.4919821172952652, flat: 0.767126053571701, pod: 14.3938570022583, loss: 15.652965188026428 
Train [11/26] | Epoch [173/180] |	nca: 0.460031658411026, flat: 0.7621703743934631, pod: 14.16263622045517, loss: 15.384838104248047 
Train [11/26] | Epoch [174/180] |	nca: 0.47511111944913864, flat: 0.7569156810641289, pod: 14.166043758392334, loss: 15.398070454597473 
Train [11/26] | Epoch [175/180] |	nca: 0.4541781656444073, flat: 0.7413070648908615, pod: 14.253327488899231, loss: 15.44881272315979 
Train [11/26] | Epoch [176/180] |	nca: 0.44418754801154137, flat: 0.7458403371274471, pod: 13.965006828308105, loss: 15.15503466129303 
Train [11/26] | Epoch [177/180] |	nca: 0.4335856642574072, flat: 0.7586106471717358, pod: 14.165474772453308, loss: 15.35767114162445 
Train [11/26] | Epoch [178/180] |	nca: 0.4120570160448551, flat: 0.7650538124144077, pod: 13.833997130393982, loss: 15.011108160018921 
Train [11/26] | Epoch [179/180] |	nca: 0.4289253707975149, flat: 0.7610256634652615, pod: 13.837990403175354, loss: 15.027941584587097 
Train [11/26] | Epoch [180/180] |	nca: 0.44697630405426025, flat: 0.7966353856027126, pod: 14.318446278572083, loss: 15.562058091163635 
after task
Building & updating memory.
after task
Eval on 0->70.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6615454545454545.
Current acc: {'total': 0.582, '00-09': 0.636, '10-19': 0.597, '20-29': 0.525, '30-39': 0.547, '40-49': 0.618, '50-59': 0.615, '60-69': 0.537}.
Avg inc acc top5: 0.8898181818181818.
Current acc top5: {'total': 0.845}.
Forgetting: 0.1205.
Cord metric: 0.65.
Old accuracy: 0.58, mean: 0.65.
New accuracy: 0.67, mean: 0.65.
================Task 11 Start!================
Testing on False unseen tasks (max class = 72).
Set memory of size: 1400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 11 Training!================
The training samples number: 2400
Train on 70->72.
train task
nb 2400.
Train [12/26] | Epoch [1/160] |	nca: 7.050830513238907, flat: 4.053269118070602, pod: 50.65593123435974, loss: 61.76003098487854 
Train [12/26] | Epoch [2/160] |	nca: 3.579713426530361, flat: 3.9601647704839706, pod: 53.319597482681274, loss: 60.85947632789612 
Train [12/26] | Epoch [3/160] |	nca: 2.799112394452095, flat: 3.32855387032032, pod: 50.76573634147644, loss: 56.893402338027954 
Train [12/26] | Epoch [4/160] |	nca: 2.666051462292671, flat: 3.0206504315137863, pod: 49.71764612197876, loss: 55.40434813499451 
Train [12/26] | Epoch [5/160] |	nca: 2.402695171535015, flat: 2.7840988785028458, pod: 47.615267515182495, loss: 52.802061796188354 
Train [12/26] | Epoch [6/160] |	nca: 2.10476166754961, flat: 2.5227191150188446, pod: 45.12100887298584, loss: 49.74848961830139 
Train [12/26] | Epoch [7/160] |	nca: 1.8974900729954243, flat: 2.657807558774948, pod: 47.75424408912659, loss: 52.30954194068909 
Train [12/26] | Epoch [8/160] |	nca: 2.032656215131283, flat: 2.607733890414238, pod: 47.50948214530945, loss: 52.14987230300903 
Train [12/26] | Epoch [9/160] |	nca: 1.807189479470253, flat: 2.431892581284046, pod: 45.238911867141724, loss: 49.477994203567505 
Train [12/26] | Epoch [10/160] |	nca: 1.8448709435760975, flat: 2.3084126859903336, pod: 42.71476912498474, loss: 46.86805272102356 
Train [12/26] | Epoch [11/160] |	nca: 2.027229681611061, flat: 2.3905248418450356, pod: 44.67027997970581, loss: 49.088034868240356 
Train [12/26] | Epoch [12/160] |	nca: 1.8054770603775978, flat: 2.3645330742001534, pod: 44.09536099433899, loss: 48.26537084579468 
Train [12/26] | Epoch [13/160] |	nca: 1.7598262429237366, flat: 2.252685062587261, pod: 42.43986964225769, loss: 46.452380418777466 
Train [12/26] | Epoch [14/160] |	nca: 1.7712367586791515, flat: 2.3251600861549377, pod: 43.74823260307312, loss: 47.84462904930115 
Train [12/26] | Epoch [15/160] |	nca: 1.7898266315460205, flat: 2.1633723378181458, pod: 41.77627897262573, loss: 45.729477882385254 
Train [12/26] | Epoch [16/160] |	nca: 1.7739334367215633, flat: 2.175305798649788, pod: 40.92133283615112, loss: 44.870572328567505 
Train [12/26] | Epoch [17/160] |	nca: 1.7659963741898537, flat: 2.246042415499687, pod: 42.0479052066803, loss: 46.05994391441345 
Train [12/26] | Epoch [18/160] |	nca: 1.62889863550663, flat: 2.1079201251268387, pod: 41.646862745285034, loss: 45.383681774139404 
Train [12/26] | Epoch [19/160] |	nca: 1.6848082914948463, flat: 2.110308438539505, pod: 40.66318917274475, loss: 44.45830583572388 
Train [12/26] | Epoch [20/160] |	nca: 1.6721469312906265, flat: 2.3580547496676445, pod: 44.043272256851196, loss: 48.07347393035889 
Train [12/26] | Epoch [21/160] |	nca: 1.640499521046877, flat: 2.1367655023932457, pod: 41.5280921459198, loss: 45.30535697937012 
Train [12/26] | Epoch [22/160] |	nca: 1.7857850939035416, flat: 2.131491482257843, pod: 41.545831084251404, loss: 45.46310758590698 
Train [12/26] | Epoch [23/160] |	nca: 1.6044661812484264, flat: 2.248691715300083, pod: 42.49483942985535, loss: 46.34799766540527 
Train [12/26] | Epoch [24/160] |	nca: 1.5288480632007122, flat: 2.05272875726223, pod: 40.4555846452713, loss: 44.037161111831665 
Train [12/26] | Epoch [25/160] |	nca: 1.7890280112624168, flat: 2.182928390800953, pod: 42.51919448375702, loss: 46.491151094436646 
Train [12/26] | Epoch [26/160] |	nca: 1.631574597209692, flat: 2.285367250442505, pod: 42.78623390197754, loss: 46.70317578315735 
Train [12/26] | Epoch [27/160] |	nca: 1.8885222263634205, flat: 2.288617804646492, pod: 41.55597364902496, loss: 45.73311376571655 
Train [12/26] | Epoch [28/160] |	nca: 1.5103768929839134, flat: 2.092201866209507, pod: 40.818777203559875, loss: 44.421356201171875 
Train [12/26] | Epoch [29/160] |	nca: 1.575390812009573, flat: 2.259669929742813, pod: 42.855327129364014, loss: 46.69038772583008 
Train [12/26] | Epoch [30/160] |	nca: 1.6118619665503502, flat: 1.995448812842369, pod: 39.6525673866272, loss: 43.259878158569336 
Train [12/26] | Epoch [31/160] |	nca: 1.677332542836666, flat: 2.040302962064743, pod: 41.06073760986328, loss: 44.77837300300598 
Train [12/26] | Epoch [32/160] |	nca: 1.8405083976686, flat: 2.2391452565789223, pod: 40.965906739234924, loss: 45.045560359954834 
Train [12/26] | Epoch [33/160] |	nca: 1.7124271541833878, flat: 2.108538307249546, pod: 40.75162935256958, loss: 44.57259464263916 
Train [12/26] | Epoch [34/160] |	nca: 1.6788590736687183, flat: 2.13619277626276, pod: 42.10611140727997, loss: 45.92116332054138 
Train [12/26] | Epoch [35/160] |	nca: 1.5894115939736366, flat: 1.9977824911475182, pod: 40.02792477607727, loss: 43.615119218826294 
Train [12/26] | Epoch [36/160] |	nca: 1.6969539821147919, flat: 2.050304114818573, pod: 40.55025935173035, loss: 44.2975172996521 
Train [12/26] | Epoch [37/160] |	nca: 1.442603636533022, flat: 1.95828328281641, pod: 39.95969092845917, loss: 43.36057806015015 
Train [12/26] | Epoch [38/160] |	nca: 1.3588327206671238, flat: 1.6804248988628387, pod: 36.22410809993744, loss: 39.263365626335144 
Train [12/26] | Epoch [39/160] |	nca: 1.3576412536203861, flat: 1.8752139657735825, pod: 39.25856971740723, loss: 42.49142551422119 
Train [12/26] | Epoch [40/160] |	nca: 1.40012776106596, flat: 1.9022580236196518, pod: 39.9306857585907, loss: 43.23307132720947 
Train [12/26] | Epoch [41/160] |	nca: 1.533699169754982, flat: 1.9955969452857971, pod: 39.970722913742065, loss: 43.50001931190491 
Train [12/26] | Epoch [42/160] |	nca: 1.5256519205868244, flat: 1.8958388715982437, pod: 38.30340039730072, loss: 41.72489106655121 
Train [12/26] | Epoch [43/160] |	nca: 1.4154375940561295, flat: 1.7846717834472656, pod: 37.56058859825134, loss: 40.760698199272156 
Train [12/26] | Epoch [44/160] |	nca: 1.4856921508908272, flat: 1.846219651401043, pod: 38.57487404346466, loss: 41.9067862033844 
Train [12/26] | Epoch [45/160] |	nca: 1.4154461361467838, flat: 1.847913146018982, pod: 38.97331750392914, loss: 42.23667657375336 
Train [12/26] | Epoch [46/160] |	nca: 1.5026543624699116, flat: 1.776687502861023, pod: 37.77478075027466, loss: 41.05412256717682 
Train [12/26] | Epoch [47/160] |	nca: 1.446558304131031, flat: 1.73076730966568, pod: 37.67513942718506, loss: 40.85246467590332 
Train [12/26] | Epoch [48/160] |	nca: 1.4210269041359425, flat: 1.7617749944329262, pod: 37.385902404785156, loss: 40.56870424747467 
Train [12/26] | Epoch [49/160] |	nca: 1.3427706360816956, flat: 1.7393335551023483, pod: 37.769392013549805, loss: 40.85149562358856 
Train [12/26] | Epoch [50/160] |	nca: 1.5017623230814934, flat: 1.8904712945222855, pod: 39.509233474731445, loss: 42.901466965675354 
Train [12/26] | Epoch [51/160] |	nca: 1.4612754434347153, flat: 1.842338278889656, pod: 39.82505452632904, loss: 43.12866806983948 
Train [12/26] | Epoch [52/160] |	nca: 1.480242732912302, flat: 1.8174824267625809, pod: 38.314650893211365, loss: 41.61237633228302 
Train [12/26] | Epoch [53/160] |	nca: 1.400213923305273, flat: 1.6212920919060707, pod: 35.43871247768402, loss: 38.46021831035614 
Train [12/26] | Epoch [54/160] |	nca: 1.3714443072676659, flat: 1.6725088357925415, pod: 36.94178128242493, loss: 39.98573410511017 
Train [12/26] | Epoch [55/160] |	nca: 1.5213167071342468, flat: 1.670354314148426, pod: 36.331984996795654, loss: 39.52365589141846 
Train [12/26] | Epoch [56/160] |	nca: 1.5669125989079475, flat: 1.6778725236654282, pod: 36.78530657291412, loss: 40.030091643333435 
Train [12/26] | Epoch [57/160] |	nca: 1.4484404847025871, flat: 1.7660485357046127, pod: 37.52579343318939, loss: 40.74028217792511 
Train [12/26] | Epoch [58/160] |	nca: 1.4590521976351738, flat: 1.6682717055082321, pod: 35.754268407821655, loss: 38.88159263134003 
Train [12/26] | Epoch [59/160] |	nca: 1.4613868072628975, flat: 1.6738309562206268, pod: 36.011276841163635, loss: 39.14649450778961 
Train [12/26] | Epoch [60/160] |	nca: 1.3459331467747688, flat: 1.5423978716135025, pod: 34.46077084541321, loss: 37.34910178184509 
Train [12/26] | Epoch [61/160] |	nca: 1.6104055978357792, flat: 1.5738653093576431, pod: 34.93324327468872, loss: 38.11751401424408 
Train [12/26] | Epoch [62/160] |	nca: 1.3128148168325424, flat: 1.5209976956248283, pod: 34.78927147388458, loss: 37.62308371067047 
Train [12/26] | Epoch [63/160] |	nca: 1.440247368067503, flat: 1.5341725274920464, pod: 35.13672876358032, loss: 38.11114835739136 
Train [12/26] | Epoch [64/160] |	nca: 1.4059190079569817, flat: 1.6752024590969086, pod: 35.8180947303772, loss: 38.899216413497925 
Train [12/26] | Epoch [65/160] |	nca: 1.3580788299441338, flat: 1.5346591472625732, pod: 33.15906012058258, loss: 36.05179822444916 
Train [12/26] | Epoch [66/160] |	nca: 1.4902118481695652, flat: 1.5318326279520988, pod: 33.921849966049194, loss: 36.94389462471008 
Train [12/26] | Epoch [67/160] |	nca: 1.4352961629629135, flat: 1.453004613518715, pod: 34.12714385986328, loss: 37.01544463634491 
Train [12/26] | Epoch [68/160] |	nca: 1.4986019022762775, flat: 1.6127887517213821, pod: 35.55574715137482, loss: 38.66713774204254 
Train [12/26] | Epoch [69/160] |	nca: 1.3766308687627316, flat: 1.5778224021196365, pod: 34.88945531845093, loss: 37.8439085483551 
Train [12/26] | Epoch [70/160] |	nca: 1.3676654659211636, flat: 1.5534183755517006, pod: 34.56339991092682, loss: 37.48448371887207 
Train [12/26] | Epoch [71/160] |	nca: 1.2942819371819496, flat: 1.3881777599453926, pod: 32.647778153419495, loss: 35.33023810386658 
Train [12/26] | Epoch [72/160] |	nca: 1.317107204347849, flat: 1.4263282790780067, pod: 33.637451171875, loss: 36.38088655471802 
Train [12/26] | Epoch [73/160] |	nca: 1.349652148783207, flat: 1.3244407661259174, pod: 31.593424916267395, loss: 34.26751780509949 
Train [12/26] | Epoch [74/160] |	nca: 1.3665707372128963, flat: 1.4546599611639977, pod: 33.44806206226349, loss: 36.2692928314209 
Train [12/26] | Epoch [75/160] |	nca: 1.3628597110509872, flat: 1.5580506846308708, pod: 36.56212091445923, loss: 39.48303186893463 
Train [12/26] | Epoch [76/160] |	nca: 1.3535737991333008, flat: 1.4580680429935455, pod: 34.15368962287903, loss: 36.96533143520355 
Train [12/26] | Epoch [77/160] |	nca: 1.3892729841172695, flat: 1.4389129467308521, pod: 33.504682183265686, loss: 36.33286809921265 
Train [12/26] | Epoch [78/160] |	nca: 1.354143425822258, flat: 1.2920784503221512, pod: 31.43864333629608, loss: 34.08486545085907 
Train [12/26] | Epoch [79/160] |	nca: 1.2360634095966816, flat: 1.3333609886467457, pod: 32.2366486787796, loss: 34.80607318878174 
Train [12/26] | Epoch [80/160] |	nca: 1.3501658961176872, flat: 1.4576151072978973, pod: 34.08274984359741, loss: 36.890530943870544 
Train [12/26] | Epoch [81/160] |	nca: 1.2757853642106056, flat: 1.3603166155517101, pod: 32.311378836631775, loss: 34.94748115539551 
Train [12/26] | Epoch [82/160] |	nca: 1.285503588616848, flat: 1.3054036684334278, pod: 30.87359082698822, loss: 33.4644980430603 
Train [12/26] | Epoch [83/160] |	nca: 1.3413077965378761, flat: 1.3025055155158043, pod: 31.62682020664215, loss: 34.27063345909119 
Train [12/26] | Epoch [84/160] |	nca: 1.3417935743927956, flat: 1.3321056328713894, pod: 31.67004632949829, loss: 34.343945384025574 
Train [12/26] | Epoch [85/160] |	nca: 1.3424563594162464, flat: 1.2647992633283138, pod: 30.931482076644897, loss: 33.538737773895264 
Train [12/26] | Epoch [86/160] |	nca: 1.277346894145012, flat: 1.3023900017142296, pod: 31.752974033355713, loss: 34.33271074295044 
Train [12/26] | Epoch [87/160] |	nca: 1.2938308715820312, flat: 1.2315464317798615, pod: 30.712504863739014, loss: 33.237882137298584 
Train [12/26] | Epoch [88/160] |	nca: 1.1677077263593674, flat: 1.104650802910328, pod: 28.39226460456848, loss: 30.664623379707336 
Train [12/26] | Epoch [89/160] |	nca: 1.3315961845219135, flat: 1.1691362112760544, pod: 29.05921494960785, loss: 31.55994749069214 
Train [12/26] | Epoch [90/160] |	nca: 1.3255598098039627, flat: 1.2721215784549713, pod: 31.00274384021759, loss: 33.600425124168396 
Train [12/26] | Epoch [91/160] |	nca: 1.2142073921859264, flat: 1.2420316450297832, pod: 30.42988610267639, loss: 32.88612508773804 
Train [12/26] | Epoch [92/160] |	nca: 1.2538168504834175, flat: 1.1197369918227196, pod: 28.735240817070007, loss: 31.108794450759888 
Train [12/26] | Epoch [93/160] |	nca: 1.3186752423644066, flat: 1.1407165043056011, pod: 29.669299602508545, loss: 32.12869143486023 
Train [12/26] | Epoch [94/160] |	nca: 1.289659522473812, flat: 1.094971414655447, pod: 29.413291454315186, loss: 31.797922492027283 
Train [12/26] | Epoch [95/160] |	nca: 1.2746299542486668, flat: 1.0805162750184536, pod: 28.657564759254456, loss: 31.0127112865448 
Train [12/26] | Epoch [96/160] |	nca: 1.2778108455240726, flat: 1.243772566318512, pod: 31.134508967399597, loss: 33.6560925245285 
Train [12/26] | Epoch [97/160] |	nca: 1.1916246563196182, flat: 1.082773257046938, pod: 28.37258517742157, loss: 30.64698314666748 
Train [12/26] | Epoch [98/160] |	nca: 1.2952499501407146, flat: 1.2104168757796288, pod: 29.140287160873413, loss: 31.645954251289368 
Train [12/26] | Epoch [99/160] |	nca: 1.207772459834814, flat: 1.116200990974903, pod: 28.742915987968445, loss: 31.06688940525055 
Train [12/26] | Epoch [100/160] |	nca: 1.279799111187458, flat: 1.0101988799870014, pod: 27.311546564102173, loss: 29.601544737815857 
Train [12/26] | Epoch [101/160] |	nca: 1.2038986533880234, flat: 1.0435277670621872, pod: 27.58382248878479, loss: 29.83124876022339 
Train [12/26] | Epoch [102/160] |	nca: 1.1938873007893562, flat: 0.942260030657053, pod: 26.762120604515076, loss: 28.89826810359955 
Train [12/26] | Epoch [103/160] |	nca: 1.198409866541624, flat: 1.027593970298767, pod: 27.7885080575943, loss: 30.014511823654175 
Train [12/26] | Epoch [104/160] |	nca: 1.2294513955712318, flat: 1.0664171613752842, pod: 28.923739790916443, loss: 31.219608306884766 
Train [12/26] | Epoch [105/160] |	nca: 1.3392725810408592, flat: 1.0385714061558247, pod: 27.546704292297363, loss: 29.924547910690308 
Train [12/26] | Epoch [106/160] |	nca: 1.252614263445139, flat: 0.9809276238083839, pod: 27.182488918304443, loss: 29.416030526161194 
Train [12/26] | Epoch [107/160] |	nca: 1.195558875799179, flat: 0.9568988382816315, pod: 27.01226556301117, loss: 29.1647230386734 
Train [12/26] | Epoch [108/160] |	nca: 1.2105969451367855, flat: 0.9668859168887138, pod: 27.314152479171753, loss: 29.4916353225708 
Train [12/26] | Epoch [109/160] |	nca: 1.2297111488878727, flat: 0.8827568180859089, pod: 25.157893180847168, loss: 27.270361304283142 
Train [12/26] | Epoch [110/160] |	nca: 1.3171657882630825, flat: 0.9113704189658165, pod: 25.434820294380188, loss: 27.66335642337799 
Train [12/26] | Epoch [111/160] |	nca: 1.1817097142338753, flat: 0.8180899545550346, pod: 23.764464855194092, loss: 25.764264702796936 
Train [12/26] | Epoch [112/160] |	nca: 1.297934215515852, flat: 0.8856101110577583, pod: 25.064545035362244, loss: 27.24808931350708 
Train [12/26] | Epoch [113/160] |	nca: 1.2195459455251694, flat: 0.8991900309920311, pod: 25.38828992843628, loss: 27.507025599479675 
Train [12/26] | Epoch [114/160] |	nca: 1.2902468852698803, flat: 0.7677642852067947, pod: 22.436662435531616, loss: 24.494673490524292 
Train [12/26] | Epoch [115/160] |	nca: 1.0587037689983845, flat: 0.8252464607357979, pod: 23.954257130622864, loss: 25.838207483291626 
Train [12/26] | Epoch [116/160] |	nca: 1.2846205048263073, flat: 0.7949084304273129, pod: 23.242280304431915, loss: 25.3218092918396 
Train [12/26] | Epoch [117/160] |	nca: 1.29366335272789, flat: 0.8055665381252766, pod: 23.355297923088074, loss: 25.454527974128723 
Train [12/26] | Epoch [118/160] |	nca: 1.1019604429602623, flat: 0.7548817954957485, pod: 22.270384550094604, loss: 24.12722682952881 
Train [12/26] | Epoch [119/160] |	nca: 1.090318612754345, flat: 0.6920484304428101, pod: 21.446563184261322, loss: 23.228930354118347 
Train [12/26] | Epoch [120/160] |	nca: 1.1905379183590412, flat: 0.7097248751670122, pod: 21.742032885551453, loss: 23.642295122146606 
Train [12/26] | Epoch [121/160] |	nca: 1.2882038466632366, flat: 0.8404947482049465, pod: 24.467888593673706, loss: 26.59658706188202 
Train [12/26] | Epoch [122/160] |	nca: 1.2194792032241821, flat: 0.7394601479172707, pod: 22.047160029411316, loss: 24.006099343299866 
Train [12/26] | Epoch [123/160] |	nca: 1.2710352763533592, flat: 0.7900691293179989, pod: 23.233420610427856, loss: 25.294525265693665 
Train [12/26] | Epoch [124/160] |	nca: 1.259782563894987, flat: 0.7409288343042135, pod: 22.293290197849274, loss: 24.294001698493958 
Train [12/26] | Epoch [125/160] |	nca: 1.1902635134756565, flat: 0.7086184285581112, pod: 21.458048403263092, loss: 23.356930375099182 
Train [12/26] | Epoch [126/160] |	nca: 1.1662589013576508, flat: 0.7653951607644558, pod: 23.19767916202545, loss: 25.12933313846588 
Train [12/26] | Epoch [127/160] |	nca: 1.2621143348515034, flat: 0.6911510620266199, pod: 21.030452966690063, loss: 22.983718276023865 
Train [12/26] | Epoch [128/160] |	nca: 1.2128910645842552, flat: 0.6508202962577343, pod: 20.088770151138306, loss: 21.952481389045715 
Train [12/26] | Epoch [129/160] |	nca: 1.1549390070140362, flat: 0.680869810283184, pod: 21.029813706874847, loss: 22.865622401237488 
Train [12/26] | Epoch [130/160] |	nca: 1.2059234157204628, flat: 0.6894424334168434, pod: 21.103435754776, loss: 22.998801589012146 
Train [12/26] | Epoch [131/160] |	nca: 1.1194617934525013, flat: 0.6902889292687178, pod: 21.616063714027405, loss: 23.425814390182495 
Train [12/26] | Epoch [132/160] |	nca: 1.2160828299820423, flat: 0.6112575810402632, pod: 19.838783979415894, loss: 21.666124403476715 
Train [12/26] | Epoch [133/160] |	nca: 1.192509587854147, flat: 0.6036013644188643, pod: 19.307342290878296, loss: 21.10345309972763 
Train [12/26] | Epoch [134/160] |	nca: 1.2329170629382133, flat: 0.6405060924589634, pod: 20.276391744613647, loss: 22.149815142154694 
Train [12/26] | Epoch [135/160] |	nca: 1.1703298836946487, flat: 0.6006417218595743, pod: 19.58177000284195, loss: 21.352741420269012 
Train [12/26] | Epoch [136/160] |	nca: 1.1541491858661175, flat: 0.6244030613452196, pod: 19.831434845924377, loss: 21.609987139701843 
Train [12/26] | Epoch [137/160] |	nca: 1.2379659712314606, flat: 0.6461384240537882, pod: 19.961293756961823, loss: 21.84539794921875 
Train [12/26] | Epoch [138/160] |	nca: 1.1651898138225079, flat: 0.6715978905558586, pod: 20.791620671749115, loss: 22.628408432006836 
Train [12/26] | Epoch [139/160] |	nca: 1.1120260991156101, flat: 0.5872978866100311, pod: 18.832215428352356, loss: 20.531539380550385 
Train [12/26] | Epoch [140/160] |	nca: 1.168591469526291, flat: 0.555714687332511, pod: 18.319355964660645, loss: 20.043662130832672 
Train [12/26] | Epoch [141/160] |	nca: 1.1894704587757587, flat: 0.5760575737804174, pod: 18.459333777427673, loss: 20.224861443042755 
Train [12/26] | Epoch [142/160] |	nca: 1.1387709975242615, flat: 0.5787688419222832, pod: 18.787384271621704, loss: 20.504924178123474 
Train [12/26] | Epoch [143/160] |	nca: 1.2447901405394077, flat: 0.5727486051619053, pod: 18.5215784907341, loss: 20.3391170501709 
Train [12/26] | Epoch [144/160] |	nca: 1.0799398981034756, flat: 0.5389042682945728, pod: 17.802868366241455, loss: 19.421712636947632 
Train [12/26] | Epoch [145/160] |	nca: 1.1640552952885628, flat: 0.5844604428857565, pod: 19.03369563817978, loss: 20.782211422920227 
Train [12/26] | Epoch [146/160] |	nca: 1.1659303419291973, flat: 0.5559806134551764, pod: 18.15283489227295, loss: 19.874745845794678 
Train [12/26] | Epoch [147/160] |	nca: 1.0995754189789295, flat: 0.5465652123093605, pod: 17.9810830950737, loss: 19.62722361087799 
Train [12/26] | Epoch [148/160] |	nca: 1.163950152695179, flat: 0.5756255947053432, pod: 18.135347366333008, loss: 19.874923169612885 
Train [12/26] | Epoch [149/160] |	nca: 1.2122256569564342, flat: 0.5638081282377243, pod: 18.26847118139267, loss: 20.04450500011444 
Train [12/26] | Epoch [150/160] |	nca: 1.204729463905096, flat: 0.5374593399465084, pod: 17.57455438375473, loss: 19.31674337387085 
Train [12/26] | Epoch [151/160] |	nca: 1.1456287316977978, flat: 0.575503271073103, pod: 17.965955317020416, loss: 19.687087297439575 
Train [12/26] | Epoch [152/160] |	nca: 1.1162096746265888, flat: 0.5255874563008547, pod: 17.204286336898804, loss: 18.846083402633667 
Train [12/26] | Epoch [153/160] |	nca: 1.165612816810608, flat: 0.5698949452489614, pod: 17.85536551475525, loss: 19.590873420238495 
Train [12/26] | Epoch [154/160] |	nca: 1.1485410928726196, flat: 0.5084135625511408, pod: 16.550412118434906, loss: 18.20736688375473 
Train [12/26] | Epoch [155/160] |	nca: 1.2190882749855518, flat: 0.5409545414149761, pod: 17.69538277387619, loss: 19.455425560474396 
Train [12/26] | Epoch [156/160] |	nca: 1.1353729963302612, flat: 0.5287953745573759, pod: 17.42936861515045, loss: 19.093537092208862 
Train [12/26] | Epoch [157/160] |	nca: 1.1521414332091808, flat: 0.494575684890151, pod: 16.352997601032257, loss: 17.99971479177475 
Train [12/26] | Epoch [158/160] |	nca: 1.1367469057440758, flat: 0.48760932870209217, pod: 16.194502592086792, loss: 17.81885862350464 
Train [12/26] | Epoch [159/160] |	nca: 1.143936175853014, flat: 0.557599626481533, pod: 17.50449848175049, loss: 19.206034421920776 
Train [12/26] | Epoch [160/160] |	nca: 1.1877847127616405, flat: 0.5211031045764685, pod: 16.318030893802643, loss: 18.02691876888275 
Fine-tuning
Building & updating memory.
Train [12/26] | Epoch [161/180] |	nca: 1.2769255340099335, flat: 1.1565635204315186, pod: 18.785739541053772, loss: 21.219228744506836 
Train [12/26] | Epoch [162/180] |	nca: 0.7951923161745071, flat: 1.1440799050033092, pod: 18.602145433425903, loss: 20.541417717933655 
Train [12/26] | Epoch [163/180] |	nca: 0.6352508552372456, flat: 1.1607493050396442, pod: 18.62892246246338, loss: 20.424922466278076 
Train [12/26] | Epoch [164/180] |	nca: 0.5641388930380344, flat: 1.1440878808498383, pod: 18.31835949420929, loss: 20.026586174964905 
Train [12/26] | Epoch [165/180] |	nca: 0.5434570461511612, flat: 1.1298006623983383, pod: 18.192469358444214, loss: 19.865726947784424 
Train [12/26] | Epoch [166/180] |	nca: 0.6465186215937138, flat: 1.1162894666194916, pod: 17.982868194580078, loss: 19.745676279067993 
Train [12/26] | Epoch [167/180] |	nca: 0.571852944791317, flat: 1.1831962242722511, pod: 18.556366562843323, loss: 20.311415791511536 
Train [12/26] | Epoch [168/180] |	nca: 0.5218839198350906, flat: 1.132042020559311, pod: 18.34199559688568, loss: 19.995921730995178 
Train [12/26] | Epoch [169/180] |	nca: 0.5566117204725742, flat: 1.120196558535099, pod: 18.483959794044495, loss: 20.160768032073975 
Train [12/26] | Epoch [170/180] |	nca: 0.4962790906429291, flat: 1.154210552573204, pod: 18.49448788166046, loss: 20.144977569580078 
Train [12/26] | Epoch [171/180] |	nca: 0.49559207260608673, flat: 1.186283465474844, pod: 18.660223722457886, loss: 20.34209942817688 
Train [12/26] | Epoch [172/180] |	nca: 0.4869336187839508, flat: 1.1681739836931229, pod: 18.657479166984558, loss: 20.312586545944214 
Train [12/26] | Epoch [173/180] |	nca: 0.5342304967343807, flat: 1.127996563911438, pod: 18.20870804786682, loss: 19.87093484401703 
Train [12/26] | Epoch [174/180] |	nca: 0.5181649103760719, flat: 1.188148394227028, pod: 18.985617756843567, loss: 20.691930770874023 
Train [12/26] | Epoch [175/180] |	nca: 0.44518507085740566, flat: 1.1389595046639442, pod: 18.244349718093872, loss: 19.82849431037903 
Train [12/26] | Epoch [176/180] |	nca: 0.5383104477077723, flat: 1.1319704502820969, pod: 18.51560401916504, loss: 20.185884833335876 
Train [12/26] | Epoch [177/180] |	nca: 0.4736780971288681, flat: 1.1499529406428337, pod: 18.423832535743713, loss: 20.0474636554718 
Train [12/26] | Epoch [178/180] |	nca: 0.4618203230202198, flat: 1.2334303557872772, pod: 19.210564970970154, loss: 20.905815601348877 
Train [12/26] | Epoch [179/180] |	nca: 0.4793330319225788, flat: 1.13480843603611, pod: 18.055249333381653, loss: 19.66939079761505 
Train [12/26] | Epoch [180/180] |	nca: 0.445715494453907, flat: 1.16252401471138, pod: 18.696043372154236, loss: 20.304282903671265 
after task
Building & updating memory.
after task
Eval on 0->72.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6549166666666667.
Current acc: {'total': 0.582, '00-09': 0.623, '10-19': 0.59, '20-29': 0.519, '30-39': 0.543, '40-49': 0.623, '50-59': 0.61, '60-69': 0.532, '70-79': 0.75}.
Avg inc acc top5: 0.886.
Current acc top5: {'total': 0.844}.
Forgetting: 0.027666666666666666.
Cord metric: 0.64.
Old accuracy: 0.58, mean: 0.65.
New accuracy: 0.75, mean: 0.65.
================Task 12 Start!================
Testing on False unseen tasks (max class = 74).
Set memory of size: 1440.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 12 Training!================
The training samples number: 2440
Train on 72->74.
train task
nb 2440.
Train [13/26] | Epoch [1/160] |	nca: 7.45724818110466, flat: 3.8102470487356186, pod: 49.627663373947144, loss: 60.895158529281616 
Train [13/26] | Epoch [2/160] |	nca: 16.64048683643341, flat: 11.777245908975601, pod: 89.2474958896637, loss: 117.66522789001465 
Train [13/26] | Epoch [3/160] |	nca: 18.142769694328308, flat: 13.584539592266083, pod: 96.88164901733398, loss: 128.6089587211609 
Train [13/26] | Epoch [4/160] |	nca: 14.664144188165665, flat: 11.556881725788116, pod: 88.6092357635498, loss: 114.83026218414307 
Train [13/26] | Epoch [5/160] |	nca: 12.229685634374619, flat: 10.717771023511887, pod: 85.27898216247559, loss: 108.22643804550171 
Train [13/26] | Epoch [6/160] |	nca: 8.152070567011833, flat: 9.14661779999733, pod: 78.76699447631836, loss: 96.06568193435669 
Train [13/26] | Epoch [7/160] |	nca: 5.318704262375832, flat: 7.271847069263458, pod: 72.28768157958984, loss: 84.87823295593262 
Train [13/26] | Epoch [8/160] |	nca: 4.249883100390434, flat: 6.309737205505371, pod: 66.4532642364502, loss: 77.01288533210754 
Train [13/26] | Epoch [9/160] |	nca: 3.5405809581279755, flat: 5.280425429344177, pod: 61.31537628173828, loss: 70.13638257980347 
Train [13/26] | Epoch [10/160] |	nca: 3.787984788417816, flat: 5.288688883185387, pod: 58.8559045791626, loss: 67.93257856369019 
Train [13/26] | Epoch [11/160] |	nca: 5.8283345848321915, flat: 6.216994941234589, pod: 64.18085217475891, loss: 76.22618103027344 
Train [13/26] | Epoch [12/160] |	nca: 5.111383870244026, flat: 6.418629169464111, pod: 64.00027894973755, loss: 75.53029251098633 
Train [13/26] | Epoch [13/160] |	nca: 4.263968273997307, flat: 5.391322821378708, pod: 61.210742235183716, loss: 70.86603331565857 
Train [13/26] | Epoch [14/160] |	nca: 4.054649293422699, flat: 5.022892341017723, pod: 59.07042574882507, loss: 68.14796781539917 
Train [13/26] | Epoch [15/160] |	nca: 4.417857229709625, flat: 5.00396953523159, pod: 56.91458511352539, loss: 66.33641195297241 
Train [13/26] | Epoch [16/160] |	nca: 8.446848586201668, flat: 8.287370055913925, pod: 72.41902112960815, loss: 89.15323948860168 
Train [13/26] | Epoch [17/160] |	nca: 7.431030511856079, flat: 7.790030270814896, pod: 71.11610913276672, loss: 86.33717012405396 
Train [13/26] | Epoch [18/160] |	nca: 5.410194143652916, flat: 6.798521131277084, pod: 67.63691830635071, loss: 79.84563398361206 
Train [13/26] | Epoch [19/160] |	nca: 4.84026563167572, flat: 5.884790897369385, pod: 63.40457820892334, loss: 74.129634141922 
Train [13/26] | Epoch [20/160] |	nca: 3.619913399219513, flat: 4.969042882323265, pod: 59.09131383895874, loss: 67.68027019500732 
Train [13/26] | Epoch [21/160] |	nca: 3.337941773235798, flat: 4.785363346338272, pod: 57.62999939918518, loss: 65.75330448150635 
Train [13/26] | Epoch [22/160] |	nca: 3.5734319165349007, flat: 4.735991582274437, pod: 58.00747895240784, loss: 66.31690311431885 
Train [13/26] | Epoch [23/160] |	nca: 3.196229189634323, flat: 4.536764681339264, pod: 57.272902727127075, loss: 65.00589656829834 
Train [13/26] | Epoch [24/160] |	nca: 3.183340460062027, flat: 4.437913775444031, pod: 55.72200083732605, loss: 63.34325551986694 
Train [13/26] | Epoch [25/160] |	nca: 3.0660171285271645, flat: 4.619282826781273, pod: 57.181854248046875, loss: 64.8671543598175 
Train [13/26] | Epoch [26/160] |	nca: 3.832478240132332, flat: 4.560152024030685, pod: 57.70820498466492, loss: 66.10083508491516 
Train [13/26] | Epoch [27/160] |	nca: 6.621905252337456, flat: 7.176746502518654, pod: 67.974289894104, loss: 81.77294206619263 
Train [13/26] | Epoch [28/160] |	nca: 6.778862088918686, flat: 7.465588688850403, pod: 70.67104315757751, loss: 84.9154942035675 
Train [13/26] | Epoch [29/160] |	nca: 6.810371220111847, flat: 7.248243927955627, pod: 67.65595388412476, loss: 81.71456909179688 
Train [13/26] | Epoch [30/160] |	nca: 6.24945467710495, flat: 7.211694419384003, pod: 67.89719223976135, loss: 81.35834193229675 
Train [13/26] | Epoch [31/160] |	nca: 7.097728565335274, flat: 7.754513531923294, pod: 69.57229328155518, loss: 84.42453598976135 
Train [13/26] | Epoch [32/160] |	nca: 3.8534006774425507, flat: 6.318291947245598, pod: 66.04877161979675, loss: 76.22046494483948 
Train [13/26] | Epoch [33/160] |	nca: 3.3305341973900795, flat: 4.581615537405014, pod: 56.50111365318298, loss: 64.41326332092285 
Train [13/26] | Epoch [34/160] |	nca: 3.9574472084641457, flat: 4.748199686408043, pod: 56.2740204334259, loss: 64.97966766357422 
Train [13/26] | Epoch [35/160] |	nca: 4.430940017104149, flat: 5.053384304046631, pod: 57.905898571014404, loss: 67.39022278785706 
Train [13/26] | Epoch [36/160] |	nca: 3.556166149675846, flat: 5.3618223965168, pod: 58.99268698692322, loss: 67.9106752872467 
Train [13/26] | Epoch [37/160] |	nca: 3.238757647573948, flat: 4.3633726835250854, pod: 54.569209575653076, loss: 62.171339988708496 
Train [13/26] | Epoch [38/160] |	nca: 3.246407061815262, flat: 4.583116739988327, pod: 57.74219560623169, loss: 65.5717191696167 
Train [13/26] | Epoch [39/160] |	nca: 2.693620391190052, flat: 3.7925217002630234, pod: 52.06868529319763, loss: 58.55482721328735 
Train [13/26] | Epoch [40/160] |	nca: 3.485749952495098, flat: 4.309371590614319, pod: 53.46229362487793, loss: 61.257415771484375 
Train [13/26] | Epoch [41/160] |	nca: 4.271752707660198, flat: 5.158230766654015, pod: 57.866456031799316, loss: 67.29643988609314 
Train [13/26] | Epoch [42/160] |	nca: 3.6432385742664337, flat: 4.79171895980835, pod: 56.43861770629883, loss: 64.87357497215271 
Train [13/26] | Epoch [43/160] |	nca: 6.1704346388578415, flat: 6.680421411991119, pod: 65.12245178222656, loss: 77.97330737113953 
Train [13/26] | Epoch [44/160] |	nca: 5.6430114060640335, flat: 6.559021979570389, pod: 63.62354755401611, loss: 75.82558107376099 
Train [13/26] | Epoch [45/160] |	nca: 4.596650838851929, flat: 6.015350118279457, pod: 62.18718600273132, loss: 72.79918718338013 
Train [13/26] | Epoch [46/160] |	nca: 4.107958987355232, flat: 5.563556909561157, pod: 59.81905484199524, loss: 69.49057054519653 
Train [13/26] | Epoch [47/160] |	nca: 2.854823760688305, flat: 4.317727595567703, pod: 54.69842720031738, loss: 61.870978593826294 
Train [13/26] | Epoch [48/160] |	nca: 2.5355524197220802, flat: 3.7092811316251755, pod: 49.92652940750122, loss: 56.17136240005493 
Train [13/26] | Epoch [49/160] |	nca: 4.434201404452324, flat: 4.662703827023506, pod: 53.465808629989624, loss: 62.562713861465454 
Train [13/26] | Epoch [50/160] |	nca: 5.1997618824243546, flat: 6.304505363106728, pod: 63.19453454017639, loss: 74.69880175590515 
Train [13/26] | Epoch [51/160] |	nca: 3.7837660908699036, flat: 5.403073579072952, pod: 59.272258281707764, loss: 68.45909810066223 
Train [13/26] | Epoch [52/160] |	nca: 4.16774233430624, flat: 4.5259086936712265, pod: 55.06577515602112, loss: 63.75942659378052 
Train [13/26] | Epoch [53/160] |	nca: 5.068518631160259, flat: 5.713274911046028, pod: 61.89900040626526, loss: 72.68079423904419 
Train [13/26] | Epoch [54/160] |	nca: 4.133075222373009, flat: 5.318629518151283, pod: 59.74427914619446, loss: 69.19598364830017 
Train [13/26] | Epoch [55/160] |	nca: 3.469122849404812, flat: 4.926787495613098, pod: 57.05358147621155, loss: 65.44949150085449 
Train [13/26] | Epoch [56/160] |	nca: 3.9762753397226334, flat: 5.186945706605911, pod: 59.212180376052856, loss: 68.37540102005005 
Train [13/26] | Epoch [57/160] |	nca: 3.8367042392492294, flat: 4.8457843363285065, pod: 56.4746835231781, loss: 65.15717220306396 
Train [13/26] | Epoch [58/160] |	nca: 2.220328241586685, flat: 4.021680876612663, pod: 50.49723815917969, loss: 56.7392475605011 
Train [13/26] | Epoch [59/160] |	nca: 2.759321879595518, flat: 3.1756623685359955, pod: 46.45365619659424, loss: 52.38864016532898 
Train [13/26] | Epoch [60/160] |	nca: 3.4520645439624786, flat: 4.452074497938156, pod: 54.042049169540405, loss: 61.94618797302246 
Train [13/26] | Epoch [61/160] |	nca: 1.9126842245459557, flat: 3.3298183381557465, pod: 48.076987743377686, loss: 53.31949043273926 
Train [13/26] | Epoch [62/160] |	nca: 1.9468117840588093, flat: 3.0755424201488495, pod: 46.71066677570343, loss: 51.733020544052124 
Train [13/26] | Epoch [63/160] |	nca: 2.4419755414128304, flat: 3.552991434931755, pod: 51.074496269226074, loss: 57.0694637298584 
Train [13/26] | Epoch [64/160] |	nca: 2.1740199103951454, flat: 3.455060437321663, pod: 49.54862141609192, loss: 55.17770195007324 
Train [13/26] | Epoch [65/160] |	nca: 2.1407128795981407, flat: 2.9591674357652664, pod: 43.961617827415466, loss: 49.06149768829346 
Train [13/26] | Epoch [66/160] |	nca: 2.657479092478752, flat: 3.643526941537857, pod: 47.55450129508972, loss: 53.855507612228394 
Train [13/26] | Epoch [67/160] |	nca: 1.8957729041576385, flat: 2.868541345000267, pod: 43.60648155212402, loss: 48.3707959651947 
Train [13/26] | Epoch [68/160] |	nca: 2.693548709154129, flat: 3.570882722735405, pod: 49.550437927246094, loss: 55.81486964225769 
Train [13/26] | Epoch [69/160] |	nca: 2.2839412838220596, flat: 3.030355729162693, pod: 45.205618143081665, loss: 50.51991534233093 
Train [13/26] | Epoch [70/160] |	nca: 2.6645381078124046, flat: 3.4718587547540665, pod: 48.31756091117859, loss: 54.45395803451538 
Train [13/26] | Epoch [71/160] |	nca: 2.321110501885414, flat: 3.4222220554947853, pod: 47.89384055137634, loss: 53.63717317581177 
Train [13/26] | Epoch [72/160] |	nca: 2.3929019272327423, flat: 3.4198472425341606, pod: 47.15957510471344, loss: 52.97232389450073 
Train [13/26] | Epoch [73/160] |	nca: 1.8274185508489609, flat: 2.902582496404648, pod: 45.133806467056274, loss: 49.863807678222656 
Train [13/26] | Epoch [74/160] |	nca: 1.7504647560417652, flat: 2.4247109666466713, pod: 40.02615761756897, loss: 44.20133376121521 
Train [13/26] | Epoch [75/160] |	nca: 2.111209660768509, flat: 2.728973925113678, pod: 43.49452102184296, loss: 48.334704875946045 
Train [13/26] | Epoch [76/160] |	nca: 2.8661657571792603, flat: 3.1232027634978294, pod: 43.58090698719025, loss: 49.57027554512024 
Train [13/26] | Epoch [77/160] |	nca: 3.0060992315411568, flat: 3.583656921982765, pod: 47.12809121608734, loss: 53.71784782409668 
Train [13/26] | Epoch [78/160] |	nca: 2.815802998840809, flat: 3.421651214361191, pod: 47.076640367507935, loss: 53.31409502029419 
Train [13/26] | Epoch [79/160] |	nca: 2.314663216471672, flat: 3.2893864661455154, pod: 45.629623770713806, loss: 51.233673095703125 
Train [13/26] | Epoch [80/160] |	nca: 1.9451362863183022, flat: 2.726886957883835, pod: 42.242066860198975, loss: 46.914090156555176 
Train [13/26] | Epoch [81/160] |	nca: 2.7295583114027977, flat: 3.1780429631471634, pod: 45.09532356262207, loss: 51.00292444229126 
Train [13/26] | Epoch [82/160] |	nca: 1.839708112180233, flat: 2.5269901156425476, pod: 40.33450138568878, loss: 44.70120024681091 
Train [13/26] | Epoch [83/160] |	nca: 2.0457069352269173, flat: 2.6545513719320297, pod: 40.52703523635864, loss: 45.227293968200684 
Train [13/26] | Epoch [84/160] |	nca: 1.9530146569013596, flat: 2.6044585332274437, pod: 40.2068817615509, loss: 44.764354944229126 
Train [13/26] | Epoch [85/160] |	nca: 1.8767763078212738, flat: 2.5052511543035507, pod: 40.16961133480072, loss: 44.55163824558258 
Train [13/26] | Epoch [86/160] |	nca: 2.3303166776895523, flat: 2.8127017319202423, pod: 41.663455963134766, loss: 46.806474804878235 
Train [13/26] | Epoch [87/160] |	nca: 2.947906047105789, flat: 3.201025053858757, pod: 43.9695383310318, loss: 50.11846947669983 
Train [13/26] | Epoch [88/160] |	nca: 2.7308698669075966, flat: 3.201346881687641, pod: 43.7420699596405, loss: 49.67428684234619 
Train [13/26] | Epoch [89/160] |	nca: 2.1249143481254578, flat: 3.091724969446659, pod: 42.70442271232605, loss: 47.92106235027313 
Train [13/26] | Epoch [90/160] |	nca: 1.9811583831906319, flat: 2.5561835542321205, pod: 40.00966715812683, loss: 44.547008991241455 
Train [13/26] | Epoch [91/160] |	nca: 2.4219443276524544, flat: 2.9414961338043213, pod: 41.54520905017853, loss: 46.9086492061615 
Train [13/26] | Epoch [92/160] |	nca: 2.131100080907345, flat: 2.928679123520851, pod: 41.501935839653015, loss: 46.56171488761902 
Train [13/26] | Epoch [93/160] |	nca: 1.6440783441066742, flat: 2.415271021425724, pod: 38.85072195529938, loss: 42.91007173061371 
Train [13/26] | Epoch [94/160] |	nca: 1.6128217950463295, flat: 2.1587509140372276, pod: 36.63832211494446, loss: 40.409894824028015 
Train [13/26] | Epoch [95/160] |	nca: 1.522202217951417, flat: 2.249160796403885, pod: 36.87887358665466, loss: 40.65023684501648 
Train [13/26] | Epoch [96/160] |	nca: 1.6403252705931664, flat: 2.1778465658426285, pod: 37.772656202316284, loss: 41.59082806110382 
Train [13/26] | Epoch [97/160] |	nca: 1.8362013287842274, flat: 2.041296273469925, pod: 34.860331654548645, loss: 38.73782980442047 
Train [13/26] | Epoch [98/160] |	nca: 2.325407885015011, flat: 2.4009414315223694, pod: 38.256213426589966, loss: 42.98256289958954 
Train [13/26] | Epoch [99/160] |	nca: 1.510686181485653, flat: 2.132643848657608, pod: 36.24431395530701, loss: 39.88764417171478 
Train [13/26] | Epoch [100/160] |	nca: 1.573108684271574, flat: 2.2198617681860924, pod: 37.44937002658844, loss: 41.242340326309204 
Train [13/26] | Epoch [101/160] |	nca: 1.850616704672575, flat: 2.2485744059085846, pod: 36.806450724601746, loss: 40.90564227104187 
Train [13/26] | Epoch [102/160] |	nca: 1.8772244304418564, flat: 2.229498729109764, pod: 35.96174597740173, loss: 40.068469166755676 
Train [13/26] | Epoch [103/160] |	nca: 1.6261155903339386, flat: 1.992601864039898, pod: 34.90109610557556, loss: 38.519813537597656 
Train [13/26] | Epoch [104/160] |	nca: 2.32069756090641, flat: 2.0463696122169495, pod: 34.01710867881775, loss: 38.3841757774353 
Train [13/26] | Epoch [105/160] |	nca: 2.5809521563351154, flat: 2.206653207540512, pod: 36.28250277042389, loss: 41.07010841369629 
Train [13/26] | Epoch [106/160] |	nca: 2.1981925666332245, flat: 2.469612307846546, pod: 38.06062054634094, loss: 42.7284255027771 
Train [13/26] | Epoch [107/160] |	nca: 1.8275838792324066, flat: 2.3820078149437904, pod: 37.7552946805954, loss: 41.96488606929779 
Train [13/26] | Epoch [108/160] |	nca: 1.767191480845213, flat: 2.085022985935211, pod: 34.76440989971161, loss: 38.61662483215332 
Train [13/26] | Epoch [109/160] |	nca: 2.6623589396476746, flat: 2.1660135984420776, pod: 35.036789417266846, loss: 39.86516213417053 
Train [13/26] | Epoch [110/160] |	nca: 2.0821546837687492, flat: 2.581766463816166, pod: 38.419626116752625, loss: 43.08354687690735 
Train [13/26] | Epoch [111/160] |	nca: 1.5682849697768688, flat: 2.1086829528212547, pod: 36.13812971115112, loss: 39.81509721279144 
Train [13/26] | Epoch [112/160] |	nca: 2.498343948274851, flat: 2.0165405720472336, pod: 33.404356241226196, loss: 37.91924059391022 
Train [13/26] | Epoch [113/160] |	nca: 2.6091436855494976, flat: 2.2917841896414757, pod: 36.20468306541443, loss: 41.105610609054565 
Train [13/26] | Epoch [114/160] |	nca: 2.025268066674471, flat: 2.0868151262402534, pod: 34.8251895904541, loss: 38.937272906303406 
Train [13/26] | Epoch [115/160] |	nca: 1.6398584209382534, flat: 2.082908533513546, pod: 34.374629974365234, loss: 38.09739708900452 
Train [13/26] | Epoch [116/160] |	nca: 1.7417989112436771, flat: 1.8445173427462578, pod: 32.7436318397522, loss: 36.3299480676651 
Train [13/26] | Epoch [117/160] |	nca: 1.7476316578686237, flat: 1.8167004063725471, pod: 31.767146587371826, loss: 35.331478238105774 
Train [13/26] | Epoch [118/160] |	nca: 1.7877145148813725, flat: 1.9450854286551476, pod: 33.36397898197174, loss: 37.096779108047485 
Train [13/26] | Epoch [119/160] |	nca: 1.5323476046323776, flat: 1.8896773904561996, pod: 32.7689323425293, loss: 36.19095754623413 
Train [13/26] | Epoch [120/160] |	nca: 1.7707780078053474, flat: 1.666230522096157, pod: 30.111652374267578, loss: 33.54866099357605 
Train [13/26] | Epoch [121/160] |	nca: 1.6380793824791908, flat: 2.011400394141674, pod: 32.76112926006317, loss: 36.410608887672424 
Train [13/26] | Epoch [122/160] |	nca: 1.7528100349009037, flat: 1.8515106737613678, pod: 31.64415740966797, loss: 35.248478174209595 
Train [13/26] | Epoch [123/160] |	nca: 1.9209247343242168, flat: 1.767999306321144, pod: 31.157173991203308, loss: 34.84609770774841 
Train [13/26] | Epoch [124/160] |	nca: 2.528193574398756, flat: 1.936850719153881, pod: 31.97372329235077, loss: 36.43876755237579 
Train [13/26] | Epoch [125/160] |	nca: 2.2129907459020615, flat: 1.8897419646382332, pod: 31.45625674724579, loss: 35.5589896440506 
Train [13/26] | Epoch [126/160] |	nca: 1.9344522766768932, flat: 2.0403605327010155, pod: 33.04382264614105, loss: 37.018635749816895 
Train [13/26] | Epoch [127/160] |	nca: 1.4375220350921154, flat: 1.7909277379512787, pod: 31.45505702495575, loss: 34.68350660800934 
Train [13/26] | Epoch [128/160] |	nca: 1.4833968803286552, flat: 1.6324352882802486, pod: 29.59963047504425, loss: 32.71546256542206 
Train [13/26] | Epoch [129/160] |	nca: 1.5536989569664001, flat: 1.8439993374049664, pod: 30.741602182388306, loss: 34.13930058479309 
Train [13/26] | Epoch [130/160] |	nca: 1.8285176567733288, flat: 1.6327254250645638, pod: 28.97791051864624, loss: 32.43915390968323 
Train [13/26] | Epoch [131/160] |	nca: 1.6004169397056103, flat: 1.7446329146623611, pod: 28.92511749267578, loss: 32.27016746997833 
Train [13/26] | Epoch [132/160] |	nca: 1.581212181597948, flat: 1.613067775964737, pod: 30.027504205703735, loss: 33.22178387641907 
Train [13/26] | Epoch [133/160] |	nca: 1.4065850302577019, flat: 1.6677579805254936, pod: 30.33998668193817, loss: 33.41432964801788 
Train [13/26] | Epoch [134/160] |	nca: 1.780283484607935, flat: 1.642517939209938, pod: 29.477715253829956, loss: 32.900516390800476 
Train [13/26] | Epoch [135/160] |	nca: 1.594645630568266, flat: 1.5657218284904957, pod: 28.55829095840454, loss: 31.718658328056335 
Train [13/26] | Epoch [136/160] |	nca: 1.680308736860752, flat: 1.6322453767061234, pod: 28.287768721580505, loss: 31.60032284259796 
Train [13/26] | Epoch [137/160] |	nca: 1.6939808763563633, flat: 1.6854781582951546, pod: 29.61201310157776, loss: 32.991472244262695 
Train [13/26] | Epoch [138/160] |	nca: 1.9411540739238262, flat: 1.805257212370634, pod: 29.51177752017975, loss: 33.25818848609924 
Train [13/26] | Epoch [139/160] |	nca: 1.4185076616704464, flat: 1.537254761904478, pod: 27.690813422203064, loss: 30.646576285362244 
Train [13/26] | Epoch [140/160] |	nca: 1.7488031946122646, flat: 1.767832588404417, pod: 30.022189378738403, loss: 33.538824915885925 
Train [13/26] | Epoch [141/160] |	nca: 1.3906537368893623, flat: 1.6189977712929249, pod: 28.808046102523804, loss: 31.817697763442993 
Train [13/26] | Epoch [142/160] |	nca: 1.5062103495001793, flat: 1.578325066715479, pod: 27.342093467712402, loss: 30.426628828048706 
Train [13/26] | Epoch [143/160] |	nca: 1.4343690983951092, flat: 1.4953121095895767, pod: 26.812187552452087, loss: 29.74186861515045 
Train [13/26] | Epoch [144/160] |	nca: 1.6116068847477436, flat: 1.5344027504324913, pod: 26.66516602039337, loss: 29.81117570400238 
Train [13/26] | Epoch [145/160] |	nca: 1.3287907727062702, flat: 1.5132257342338562, pod: 27.33390748500824, loss: 30.17592430114746 
Train [13/26] | Epoch [146/160] |	nca: 1.4808782897889614, flat: 1.3876539692282677, pod: 26.37505865097046, loss: 29.24359118938446 
Train [13/26] | Epoch [147/160] |	nca: 1.4806790687143803, flat: 1.441640455275774, pod: 27.231475591659546, loss: 30.15379512310028 
Train [13/26] | Epoch [148/160] |	nca: 1.8484400436282158, flat: 1.5806280672550201, pod: 27.54350197315216, loss: 30.972569584846497 
Train [13/26] | Epoch [149/160] |	nca: 1.5403916165232658, flat: 1.5190136767923832, pod: 25.735991835594177, loss: 28.79539692401886 
Train [13/26] | Epoch [150/160] |	nca: 1.4893411882221699, flat: 1.4241969287395477, pod: 25.927462697029114, loss: 28.84100091457367 
Train [13/26] | Epoch [151/160] |	nca: 1.3873523846268654, flat: 1.3815375939011574, pod: 25.61981236934662, loss: 28.388702154159546 
Train [13/26] | Epoch [152/160] |	nca: 1.7944489568471909, flat: 1.4478325992822647, pod: 25.845224142074585, loss: 29.08750569820404 
Train [13/26] | Epoch [153/160] |	nca: 1.6295631788671017, flat: 1.380495075136423, pod: 25.539990186691284, loss: 28.550048351287842 
Train [13/26] | Epoch [154/160] |	nca: 1.436304148286581, flat: 1.4371741376817226, pod: 26.355839610099792, loss: 29.229317784309387 
Train [13/26] | Epoch [155/160] |	nca: 1.4731024503707886, flat: 1.3617457821965218, pod: 26.253437161445618, loss: 29.088285326957703 
Train [13/26] | Epoch [156/160] |	nca: 1.3422531746327877, flat: 1.4053016491234303, pod: 25.42884588241577, loss: 28.176400661468506 
Train [13/26] | Epoch [157/160] |	nca: 1.500075500458479, flat: 1.5929597988724709, pod: 26.310829877853394, loss: 29.403865098953247 
Train [13/26] | Epoch [158/160] |	nca: 1.3692687824368477, flat: 1.4421188049018383, pod: 25.981709837913513, loss: 28.793097734451294 
Train [13/26] | Epoch [159/160] |	nca: 1.3410938903689384, flat: 1.4609531089663506, pod: 25.988864183425903, loss: 28.790911436080933 
Train [13/26] | Epoch [160/160] |	nca: 1.7275336720049381, flat: 1.3756367936730385, pod: 25.77396261692047, loss: 28.877133011817932 
Fine-tuning
Building & updating memory.
Train [13/26] | Epoch [161/180] |	nca: 1.2998352497816086, flat: 1.2114144936203957, pod: 20.345866680145264, loss: 22.85711669921875 
Train [13/26] | Epoch [162/180] |	nca: 0.6339142620563507, flat: 1.2002879828214645, pod: 20.013677954673767, loss: 21.847880244255066 
Train [13/26] | Epoch [163/180] |	nca: 0.5617866516113281, flat: 1.204817183315754, pod: 20.182750463485718, loss: 21.94935417175293 
Train [13/26] | Epoch [164/180] |	nca: 0.5972067043185234, flat: 1.2086662873625755, pod: 20.012420773506165, loss: 21.818293809890747 
Train [13/26] | Epoch [165/180] |	nca: 0.5105525813996792, flat: 1.188834197819233, pod: 20.03900957107544, loss: 21.738396406173706 
Train [13/26] | Epoch [166/180] |	nca: 0.5294821299612522, flat: 1.1859864741563797, pod: 20.100452065467834, loss: 21.81592059135437 
Train [13/26] | Epoch [167/180] |	nca: 0.5135571360588074, flat: 1.2183688059449196, pod: 20.084792971611023, loss: 21.81671917438507 
Train [13/26] | Epoch [168/180] |	nca: 0.524413950741291, flat: 1.192365251481533, pod: 20.13514482975006, loss: 21.85192382335663 
Train [13/26] | Epoch [169/180] |	nca: 0.4903181195259094, flat: 1.1965833008289337, pod: 20.243486881256104, loss: 21.93038845062256 
Train [13/26] | Epoch [170/180] |	nca: 0.5197987221181393, flat: 1.225326582789421, pod: 20.303338050842285, loss: 22.048463344573975 
Train [13/26] | Epoch [171/180] |	nca: 0.49664418026804924, flat: 1.2053306698799133, pod: 20.14225947856903, loss: 21.844234466552734 
Train [13/26] | Epoch [172/180] |	nca: 0.4715730641037226, flat: 1.1817796677350998, pod: 20.033594846725464, loss: 21.686947464942932 
Train [13/26] | Epoch [173/180] |	nca: 0.4826953634619713, flat: 1.197291649878025, pod: 20.017436146736145, loss: 21.697423100471497 
Train [13/26] | Epoch [174/180] |	nca: 0.49208033084869385, flat: 1.2143523320555687, pod: 20.39562439918518, loss: 22.102056980133057 
Train [13/26] | Epoch [175/180] |	nca: 0.4655114933848381, flat: 1.1787459179759026, pod: 20.127878665924072, loss: 21.772136092185974 
Train [13/26] | Epoch [176/180] |	nca: 0.46548978239297867, flat: 1.2456561625003815, pod: 20.80449104309082, loss: 22.515637040138245 
Train [13/26] | Epoch [177/180] |	nca: 0.4395557753741741, flat: 1.2107143476605415, pod: 20.383073091506958, loss: 22.033343076705933 
Train [13/26] | Epoch [178/180] |	nca: 0.4108907338231802, flat: 1.209230825304985, pod: 20.111151933670044, loss: 21.731273293495178 
Train [13/26] | Epoch [179/180] |	nca: 0.4306122474372387, flat: 1.1940930485725403, pod: 19.978063106536865, loss: 21.602768301963806 
Train [13/26] | Epoch [180/180] |	nca: 0.43873291462659836, flat: 1.186208538711071, pod: 19.867384910583496, loss: 21.492326259613037 
after task
Building & updating memory.
after task
Eval on 0->74.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6487692307692308.
Current acc: {'total': 0.575, '00-09': 0.627, '10-19': 0.577, '20-29': 0.518, '30-39': 0.542, '40-49': 0.608, '50-59': 0.589, '60-69': 0.512, '70-79': 0.708}.
Avg inc acc top5: 0.8829230769230769.
Current acc top5: {'total': 0.846}.
Forgetting: 0.12311111111111112.
Cord metric: 0.64.
Old accuracy: 0.57, mean: 0.64.
New accuracy: 0.67, mean: 0.66.
================Task 13 Start!================
Testing on False unseen tasks (max class = 76).
Set memory of size: 1480.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 13 Training!================
The training samples number: 2480
Train on 74->76.
train task
nb 2480.
Train [14/26] | Epoch [1/160] |	nca: 7.199903517961502, flat: 2.6410734094679356, pod: 41.56683123111725, loss: 51.40780758857727 
Train [14/26] | Epoch [2/160] |	nca: 3.5715107694268227, flat: 2.4556493684649467, pod: 45.774882316589355, loss: 51.80204248428345 
Train [14/26] | Epoch [3/160] |	nca: 2.7091160491108894, flat: 2.149544484913349, pod: 40.81382942199707, loss: 45.67249035835266 
Train [14/26] | Epoch [4/160] |	nca: 2.2822127267718315, flat: 1.783970981836319, pod: 38.558860540390015, loss: 42.62504434585571 
Train [14/26] | Epoch [5/160] |	nca: 2.105859376490116, flat: 1.7729998528957367, pod: 38.73571312427521, loss: 42.61457276344299 
Train [14/26] | Epoch [6/160] |	nca: 2.0133999586105347, flat: 1.6481769680976868, pod: 37.865877628326416, loss: 41.5274543762207 
Train [14/26] | Epoch [7/160] |	nca: 2.130909286439419, flat: 1.8058746606111526, pod: 40.112500071525574, loss: 44.04928433895111 
Train [14/26] | Epoch [8/160] |	nca: 1.9903449416160583, flat: 1.7477954030036926, pod: 38.475144028663635, loss: 42.21328413486481 
Train [14/26] | Epoch [9/160] |	nca: 1.9018014892935753, flat: 1.8102285638451576, pod: 37.87456548213959, loss: 41.58659553527832 
Train [14/26] | Epoch [10/160] |	nca: 1.84469548240304, flat: 1.6086346805095673, pod: 36.47485673427582, loss: 39.928187012672424 
Train [14/26] | Epoch [11/160] |	nca: 2.063395395874977, flat: 2.1594639644026756, pod: 44.176082491874695, loss: 48.39894104003906 
Train [14/26] | Epoch [12/160] |	nca: 2.0097021758556366, flat: 2.0314101576805115, pod: 42.28659152984619, loss: 46.32770371437073 
Train [14/26] | Epoch [13/160] |	nca: 1.9631796032190323, flat: 2.0839970856904984, pod: 43.90474998950958, loss: 47.951926708221436 
Train [14/26] | Epoch [14/160] |	nca: 2.0655306577682495, flat: 1.9250304251909256, pod: 39.94569540023804, loss: 43.936256527900696 
Train [14/26] | Epoch [15/160] |	nca: 1.8472501076757908, flat: 1.7343737110495567, pod: 38.55486011505127, loss: 42.136483907699585 
Train [14/26] | Epoch [16/160] |	nca: 1.9417708925902843, flat: 1.8090477734804153, pod: 39.341530323028564, loss: 43.09234952926636 
Train [14/26] | Epoch [17/160] |	nca: 1.6818067580461502, flat: 1.7388426139950752, pod: 37.77192997932434, loss: 41.1925790309906 
Train [14/26] | Epoch [18/160] |	nca: 1.748701248317957, flat: 1.633400447666645, pod: 37.4052791595459, loss: 40.78738045692444 
Train [14/26] | Epoch [19/160] |	nca: 1.688377559185028, flat: 1.6216167509555817, pod: 36.79864513874054, loss: 40.10863924026489 
Train [14/26] | Epoch [20/160] |	nca: 1.8783811964094639, flat: 1.6720993667840958, pod: 37.19841527938843, loss: 40.74889588356018 
Train [14/26] | Epoch [21/160] |	nca: 1.5557710006833076, flat: 1.5868873447179794, pod: 36.108348965644836, loss: 39.251007199287415 
Train [14/26] | Epoch [22/160] |	nca: 1.8204773366451263, flat: 1.7156714648008347, pod: 38.99034559726715, loss: 42.52649426460266 
Train [14/26] | Epoch [23/160] |	nca: 2.078836925327778, flat: 1.9828065484762192, pod: 42.195019602775574, loss: 46.25666308403015 
Train [14/26] | Epoch [24/160] |	nca: 1.6986372359097004, flat: 1.6805760376155376, pod: 36.0532842874527, loss: 39.43249773979187 
Train [14/26] | Epoch [25/160] |	nca: 1.7731052972376347, flat: 1.7380703538656235, pod: 37.08923137187958, loss: 40.600406646728516 
Train [14/26] | Epoch [26/160] |	nca: 1.7818463817238808, flat: 1.740865707397461, pod: 37.951618790626526, loss: 41.47433125972748 
Train [14/26] | Epoch [27/160] |	nca: 2.079912707209587, flat: 1.940681405365467, pod: 41.17355513572693, loss: 45.19414925575256 
Train [14/26] | Epoch [28/160] |	nca: 1.9410416930913925, flat: 2.0791510194540024, pod: 42.50017440319061, loss: 46.52036726474762 
Train [14/26] | Epoch [29/160] |	nca: 2.0384665951132774, flat: 2.033657304942608, pod: 41.66984283924103, loss: 45.74196684360504 
Train [14/26] | Epoch [30/160] |	nca: 1.565708752721548, flat: 1.9175925105810165, pod: 40.060490131378174, loss: 43.54379141330719 
Train [14/26] | Epoch [31/160] |	nca: 1.5492813102900982, flat: 1.599502019584179, pod: 36.74533689022064, loss: 39.89412045478821 
Train [14/26] | Epoch [32/160] |	nca: 1.701097548007965, flat: 1.8002871796488762, pod: 38.24111235141754, loss: 41.74249708652496 
Train [14/26] | Epoch [33/160] |	nca: 1.5733748599886894, flat: 1.626839816570282, pod: 36.297582030296326, loss: 39.49779665470123 
Train [14/26] | Epoch [34/160] |	nca: 1.7103267684578896, flat: 1.5881629958748817, pod: 35.398600935935974, loss: 38.69709062576294 
Train [14/26] | Epoch [35/160] |	nca: 1.5475134439766407, flat: 1.4623571410775185, pod: 34.41672503948212, loss: 37.42659556865692 
Train [14/26] | Epoch [36/160] |	nca: 1.8939651399850845, flat: 1.7668870687484741, pod: 37.525368452072144, loss: 41.18622088432312 
Train [14/26] | Epoch [37/160] |	nca: 1.638780478388071, flat: 1.6617431417107582, pod: 36.38817381858826, loss: 39.68869733810425 
Train [14/26] | Epoch [38/160] |	nca: 1.7322818227112293, flat: 1.8209014013409615, pod: 39.69732987880707, loss: 43.250513434410095 
Train [14/26] | Epoch [39/160] |	nca: 1.9826049208641052, flat: 1.7426533475518227, pod: 38.479321241378784, loss: 42.20457971096039 
Train [14/26] | Epoch [40/160] |	nca: 1.6706988587975502, flat: 1.6744304820895195, pod: 36.80613088607788, loss: 40.15126025676727 
Train [14/26] | Epoch [41/160] |	nca: 1.7347839698195457, flat: 1.6788541674613953, pod: 36.662251114845276, loss: 40.075888991355896 
Train [14/26] | Epoch [42/160] |	nca: 1.6767955534160137, flat: 1.700468622148037, pod: 36.89373481273651, loss: 40.27099871635437 
Train [14/26] | Epoch [43/160] |	nca: 1.6385191231966019, flat: 1.5343243479728699, pod: 34.715912222862244, loss: 37.888755321502686 
Train [14/26] | Epoch [44/160] |	nca: 1.5905195660889149, flat: 1.58128160238266, pod: 34.95445489883423, loss: 38.12625586986542 
Train [14/26] | Epoch [45/160] |	nca: 1.5634919255971909, flat: 1.5474044494330883, pod: 36.12417411804199, loss: 39.23507082462311 
Train [14/26] | Epoch [46/160] |	nca: 1.6196375414729118, flat: 1.552581187337637, pod: 35.95022714138031, loss: 39.122446060180664 
Train [14/26] | Epoch [47/160] |	nca: 1.7103438526391983, flat: 1.4390989691019058, pod: 34.76046419143677, loss: 37.90990698337555 
Train [14/26] | Epoch [48/160] |	nca: 1.7654088251292706, flat: 1.6694817543029785, pod: 36.24986255168915, loss: 39.68475341796875 
Train [14/26] | Epoch [49/160] |	nca: 1.5105654075741768, flat: 1.6428598761558533, pod: 36.606637835502625, loss: 39.76006305217743 
Train [14/26] | Epoch [50/160] |	nca: 1.5866298079490662, flat: 1.535534717142582, pod: 35.86911928653717, loss: 38.991283655166626 
Train [14/26] | Epoch [51/160] |	nca: 1.6803342513740063, flat: 1.6528727263212204, pod: 36.035374999046326, loss: 39.368582367897034 
Train [14/26] | Epoch [52/160] |	nca: 1.7791464664041996, flat: 1.563980869948864, pod: 34.81047058105469, loss: 38.153597712516785 
Train [14/26] | Epoch [53/160] |	nca: 1.5563554763793945, flat: 1.58292618393898, pod: 36.677485942840576, loss: 39.81676733493805 
Train [14/26] | Epoch [54/160] |	nca: 1.6270883567631245, flat: 1.4509302228689194, pod: 33.963583111763, loss: 37.04160153865814 
Train [14/26] | Epoch [55/160] |	nca: 1.6846137829124928, flat: 1.663734182715416, pod: 37.65872371196747, loss: 41.00707185268402 
Train [14/26] | Epoch [56/160] |	nca: 1.7924675904214382, flat: 1.7967870607972145, pod: 38.99472224712372, loss: 42.58397698402405 
Train [14/26] | Epoch [57/160] |	nca: 1.694486167281866, flat: 1.7903480231761932, pod: 38.49704051017761, loss: 41.98187458515167 
Train [14/26] | Epoch [58/160] |	nca: 1.5737768076360226, flat: 1.488612286746502, pod: 34.202189445495605, loss: 37.26457858085632 
Train [14/26] | Epoch [59/160] |	nca: 1.622997909784317, flat: 1.435851275920868, pod: 33.68000304698944, loss: 36.73885214328766 
Train [14/26] | Epoch [60/160] |	nca: 1.6556889787316322, flat: 1.5009431764483452, pod: 34.74487614631653, loss: 37.90150856971741 
Train [14/26] | Epoch [61/160] |	nca: 1.703721135854721, flat: 1.6594401746988297, pod: 35.921552658081055, loss: 39.284714221954346 
Train [14/26] | Epoch [62/160] |	nca: 1.5854713097214699, flat: 1.4584867246448994, pod: 34.00936806201935, loss: 37.05332601070404 
Train [14/26] | Epoch [63/160] |	nca: 1.3672580011188984, flat: 1.3081685900688171, pod: 32.086220502853394, loss: 34.76164662837982 
Train [14/26] | Epoch [64/160] |	nca: 1.5042861066758633, flat: 1.3241639249026775, pod: 32.707244873046875, loss: 35.5356947183609 
Train [14/26] | Epoch [65/160] |	nca: 1.6560509391129017, flat: 1.4162818752229214, pod: 33.407408356666565, loss: 36.47974109649658 
Train [14/26] | Epoch [66/160] |	nca: 1.6178624629974365, flat: 1.5738054290413857, pod: 35.30670475959778, loss: 38.49837255477905 
Train [14/26] | Epoch [67/160] |	nca: 1.4852363876998425, flat: 1.501740649342537, pod: 35.35498404502869, loss: 38.34196090698242 
Train [14/26] | Epoch [68/160] |	nca: 1.5304777063429356, flat: 1.377702184021473, pod: 32.65945792198181, loss: 35.56763792037964 
Train [14/26] | Epoch [69/160] |	nca: 1.4981928020715714, flat: 1.3358177542686462, pod: 31.573173999786377, loss: 34.40718460083008 
Train [14/26] | Epoch [70/160] |	nca: 1.449814509600401, flat: 1.308973092585802, pod: 32.4034560918808, loss: 35.162243604660034 
Train [14/26] | Epoch [71/160] |	nca: 1.8029350489377975, flat: 1.5007960796356201, pod: 34.21306586265564, loss: 37.516796946525574 
Train [14/26] | Epoch [72/160] |	nca: 1.4390696659684181, flat: 1.4039554633200169, pod: 33.45480823516846, loss: 36.2978333234787 
Train [14/26] | Epoch [73/160] |	nca: 1.5924064628779888, flat: 1.3938721977174282, pod: 33.37521302700043, loss: 36.361491680145264 
Train [14/26] | Epoch [74/160] |	nca: 1.3977252058684826, flat: 1.3394459784030914, pod: 32.66251611709595, loss: 35.39968717098236 
Train [14/26] | Epoch [75/160] |	nca: 1.336124248802662, flat: 1.2251216918230057, pod: 31.285062074661255, loss: 33.84630811214447 
Train [14/26] | Epoch [76/160] |	nca: 1.527404922991991, flat: 1.243777971714735, pod: 31.687798380851746, loss: 34.45898127555847 
Train [14/26] | Epoch [77/160] |	nca: 1.4622224755585194, flat: 1.2261562421917915, pod: 30.90601146221161, loss: 33.59439039230347 
Train [14/26] | Epoch [78/160] |	nca: 1.473593544214964, flat: 1.2613818943500519, pod: 30.967037200927734, loss: 33.70201301574707 
Train [14/26] | Epoch [79/160] |	nca: 1.5246282033622265, flat: 1.25410121306777, pod: 31.188733458518982, loss: 33.9674631357193 
Train [14/26] | Epoch [80/160] |	nca: 1.4654333405196667, flat: 1.350006241351366, pod: 32.62944030761719, loss: 35.44487977027893 
Train [14/26] | Epoch [81/160] |	nca: 1.5044471248984337, flat: 1.2376540936529636, pod: 30.506747484207153, loss: 33.24884867668152 
Train [14/26] | Epoch [82/160] |	nca: 1.5360454134643078, flat: 1.2095598205924034, pod: 30.489830374717712, loss: 33.23543560504913 
Train [14/26] | Epoch [83/160] |	nca: 1.4698005132377148, flat: 1.2542988620698452, pod: 31.133293628692627, loss: 33.85739290714264 
Train [14/26] | Epoch [84/160] |	nca: 1.433006152510643, flat: 1.2099106311798096, pod: 32.26615917682648, loss: 34.90907609462738 
Train [14/26] | Epoch [85/160] |	nca: 1.386415220797062, flat: 1.2466332279145718, pod: 32.07184147834778, loss: 34.70489001274109 
Train [14/26] | Epoch [86/160] |	nca: 1.3421864435076714, flat: 1.1003370955586433, pod: 29.771910786628723, loss: 32.21443438529968 
Train [14/26] | Epoch [87/160] |	nca: 1.4757221899926662, flat: 1.1622908003628254, pod: 29.5018892288208, loss: 32.13990235328674 
Train [14/26] | Epoch [88/160] |	nca: 1.5193045362830162, flat: 1.1725098490715027, pod: 30.17530906200409, loss: 32.86712324619293 
Train [14/26] | Epoch [89/160] |	nca: 1.635469488799572, flat: 1.1511138044297695, pod: 28.62469506263733, loss: 31.41127836704254 
Train [14/26] | Epoch [90/160] |	nca: 1.486701101064682, flat: 1.0664848499000072, pod: 28.274393558502197, loss: 30.827579379081726 
Train [14/26] | Epoch [91/160] |	nca: 1.4266207851469517, flat: 1.0878463238477707, pod: 28.84052288532257, loss: 31.354989886283875 
Train [14/26] | Epoch [92/160] |	nca: 1.4317156113684177, flat: 1.1558827944099903, pod: 30.180625200271606, loss: 32.76822364330292 
Train [14/26] | Epoch [93/160] |	nca: 1.450632955878973, flat: 1.0484391041100025, pod: 29.459737062454224, loss: 31.95880925655365 
Train [14/26] | Epoch [94/160] |	nca: 1.374405350536108, flat: 1.1101249270141125, pod: 28.85933566093445, loss: 31.343865990638733 
Train [14/26] | Epoch [95/160] |	nca: 1.33047778531909, flat: 1.0148763991892338, pod: 27.06375300884247, loss: 29.409107089042664 
Train [14/26] | Epoch [96/160] |	nca: 1.325324285775423, flat: 0.9635263346135616, pod: 27.139548301696777, loss: 29.428398489952087 
Train [14/26] | Epoch [97/160] |	nca: 1.4695690125226974, flat: 0.953654695302248, pod: 26.315307140350342, loss: 28.73853063583374 
Train [14/26] | Epoch [98/160] |	nca: 1.3914082795381546, flat: 1.0492372661828995, pod: 26.877321481704712, loss: 29.31796681880951 
Train [14/26] | Epoch [99/160] |	nca: 1.2769351303577423, flat: 0.9420862458646297, pod: 26.99911606311798, loss: 29.21813726425171 
Train [14/26] | Epoch [100/160] |	nca: 1.3006851635873318, flat: 0.931996550410986, pod: 26.239282846450806, loss: 28.471964597702026 
Train [14/26] | Epoch [101/160] |	nca: 1.4368745274841785, flat: 0.9522336237132549, pod: 26.600634336471558, loss: 28.989742159843445 
Train [14/26] | Epoch [102/160] |	nca: 1.459535390138626, flat: 0.9511034116148949, pod: 25.766645669937134, loss: 28.177284479141235 
Train [14/26] | Epoch [103/160] |	nca: 1.4569825753569603, flat: 0.9709687307476997, pod: 27.415079832077026, loss: 29.84303104877472 
Train [14/26] | Epoch [104/160] |	nca: 1.4822822473943233, flat: 0.9813949652016163, pod: 27.054399967193604, loss: 29.51807689666748 
Train [14/26] | Epoch [105/160] |	nca: 1.3125170767307281, flat: 0.9486672170460224, pod: 26.010817646980286, loss: 28.27200198173523 
Train [14/26] | Epoch [106/160] |	nca: 1.3479164727032185, flat: 0.8710536882281303, pod: 24.481754779815674, loss: 26.700724720954895 
Train [14/26] | Epoch [107/160] |	nca: 1.4031398929655552, flat: 0.9753382094204426, pod: 26.938392162322998, loss: 29.3168705701828 
Train [14/26] | Epoch [108/160] |	nca: 1.4051128923892975, flat: 0.874616876244545, pod: 24.703832626342773, loss: 26.983562350273132 
Train [14/26] | Epoch [109/160] |	nca: 1.3217509277164936, flat: 0.8280581198632717, pod: 24.0571551322937, loss: 26.20696449279785 
Train [14/26] | Epoch [110/160] |	nca: 1.3534807115793228, flat: 0.9094684459269047, pod: 26.057665467262268, loss: 28.3206148147583 
Train [14/26] | Epoch [111/160] |	nca: 1.3295511081814766, flat: 0.8709586411714554, pod: 24.169598698616028, loss: 26.370108366012573 
Train [14/26] | Epoch [112/160] |	nca: 1.3017602115869522, flat: 0.81694645434618, pod: 23.860551357269287, loss: 25.979258179664612 
Train [14/26] | Epoch [113/160] |	nca: 1.2592269070446491, flat: 0.8290963303297758, pod: 23.532761335372925, loss: 25.621084332466125 
Train [14/26] | Epoch [114/160] |	nca: 1.4188149683177471, flat: 0.8265354186296463, pod: 23.93523335456848, loss: 26.180583715438843 
Train [14/26] | Epoch [115/160] |	nca: 1.2718971334397793, flat: 0.8034704625606537, pod: 23.498478770256042, loss: 25.573846340179443 
Train [14/26] | Epoch [116/160] |	nca: 1.4127308540046215, flat: 0.8147850316017866, pod: 23.38162076473236, loss: 25.6091365814209 
Train [14/26] | Epoch [117/160] |	nca: 1.4643592052161694, flat: 0.8494340628385544, pod: 24.3734347820282, loss: 26.687227964401245 
Train [14/26] | Epoch [118/160] |	nca: 1.3291757702827454, flat: 0.7989396080374718, pod: 23.445671319961548, loss: 25.57378661632538 
Train [14/26] | Epoch [119/160] |	nca: 1.202376402914524, flat: 0.7462763655930758, pod: 23.098068416118622, loss: 25.04672133922577 
Train [14/26] | Epoch [120/160] |	nca: 1.3069339990615845, flat: 0.7672608904540539, pod: 22.95956528186798, loss: 25.03376007080078 
Train [14/26] | Epoch [121/160] |	nca: 1.2424978576600552, flat: 0.6668312195688486, pod: 20.728094577789307, loss: 22.63742369413376 
Train [14/26] | Epoch [122/160] |	nca: 1.17794993147254, flat: 0.7058600801974535, pod: 21.635568141937256, loss: 23.519378066062927 
Train [14/26] | Epoch [123/160] |	nca: 1.361920665949583, flat: 0.7091708611696959, pod: 21.70546132326126, loss: 23.77655279636383 
Train [14/26] | Epoch [124/160] |	nca: 1.3527371734380722, flat: 0.7216001693159342, pod: 22.60821968317032, loss: 24.682557106018066 
Train [14/26] | Epoch [125/160] |	nca: 1.3274735771119595, flat: 0.6935003101825714, pod: 21.71799236536026, loss: 23.73896622657776 
Train [14/26] | Epoch [126/160] |	nca: 1.337359894067049, flat: 0.6909003648906946, pod: 20.43619078397751, loss: 22.46445107460022 
Train [14/26] | Epoch [127/160] |	nca: 1.2129253298044205, flat: 0.6543702110648155, pod: 20.290321588516235, loss: 22.157617151737213 
Train [14/26] | Epoch [128/160] |	nca: 1.2534696161746979, flat: 0.6481640972197056, pod: 20.300208568572998, loss: 22.20184236764908 
Train [14/26] | Epoch [129/160] |	nca: 1.2600303031504154, flat: 0.6596723403781652, pod: 20.13570737838745, loss: 22.055409848690033 
Train [14/26] | Epoch [130/160] |	nca: 1.3411009050905704, flat: 0.6725703477859497, pod: 20.695958733558655, loss: 22.709629893302917 
Train [14/26] | Epoch [131/160] |	nca: 1.3515956811606884, flat: 0.6777176577597857, pod: 20.6493039727211, loss: 22.678617119789124 
Train [14/26] | Epoch [132/160] |	nca: 1.3510048799216747, flat: 0.6504386886954308, pod: 20.059635639190674, loss: 22.06107920408249 
Train [14/26] | Epoch [133/160] |	nca: 1.3008512891829014, flat: 0.6748105138540268, pod: 21.009015262126923, loss: 22.98467719554901 
Train [14/26] | Epoch [134/160] |	nca: 1.3216066807508469, flat: 0.6038510799407959, pod: 19.131716012954712, loss: 21.05717372894287 
Train [14/26] | Epoch [135/160] |	nca: 1.3735667504370213, flat: 0.5827584788203239, pod: 18.662856459617615, loss: 20.619181632995605 
Train [14/26] | Epoch [136/160] |	nca: 1.3319627493619919, flat: 0.5798619017004967, pod: 18.27903014421463, loss: 20.19085466861725 
Train [14/26] | Epoch [137/160] |	nca: 1.2945708967745304, flat: 0.5607167817652225, pod: 18.19619733095169, loss: 20.051485121250153 
Train [14/26] | Epoch [138/160] |	nca: 1.3385365679860115, flat: 0.5735406577587128, pod: 18.34883826971054, loss: 20.260915458202362 
Train [14/26] | Epoch [139/160] |	nca: 1.324495803564787, flat: 0.590208837762475, pod: 18.491088449954987, loss: 20.405793070793152 
Train [14/26] | Epoch [140/160] |	nca: 1.2933384962379932, flat: 0.5550752803683281, pod: 17.965868413448334, loss: 19.81428223848343 
Train [14/26] | Epoch [141/160] |	nca: 1.351414479315281, flat: 0.5711359307169914, pod: 18.12521255016327, loss: 20.047763109207153 
Train [14/26] | Epoch [142/160] |	nca: 1.2122485041618347, flat: 0.6053628325462341, pod: 17.981586277484894, loss: 19.799197554588318 
Train [14/26] | Epoch [143/160] |	nca: 1.3163586296141148, flat: 0.5198084637522697, pod: 17.151137590408325, loss: 18.98730456829071 
Train [14/26] | Epoch [144/160] |	nca: 1.3187530897557735, flat: 0.5288872960954905, pod: 17.4529749751091, loss: 19.300615429878235 
Train [14/26] | Epoch [145/160] |	nca: 1.3506501279771328, flat: 0.5469727758318186, pod: 17.333598375320435, loss: 19.23122137784958 
Train [14/26] | Epoch [146/160] |	nca: 1.267887219786644, flat: 0.5483067873865366, pod: 17.58602225780487, loss: 19.40221631526947 
Train [14/26] | Epoch [147/160] |	nca: 1.2743489667773247, flat: 0.6040406934916973, pod: 17.781437814235687, loss: 19.659827411174774 
Train [14/26] | Epoch [148/160] |	nca: 1.3487268947064877, flat: 0.5420021899044514, pod: 16.979374945163727, loss: 18.87010395526886 
Train [14/26] | Epoch [149/160] |	nca: 1.3537437245249748, flat: 0.5318921487778425, pod: 16.417429625988007, loss: 18.303065299987793 
Train [14/26] | Epoch [150/160] |	nca: 1.296587523072958, flat: 0.5245636720210314, pod: 16.50928682088852, loss: 18.330438137054443 
Train [14/26] | Epoch [151/160] |	nca: 1.2178902588784695, flat: 0.5076622236520052, pod: 16.526147723197937, loss: 18.251700282096863 
Train [14/26] | Epoch [152/160] |	nca: 1.4078880175948143, flat: 0.5332462638616562, pod: 16.567063212394714, loss: 18.50819742679596 
Train [14/26] | Epoch [153/160] |	nca: 1.32636683806777, flat: 0.5829843375831842, pod: 16.973404228687286, loss: 18.882755398750305 
Train [14/26] | Epoch [154/160] |	nca: 1.2661888152360916, flat: 0.47893257439136505, pod: 15.88581645488739, loss: 17.630937933921814 
Train [14/26] | Epoch [155/160] |	nca: 1.272511251270771, flat: 0.49397085048258305, pod: 16.233285665512085, loss: 17.999767661094666 
Train [14/26] | Epoch [156/160] |	nca: 1.3507917262613773, flat: 0.5088863791897893, pod: 15.736678123474121, loss: 17.59635627269745 
Train [14/26] | Epoch [157/160] |	nca: 1.4264498502016068, flat: 0.513425350189209, pod: 16.011671662330627, loss: 17.951546847820282 
Train [14/26] | Epoch [158/160] |	nca: 1.2743672281503677, flat: 0.5003098845481873, pod: 15.753794014453888, loss: 17.528471052646637 
Train [14/26] | Epoch [159/160] |	nca: 1.282812137156725, flat: 0.4815818639472127, pod: 15.7533038854599, loss: 17.517698049545288 
Train [14/26] | Epoch [160/160] |	nca: 1.257033333182335, flat: 0.5011612363159657, pod: 16.17889267206192, loss: 17.937087178230286 
Fine-tuning
Building & updating memory.
Train [14/26] | Epoch [161/180] |	nca: 1.065738756209612, flat: 0.6114517562091351, pod: 15.012200355529785, loss: 16.689390897750854 
Train [14/26] | Epoch [162/180] |	nca: 0.6727342531085014, flat: 0.5832309350371361, pod: 14.520601451396942, loss: 15.776566624641418 
Train [14/26] | Epoch [163/180] |	nca: 0.6646311171352863, flat: 0.6269444487988949, pod: 15.00346690416336, loss: 16.295042276382446 
Train [14/26] | Epoch [164/180] |	nca: 0.612066987901926, flat: 0.580543402582407, pod: 14.496299982070923, loss: 15.688910365104675 
Train [14/26] | Epoch [165/180] |	nca: 0.5989805646240711, flat: 0.6121680587530136, pod: 15.04740834236145, loss: 16.258557081222534 
Train [14/26] | Epoch [166/180] |	nca: 0.5892714001238346, flat: 0.5839694701135159, pod: 14.570268869400024, loss: 15.743509531021118 
Train [14/26] | Epoch [167/180] |	nca: 0.5772162713110447, flat: 0.5963438116014004, pod: 14.548381268978119, loss: 15.721941351890564 
Train [14/26] | Epoch [168/180] |	nca: 0.5331291295588017, flat: 0.616677638143301, pod: 14.598835587501526, loss: 15.748642206192017 
Train [14/26] | Epoch [169/180] |	nca: 0.5644444040954113, flat: 0.5734613873064518, pod: 14.611266255378723, loss: 15.74917185306549 
Train [14/26] | Epoch [170/180] |	nca: 0.5407760255038738, flat: 0.6226514466106892, pod: 14.697766780853271, loss: 15.861194372177124 
Train [14/26] | Epoch [171/180] |	nca: 0.540113914757967, flat: 0.6061014924198389, pod: 14.648773074150085, loss: 15.794988572597504 
Train [14/26] | Epoch [172/180] |	nca: 0.5207676850259304, flat: 0.5714350007474422, pod: 14.635252833366394, loss: 15.727455496788025 
Train [14/26] | Epoch [173/180] |	nca: 0.5045086853206158, flat: 0.634318120777607, pod: 15.007851600646973, loss: 16.146678566932678 
Train [14/26] | Epoch [174/180] |	nca: 0.5040950179100037, flat: 0.5981362834572792, pod: 14.526977598667145, loss: 15.629209041595459 
Train [14/26] | Epoch [175/180] |	nca: 0.5263932757079601, flat: 0.5837297514081001, pod: 14.537201762199402, loss: 15.647324919700623 
Train [14/26] | Epoch [176/180] |	nca: 0.49422862008213997, flat: 0.6231575645506382, pod: 15.159378945827484, loss: 16.27676510810852 
Train [14/26] | Epoch [177/180] |	nca: 0.47976894304156303, flat: 0.5959396660327911, pod: 14.590896904468536, loss: 15.666605353355408 
Train [14/26] | Epoch [178/180] |	nca: 0.5175797380506992, flat: 0.6102659702301025, pod: 14.750404477119446, loss: 15.878250002861023 
Train [14/26] | Epoch [179/180] |	nca: 0.49618678726255894, flat: 0.6174410730600357, pod: 15.035792112350464, loss: 16.149420142173767 
Train [14/26] | Epoch [180/180] |	nca: 0.5219222456216812, flat: 0.6165097169578075, pod: 15.08938455581665, loss: 16.227816581726074 
after task
Building & updating memory.
after task
Eval on 0->76.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6422857142857142.
Current acc: {'total': 0.558, '00-09': 0.602, '10-19': 0.568, '20-29': 0.502, '30-39': 0.519, '40-49': 0.586, '50-59': 0.583, '60-69': 0.488, '70-79': 0.653}.
Avg inc acc top5: 0.8794285714285713.
Current acc top5: {'total': 0.834}.
Forgetting: 0.1431111111111111.
Cord metric: 0.63.
Old accuracy: 0.56, mean: 0.63.
New accuracy: 0.66, mean: 0.66.
================Task 14 Start!================
Testing on False unseen tasks (max class = 78).
Set memory of size: 1520.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 14 Training!================
The training samples number: 2520
Train on 76->78.
train task
nb 2520.
Train [15/26] | Epoch [1/160] |	nca: 10.219561159610748, flat: 4.278910629451275, pod: 49.37709927558899, loss: 63.87557101249695 
Train [15/26] | Epoch [2/160] |	nca: 6.24650377035141, flat: 4.612302154302597, pod: 57.36931133270264, loss: 68.22811675071716 
Train [15/26] | Epoch [3/160] |	nca: 4.4805169850587845, flat: 3.7449746131896973, pod: 51.187498331069946, loss: 59.41299033164978 
Train [15/26] | Epoch [4/160] |	nca: 3.6537391915917397, flat: 3.0339142978191376, pod: 48.73417806625366, loss: 55.421831369400024 
Train [15/26] | Epoch [5/160] |	nca: 3.1300726756453514, flat: 2.7705268040299416, pod: 46.45859622955322, loss: 52.359195709228516 
Train [15/26] | Epoch [6/160] |	nca: 3.0333375930786133, flat: 2.659120500087738, pod: 45.870062828063965, loss: 51.56252145767212 
Train [15/26] | Epoch [7/160] |	nca: 3.1678091809153557, flat: 2.49300380051136, pod: 43.409284591674805, loss: 49.07009744644165 
Train [15/26] | Epoch [8/160] |	nca: 3.060383379459381, flat: 2.685951344668865, pod: 47.43971586227417, loss: 53.18605065345764 
Train [15/26] | Epoch [9/160] |	nca: 2.6321127340197563, flat: 2.40052280575037, pod: 43.89447808265686, loss: 48.9271137714386 
Train [15/26] | Epoch [10/160] |	nca: 2.859900750219822, flat: 2.7453863322734833, pod: 48.21742916107178, loss: 53.82271671295166 
Train [15/26] | Epoch [11/160] |	nca: 2.6419473215937614, flat: 2.5345973670482635, pod: 46.53053164482117, loss: 51.70707583427429 
Train [15/26] | Epoch [12/160] |	nca: 2.632247306406498, flat: 2.5417340844869614, pod: 47.044246673583984, loss: 52.21822810173035 
Train [15/26] | Epoch [13/160] |	nca: 2.5740110129117966, flat: 2.39832516759634, pod: 43.79100322723389, loss: 48.76333928108215 
Train [15/26] | Epoch [14/160] |	nca: 2.3468157425522804, flat: 2.2430834844708443, pod: 41.58446907997131, loss: 46.17436861991882 
Train [15/26] | Epoch [15/160] |	nca: 2.6306074783205986, flat: 2.4542714282870293, pod: 44.556451201438904, loss: 49.64133024215698 
Train [15/26] | Epoch [16/160] |	nca: 2.5212817043066025, flat: 2.4460892751812935, pod: 45.0286169052124, loss: 49.995988607406616 
Train [15/26] | Epoch [17/160] |	nca: 2.6050016582012177, flat: 2.4145314171910286, pod: 44.2742133140564, loss: 49.29374623298645 
Train [15/26] | Epoch [18/160] |	nca: 2.545323021709919, flat: 2.313597582280636, pod: 43.19702076911926, loss: 48.055941343307495 
Train [15/26] | Epoch [19/160] |	nca: 2.583996996283531, flat: 2.4099607914686203, pod: 44.45836782455444, loss: 49.45232605934143 
Train [15/26] | Epoch [20/160] |	nca: 2.3011007085442543, flat: 2.1907305121421814, pod: 41.44472062587738, loss: 45.93655204772949 
Train [15/26] | Epoch [21/160] |	nca: 2.3637499436736107, flat: 2.086139291524887, pod: 40.27257215976715, loss: 44.72246170043945 
Train [15/26] | Epoch [22/160] |	nca: 2.310232326388359, flat: 2.261508174240589, pod: 41.246325969696045, loss: 45.81806659698486 
Train [15/26] | Epoch [23/160] |	nca: 2.249193787574768, flat: 2.2153017297387123, pod: 42.460150480270386, loss: 46.92464566230774 
Train [15/26] | Epoch [24/160] |	nca: 2.108576588332653, flat: 2.0539863035082817, pod: 40.35935080051422, loss: 44.52191400527954 
Train [15/26] | Epoch [25/160] |	nca: 2.228988505899906, flat: 1.986799880862236, pod: 40.436155915260315, loss: 44.651944160461426 
Train [15/26] | Epoch [26/160] |	nca: 2.078420400619507, flat: 1.9703785926103592, pod: 39.96638572216034, loss: 44.01518499851227 
Train [15/26] | Epoch [27/160] |	nca: 2.160943880677223, flat: 1.9348592013120651, pod: 39.359288573265076, loss: 43.45509147644043 
Train [15/26] | Epoch [28/160] |	nca: 2.340588018298149, flat: 2.4282721281051636, pod: 43.17419731616974, loss: 47.9430570602417 
Train [15/26] | Epoch [29/160] |	nca: 2.16633003950119, flat: 2.0546752586960793, pod: 40.722548961639404, loss: 44.943554162979126 
Train [15/26] | Epoch [30/160] |	nca: 2.0027041025459766, flat: 1.9130699336528778, pod: 38.44996500015259, loss: 42.36573839187622 
Train [15/26] | Epoch [31/160] |	nca: 2.0180822908878326, flat: 1.8661187589168549, pod: 37.87562918663025, loss: 41.75982964038849 
Train [15/26] | Epoch [32/160] |	nca: 2.1341608241200447, flat: 1.9866229891777039, pod: 39.99053978919983, loss: 44.111323595047 
Train [15/26] | Epoch [33/160] |	nca: 2.180323004722595, flat: 1.9349184334278107, pod: 39.56632113456726, loss: 43.681562662124634 
Train [15/26] | Epoch [34/160] |	nca: 1.9066172763705254, flat: 1.8782099336385727, pod: 38.406575322151184, loss: 42.191402316093445 
Train [15/26] | Epoch [35/160] |	nca: 2.0419516637921333, flat: 1.9364542216062546, pod: 39.28994345664978, loss: 43.268349051475525 
Train [15/26] | Epoch [36/160] |	nca: 2.0128250047564507, flat: 1.9053980559110641, pod: 38.57245349884033, loss: 42.49067687988281 
Train [15/26] | Epoch [37/160] |	nca: 2.11408244818449, flat: 1.8061466291546822, pod: 37.989715695381165, loss: 41.90994429588318 
Train [15/26] | Epoch [38/160] |	nca: 2.067909635603428, flat: 1.9895747676491737, pod: 40.387959480285645, loss: 44.445443630218506 
Train [15/26] | Epoch [39/160] |	nca: 2.150430679321289, flat: 1.8791711404919624, pod: 38.130573749542236, loss: 42.16017532348633 
Train [15/26] | Epoch [40/160] |	nca: 2.0144385248422623, flat: 1.9190208539366722, pod: 38.5869961977005, loss: 42.520456075668335 
Train [15/26] | Epoch [41/160] |	nca: 2.132147904485464, flat: 1.9931883588433266, pod: 40.40802586078644, loss: 44.53336215019226 
Train [15/26] | Epoch [42/160] |	nca: 2.023985967040062, flat: 1.8123028352856636, pod: 37.79942214488983, loss: 41.63571095466614 
Train [15/26] | Epoch [43/160] |	nca: 1.8687163963913918, flat: 1.8261613249778748, pod: 38.04266834259033, loss: 41.73754632472992 
Train [15/26] | Epoch [44/160] |	nca: 1.8228175044059753, flat: 1.7738156095147133, pod: 38.80229294300079, loss: 42.39892590045929 
Train [15/26] | Epoch [45/160] |	nca: 1.9492357075214386, flat: 1.7195390090346336, pod: 37.551610589027405, loss: 41.22038543224335 
Train [15/26] | Epoch [46/160] |	nca: 1.9743127636611462, flat: 1.7762129306793213, pod: 37.27049469947815, loss: 41.02102041244507 
Train [15/26] | Epoch [47/160] |	nca: 2.5036730244755745, flat: 2.1113394126296043, pod: 40.547964453697205, loss: 45.16297698020935 
Train [15/26] | Epoch [48/160] |	nca: 2.0600257888436317, flat: 1.975609228014946, pod: 40.396923542022705, loss: 44.43255853652954 
Train [15/26] | Epoch [49/160] |	nca: 2.042704753577709, flat: 1.8078334033489227, pod: 38.70610463619232, loss: 42.5566428899765 
Train [15/26] | Epoch [50/160] |	nca: 1.8346609845757484, flat: 1.8649699091911316, pod: 38.88401710987091, loss: 42.58364796638489 
Train [15/26] | Epoch [51/160] |	nca: 1.8060375601053238, flat: 1.6584244966506958, pod: 35.297470927238464, loss: 38.76193296909332 
Train [15/26] | Epoch [52/160] |	nca: 1.8572729043662548, flat: 1.8081130757927895, pod: 37.19035577774048, loss: 40.8557413816452 
Train [15/26] | Epoch [53/160] |	nca: 1.890964835882187, flat: 1.526450902223587, pod: 33.758614897727966, loss: 37.17603051662445 
Train [15/26] | Epoch [54/160] |	nca: 1.9011668115854263, flat: 1.7762169539928436, pod: 37.89851474761963, loss: 41.57589793205261 
Train [15/26] | Epoch [55/160] |	nca: 1.807058371603489, flat: 1.587567426264286, pod: 36.16550946235657, loss: 39.56013488769531 
Train [15/26] | Epoch [56/160] |	nca: 1.8284493684768677, flat: 1.466991450637579, pod: 34.046266078948975, loss: 37.34170711040497 
Train [15/26] | Epoch [57/160] |	nca: 1.8929014205932617, flat: 1.7825308963656425, pod: 37.98484396934509, loss: 41.66027641296387 
Train [15/26] | Epoch [58/160] |	nca: 1.945359155535698, flat: 1.6572978124022484, pod: 36.92525637149811, loss: 40.52791345119476 
Train [15/26] | Epoch [59/160] |	nca: 1.7721525765955448, flat: 1.730058379471302, pod: 37.139111161231995, loss: 40.64132249355316 
Train [15/26] | Epoch [60/160] |	nca: 2.139337532222271, flat: 1.8737044855952263, pod: 39.88198709487915, loss: 43.89502930641174 
Train [15/26] | Epoch [61/160] |	nca: 1.888292659074068, flat: 1.6358057484030724, pod: 36.18515121936798, loss: 39.70924937725067 
Train [15/26] | Epoch [62/160] |	nca: 1.851284384727478, flat: 1.588789351284504, pod: 35.30119013786316, loss: 38.74126362800598 
Train [15/26] | Epoch [63/160] |	nca: 1.6827913261950016, flat: 1.4535608440637589, pod: 33.57958483695984, loss: 36.71593713760376 
Train [15/26] | Epoch [64/160] |	nca: 1.8119828887283802, flat: 1.6216904819011688, pod: 35.54379844665527, loss: 38.977471590042114 
Train [15/26] | Epoch [65/160] |	nca: 2.0812566950917244, flat: 1.659007616341114, pod: 35.05708181858063, loss: 38.797346115112305 
Train [15/26] | Epoch [66/160] |	nca: 2.0174346677958965, flat: 1.7816147208213806, pod: 37.35601568222046, loss: 41.155065059661865 
Train [15/26] | Epoch [67/160] |	nca: 1.6290874555706978, flat: 1.392863031476736, pod: 32.471126198768616, loss: 35.49307680130005 
Train [15/26] | Epoch [68/160] |	nca: 1.6354146748781204, flat: 1.3504236228764057, pod: 31.961088180541992, loss: 34.94692623615265 
Train [15/26] | Epoch [69/160] |	nca: 1.8074311055243015, flat: 1.3580951541662216, pod: 32.92030930519104, loss: 36.085835576057434 
Train [15/26] | Epoch [70/160] |	nca: 1.7568380162119865, flat: 1.515087440609932, pod: 34.72361660003662, loss: 37.99554216861725 
Train [15/26] | Epoch [71/160] |	nca: 1.7977642603218555, flat: 1.5147090181708336, pod: 33.888617634773254, loss: 37.201091051101685 
Train [15/26] | Epoch [72/160] |	nca: 1.781250350177288, flat: 1.3971344977617264, pod: 32.29960322380066, loss: 35.47798836231232 
Train [15/26] | Epoch [73/160] |	nca: 1.7509806603193283, flat: 1.4365623407065868, pod: 32.89509081840515, loss: 36.08263349533081 
Train [15/26] | Epoch [74/160] |	nca: 1.8417226560413837, flat: 1.4261829368770123, pod: 33.79026114940643, loss: 37.05816698074341 
Train [15/26] | Epoch [75/160] |	nca: 1.682092111557722, flat: 1.338992029428482, pod: 31.795852780342102, loss: 34.81693732738495 
Train [15/26] | Epoch [76/160] |	nca: 1.669114738702774, flat: 1.3551486507058144, pod: 33.02496898174286, loss: 36.049232482910156 
Train [15/26] | Epoch [77/160] |	nca: 1.7861440815031528, flat: 1.4351610206067562, pod: 33.99847710132599, loss: 37.21978223323822 
Train [15/26] | Epoch [78/160] |	nca: 1.719598826020956, flat: 1.4976528212428093, pod: 34.46957612037659, loss: 37.68682789802551 
Train [15/26] | Epoch [79/160] |	nca: 1.58268416300416, flat: 1.3262290582060814, pod: 32.25583016872406, loss: 35.164743304252625 
Train [15/26] | Epoch [80/160] |	nca: 1.6062032021582127, flat: 1.3984712064266205, pod: 33.25671863555908, loss: 36.26139318943024 
Train [15/26] | Epoch [81/160] |	nca: 1.7689648009836674, flat: 1.2983892932534218, pod: 31.59188437461853, loss: 34.65923857688904 
Train [15/26] | Epoch [82/160] |	nca: 1.5603955797851086, flat: 1.3053462356328964, pod: 31.251611709594727, loss: 34.117353677749634 
Train [15/26] | Epoch [83/160] |	nca: 1.4927456006407738, flat: 1.1126306466758251, pod: 29.425158143043518, loss: 32.03053426742554 
Train [15/26] | Epoch [84/160] |	nca: 1.85409839078784, flat: 1.306759301573038, pod: 31.773547291755676, loss: 34.9344048500061 
Train [15/26] | Epoch [85/160] |	nca: 1.6747797690331936, flat: 1.2738948911428452, pod: 30.397258758544922, loss: 33.34593343734741 
Train [15/26] | Epoch [86/160] |	nca: 1.6423349119722843, flat: 1.2295287102460861, pod: 30.32598876953125, loss: 33.19785225391388 
Train [15/26] | Epoch [87/160] |	nca: 1.6869467869400978, flat: 1.319147314876318, pod: 32.63073182106018, loss: 35.636826038360596 
Train [15/26] | Epoch [88/160] |	nca: 1.6383304335176945, flat: 1.1652478277683258, pod: 29.810739159584045, loss: 32.614317536354065 
Train [15/26] | Epoch [89/160] |	nca: 1.621766958385706, flat: 1.1784919947385788, pod: 29.773421049118042, loss: 32.57368016242981 
Train [15/26] | Epoch [90/160] |	nca: 1.6659421175718307, flat: 1.1874777898192406, pod: 30.61116325855255, loss: 33.46458339691162 
Train [15/26] | Epoch [91/160] |	nca: 1.712142150849104, flat: 1.0981104485690594, pod: 28.02809500694275, loss: 30.838347792625427 
Train [15/26] | Epoch [92/160] |	nca: 1.6269581280648708, flat: 1.0780673138797283, pod: 27.751346707344055, loss: 30.456372141838074 
Train [15/26] | Epoch [93/160] |	nca: 1.5342482663691044, flat: 1.1237644776701927, pod: 27.737568855285645, loss: 30.395581603050232 
Train [15/26] | Epoch [94/160] |	nca: 1.6368805803358555, flat: 1.1317219771444798, pod: 28.693360447883606, loss: 31.461963176727295 
Train [15/26] | Epoch [95/160] |	nca: 1.5083754323422909, flat: 1.0852005332708359, pod: 28.176496505737305, loss: 30.77007257938385 
Train [15/26] | Epoch [96/160] |	nca: 1.5223862193524837, flat: 1.019920650869608, pod: 26.924574971199036, loss: 29.46688199043274 
Train [15/26] | Epoch [97/160] |	nca: 1.5836157351732254, flat: 1.1499903164803982, pod: 29.948906540870667, loss: 32.68251287937164 
Train [15/26] | Epoch [98/160] |	nca: 1.5304766967892647, flat: 1.0309219844639301, pod: 27.951740503311157, loss: 30.513139367103577 
Train [15/26] | Epoch [99/160] |	nca: 1.6448613367974758, flat: 1.07612856477499, pod: 28.680524468421936, loss: 31.401514649391174 
Train [15/26] | Epoch [100/160] |	nca: 1.7153849080204964, flat: 1.0907902643084526, pod: 29.26052188873291, loss: 32.06669723987579 
Train [15/26] | Epoch [101/160] |	nca: 1.5984784588217735, flat: 1.016615267843008, pod: 27.609839916229248, loss: 30.22493350505829 
Train [15/26] | Epoch [102/160] |	nca: 1.490767441689968, flat: 0.9990599229931831, pod: 27.090502858161926, loss: 29.58033037185669 
Train [15/26] | Epoch [103/160] |	nca: 1.6537562869489193, flat: 1.048012726008892, pod: 28.332008361816406, loss: 31.033777236938477 
Train [15/26] | Epoch [104/160] |	nca: 1.5760239697992802, flat: 1.0109341815114021, pod: 27.325875997543335, loss: 29.9128338098526 
Train [15/26] | Epoch [105/160] |	nca: 1.5998944081366062, flat: 1.0005273520946503, pod: 26.72211766242981, loss: 29.322539448738098 
Train [15/26] | Epoch [106/160] |	nca: 1.488952774554491, flat: 0.9518509656190872, pod: 25.93431031703949, loss: 28.37511432170868 
Train [15/26] | Epoch [107/160] |	nca: 1.4387837648391724, flat: 0.9531478695571423, pod: 25.833314418792725, loss: 28.22524607181549 
Train [15/26] | Epoch [108/160] |	nca: 1.5761055760085583, flat: 0.9061510637402534, pod: 25.070749402046204, loss: 27.553005814552307 
Train [15/26] | Epoch [109/160] |	nca: 1.6964930035173893, flat: 0.9542434848845005, pod: 26.151392102241516, loss: 28.802128434181213 
Train [15/26] | Epoch [110/160] |	nca: 1.6492847874760628, flat: 0.9779000505805016, pod: 25.701621413230896, loss: 28.328806042671204 
Train [15/26] | Epoch [111/160] |	nca: 1.4205547384917736, flat: 0.9012830443680286, pod: 25.24042308330536, loss: 27.56226086616516 
Train [15/26] | Epoch [112/160] |	nca: 1.4982302710413933, flat: 0.8745296485722065, pod: 24.550458312034607, loss: 26.92321801185608 
Train [15/26] | Epoch [113/160] |	nca: 1.5150782354176044, flat: 0.8938232883810997, pod: 24.770751953125, loss: 27.179653525352478 
Train [15/26] | Epoch [114/160] |	nca: 1.6113006956875324, flat: 0.9184162095189095, pod: 26.02182900905609, loss: 28.551546096801758 
Train [15/26] | Epoch [115/160] |	nca: 1.4708819650113583, flat: 0.7841210812330246, pod: 23.299264192581177, loss: 25.554267168045044 
Train [15/26] | Epoch [116/160] |	nca: 1.4165473468601704, flat: 0.8501197509467602, pod: 24.195238709449768, loss: 26.46190571784973 
Train [15/26] | Epoch [117/160] |	nca: 1.525769505649805, flat: 0.8070850148797035, pod: 23.32107186317444, loss: 25.653926372528076 
Train [15/26] | Epoch [118/160] |	nca: 1.6853907108306885, flat: 0.8628447465598583, pod: 25.139206290245056, loss: 27.68744158744812 
Train [15/26] | Epoch [119/160] |	nca: 1.4795280285179615, flat: 0.783650454133749, pod: 22.94438201189041, loss: 25.207560658454895 
Train [15/26] | Epoch [120/160] |	nca: 1.588944710791111, flat: 0.8641840741038322, pod: 23.918921947479248, loss: 26.372050881385803 
Train [15/26] | Epoch [121/160] |	nca: 1.5136284790933132, flat: 0.8353626355528831, pod: 23.325534999370575, loss: 25.67452597618103 
Train [15/26] | Epoch [122/160] |	nca: 1.5798128694295883, flat: 0.8265345878899097, pod: 24.01608443260193, loss: 26.42243206501007 
Train [15/26] | Epoch [123/160] |	nca: 1.4166448339819908, flat: 0.7663956768810749, pod: 22.20363360643387, loss: 24.38667404651642 
Train [15/26] | Epoch [124/160] |	nca: 1.4332841336727142, flat: 0.778368603438139, pod: 22.70584499835968, loss: 24.917497515678406 
Train [15/26] | Epoch [125/160] |	nca: 1.5028818547725677, flat: 0.7934915237128735, pod: 22.79735392332077, loss: 25.093727231025696 
Train [15/26] | Epoch [126/160] |	nca: 1.4212226048111916, flat: 0.772785134613514, pod: 22.389215767383575, loss: 24.583223700523376 
Train [15/26] | Epoch [127/160] |	nca: 1.3048636466264725, flat: 0.7224722560495138, pod: 22.198767840862274, loss: 24.22610366344452 
Train [15/26] | Epoch [128/160] |	nca: 1.491549376398325, flat: 0.670714108273387, pod: 20.910140454769135, loss: 23.072404146194458 
Train [15/26] | Epoch [129/160] |	nca: 1.5035444647073746, flat: 0.7116037476807833, pod: 21.28882986307144, loss: 23.50397825241089 
Train [15/26] | Epoch [130/160] |	nca: 1.5603161789476871, flat: 0.6875326056033373, pod: 20.453779816627502, loss: 22.701628863811493 
Train [15/26] | Epoch [131/160] |	nca: 1.5239932388067245, flat: 0.7228494882583618, pod: 21.714096069335938, loss: 23.96093875169754 
Train [15/26] | Epoch [132/160] |	nca: 1.3974190838634968, flat: 0.7271344847977161, pod: 21.64476066827774, loss: 23.769314467906952 
Train [15/26] | Epoch [133/160] |	nca: 1.4977718628942966, flat: 0.657165452837944, pod: 20.126380562782288, loss: 22.281317591667175 
Train [15/26] | Epoch [134/160] |	nca: 1.3980276100337505, flat: 0.6237276215106249, pod: 19.540544390678406, loss: 21.56229931116104 
Train [15/26] | Epoch [135/160] |	nca: 1.5002247542142868, flat: 0.5984713789075613, pod: 18.987069487571716, loss: 21.08576536178589 
Train [15/26] | Epoch [136/160] |	nca: 1.4198521450161934, flat: 0.653729697689414, pod: 19.921136736869812, loss: 21.994718372821808 
Train [15/26] | Epoch [137/160] |	nca: 1.45487454906106, flat: 0.6207795292139053, pod: 19.279737949371338, loss: 21.355392158031464 
Train [15/26] | Epoch [138/160] |	nca: 1.5215420462191105, flat: 0.6578732747584581, pod: 19.981338918209076, loss: 22.160754203796387 
Train [15/26] | Epoch [139/160] |	nca: 1.3982019275426865, flat: 0.6072518397122622, pod: 18.833959758281708, loss: 20.8394136428833 
Train [15/26] | Epoch [140/160] |	nca: 1.3688142746686935, flat: 0.6055999230593443, pod: 18.799889147281647, loss: 20.774303376674652 
Train [15/26] | Epoch [141/160] |	nca: 1.4360847547650337, flat: 0.5809952840209007, pod: 18.321599423885345, loss: 20.338679671287537 
Train [15/26] | Epoch [142/160] |	nca: 1.3827004507184029, flat: 0.5693142022937536, pod: 18.08070069551468, loss: 20.032715320587158 
Train [15/26] | Epoch [143/160] |	nca: 1.497845035046339, flat: 0.6136507876217365, pod: 19.23278820514679, loss: 21.344283998012543 
Train [15/26] | Epoch [144/160] |	nca: 1.4097756408154964, flat: 0.5965474303811789, pod: 18.78225725889206, loss: 20.7885804772377 
Train [15/26] | Epoch [145/160] |	nca: 1.3906367979943752, flat: 0.5230225753039122, pod: 17.31570065021515, loss: 19.229360163211823 
Train [15/26] | Epoch [146/160] |	nca: 1.3694074302911758, flat: 0.5221642572432756, pod: 17.121754050254822, loss: 19.013325572013855 
Train [15/26] | Epoch [147/160] |	nca: 1.5305132530629635, flat: 0.5895075872540474, pod: 18.50831538438797, loss: 20.628335893154144 
Train [15/26] | Epoch [148/160] |	nca: 1.4060353450477123, flat: 0.5254792803898454, pod: 16.929095327854156, loss: 18.8606099486351 
Train [15/26] | Epoch [149/160] |	nca: 1.3080860041081905, flat: 0.551874091848731, pod: 17.108769059181213, loss: 18.968729078769684 
Train [15/26] | Epoch [150/160] |	nca: 1.4412223771214485, flat: 0.5386925544589758, pod: 17.582638680934906, loss: 19.562553644180298 
Train [15/26] | Epoch [151/160] |	nca: 1.3882848508656025, flat: 0.5180457774549723, pod: 16.185453414916992, loss: 18.091783940792084 
Train [15/26] | Epoch [152/160] |	nca: 1.4196759089827538, flat: 0.5734652429819107, pod: 17.34146159887314, loss: 19.3346027135849 
Train [15/26] | Epoch [153/160] |	nca: 1.456130564212799, flat: 0.5250065270811319, pod: 16.591965436935425, loss: 18.57310265302658 
Train [15/26] | Epoch [154/160] |	nca: 1.4478296302258968, flat: 0.529121145606041, pod: 16.553286850452423, loss: 18.53023785352707 
Train [15/26] | Epoch [155/160] |	nca: 1.3800334818661213, flat: 0.5362370889633894, pod: 16.851123690605164, loss: 18.767394423484802 
Train [15/26] | Epoch [156/160] |	nca: 1.3725338093936443, flat: 0.5146799590438604, pod: 16.245121359825134, loss: 18.13233518600464 
Train [15/26] | Epoch [157/160] |	nca: 1.3711573220789433, flat: 0.5077867545187473, pod: 16.191730320453644, loss: 18.070674419403076 
Train [15/26] | Epoch [158/160] |	nca: 1.361864734441042, flat: 0.4936611223965883, pod: 15.68431556224823, loss: 17.53984147310257 
Train [15/26] | Epoch [159/160] |	nca: 1.448337621986866, flat: 0.5309476852416992, pod: 16.73413860797882, loss: 18.713423907756805 
Train [15/26] | Epoch [160/160] |	nca: 1.5114247128367424, flat: 0.5200788900256157, pod: 16.85718685388565, loss: 18.88869047164917 
Fine-tuning
Building & updating memory.
Train [15/26] | Epoch [161/180] |	nca: 1.1519682668149471, flat: 0.7444237545132637, pod: 18.788243055343628, loss: 20.684634923934937 
Train [15/26] | Epoch [162/180] |	nca: 0.9304241389036179, flat: 0.7547469194978476, pod: 18.068262040615082, loss: 19.753433227539062 
Train [15/26] | Epoch [163/180] |	nca: 0.708412628620863, flat: 0.7508735954761505, pod: 18.20332407951355, loss: 19.662610411643982 
Train [15/26] | Epoch [164/180] |	nca: 0.7462527081370354, flat: 0.7681449167430401, pod: 18.243868708610535, loss: 19.75826621055603 
Train [15/26] | Epoch [165/180] |	nca: 0.8204615712165833, flat: 0.7449793331325054, pod: 18.071295142173767, loss: 19.636736392974854 
Train [15/26] | Epoch [166/180] |	nca: 0.6829830128699541, flat: 0.7173124104738235, pod: 17.614702343940735, loss: 19.014997959136963 
Train [15/26] | Epoch [167/180] |	nca: 0.6454431414604187, flat: 0.747089110314846, pod: 18.173262000083923, loss: 19.565794229507446 
Train [15/26] | Epoch [168/180] |	nca: 0.6446528770029545, flat: 0.7843377813696861, pod: 18.56267488002777, loss: 19.991665482521057 
Train [15/26] | Epoch [169/180] |	nca: 0.5914795231074095, flat: 0.7397863939404488, pod: 18.1010422706604, loss: 19.432308316230774 
Train [15/26] | Epoch [170/180] |	nca: 0.6431087628006935, flat: 0.8216118142008781, pod: 18.777639627456665, loss: 20.24236035346985 
Train [15/26] | Epoch [171/180] |	nca: 0.6491136066615582, flat: 0.7660518400371075, pod: 18.133005142211914, loss: 19.548170566558838 
Train [15/26] | Epoch [172/180] |	nca: 0.5930605940520763, flat: 0.7569712325930595, pod: 18.343809723854065, loss: 19.693841457366943 
Train [15/26] | Epoch [173/180] |	nca: 0.6200777012854815, flat: 0.7628234699368477, pod: 18.5247745513916, loss: 19.907675623893738 
Train [15/26] | Epoch [174/180] |	nca: 0.6899563707411289, flat: 0.7483120821416378, pod: 18.484184622764587, loss: 19.92245316505432 
Train [15/26] | Epoch [175/180] |	nca: 0.934826735407114, flat: 0.7606907151639462, pod: 18.517918467521667, loss: 20.213435888290405 
Train [15/26] | Epoch [176/180] |	nca: 0.6693315766751766, flat: 0.7519684843719006, pod: 18.735567688941956, loss: 20.156867623329163 
Train [15/26] | Epoch [177/180] |	nca: 0.6149415299296379, flat: 0.7363507188856602, pod: 18.472200632095337, loss: 19.823492884635925 
Train [15/26] | Epoch [178/180] |	nca: 0.5443306434899569, flat: 0.8343031480908394, pod: 18.75343257188797, loss: 20.1320663690567 
Train [15/26] | Epoch [179/180] |	nca: 0.5479800291359425, flat: 0.7516100853681564, pod: 17.858680367469788, loss: 19.158270359039307 
Train [15/26] | Epoch [180/180] |	nca: 0.5980461351573467, flat: 0.7426455356180668, pod: 18.142348170280457, loss: 19.48303997516632 
after task
Building & updating memory.
after task
Eval on 0->78.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6362.
Current acc: {'total': 0.551, '00-09': 0.592, '10-19': 0.571, '20-29': 0.481, '30-39': 0.512, '40-49': 0.561, '50-59': 0.586, '60-69': 0.475, '70-79': 0.651}.
Avg inc acc top5: 0.8759999999999999.
Current acc top5: {'total': 0.828}.
Forgetting: 0.1511111111111111.
Cord metric: 0.62.
Old accuracy: 0.55, mean: 0.63.
New accuracy: 0.65, mean: 0.66.
================Task 15 Start!================
Testing on False unseen tasks (max class = 80).
Set memory of size: 1560.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 15 Training!================
The training samples number: 2560
Train on 78->80.
train task
nb 2560.
Train [16/26] | Epoch [1/160] |	nca: 10.416450768709183, flat: 4.164015334099531, pod: 50.241108536720276, loss: 64.82157468795776 
Train [16/26] | Epoch [2/160] |	nca: 6.485067889094353, flat: 4.691838026046753, pod: 57.895952224731445, loss: 69.07285785675049 
Train [16/26] | Epoch [3/160] |	nca: 4.85144479572773, flat: 3.8265553265810013, pod: 54.49784255027771, loss: 63.17584228515625 
Train [16/26] | Epoch [4/160] |	nca: 4.497562736272812, flat: 3.529147431254387, pod: 51.94953894615173, loss: 59.97624921798706 
Train [16/26] | Epoch [5/160] |	nca: 3.4996588304638863, flat: 3.0984329730272293, pod: 50.19722557067871, loss: 56.79531717300415 
Train [16/26] | Epoch [6/160] |	nca: 3.353067308664322, flat: 2.7387586683034897, pod: 47.00095725059509, loss: 53.092782974243164 
Train [16/26] | Epoch [7/160] |	nca: 3.0503072515130043, flat: 2.7093478813767433, pod: 48.00672221183777, loss: 53.766377210617065 
Train [16/26] | Epoch [8/160] |	nca: 3.1505980119109154, flat: 2.6291821524500847, pod: 47.399866342544556, loss: 53.179646253585815 
Train [16/26] | Epoch [9/160] |	nca: 2.6937748715281487, flat: 2.2967444732785225, pod: 44.35691690444946, loss: 49.34743595123291 
Train [16/26] | Epoch [10/160] |	nca: 2.873848184943199, flat: 2.4045152440667152, pod: 44.63373017311096, loss: 49.91209316253662 
Train [16/26] | Epoch [11/160] |	nca: 3.220810130238533, flat: 2.5906955525279045, pod: 45.03345203399658, loss: 50.844958543777466 
Train [16/26] | Epoch [12/160] |	nca: 2.277812197804451, flat: 2.2463585436344147, pod: 42.625652551651, loss: 47.14982318878174 
Train [16/26] | Epoch [13/160] |	nca: 2.567987859249115, flat: 2.138387754559517, pod: 42.07578110694885, loss: 46.782155990600586 
Train [16/26] | Epoch [14/160] |	nca: 2.4388239458203316, flat: 2.116133965551853, pod: 42.418811559677124, loss: 46.973769426345825 
Train [16/26] | Epoch [15/160] |	nca: 2.588114008307457, flat: 2.223103106021881, pod: 43.14592528343201, loss: 47.95714235305786 
Train [16/26] | Epoch [16/160] |	nca: 2.5878212824463844, flat: 2.1448695808649063, pod: 41.94805884361267, loss: 46.68074917793274 
Train [16/26] | Epoch [17/160] |	nca: 2.6777996346354485, flat: 2.348602816462517, pod: 43.336493492126465, loss: 48.36289596557617 
Train [16/26] | Epoch [18/160] |	nca: 2.484633170068264, flat: 2.231500692665577, pod: 42.967817068099976, loss: 47.683950662612915 
Train [16/26] | Epoch [19/160] |	nca: 2.639905847609043, flat: 2.33776044100523, pod: 44.608625650405884, loss: 49.586292028427124 
Train [16/26] | Epoch [20/160] |	nca: 2.22359286993742, flat: 2.133577585220337, pod: 42.635284543037415, loss: 46.99245500564575 
Train [16/26] | Epoch [21/160] |	nca: 2.2179794162511826, flat: 2.172466889023781, pod: 43.637860894203186, loss: 48.02830767631531 
Train [16/26] | Epoch [22/160] |	nca: 2.3782286420464516, flat: 2.1842973232269287, pod: 43.09093689918518, loss: 47.65346312522888 
Train [16/26] | Epoch [23/160] |	nca: 2.2727005779743195, flat: 2.0750367268919945, pod: 41.720465779304504, loss: 46.06820344924927 
Train [16/26] | Epoch [24/160] |	nca: 2.225957401096821, flat: 1.948554389178753, pod: 40.428690671920776, loss: 44.60320234298706 
Train [16/26] | Epoch [25/160] |	nca: 2.4216760098934174, flat: 1.9808426946401596, pod: 40.434218883514404, loss: 44.836737632751465 
Train [16/26] | Epoch [26/160] |	nca: 2.6217184141278267, flat: 2.063417501747608, pod: 41.184369802474976, loss: 45.869505882263184 
Train [16/26] | Epoch [27/160] |	nca: 2.0921006202697754, flat: 1.9959417805075645, pod: 42.19868993759155, loss: 46.2867329120636 
Train [16/26] | Epoch [28/160] |	nca: 2.215660944581032, flat: 2.0036175698041916, pod: 41.202149510383606, loss: 45.421427965164185 
Train [16/26] | Epoch [29/160] |	nca: 2.3199880123138428, flat: 1.9200164526700974, pod: 40.36571192741394, loss: 44.605716705322266 
Train [16/26] | Epoch [30/160] |	nca: 2.4757534861564636, flat: 2.031310983002186, pod: 40.755396485328674, loss: 45.26246130466461 
Train [16/26] | Epoch [31/160] |	nca: 2.243123099207878, flat: 2.0410231724381447, pod: 41.0045268535614, loss: 45.28867316246033 
Train [16/26] | Epoch [32/160] |	nca: 2.5839223489165306, flat: 2.095424622297287, pod: 42.04665815830231, loss: 46.72600555419922 
Train [16/26] | Epoch [33/160] |	nca: 2.282636396586895, flat: 2.1018693447113037, pod: 41.66114687919617, loss: 46.045653104782104 
Train [16/26] | Epoch [34/160] |	nca: 2.1000841930508614, flat: 2.0497166365385056, pod: 42.819223046302795, loss: 46.96902394294739 
Train [16/26] | Epoch [35/160] |	nca: 2.4519530534744263, flat: 2.1562928706407547, pod: 41.494251132011414, loss: 46.10249733924866 
Train [16/26] | Epoch [36/160] |	nca: 2.1020456925034523, flat: 1.9609068110585213, pod: 39.793341398239136, loss: 43.85629439353943 
Train [16/26] | Epoch [37/160] |	nca: 2.0388471484184265, flat: 1.9104986786842346, pod: 39.02322030067444, loss: 42.97256636619568 
Train [16/26] | Epoch [38/160] |	nca: 2.3844045624136925, flat: 1.9846529513597488, pod: 40.50751233100891, loss: 44.876569509506226 
Train [16/26] | Epoch [39/160] |	nca: 2.432546764612198, flat: 2.203637473285198, pod: 43.31738471984863, loss: 47.95356893539429 
Train [16/26] | Epoch [40/160] |	nca: 2.1225806698203087, flat: 2.086906358599663, pod: 42.38915526866913, loss: 46.598642349243164 
Train [16/26] | Epoch [41/160] |	nca: 2.1537837386131287, flat: 1.913442738354206, pod: 40.157965898513794, loss: 44.22519266605377 
Train [16/26] | Epoch [42/160] |	nca: 2.15553081035614, flat: 1.9095934554934502, pod: 40.51637637615204, loss: 44.5815007686615 
Train [16/26] | Epoch [43/160] |	nca: 1.8837845921516418, flat: 1.702550545334816, pod: 37.727973222732544, loss: 41.314308524131775 
Train [16/26] | Epoch [44/160] |	nca: 1.8751393184065819, flat: 1.697451300919056, pod: 38.19698083400726, loss: 41.76957178115845 
Train [16/26] | Epoch [45/160] |	nca: 2.136383481323719, flat: 1.810605451464653, pod: 40.28852093219757, loss: 44.2355101108551 
Train [16/26] | Epoch [46/160] |	nca: 2.295066609978676, flat: 1.820762611925602, pod: 39.61715757846832, loss: 43.73298645019531 
Train [16/26] | Epoch [47/160] |	nca: 2.1794036999344826, flat: 1.9010019749403, pod: 39.50344967842102, loss: 43.583855509757996 
Train [16/26] | Epoch [48/160] |	nca: 2.1385684236884117, flat: 1.7894137874245644, pod: 38.620230197906494, loss: 42.54821264743805 
Train [16/26] | Epoch [49/160] |	nca: 2.1432138979434967, flat: 1.8148300126194954, pod: 39.231472969055176, loss: 43.1895170211792 
Train [16/26] | Epoch [50/160] |	nca: 1.875865176320076, flat: 1.6650875210762024, pod: 38.43656027317047, loss: 41.97751319408417 
Train [16/26] | Epoch [51/160] |	nca: 1.9325293265283108, flat: 1.6853282451629639, pod: 38.04068326950073, loss: 41.65854036808014 
Train [16/26] | Epoch [52/160] |	nca: 2.0510978922247887, flat: 1.7423674166202545, pod: 37.341408371925354, loss: 41.13487362861633 
Train [16/26] | Epoch [53/160] |	nca: 2.074332572519779, flat: 1.6620125025510788, pod: 37.01048946380615, loss: 40.74683451652527 
Train [16/26] | Epoch [54/160] |	nca: 1.9800766333937645, flat: 1.6647882461547852, pod: 37.26012623310089, loss: 40.904991030693054 
Train [16/26] | Epoch [55/160] |	nca: 1.865341104567051, flat: 1.5955900102853775, pod: 37.37100279331207, loss: 40.83193385601044 
Train [16/26] | Epoch [56/160] |	nca: 2.0750878304243088, flat: 1.7067274302244186, pod: 37.1105260848999, loss: 40.89234149456024 
Train [16/26] | Epoch [57/160] |	nca: 1.9871479645371437, flat: 1.6099795550107956, pod: 36.583179354667664, loss: 40.180307269096375 
Train [16/26] | Epoch [58/160] |	nca: 1.9907944723963737, flat: 1.607318326830864, pod: 36.273306488990784, loss: 39.87141954898834 
Train [16/26] | Epoch [59/160] |	nca: 1.883942000567913, flat: 1.6924858689308167, pod: 38.42245435714722, loss: 41.99888241291046 
Train [16/26] | Epoch [60/160] |	nca: 1.9508396983146667, flat: 1.6545358002185822, pod: 36.05364668369293, loss: 39.659021735191345 
Train [16/26] | Epoch [61/160] |	nca: 1.8957499228417873, flat: 1.6713695004582405, pod: 36.48414695262909, loss: 40.05126655101776 
Train [16/26] | Epoch [62/160] |	nca: 2.0244795382022858, flat: 1.6142809242010117, pod: 36.269646525382996, loss: 39.90840709209442 
Train [16/26] | Epoch [63/160] |	nca: 1.9630330242216587, flat: 1.5502196699380875, pod: 36.30204713344574, loss: 39.81529974937439 
Train [16/26] | Epoch [64/160] |	nca: 1.86947301030159, flat: 1.507814183831215, pod: 35.687573194503784, loss: 39.064860224723816 
Train [16/26] | Epoch [65/160] |	nca: 1.7926406487822533, flat: 1.5184365287423134, pod: 36.54529786109924, loss: 39.856375098228455 
Train [16/26] | Epoch [66/160] |	nca: 1.8455601334571838, flat: 1.4929218851029873, pod: 35.52558672428131, loss: 38.86406874656677 
Train [16/26] | Epoch [67/160] |	nca: 1.7228125184774399, flat: 1.4606221467256546, pod: 35.315664768218994, loss: 38.499099373817444 
Train [16/26] | Epoch [68/160] |	nca: 2.128012463450432, flat: 1.3918749950826168, pod: 33.58825969696045, loss: 37.108147382736206 
Train [16/26] | Epoch [69/160] |	nca: 2.0095022097229958, flat: 1.5982263535261154, pod: 35.07664954662323, loss: 38.684378266334534 
Train [16/26] | Epoch [70/160] |	nca: 1.8459921814501286, flat: 1.4018866755068302, pod: 33.30169343948364, loss: 36.549572467803955 
Train [16/26] | Epoch [71/160] |	nca: 1.9973821565508842, flat: 1.5119679644703865, pod: 36.25377416610718, loss: 39.763124227523804 
Train [16/26] | Epoch [72/160] |	nca: 1.9104290828108788, flat: 1.417161226272583, pod: 33.85553002357483, loss: 37.183120369911194 
Train [16/26] | Epoch [73/160] |	nca: 1.82134810090065, flat: 1.4071325547993183, pod: 32.915509939193726, loss: 36.1439905166626 
Train [16/26] | Epoch [74/160] |	nca: 1.7063549980521202, flat: 1.345782395452261, pod: 32.76573693752289, loss: 35.81787419319153 
Train [16/26] | Epoch [75/160] |	nca: 1.6803673431277275, flat: 1.3928405418992043, pod: 34.42483901977539, loss: 37.498046875 
Train [16/26] | Epoch [76/160] |	nca: 1.7982064671814442, flat: 1.4811865612864494, pod: 35.882410287857056, loss: 39.16180336475372 
Train [16/26] | Epoch [77/160] |	nca: 1.873045764863491, flat: 1.3444298096001148, pod: 33.11384701728821, loss: 36.3313227891922 
Train [16/26] | Epoch [78/160] |	nca: 1.7599295414984226, flat: 1.3352094031870365, pod: 32.60104429721832, loss: 35.69618308544159 
Train [16/26] | Epoch [79/160] |	nca: 1.9603001922369003, flat: 1.3470232151448727, pod: 31.745304226875305, loss: 35.05262768268585 
Train [16/26] | Epoch [80/160] |	nca: 1.853133775293827, flat: 1.4071381464600563, pod: 34.292937994003296, loss: 37.55320978164673 
Train [16/26] | Epoch [81/160] |	nca: 1.8589362427592278, flat: 1.4420848041772842, pod: 34.36330997943878, loss: 37.66433107852936 
Train [16/26] | Epoch [82/160] |	nca: 1.8383682817220688, flat: 1.3995811566710472, pod: 34.85070204734802, loss: 38.08865141868591 
Train [16/26] | Epoch [83/160] |	nca: 1.7072347924113274, flat: 1.3329259902238846, pod: 33.077646255493164, loss: 36.117807030677795 
Train [16/26] | Epoch [84/160] |	nca: 1.8428632989525795, flat: 1.319988515228033, pod: 33.24134612083435, loss: 36.404197692871094 
Train [16/26] | Epoch [85/160] |	nca: 1.7638029307127, flat: 1.2084708139300346, pod: 30.47035789489746, loss: 33.44263172149658 
Train [16/26] | Epoch [86/160] |	nca: 1.755212925374508, flat: 1.2814274281263351, pod: 31.21908450126648, loss: 34.25572466850281 
Train [16/26] | Epoch [87/160] |	nca: 1.7676084339618683, flat: 1.2616870403289795, pod: 30.924771308898926, loss: 33.95406675338745 
Train [16/26] | Epoch [88/160] |	nca: 1.7480461187660694, flat: 1.2631149254739285, pod: 31.684550046920776, loss: 34.69571053981781 
Train [16/26] | Epoch [89/160] |	nca: 1.8499208465218544, flat: 1.255214899778366, pod: 30.69254422187805, loss: 33.797680258750916 
Train [16/26] | Epoch [90/160] |	nca: 1.7382947839796543, flat: 1.1435794718563557, pod: 29.967713236808777, loss: 32.84958744049072 
Train [16/26] | Epoch [91/160] |	nca: 1.617390975356102, flat: 1.2774145528674126, pod: 31.595391631126404, loss: 34.49019718170166 
Train [16/26] | Epoch [92/160] |	nca: 1.669484943151474, flat: 1.1308601722121239, pod: 29.580846428871155, loss: 32.38119173049927 
Train [16/26] | Epoch [93/160] |	nca: 1.7718311920762062, flat: 1.1086697839200497, pod: 28.8526713848114, loss: 31.733172178268433 
Train [16/26] | Epoch [94/160] |	nca: 1.6142984628677368, flat: 1.1586104221642017, pod: 29.944485783576965, loss: 32.7173947095871 
Train [16/26] | Epoch [95/160] |	nca: 1.6774022355675697, flat: 1.174337912350893, pod: 30.64927113056183, loss: 33.50101149082184 
Train [16/26] | Epoch [96/160] |	nca: 1.7033146023750305, flat: 1.0416108556091785, pod: 28.28004491329193, loss: 31.024970412254333 
Train [16/26] | Epoch [97/160] |	nca: 1.6570113562047482, flat: 1.0008551105856895, pod: 27.9534991979599, loss: 30.611365795135498 
Train [16/26] | Epoch [98/160] |	nca: 1.5725006833672523, flat: 1.0458263717591763, pod: 28.339152216911316, loss: 30.95747947692871 
Train [16/26] | Epoch [99/160] |	nca: 1.5952751636505127, flat: 1.1327049061655998, pod: 30.19958221912384, loss: 32.92756223678589 
Train [16/26] | Epoch [100/160] |	nca: 1.5224984399974346, flat: 1.0593064911663532, pod: 28.733140230178833, loss: 31.314944982528687 
Train [16/26] | Epoch [101/160] |	nca: 1.575581718236208, flat: 1.1045027077198029, pod: 29.89827334880829, loss: 32.57835793495178 
Train [16/26] | Epoch [102/160] |	nca: 1.6637701764702797, flat: 0.9573304727673531, pod: 27.828753352165222, loss: 30.449853897094727 
Train [16/26] | Epoch [103/160] |	nca: 1.7692305780947208, flat: 1.0478573739528656, pod: 27.8123140335083, loss: 30.629401922225952 
Train [16/26] | Epoch [104/160] |	nca: 1.6680936850607395, flat: 1.0795388333499432, pod: 28.093787670135498, loss: 30.84142017364502 
Train [16/26] | Epoch [105/160] |	nca: 1.4196433909237385, flat: 0.9503047466278076, pod: 26.833619236946106, loss: 29.203567504882812 
Train [16/26] | Epoch [106/160] |	nca: 1.6185693591833115, flat: 0.9736464992165565, pod: 27.581751942634583, loss: 30.173967838287354 
Train [16/26] | Epoch [107/160] |	nca: 1.5883582197129726, flat: 0.9808168262243271, pod: 27.962520837783813, loss: 30.53169584274292 
Train [16/26] | Epoch [108/160] |	nca: 1.5548555999994278, flat: 0.8994990065693855, pod: 25.88469362258911, loss: 28.339048385620117 
Train [16/26] | Epoch [109/160] |	nca: 1.6637900918722153, flat: 0.8687772676348686, pod: 25.904447436332703, loss: 28.43701469898224 
Train [16/26] | Epoch [110/160] |	nca: 1.6585494317114353, flat: 0.9032447598874569, pod: 26.399365067481995, loss: 28.961159348487854 
Train [16/26] | Epoch [111/160] |	nca: 1.7259121015667915, flat: 0.9118645861744881, pod: 26.31223499774933, loss: 28.95001184940338 
Train [16/26] | Epoch [112/160] |	nca: 1.7367477342486382, flat: 0.9208255968987942, pod: 25.70796239376068, loss: 28.365535736083984 
Train [16/26] | Epoch [113/160] |	nca: 1.5709449350833893, flat: 0.8573909662663937, pod: 24.936971187591553, loss: 27.365307092666626 
Train [16/26] | Epoch [114/160] |	nca: 1.6020947508513927, flat: 0.8933072537183762, pod: 26.164064407348633, loss: 28.65946626663208 
Train [16/26] | Epoch [115/160] |	nca: 1.6144653782248497, flat: 0.8185035139322281, pod: 24.96342396736145, loss: 27.396392822265625 
Train [16/26] | Epoch [116/160] |	nca: 1.5833343863487244, flat: 0.8788642808794975, pod: 25.81385886669159, loss: 28.276057481765747 
Train [16/26] | Epoch [117/160] |	nca: 1.6834839507937431, flat: 0.9000706858932972, pod: 25.770933210849762, loss: 28.354487776756287 
Train [16/26] | Epoch [118/160] |	nca: 1.641351729631424, flat: 0.8192028254270554, pod: 23.743805170059204, loss: 26.204359531402588 
Train [16/26] | Epoch [119/160] |	nca: 1.5750239454209805, flat: 0.8133476302027702, pod: 23.87116903066635, loss: 26.25954043865204 
Train [16/26] | Epoch [120/160] |	nca: 1.579908326268196, flat: 0.8090297617018223, pod: 23.490845680236816, loss: 25.879783630371094 
Train [16/26] | Epoch [121/160] |	nca: 1.6413290277123451, flat: 0.7884838618338108, pod: 23.09100741147995, loss: 25.520820260047913 
Train [16/26] | Epoch [122/160] |	nca: 1.6252900511026382, flat: 0.7645059805363417, pod: 23.359058499336243, loss: 25.748854398727417 
Train [16/26] | Epoch [123/160] |	nca: 1.5534729212522507, flat: 0.80460693128407, pod: 23.592946708202362, loss: 25.951026916503906 
Train [16/26] | Epoch [124/160] |	nca: 1.5990130826830864, flat: 0.6991010997444391, pod: 21.714683651924133, loss: 24.012797713279724 
Train [16/26] | Epoch [125/160] |	nca: 1.5590897649526596, flat: 0.7431978099048138, pod: 22.232703685760498, loss: 24.534991025924683 
Train [16/26] | Epoch [126/160] |	nca: 1.4762752577662468, flat: 0.7496675048023462, pod: 22.24124586582184, loss: 24.467188715934753 
Train [16/26] | Epoch [127/160] |	nca: 1.557933870702982, flat: 0.706278732046485, pod: 22.214622795581818, loss: 24.478835344314575 
Train [16/26] | Epoch [128/160] |	nca: 1.6059029214084148, flat: 0.6760029140859842, pod: 21.639063119888306, loss: 23.920969128608704 
Train [16/26] | Epoch [129/160] |	nca: 1.5669909082353115, flat: 0.7080578748136759, pod: 21.752753973007202, loss: 24.027802765369415 
Train [16/26] | Epoch [130/160] |	nca: 1.6895382478833199, flat: 0.6974232476204634, pod: 21.858939945697784, loss: 24.245901226997375 
Train [16/26] | Epoch [131/160] |	nca: 1.480854369699955, flat: 0.657380435615778, pod: 21.202881932258606, loss: 23.341116547584534 
Train [16/26] | Epoch [132/160] |	nca: 1.6262751184403896, flat: 0.7167082112282515, pod: 20.8443683385849, loss: 23.187351644039154 
Train [16/26] | Epoch [133/160] |	nca: 1.572056483477354, flat: 0.6745202895253897, pod: 20.85817915201187, loss: 23.10475605726242 
Train [16/26] | Epoch [134/160] |	nca: 1.5759376101195812, flat: 0.6557216607034206, pod: 20.904338359832764, loss: 23.135997593402863 
Train [16/26] | Epoch [135/160] |	nca: 1.545168649405241, flat: 0.6717331632971764, pod: 21.512676298618317, loss: 23.72957807779312 
Train [16/26] | Epoch [136/160] |	nca: 1.5375712662935257, flat: 0.6078088618814945, pod: 19.678549468517303, loss: 21.82392954826355 
Train [16/26] | Epoch [137/160] |	nca: 1.5439657717943192, flat: 0.6306041572242975, pod: 19.75845032930374, loss: 21.933020532131195 
Train [16/26] | Epoch [138/160] |	nca: 1.4924884885549545, flat: 0.631441131234169, pod: 19.860310554504395, loss: 21.984240174293518 
Train [16/26] | Epoch [139/160] |	nca: 1.5166881866753101, flat: 0.6369338911026716, pod: 20.165823101997375, loss: 22.31944501399994 
Train [16/26] | Epoch [140/160] |	nca: 1.5702628307044506, flat: 0.5822479948401451, pod: 19.007652401924133, loss: 21.16016298532486 
Train [16/26] | Epoch [141/160] |	nca: 1.405137788504362, flat: 0.614505160599947, pod: 19.94173675775528, loss: 21.961379885673523 
Train [16/26] | Epoch [142/160] |	nca: 1.5494338274002075, flat: 0.5931845940649509, pod: 18.797896146774292, loss: 20.940514862537384 
Train [16/26] | Epoch [143/160] |	nca: 1.5434870198369026, flat: 0.6023331247270107, pod: 18.882780492305756, loss: 21.028600811958313 
Train [16/26] | Epoch [144/160] |	nca: 1.5196314938366413, flat: 0.5953171495348215, pod: 19.511463940143585, loss: 21.626412510871887 
Train [16/26] | Epoch [145/160] |	nca: 1.5967666991055012, flat: 0.6472307369112968, pod: 19.637365877628326, loss: 21.881363093852997 
Train [16/26] | Epoch [146/160] |	nca: 1.4712465293705463, flat: 0.5751710757613182, pod: 18.44758814573288, loss: 20.494005858898163 
Train [16/26] | Epoch [147/160] |	nca: 1.432550985366106, flat: 0.5646168272942305, pod: 18.042461574077606, loss: 20.039629220962524 
Train [16/26] | Epoch [148/160] |	nca: 1.5918274074792862, flat: 0.5536857433617115, pod: 17.47551816701889, loss: 19.62103134393692 
Train [16/26] | Epoch [149/160] |	nca: 1.5233234763145447, flat: 0.5708484053611755, pod: 17.899351358413696, loss: 19.993523478507996 
Train [16/26] | Epoch [150/160] |	nca: 1.5432403907179832, flat: 0.5672818403691053, pod: 17.356313586235046, loss: 19.46683567762375 
Train [16/26] | Epoch [151/160] |	nca: 1.5606916807591915, flat: 0.5541727319359779, pod: 17.206271409988403, loss: 19.321135938167572 
Train [16/26] | Epoch [152/160] |	nca: 1.5666621625423431, flat: 0.5816400852054358, pod: 18.34066331386566, loss: 20.48896551132202 
Train [16/26] | Epoch [153/160] |	nca: 1.4923633225262165, flat: 0.5597068108618259, pod: 17.461988866329193, loss: 19.514058828353882 
Train [16/26] | Epoch [154/160] |	nca: 1.508340448141098, flat: 0.5272994469851255, pod: 17.12542015314102, loss: 19.16106015443802 
Train [16/26] | Epoch [155/160] |	nca: 1.558950699865818, flat: 0.5426821857690811, pod: 17.102016627788544, loss: 19.203649520874023 
Train [16/26] | Epoch [156/160] |	nca: 1.6441714614629745, flat: 0.5186693407595158, pod: 17.25797748565674, loss: 19.420818328857422 
Train [16/26] | Epoch [157/160] |	nca: 1.5815506391227245, flat: 0.5080539342015982, pod: 16.318852841854095, loss: 18.408457398414612 
Train [16/26] | Epoch [158/160] |	nca: 1.5162109918892384, flat: 0.5633179191499949, pod: 17.433278918266296, loss: 19.512807846069336 
Train [16/26] | Epoch [159/160] |	nca: 1.5413553528487682, flat: 0.5455307178199291, pod: 17.31765776872635, loss: 19.40454375743866 
Train [16/26] | Epoch [160/160] |	nca: 1.534029882401228, flat: 0.5066585373133421, pod: 17.002153277397156, loss: 19.04284167289734 
Fine-tuning
Building & updating memory.
Train [16/26] | Epoch [161/180] |	nca: 1.0303723812103271, flat: 0.6281026788055897, pod: 15.583381354808807, loss: 17.241856455802917 
Train [16/26] | Epoch [162/180] |	nca: 0.729796189814806, flat: 0.642309695482254, pod: 15.911598861217499, loss: 17.28370463848114 
Train [16/26] | Epoch [163/180] |	nca: 0.5751850754022598, flat: 0.6184020191431046, pod: 15.444959044456482, loss: 16.638545989990234 
Train [16/26] | Epoch [164/180] |	nca: 0.5714085325598717, flat: 0.6573797073215246, pod: 15.819208979606628, loss: 17.047997295856476 
Train [16/26] | Epoch [165/180] |	nca: 0.5537278093397617, flat: 0.6473823003470898, pod: 15.948211312294006, loss: 17.14932143688202 
Train [16/26] | Epoch [166/180] |	nca: 0.5602238662540913, flat: 0.7035294286906719, pod: 16.570744276046753, loss: 17.834497690200806 
Train [16/26] | Epoch [167/180] |	nca: 0.5429920665919781, flat: 0.6651114858686924, pod: 16.190353572368622, loss: 17.398457288742065 
Train [16/26] | Epoch [168/180] |	nca: 0.5789023749530315, flat: 0.6792701035737991, pod: 15.970868229866028, loss: 17.22904074192047 
Train [16/26] | Epoch [169/180] |	nca: 0.5126345679163933, flat: 0.6203052923083305, pod: 15.483097672462463, loss: 16.616037487983704 
Train [16/26] | Epoch [170/180] |	nca: 0.5099645312875509, flat: 0.6602198649197817, pod: 15.643652200698853, loss: 16.813836693763733 
Train [16/26] | Epoch [171/180] |	nca: 0.4968155212700367, flat: 0.6210560761392117, pod: 15.26116806268692, loss: 16.379039764404297 
Train [16/26] | Epoch [172/180] |	nca: 0.5459502097219229, flat: 0.6656921170651913, pod: 15.897579789161682, loss: 17.109222173690796 
Train [16/26] | Epoch [173/180] |	nca: 0.5297538340091705, flat: 0.7176445312798023, pod: 16.30331242084503, loss: 17.550710678100586 
Train [16/26] | Epoch [174/180] |	nca: 0.5015015620738268, flat: 0.626303568482399, pod: 15.622628629207611, loss: 16.75043362379074 
Train [16/26] | Epoch [175/180] |	nca: 0.4836094956845045, flat: 0.6744325086474419, pod: 16.39237803220749, loss: 17.55042016506195 
Train [16/26] | Epoch [176/180] |	nca: 0.5120197311043739, flat: 0.6423190571367741, pod: 15.63447916507721, loss: 16.78881800174713 
Train [16/26] | Epoch [177/180] |	nca: 0.5176864173263311, flat: 0.625548405572772, pod: 15.696138560771942, loss: 16.839373409748077 
Train [16/26] | Epoch [178/180] |	nca: 0.49689152650535107, flat: 0.652938075363636, pod: 15.907582759857178, loss: 17.057412266731262 
Train [16/26] | Epoch [179/180] |	nca: 0.47718845307826996, flat: 0.6416721828281879, pod: 15.888542175292969, loss: 17.007402658462524 
Train [16/26] | Epoch [180/180] |	nca: 0.49664968997240067, flat: 0.6692926343530416, pod: 15.846986055374146, loss: 17.012928247451782 
after task
Building & updating memory.
after task
Eval on 0->80.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6304375.
Current acc: {'total': 0.544, '00-09': 0.593, '10-19': 0.562, '20-29': 0.476, '30-39': 0.51, '40-49': 0.556, '50-59': 0.575, '60-69': 0.46, '70-79': 0.617}.
Avg inc acc top5: 0.8723749999999999.
Current acc top5: {'total': 0.818}.
Forgetting: 0.16.
Cord metric: 0.62.
Old accuracy: 0.54, mean: 0.62.
New accuracy: 0.53, mean: 0.65.
================Task 16 Start!================
Testing on False unseen tasks (max class = 82).
Set memory of size: 1600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 16 Training!================
The training samples number: 2600
Train on 80->82.
train task
nb 2600.
Train [17/26] | Epoch [1/160] |	nca: 10.638460248708725, flat: 4.601960580796003, pod: 55.82664704322815, loss: 71.06706833839417 
Train [17/26] | Epoch [2/160] |	nca: 7.76908141374588, flat: 5.622149258852005, pod: 64.11461353302002, loss: 77.50584435462952 
Train [17/26] | Epoch [3/160] |	nca: 6.275977283716202, flat: 5.31412348151207, pod: 63.97350549697876, loss: 75.56360650062561 
Train [17/26] | Epoch [4/160] |	nca: 5.216061517596245, flat: 4.463852182030678, pod: 58.116750717163086, loss: 67.79666447639465 
Train [17/26] | Epoch [5/160] |	nca: 4.131309881806374, flat: 3.5282434672117233, pod: 54.23128318786621, loss: 61.890836000442505 
Train [17/26] | Epoch [6/160] |	nca: 3.6545906215906143, flat: 3.7219787538051605, pod: 57.330806016922, loss: 64.70737504959106 
Train [17/26] | Epoch [7/160] |	nca: 3.172138601541519, flat: 3.1217159032821655, pod: 52.889798402786255, loss: 59.183653116226196 
Train [17/26] | Epoch [8/160] |	nca: 2.991900183260441, flat: 2.967197969555855, pod: 53.06661248207092, loss: 59.025710582733154 
Train [17/26] | Epoch [9/160] |	nca: 3.284563362598419, flat: 2.8855092748999596, pod: 51.39755702018738, loss: 57.56763029098511 
Train [17/26] | Epoch [10/160] |	nca: 3.079452097415924, flat: 2.834682710468769, pod: 50.370826959609985, loss: 56.284961462020874 
Train [17/26] | Epoch [11/160] |	nca: 2.8665300086140633, flat: 2.710140973329544, pod: 49.4709415435791, loss: 55.04761290550232 
Train [17/26] | Epoch [12/160] |	nca: 3.457803264260292, flat: 3.079236701130867, pod: 50.677101850509644, loss: 57.214141607284546 
Train [17/26] | Epoch [13/160] |	nca: 2.8589673712849617, flat: 2.8537535071372986, pod: 51.266664028167725, loss: 56.979384660720825 
Train [17/26] | Epoch [14/160] |	nca: 3.0176412537693977, flat: 2.7630881294608116, pod: 48.826327085494995, loss: 54.60705637931824 
Train [17/26] | Epoch [15/160] |	nca: 2.913755863904953, flat: 3.0448505505919456, pod: 51.54716181755066, loss: 57.50576853752136 
Train [17/26] | Epoch [16/160] |	nca: 2.7835718616843224, flat: 2.589601717889309, pod: 48.432190895080566, loss: 53.80536413192749 
Train [17/26] | Epoch [17/160] |	nca: 2.5135646238923073, flat: 2.5092369467020035, pod: 46.55361485481262, loss: 51.57641673088074 
Train [17/26] | Epoch [18/160] |	nca: 2.442119635641575, flat: 2.493954747915268, pod: 47.18591809272766, loss: 52.12199258804321 
Train [17/26] | Epoch [19/160] |	nca: 2.6666549742221832, flat: 2.5269301161170006, pod: 45.63032507896423, loss: 50.82391023635864 
Train [17/26] | Epoch [20/160] |	nca: 2.757843181490898, flat: 2.5350015610456467, pod: 47.555803298950195, loss: 52.84864830970764 
Train [17/26] | Epoch [21/160] |	nca: 3.1050813123583794, flat: 2.7699693515896797, pod: 48.135910749435425, loss: 54.010961294174194 
Train [17/26] | Epoch [22/160] |	nca: 2.658708155155182, flat: 2.8978894874453545, pod: 49.81752681732178, loss: 55.37412428855896 
Train [17/26] | Epoch [23/160] |	nca: 2.514854535460472, flat: 2.4872239977121353, pod: 46.66290807723999, loss: 51.66498613357544 
Train [17/26] | Epoch [24/160] |	nca: 2.3599684089422226, flat: 2.2895958870649338, pod: 45.11744940280914, loss: 49.76701331138611 
Train [17/26] | Epoch [25/160] |	nca: 2.4593639075756073, flat: 2.270418755710125, pod: 44.5429767370224, loss: 49.272759675979614 
Train [17/26] | Epoch [26/160] |	nca: 2.6011989638209343, flat: 2.4554534256458282, pod: 47.751219272613525, loss: 52.80787181854248 
Train [17/26] | Epoch [27/160] |	nca: 2.48715478181839, flat: 2.5972304344177246, pod: 47.54399228096008, loss: 52.62837791442871 
Train [17/26] | Epoch [28/160] |	nca: 2.1926572993397713, flat: 2.351755805313587, pod: 45.87445616722107, loss: 50.418869495391846 
Train [17/26] | Epoch [29/160] |	nca: 2.4228268936276436, flat: 2.199402891099453, pod: 43.43975377082825, loss: 48.06198310852051 
Train [17/26] | Epoch [30/160] |	nca: 2.566900685429573, flat: 2.3719343543052673, pod: 44.91980791091919, loss: 49.85864233970642 
Train [17/26] | Epoch [31/160] |	nca: 2.3963920176029205, flat: 2.2456896603107452, pod: 44.846272706985474, loss: 49.488354206085205 
Train [17/26] | Epoch [32/160] |	nca: 2.6607689633965492, flat: 2.444577284157276, pod: 46.32066023349762, loss: 51.42600703239441 
Train [17/26] | Epoch [33/160] |	nca: 2.635828971862793, flat: 2.533429153263569, pod: 46.68041920661926, loss: 51.84967756271362 
Train [17/26] | Epoch [34/160] |	nca: 2.475256510078907, flat: 2.5523204132914543, pod: 47.699312806129456, loss: 52.72688961029053 
Train [17/26] | Epoch [35/160] |	nca: 2.3495058119297028, flat: 2.2070448994636536, pod: 43.424888372421265, loss: 47.981438636779785 
Train [17/26] | Epoch [36/160] |	nca: 2.182700414210558, flat: 2.226274147629738, pod: 45.190394043922424, loss: 49.59936809539795 
Train [17/26] | Epoch [37/160] |	nca: 2.2465909719467163, flat: 2.28812163323164, pod: 44.45512521266937, loss: 48.98983836174011 
Train [17/26] | Epoch [38/160] |	nca: 2.4425380900502205, flat: 2.348297879099846, pod: 45.39377951622009, loss: 50.18461537361145 
Train [17/26] | Epoch [39/160] |	nca: 2.2306682094931602, flat: 2.1553324162960052, pod: 43.49289345741272, loss: 47.87889289855957 
Train [17/26] | Epoch [40/160] |	nca: 2.22487236186862, flat: 2.198024094104767, pod: 43.2887396812439, loss: 47.71163582801819 
Train [17/26] | Epoch [41/160] |	nca: 2.3578248023986816, flat: 2.202109880745411, pod: 44.51868939399719, loss: 49.07862424850464 
Train [17/26] | Epoch [42/160] |	nca: 2.215090189129114, flat: 2.1408757120370865, pod: 43.353615283966064, loss: 47.70958089828491 
Train [17/26] | Epoch [43/160] |	nca: 2.4599564746022224, flat: 2.2338090538978577, pod: 44.525759100914, loss: 49.2195246219635 
Train [17/26] | Epoch [44/160] |	nca: 2.381182737648487, flat: 2.287861183285713, pod: 43.89121615886688, loss: 48.56026029586792 
Train [17/26] | Epoch [45/160] |	nca: 2.1968494430184364, flat: 1.9799012392759323, pod: 40.074960827827454, loss: 44.25171136856079 
Train [17/26] | Epoch [46/160] |	nca: 2.1110687404870987, flat: 1.9056889340281487, pod: 40.08236122131348, loss: 44.09911859035492 
Train [17/26] | Epoch [47/160] |	nca: 2.105488955974579, flat: 2.0014359280467033, pod: 41.77559280395508, loss: 45.88251781463623 
Train [17/26] | Epoch [48/160] |	nca: 2.0837090089917183, flat: 2.0278518348932266, pod: 42.080302119255066, loss: 46.19186329841614 
Train [17/26] | Epoch [49/160] |	nca: 2.114622786641121, flat: 1.9286765456199646, pod: 41.08820676803589, loss: 45.13150644302368 
Train [17/26] | Epoch [50/160] |	nca: 2.167067416012287, flat: 2.036197431385517, pod: 43.43858480453491, loss: 47.641849994659424 
Train [17/26] | Epoch [51/160] |	nca: 2.3043051287531853, flat: 2.0720395669341087, pod: 41.859553933143616, loss: 46.23589861392975 
Train [17/26] | Epoch [52/160] |	nca: 2.385076902806759, flat: 2.118099629878998, pod: 42.6884263753891, loss: 47.19160270690918 
Train [17/26] | Epoch [53/160] |	nca: 2.334617480635643, flat: 2.1447800919413567, pod: 42.385029911994934, loss: 46.86442756652832 
Train [17/26] | Epoch [54/160] |	nca: 2.2141053676605225, flat: 2.269761949777603, pod: 44.74070644378662, loss: 49.224573850631714 
Train [17/26] | Epoch [55/160] |	nca: 1.8884961046278477, flat: 1.811117447912693, pod: 39.788323760032654, loss: 43.487937331199646 
Train [17/26] | Epoch [56/160] |	nca: 2.0093661919236183, flat: 1.671403981745243, pod: 38.20905649662018, loss: 41.88982701301575 
Train [17/26] | Epoch [57/160] |	nca: 2.1461159959435463, flat: 1.8470339998602867, pod: 41.13751554489136, loss: 45.13066518306732 
Train [17/26] | Epoch [58/160] |	nca: 2.141928642988205, flat: 1.8688001483678818, pod: 40.12731325626373, loss: 44.138041853904724 
Train [17/26] | Epoch [59/160] |	nca: 2.0394847504794598, flat: 1.9360258355736732, pod: 40.06235432624817, loss: 44.037864685058594 
Train [17/26] | Epoch [60/160] |	nca: 1.7587203793227673, flat: 1.7399876415729523, pod: 38.50032365322113, loss: 41.99903190135956 
Train [17/26] | Epoch [61/160] |	nca: 2.0429291054606438, flat: 1.7575595304369926, pod: 38.99640595912933, loss: 42.796894550323486 
Train [17/26] | Epoch [62/160] |	nca: 1.8790825940668583, flat: 1.6173555478453636, pod: 37.04437184333801, loss: 40.540809988975525 
Train [17/26] | Epoch [63/160] |	nca: 2.125256799161434, flat: 1.762859784066677, pod: 39.37306189537048, loss: 43.26117825508118 
Train [17/26] | Epoch [64/160] |	nca: 2.153827980160713, flat: 1.9030894860625267, pod: 40.27530586719513, loss: 44.33222317695618 
Train [17/26] | Epoch [65/160] |	nca: 1.9909153282642365, flat: 1.771992102265358, pod: 38.741565346717834, loss: 42.504472732543945 
Train [17/26] | Epoch [66/160] |	nca: 2.0884021185338497, flat: 1.7802296951413155, pod: 38.67434287071228, loss: 42.54297494888306 
Train [17/26] | Epoch [67/160] |	nca: 1.9621996134519577, flat: 1.8229509443044662, pod: 40.11780345439911, loss: 43.90295386314392 
Train [17/26] | Epoch [68/160] |	nca: 2.120420917868614, flat: 1.8351500779390335, pod: 39.72037661075592, loss: 43.6759477853775 
Train [17/26] | Epoch [69/160] |	nca: 1.9855980202555656, flat: 1.7878380343317986, pod: 39.98299944400787, loss: 43.7564355134964 
Train [17/26] | Epoch [70/160] |	nca: 1.7568222656846046, flat: 1.572766151279211, pod: 35.805354952812195, loss: 39.1349436044693 
Train [17/26] | Epoch [71/160] |	nca: 1.7266370989382267, flat: 1.6030766069889069, pod: 37.3864529132843, loss: 40.716166615486145 
Train [17/26] | Epoch [72/160] |	nca: 1.9461144469678402, flat: 1.525850798934698, pod: 35.9799382686615, loss: 39.45190393924713 
Train [17/26] | Epoch [73/160] |	nca: 2.0540568120777607, flat: 1.6156709305942059, pod: 37.342294573783875, loss: 41.012022256851196 
Train [17/26] | Epoch [74/160] |	nca: 1.7849410474300385, flat: 1.5664824582636356, pod: 37.55926215648651, loss: 40.91068613529205 
Train [17/26] | Epoch [75/160] |	nca: 2.0504242293536663, flat: 1.6318891122937202, pod: 36.87646007537842, loss: 40.55877327919006 
Train [17/26] | Epoch [76/160] |	nca: 2.0434818491339684, flat: 1.6974129006266594, pod: 37.73290133476257, loss: 41.473796248435974 
Train [17/26] | Epoch [77/160] |	nca: 2.007499884814024, flat: 1.7761421985924244, pod: 39.52971851825714, loss: 43.313360929489136 
Train [17/26] | Epoch [78/160] |	nca: 2.0132871568202972, flat: 1.694776937365532, pod: 37.47762846946716, loss: 41.18569231033325 
Train [17/26] | Epoch [79/160] |	nca: 1.792989406734705, flat: 1.5311594605445862, pod: 35.86543393135071, loss: 39.18958270549774 
Train [17/26] | Epoch [80/160] |	nca: 1.6850963719189167, flat: 1.372335322201252, pod: 34.22004818916321, loss: 37.27747988700867 
Train [17/26] | Epoch [81/160] |	nca: 1.845180731266737, flat: 1.4741624742746353, pod: 34.71855270862579, loss: 38.03789579868317 
Train [17/26] | Epoch [82/160] |	nca: 1.9600887894630432, flat: 1.4870720580220222, pod: 35.349645018577576, loss: 38.79680573940277 
Train [17/26] | Epoch [83/160] |	nca: 1.9034110680222511, flat: 1.505171425640583, pod: 36.42029631137848, loss: 39.82887876033783 
Train [17/26] | Epoch [84/160] |	nca: 1.896796241402626, flat: 1.449887454509735, pod: 34.03498387336731, loss: 37.381667494773865 
Train [17/26] | Epoch [85/160] |	nca: 1.844999823719263, flat: 1.4866570457816124, pod: 35.12219250202179, loss: 38.45384919643402 
Train [17/26] | Epoch [86/160] |	nca: 1.8547362089157104, flat: 1.4431774839758873, pod: 35.336556792259216, loss: 38.63447046279907 
Train [17/26] | Epoch [87/160] |	nca: 1.8703997656702995, flat: 1.3346626535058022, pod: 32.77835309505463, loss: 35.98341524600983 
Train [17/26] | Epoch [88/160] |	nca: 1.8760674968361855, flat: 1.375137884169817, pod: 33.24467051029205, loss: 36.49587607383728 
Train [17/26] | Epoch [89/160] |	nca: 1.6663003265857697, flat: 1.3163770623505116, pod: 32.98862028121948, loss: 35.97129762172699 
Train [17/26] | Epoch [90/160] |	nca: 1.7971305139362812, flat: 1.232014276087284, pod: 32.30800187587738, loss: 35.33714687824249 
Train [17/26] | Epoch [91/160] |	nca: 1.7960621900856495, flat: 1.3096270821988583, pod: 32.704530358314514, loss: 35.810219526290894 
Train [17/26] | Epoch [92/160] |	nca: 1.851050991564989, flat: 1.317114219069481, pod: 33.23560118675232, loss: 36.40376627445221 
Train [17/26] | Epoch [93/160] |	nca: 1.738261140882969, flat: 1.29705448448658, pod: 32.96635043621063, loss: 36.00166606903076 
Train [17/26] | Epoch [94/160] |	nca: 1.8384285680949688, flat: 1.2374504283070564, pod: 32.22565996646881, loss: 35.301538705825806 
Train [17/26] | Epoch [95/160] |	nca: 1.7084573954343796, flat: 1.206457044929266, pod: 30.95263135433197, loss: 33.8675457239151 
Train [17/26] | Epoch [96/160] |	nca: 1.6890172995626926, flat: 1.1959607154130936, pod: 30.985567927360535, loss: 33.870546102523804 
Train [17/26] | Epoch [97/160] |	nca: 1.8982839547097683, flat: 1.2267448715865612, pod: 31.54752206802368, loss: 34.67255079746246 
Train [17/26] | Epoch [98/160] |	nca: 1.73650424182415, flat: 1.207183726131916, pod: 31.809816122055054, loss: 34.753504276275635 
Train [17/26] | Epoch [99/160] |	nca: 1.8320121429860592, flat: 1.3150851130485535, pod: 33.30747902393341, loss: 36.45457649230957 
Train [17/26] | Epoch [100/160] |	nca: 1.7621510475873947, flat: 1.1849216260015965, pod: 31.48576581478119, loss: 34.432838678359985 
Train [17/26] | Epoch [101/160] |	nca: 1.7560750022530556, flat: 1.1840604022145271, pod: 31.234559059143066, loss: 34.174694299697876 
Train [17/26] | Epoch [102/160] |	nca: 1.5600400269031525, flat: 1.0754073522984982, pod: 29.560910940170288, loss: 32.19635856151581 
Train [17/26] | Epoch [103/160] |	nca: 1.7206780537962914, flat: 1.093374364078045, pod: 28.74122130870819, loss: 31.55527365207672 
Train [17/26] | Epoch [104/160] |	nca: 1.802200186997652, flat: 1.2725177221000195, pod: 31.494877576828003, loss: 34.56959569454193 
Train [17/26] | Epoch [105/160] |	nca: 1.8451231494545937, flat: 1.238662388175726, pod: 31.072060704231262, loss: 34.15584623813629 
Train [17/26] | Epoch [106/160] |	nca: 1.5666763596236706, flat: 1.0643247216939926, pod: 28.5638484954834, loss: 31.194849252700806 
Train [17/26] | Epoch [107/160] |	nca: 1.5603701956570148, flat: 1.0452768951654434, pod: 29.32326364517212, loss: 31.928910851478577 
Train [17/26] | Epoch [108/160] |	nca: 1.7797956615686417, flat: 1.110601019114256, pod: 30.11354351043701, loss: 33.00393998622894 
Train [17/26] | Epoch [109/160] |	nca: 1.7374792769551277, flat: 1.1179368644952774, pod: 28.857558250427246, loss: 31.712974190711975 
Train [17/26] | Epoch [110/160] |	nca: 1.7589982487261295, flat: 1.0762626715004444, pod: 28.644775390625, loss: 31.48003602027893 
Train [17/26] | Epoch [111/160] |	nca: 1.4862721264362335, flat: 0.9715719819068909, pod: 27.424944281578064, loss: 29.8827885389328 
Train [17/26] | Epoch [112/160] |	nca: 1.629758894443512, flat: 1.0403377786278725, pod: 28.27080488204956, loss: 30.940901517868042 
Train [17/26] | Epoch [113/160] |	nca: 1.7379033230245113, flat: 0.9700594358146191, pod: 27.513797521591187, loss: 30.221760630607605 
Train [17/26] | Epoch [114/160] |	nca: 1.5358694531023502, flat: 1.0452380292117596, pod: 28.21180009841919, loss: 30.79290771484375 
Train [17/26] | Epoch [115/160] |	nca: 1.6983650587499142, flat: 0.9916337914764881, pod: 27.263716340065002, loss: 29.953715085983276 
Train [17/26] | Epoch [116/160] |	nca: 1.6651085019111633, flat: 0.9733593538403511, pod: 27.05057966709137, loss: 29.68904745578766 
Train [17/26] | Epoch [117/160] |	nca: 1.6708512380719185, flat: 0.9573860242962837, pod: 26.556185007095337, loss: 29.184422373771667 
Train [17/26] | Epoch [118/160] |	nca: 1.6537929959595203, flat: 0.9459987804293633, pod: 26.689343571662903, loss: 29.289135456085205 
Train [17/26] | Epoch [119/160] |	nca: 1.5489115566015244, flat: 0.839060852304101, pod: 25.435830235481262, loss: 27.82380247116089 
Train [17/26] | Epoch [120/160] |	nca: 1.6478976383805275, flat: 0.8865530397742987, pod: 25.718199133872986, loss: 28.252649784088135 
Train [17/26] | Epoch [121/160] |	nca: 1.5817336030304432, flat: 0.8544745966792107, pod: 25.05421793460846, loss: 27.490426301956177 
Train [17/26] | Epoch [122/160] |	nca: 1.6427740827202797, flat: 0.9052971266210079, pod: 26.28396773338318, loss: 28.83203887939453 
Train [17/26] | Epoch [123/160] |	nca: 1.6182228289544582, flat: 0.8651393391191959, pod: 25.515751361846924, loss: 27.99911367893219 
Train [17/26] | Epoch [124/160] |	nca: 1.6285469867289066, flat: 0.8822755329310894, pod: 25.836497902870178, loss: 28.347320675849915 
Train [17/26] | Epoch [125/160] |	nca: 1.5033734627068043, flat: 0.7886800039559603, pod: 24.252584874629974, loss: 26.54463839530945 
Train [17/26] | Epoch [126/160] |	nca: 1.6419497430324554, flat: 0.8361449278891087, pod: 24.64347666501999, loss: 27.12157154083252 
Train [17/26] | Epoch [127/160] |	nca: 1.5771497525274754, flat: 0.8095786869525909, pod: 23.717438876628876, loss: 26.104167342185974 
Train [17/26] | Epoch [128/160] |	nca: 1.7856860347092152, flat: 0.8320455234497786, pod: 23.59707349538803, loss: 26.214805126190186 
Train [17/26] | Epoch [129/160] |	nca: 1.6776877045631409, flat: 0.8021125942468643, pod: 23.077210545539856, loss: 25.557011127471924 
Train [17/26] | Epoch [130/160] |	nca: 1.4933513067662716, flat: 0.7069913037121296, pod: 21.172131299972534, loss: 23.372474014759064 
Train [17/26] | Epoch [131/160] |	nca: 1.60654241964221, flat: 0.7348332479596138, pod: 22.972049295902252, loss: 25.313424944877625 
Train [17/26] | Epoch [132/160] |	nca: 1.6249467693269253, flat: 0.6746012475341558, pod: 21.468241095542908, loss: 23.767789244651794 
Train [17/26] | Epoch [133/160] |	nca: 1.6805861555039883, flat: 0.7448014207184315, pod: 22.5644348859787, loss: 24.989822506904602 
Train [17/26] | Epoch [134/160] |	nca: 1.5260416083037853, flat: 0.7077903896570206, pod: 21.687393128871918, loss: 23.92122507095337 
Train [17/26] | Epoch [135/160] |	nca: 1.5195603668689728, flat: 0.6810132581740618, pod: 21.999949395656586, loss: 24.200523138046265 
Train [17/26] | Epoch [136/160] |	nca: 1.6337728910148144, flat: 0.6689521800726652, pod: 21.566085159778595, loss: 23.868810057640076 
Train [17/26] | Epoch [137/160] |	nca: 1.7198205888271332, flat: 0.7320993952453136, pod: 21.42123931646347, loss: 23.873159289360046 
Train [17/26] | Epoch [138/160] |	nca: 1.532083511352539, flat: 0.7484188321977854, pod: 22.043006360530853, loss: 24.323508620262146 
Train [17/26] | Epoch [139/160] |	nca: 1.5956504382193089, flat: 0.6930994559079409, pod: 21.17419469356537, loss: 23.462944865226746 
Train [17/26] | Epoch [140/160] |	nca: 1.6507087461650372, flat: 0.7414482515305281, pod: 22.112021565437317, loss: 24.504178524017334 
Train [17/26] | Epoch [141/160] |	nca: 1.579134151339531, flat: 0.7119374480098486, pod: 21.257977068424225, loss: 23.549048483371735 
Train [17/26] | Epoch [142/160] |	nca: 1.5850441083312035, flat: 0.6771002784371376, pod: 21.25857573747635, loss: 23.52072024345398 
Train [17/26] | Epoch [143/160] |	nca: 1.5540910959243774, flat: 0.6956782750785351, pod: 21.103622138500214, loss: 23.353391468524933 
Train [17/26] | Epoch [144/160] |	nca: 1.6389368623495102, flat: 0.6761310435831547, pod: 20.18142533302307, loss: 22.496493339538574 
Train [17/26] | Epoch [145/160] |	nca: 1.54473140463233, flat: 0.6323089990764856, pod: 19.680011808872223, loss: 21.857052326202393 
Train [17/26] | Epoch [146/160] |	nca: 1.5453666858375072, flat: 0.6493489015847445, pod: 20.16322034597397, loss: 22.357935905456543 
Train [17/26] | Epoch [147/160] |	nca: 1.639794908463955, flat: 0.6231306027621031, pod: 19.364562153816223, loss: 21.627487659454346 
Train [17/26] | Epoch [148/160] |	nca: 1.4803652092814445, flat: 0.630267983302474, pod: 20.01744145154953, loss: 22.128074824810028 
Train [17/26] | Epoch [149/160] |	nca: 1.5459264479577541, flat: 0.6282661482691765, pod: 19.60740101337433, loss: 21.78159373998642 
Train [17/26] | Epoch [150/160] |	nca: 1.5342780202627182, flat: 0.6093242093920708, pod: 19.170909881591797, loss: 21.314512133598328 
Train [17/26] | Epoch [151/160] |	nca: 1.6101332381367683, flat: 0.6032545790076256, pod: 18.979540765285492, loss: 21.192928552627563 
Train [17/26] | Epoch [152/160] |	nca: 1.625285241752863, flat: 0.6112588066607714, pod: 19.468268632888794, loss: 21.704812705516815 
Train [17/26] | Epoch [153/160] |	nca: 1.575043324381113, flat: 0.5896867159754038, pod: 18.895901381969452, loss: 21.060631334781647 
Train [17/26] | Epoch [154/160] |	nca: 1.4566808007657528, flat: 0.665944043546915, pod: 19.475638270378113, loss: 21.59826308488846 
Train [17/26] | Epoch [155/160] |	nca: 1.4682409781962633, flat: 0.5809618271887302, pod: 18.637194454669952, loss: 20.686397194862366 
Train [17/26] | Epoch [156/160] |	nca: 1.5386589020490646, flat: 0.581386111676693, pod: 18.740685522556305, loss: 20.86073064804077 
Train [17/26] | Epoch [157/160] |	nca: 1.6037299185991287, flat: 0.6280882097780704, pod: 19.34493577480316, loss: 21.57675415277481 
Train [17/26] | Epoch [158/160] |	nca: 1.4576825648546219, flat: 0.5511033739894629, pod: 17.70951533317566, loss: 19.718301117420197 
Train [17/26] | Epoch [159/160] |	nca: 1.5930116288363934, flat: 0.6352262087166309, pod: 19.607977390289307, loss: 21.83621507883072 
Train [17/26] | Epoch [160/160] |	nca: 1.5482037141919136, flat: 0.586370063945651, pod: 18.829006671905518, loss: 20.963580548763275 
Fine-tuning
Building & updating memory.
Train [17/26] | Epoch [161/180] |	nca: 1.0030360482633114, flat: 0.7177952826023102, pod: 18.076221823692322, loss: 19.797053337097168 
Train [17/26] | Epoch [162/180] |	nca: 0.7337969690561295, flat: 0.7286179326474667, pod: 18.240689754486084, loss: 19.703104615211487 
Train [17/26] | Epoch [163/180] |	nca: 0.5565436147153378, flat: 0.752969816327095, pod: 18.361945152282715, loss: 19.6714586019516 
Train [17/26] | Epoch [164/180] |	nca: 0.5759749300777912, flat: 0.7466796040534973, pod: 18.4527508020401, loss: 19.775405287742615 
Train [17/26] | Epoch [165/180] |	nca: 0.5355949476361275, flat: 0.8097227662801743, pod: 19.12718641757965, loss: 20.472504138946533 
Train [17/26] | Epoch [166/180] |	nca: 0.5255771689116955, flat: 0.7468298319727182, pod: 18.41395777463913, loss: 19.686365008354187 
Train [17/26] | Epoch [167/180] |	nca: 0.48707323148846626, flat: 0.7292140796780586, pod: 18.35351324081421, loss: 19.56980049610138 
Train [17/26] | Epoch [168/180] |	nca: 0.5695804245769978, flat: 0.7332155182957649, pod: 18.22756588459015, loss: 19.530361890792847 
Train [17/26] | Epoch [169/180] |	nca: 0.5123865976929665, flat: 0.7701339609920979, pod: 18.759272933006287, loss: 20.04179334640503 
Train [17/26] | Epoch [170/180] |	nca: 0.4661355149000883, flat: 0.7722159139811993, pod: 18.544278264045715, loss: 19.78262948989868 
Train [17/26] | Epoch [171/180] |	nca: 0.487601051107049, flat: 0.7395199052989483, pod: 18.24398624897003, loss: 19.471107244491577 
Train [17/26] | Epoch [172/180] |	nca: 0.4619478415697813, flat: 0.7131038010120392, pod: 17.915579319000244, loss: 19.090631008148193 
Train [17/26] | Epoch [173/180] |	nca: 0.4640705846250057, flat: 0.7634048610925674, pod: 18.21693217754364, loss: 19.44440770149231 
Train [17/26] | Epoch [174/180] |	nca: 0.42942865565419197, flat: 0.759807676076889, pod: 18.380117893218994, loss: 19.56935441493988 
Train [17/26] | Epoch [175/180] |	nca: 0.47357319854199886, flat: 0.761650525033474, pod: 18.434385418891907, loss: 19.66960918903351 
Train [17/26] | Epoch [176/180] |	nca: 0.4589638877660036, flat: 0.7265132330358028, pod: 18.103447794914246, loss: 19.28892493247986 
Train [17/26] | Epoch [177/180] |	nca: 0.45018636621534824, flat: 0.7510433457791805, pod: 18.61608326435089, loss: 19.817313194274902 
Train [17/26] | Epoch [178/180] |	nca: 0.40816450491547585, flat: 0.7445139922201633, pod: 18.32870304584503, loss: 19.4813814163208 
Train [17/26] | Epoch [179/180] |	nca: 0.42455901205539703, flat: 0.7006693780422211, pod: 17.909433722496033, loss: 19.034662127494812 
Train [17/26] | Epoch [180/180] |	nca: 0.41557393223047256, flat: 0.7610224299132824, pod: 18.660518407821655, loss: 19.837114930152893 
after task
Building & updating memory.
after task
Eval on 0->82.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6253529411764706.
Current acc: {'total': 0.544, '00-09': 0.608, '10-19': 0.561, '20-29': 0.486, '30-39': 0.511, '40-49': 0.548, '50-59': 0.557, '60-69': 0.47, '70-79': 0.611, '80-89': 0.525}.
Avg inc acc top5: 0.869470588235294.
Current acc top5: {'total': 0.823}.
Forgetting: 0.0912.
Cord metric: 0.61.
Old accuracy: 0.54, mean: 0.62.
New accuracy: 0.53, mean: 0.64.
================Task 17 Start!================
Testing on False unseen tasks (max class = 84).
Set memory of size: 1640.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 17 Training!================
The training samples number: 2640
Train on 82->84.
train task
nb 2640.
Train [18/26] | Epoch [1/160] |	nca: 8.041064620018005, flat: 3.99704073369503, pod: 50.26334881782532, loss: 62.301454067230225 
Train [18/26] | Epoch [2/160] |	nca: 3.9969884902238846, flat: 3.93643020093441, pod: 56.73860025405884, loss: 64.67201948165894 
Train [18/26] | Epoch [3/160] |	nca: 3.02556312084198, flat: 3.0819446817040443, pod: 50.20357370376587, loss: 56.311081886291504 
Train [18/26] | Epoch [4/160] |	nca: 2.6365438252687454, flat: 2.946945443749428, pod: 50.74128079414368, loss: 56.32477068901062 
Train [18/26] | Epoch [5/160] |	nca: 2.373687244951725, flat: 2.7509304881095886, pod: 49.94590139389038, loss: 55.0705189704895 
Train [18/26] | Epoch [6/160] |	nca: 2.133103646337986, flat: 2.5306908190250397, pod: 48.4851713180542, loss: 53.14896607398987 
Train [18/26] | Epoch [7/160] |	nca: 2.0904232785105705, flat: 2.3495296463370323, pod: 45.872273683547974, loss: 50.31222701072693 
Train [18/26] | Epoch [8/160] |	nca: 2.153941310942173, flat: 2.3472565934062004, pod: 45.47282147407532, loss: 49.9740195274353 
Train [18/26] | Epoch [9/160] |	nca: 2.259887710213661, flat: 2.385726474225521, pod: 45.918128490448, loss: 50.56374263763428 
Train [18/26] | Epoch [10/160] |	nca: 2.100958738476038, flat: 2.4708885848522186, pod: 47.53885459899902, loss: 52.11070156097412 
Train [18/26] | Epoch [11/160] |	nca: 2.172915458679199, flat: 2.317076377570629, pod: 44.35063397884369, loss: 48.840625524520874 
Train [18/26] | Epoch [12/160] |	nca: 2.0670254826545715, flat: 2.3330184519290924, pod: 45.99600267410278, loss: 50.39604640007019 
Train [18/26] | Epoch [13/160] |	nca: 2.284335173666477, flat: 2.519108049571514, pod: 48.759979248046875, loss: 53.563421964645386 
Train [18/26] | Epoch [14/160] |	nca: 2.1230791583657265, flat: 2.330332487821579, pod: 44.78303503990173, loss: 49.23644661903381 
Train [18/26] | Epoch [15/160] |	nca: 1.7189219892024994, flat: 2.2091450467705727, pod: 44.33120119571686, loss: 48.259268045425415 
Train [18/26] | Epoch [16/160] |	nca: 2.035735599696636, flat: 2.2222936153411865, pod: 45.463926553726196, loss: 49.7219557762146 
Train [18/26] | Epoch [17/160] |	nca: 1.7714881859719753, flat: 2.2175746262073517, pod: 45.663912296295166, loss: 49.65297508239746 
Train [18/26] | Epoch [18/160] |	nca: 1.8904469013214111, flat: 2.07716666162014, pod: 43.085150599479675, loss: 47.05276381969452 
Train [18/26] | Epoch [19/160] |	nca: 1.9290394708514214, flat: 2.0361310094594955, pod: 43.007376074790955, loss: 46.972546339035034 
Train [18/26] | Epoch [20/160] |	nca: 1.849244024604559, flat: 2.09457615762949, pod: 43.37486934661865, loss: 47.318689823150635 
Train [18/26] | Epoch [21/160] |	nca: 1.9625241123139858, flat: 2.2271459624171257, pod: 45.812119364738464, loss: 50.001789569854736 
Train [18/26] | Epoch [22/160] |	nca: 1.7773575596511364, flat: 2.1130950897932053, pod: 44.28511369228363, loss: 48.17556667327881 
Train [18/26] | Epoch [23/160] |	nca: 1.986709713935852, flat: 2.3394569382071495, pod: 46.4213627576828, loss: 50.74752998352051 
Train [18/26] | Epoch [24/160] |	nca: 1.8242510929703712, flat: 2.024939715862274, pod: 42.57966959476471, loss: 46.42886126041412 
Train [18/26] | Epoch [25/160] |	nca: 1.7170760594308376, flat: 2.0806301161646843, pod: 44.07569098472595, loss: 47.87339699268341 
Train [18/26] | Epoch [26/160] |	nca: 1.7534312531352043, flat: 2.164415068924427, pod: 46.012621998786926, loss: 49.93046844005585 
Train [18/26] | Epoch [27/160] |	nca: 1.81753421574831, flat: 2.0366710647940636, pod: 42.65456306934357, loss: 46.50876832008362 
Train [18/26] | Epoch [28/160] |	nca: 1.786016471683979, flat: 2.0049740970134735, pod: 42.24572789669037, loss: 46.03671848773956 
Train [18/26] | Epoch [29/160] |	nca: 1.8862370885908604, flat: 1.8890905603766441, pod: 40.37635135650635, loss: 44.151678681373596 
Train [18/26] | Epoch [30/160] |	nca: 1.823929850012064, flat: 1.9689150750637054, pod: 42.50468325614929, loss: 46.2975287437439 
Train [18/26] | Epoch [31/160] |	nca: 1.8426768258213997, flat: 2.269019402563572, pod: 45.449440598487854, loss: 49.561137437820435 
Train [18/26] | Epoch [32/160] |	nca: 1.6213447600603104, flat: 1.9732429757714272, pod: 43.24461483955383, loss: 46.839202880859375 
Train [18/26] | Epoch [33/160] |	nca: 1.556431993842125, flat: 2.1409849897027016, pod: 45.71273672580719, loss: 49.41015362739563 
Train [18/26] | Epoch [34/160] |	nca: 1.7004156522452831, flat: 1.8289974704384804, pod: 40.907044410705566, loss: 44.43645739555359 
Train [18/26] | Epoch [35/160] |	nca: 1.8517091870307922, flat: 1.937296599149704, pod: 41.546396136283875, loss: 45.33540177345276 
Train [18/26] | Epoch [36/160] |	nca: 1.9061488881707191, flat: 1.9100333601236343, pod: 40.35717010498047, loss: 44.173352122306824 
Train [18/26] | Epoch [37/160] |	nca: 1.5815123543143272, flat: 1.8572146818041801, pod: 40.33880388736725, loss: 43.777531027793884 
Train [18/26] | Epoch [38/160] |	nca: 1.7471166290342808, flat: 1.8912422731518745, pod: 41.69505274295807, loss: 45.33341121673584 
Train [18/26] | Epoch [39/160] |	nca: 1.638603586703539, flat: 1.9989417642354965, pod: 43.720463156700134, loss: 47.35800850391388 
Train [18/26] | Epoch [40/160] |	nca: 1.6089622005820274, flat: 1.8774958103895187, pod: 41.8534095287323, loss: 45.3398677110672 
Train [18/26] | Epoch [41/160] |	nca: 1.589507106691599, flat: 1.7968577966094017, pod: 39.86350774765015, loss: 43.24987268447876 
Train [18/26] | Epoch [42/160] |	nca: 1.7572969198226929, flat: 1.9661991000175476, pod: 42.52780592441559, loss: 46.25130248069763 
Train [18/26] | Epoch [43/160] |	nca: 1.8380062617361546, flat: 2.0615441277623177, pod: 44.09349513053894, loss: 47.993045806884766 
Train [18/26] | Epoch [44/160] |	nca: 1.7893532142043114, flat: 1.9670220464468002, pod: 41.46830105781555, loss: 45.22467577457428 
Train [18/26] | Epoch [45/160] |	nca: 1.6733052283525467, flat: 1.8440608382225037, pod: 40.24369752407074, loss: 43.76106357574463 
Train [18/26] | Epoch [46/160] |	nca: 1.668428048491478, flat: 1.9541260600090027, pod: 42.59949517250061, loss: 46.222049951553345 
Train [18/26] | Epoch [47/160] |	nca: 1.8976553231477737, flat: 1.9492111578583717, pod: 41.01668334007263, loss: 44.86354959011078 
Train [18/26] | Epoch [48/160] |	nca: 1.913818545639515, flat: 2.025607690215111, pod: 42.895737171173096, loss: 46.835163831710815 
Train [18/26] | Epoch [49/160] |	nca: 1.740520540624857, flat: 1.9761633947491646, pod: 41.131513237953186, loss: 44.84819722175598 
Train [18/26] | Epoch [50/160] |	nca: 1.6441247314214706, flat: 1.8689815327525139, pod: 41.50993597507477, loss: 45.02304244041443 
Train [18/26] | Epoch [51/160] |	nca: 1.568274863064289, flat: 1.7297629714012146, pod: 39.84173667430878, loss: 43.139774441719055 
Train [18/26] | Epoch [52/160] |	nca: 1.4571868181228638, flat: 1.613343097269535, pod: 38.51803648471832, loss: 41.588565945625305 
Train [18/26] | Epoch [53/160] |	nca: 1.93685582280159, flat: 1.8799315989017487, pod: 41.442381143569946, loss: 45.25916814804077 
Train [18/26] | Epoch [54/160] |	nca: 1.5923718810081482, flat: 1.7501796260476112, pod: 39.04367172718048, loss: 42.38622331619263 
Train [18/26] | Epoch [55/160] |	nca: 1.9367018714547157, flat: 1.8258505910634995, pod: 39.55412149429321, loss: 43.31667423248291 
Train [18/26] | Epoch [56/160] |	nca: 1.8131701461970806, flat: 1.6701635643839836, pod: 37.79236590862274, loss: 41.275699734687805 
Train [18/26] | Epoch [57/160] |	nca: 1.6222566701471806, flat: 1.700910359621048, pod: 38.04682970046997, loss: 41.36999690532684 
Train [18/26] | Epoch [58/160] |	nca: 1.621600192040205, flat: 1.6481464430689812, pod: 37.5665864944458, loss: 40.83633291721344 
Train [18/26] | Epoch [59/160] |	nca: 1.633549764752388, flat: 1.7533679604530334, pod: 39.66241669654846, loss: 43.04933452606201 
Train [18/26] | Epoch [60/160] |	nca: 1.5906421430408955, flat: 1.6371276155114174, pod: 38.41165781021118, loss: 41.63942754268646 
Train [18/26] | Epoch [61/160] |	nca: 1.560441080480814, flat: 1.5897423885762691, pod: 36.48518192768097, loss: 39.63536560535431 
Train [18/26] | Epoch [62/160] |	nca: 1.4826181344687939, flat: 1.7028932571411133, pod: 38.21739149093628, loss: 41.40290284156799 
Train [18/26] | Epoch [63/160] |	nca: 1.5484271571040154, flat: 1.5800024941563606, pod: 37.876725912094116, loss: 41.005155086517334 
Train [18/26] | Epoch [64/160] |	nca: 1.6269350163638592, flat: 1.693366140127182, pod: 40.11429035663605, loss: 43.43459188938141 
Train [18/26] | Epoch [65/160] |	nca: 1.56173862144351, flat: 1.6146333701908588, pod: 37.90086305141449, loss: 41.077234983444214 
Train [18/26] | Epoch [66/160] |	nca: 1.6389755457639694, flat: 1.6818201169371605, pod: 38.62797296047211, loss: 41.948768854141235 
Train [18/26] | Epoch [67/160] |	nca: 1.6932440735399723, flat: 1.626249223947525, pod: 37.74216866493225, loss: 41.06166207790375 
Train [18/26] | Epoch [68/160] |	nca: 1.5258809961378574, flat: 1.61817242577672, pod: 37.78956758975983, loss: 40.9336211681366 
Train [18/26] | Epoch [69/160] |	nca: 1.4914432354271412, flat: 1.4605596289038658, pod: 35.57884657382965, loss: 38.5308495759964 
Train [18/26] | Epoch [70/160] |	nca: 1.4041910581290722, flat: 1.4637735858559608, pod: 36.493183970451355, loss: 39.36114859580994 
Train [18/26] | Epoch [71/160] |	nca: 1.628635749220848, flat: 1.4747349582612514, pod: 35.48849582672119, loss: 38.59186673164368 
Train [18/26] | Epoch [72/160] |	nca: 1.4288442954421043, flat: 1.5162577591836452, pod: 37.04595196247101, loss: 39.99105381965637 
Train [18/26] | Epoch [73/160] |	nca: 1.5365269184112549, flat: 1.50820317491889, pod: 36.93336772918701, loss: 39.978097319602966 
Train [18/26] | Epoch [74/160] |	nca: 1.6066547222435474, flat: 1.515330497175455, pod: 37.31607186794281, loss: 40.43805718421936 
Train [18/26] | Epoch [75/160] |	nca: 1.5627879686653614, flat: 1.5020109824836254, pod: 37.52389860153198, loss: 40.58869767189026 
Train [18/26] | Epoch [76/160] |	nca: 1.4433154836297035, flat: 1.3648542501032352, pod: 34.67754077911377, loss: 37.48571062088013 
Train [18/26] | Epoch [77/160] |	nca: 1.4745147973299026, flat: 1.2965558618307114, pod: 33.395331382751465, loss: 36.166402101516724 
Train [18/26] | Epoch [78/160] |	nca: 1.5380501560866833, flat: 1.4769877269864082, pod: 35.97338509559631, loss: 38.9884227514267 
Train [18/26] | Epoch [79/160] |	nca: 1.5899264924228191, flat: 1.325051225721836, pod: 33.48272526264191, loss: 36.39770317077637 
Train [18/26] | Epoch [80/160] |	nca: 1.41589979454875, flat: 1.3648683093488216, pod: 34.43084931373596, loss: 37.21161758899689 
Train [18/26] | Epoch [81/160] |	nca: 1.4399941116571426, flat: 1.2610250189900398, pod: 32.5275182723999, loss: 35.22853744029999 
Train [18/26] | Epoch [82/160] |	nca: 1.3632762432098389, flat: 1.2598891966044903, pod: 33.42713940143585, loss: 36.050304651260376 
Train [18/26] | Epoch [83/160] |	nca: 1.460587278008461, flat: 1.3090874329209328, pod: 33.87484800815582, loss: 36.64452254772186 
Train [18/26] | Epoch [84/160] |	nca: 1.5616322383284569, flat: 1.3447237126529217, pod: 33.41588115692139, loss: 36.32223725318909 
Train [18/26] | Epoch [85/160] |	nca: 1.5630150958895683, flat: 1.3315591514110565, pod: 34.02185297012329, loss: 36.91642761230469 
Train [18/26] | Epoch [86/160] |	nca: 1.5225775986909866, flat: 1.3382971100509167, pod: 34.337738037109375, loss: 37.198612689971924 
Train [18/26] | Epoch [87/160] |	nca: 1.427199013531208, flat: 1.210258986800909, pod: 33.1239275932312, loss: 35.761385560035706 
Train [18/26] | Epoch [88/160] |	nca: 1.408143512904644, flat: 1.2948642894625664, pod: 33.974231362342834, loss: 36.67723894119263 
Train [18/26] | Epoch [89/160] |	nca: 1.3679513186216354, flat: 1.162441685795784, pod: 31.974345564842224, loss: 34.504738569259644 
Train [18/26] | Epoch [90/160] |	nca: 1.4742116034030914, flat: 1.1558078862726688, pod: 31.58643341064453, loss: 34.216453075408936 
Train [18/26] | Epoch [91/160] |	nca: 1.4452410768717527, flat: 1.1715413480997086, pod: 32.05240070819855, loss: 34.669183015823364 
Train [18/26] | Epoch [92/160] |	nca: 1.4689044244587421, flat: 1.337810032069683, pod: 34.23142611980438, loss: 37.03814077377319 
Train [18/26] | Epoch [93/160] |	nca: 1.466298371553421, flat: 1.2450865730643272, pod: 31.669882655143738, loss: 34.38126742839813 
Train [18/26] | Epoch [94/160] |	nca: 1.476384487003088, flat: 1.1636067815124989, pod: 30.54860544204712, loss: 33.18859660625458 
Train [18/26] | Epoch [95/160] |	nca: 1.486921552568674, flat: 1.1268726252019405, pod: 30.62599813938141, loss: 33.239792466163635 
Train [18/26] | Epoch [96/160] |	nca: 1.447084203362465, flat: 1.0707989819347858, pod: 29.849992632865906, loss: 32.367875814437866 
Train [18/26] | Epoch [97/160] |	nca: 1.4205875024199486, flat: 1.1795236989855766, pod: 31.885371327400208, loss: 34.485482573509216 
Train [18/26] | Epoch [98/160] |	nca: 1.4439094178378582, flat: 1.091625850647688, pod: 30.69906222820282, loss: 33.2345974445343 
Train [18/26] | Epoch [99/160] |	nca: 1.452361710369587, flat: 1.1984040141105652, pod: 31.49034893512726, loss: 34.141114592552185 
Train [18/26] | Epoch [100/160] |	nca: 1.4011188596487045, flat: 1.0214485563337803, pod: 28.793317794799805, loss: 31.215885281562805 
Train [18/26] | Epoch [101/160] |	nca: 1.3082860223948956, flat: 1.0631269365549088, pod: 29.933498978614807, loss: 32.304911732673645 
Train [18/26] | Epoch [102/160] |	nca: 1.3868079110980034, flat: 1.0589457042515278, pod: 29.577255487442017, loss: 32.023009300231934 
Train [18/26] | Epoch [103/160] |	nca: 1.4320429004728794, flat: 1.124451719224453, pod: 30.266989707946777, loss: 32.823484659194946 
Train [18/26] | Epoch [104/160] |	nca: 1.413487996906042, flat: 1.0872424729168415, pod: 30.488749384880066, loss: 32.989479541778564 
Train [18/26] | Epoch [105/160] |	nca: 1.447786446660757, flat: 0.9641031250357628, pod: 27.946696043014526, loss: 30.358585476875305 
Train [18/26] | Epoch [106/160] |	nca: 1.3087857067584991, flat: 0.9817654006183147, pod: 28.250280618667603, loss: 30.540831804275513 
Train [18/26] | Epoch [107/160] |	nca: 1.4412490613758564, flat: 0.9789841845631599, pod: 28.30377185344696, loss: 30.724005103111267 
Train [18/26] | Epoch [108/160] |	nca: 1.3231086321175098, flat: 0.9700661189854145, pod: 28.58691716194153, loss: 30.880091667175293 
Train [18/26] | Epoch [109/160] |	nca: 1.3283336758613586, flat: 0.9020689930766821, pod: 27.365688800811768, loss: 29.596091508865356 
Train [18/26] | Epoch [110/160] |	nca: 1.4807189889252186, flat: 0.9811390563845634, pod: 28.33599293231964, loss: 30.797850966453552 
Train [18/26] | Epoch [111/160] |	nca: 1.3780621215701103, flat: 0.9274298753589392, pod: 27.047154426574707, loss: 29.352646708488464 
Train [18/26] | Epoch [112/160] |	nca: 1.29360631108284, flat: 0.9625219032168388, pod: 27.964906573295593, loss: 30.22103476524353 
Train [18/26] | Epoch [113/160] |	nca: 1.3169818371534348, flat: 0.8996298164129257, pod: 26.858460187911987, loss: 29.075071930885315 
Train [18/26] | Epoch [114/160] |	nca: 1.35226059705019, flat: 0.9348004851490259, pod: 26.70796287059784, loss: 28.99502408504486 
Train [18/26] | Epoch [115/160] |	nca: 1.443302232772112, flat: 0.9173045847564936, pod: 27.229182720184326, loss: 29.589789509773254 
Train [18/26] | Epoch [116/160] |	nca: 1.326948020607233, flat: 0.917939767241478, pod: 28.00854742527008, loss: 30.253435254096985 
Train [18/26] | Epoch [117/160] |	nca: 1.3914511613547802, flat: 0.9394501950591803, pod: 27.55608570575714, loss: 29.88698697090149 
Train [18/26] | Epoch [118/160] |	nca: 1.3980262018740177, flat: 0.8897203579545021, pod: 26.677725076675415, loss: 28.965471744537354 
Train [18/26] | Epoch [119/160] |	nca: 1.241718016564846, flat: 0.8976091034710407, pod: 26.453119039535522, loss: 28.592446327209473 
Train [18/26] | Epoch [120/160] |	nca: 1.4273454546928406, flat: 0.8909759409725666, pod: 25.63569962978363, loss: 27.954020738601685 
Train [18/26] | Epoch [121/160] |	nca: 1.2793214470148087, flat: 0.7498011216521263, pod: 24.06606364250183, loss: 26.095186710357666 
Train [18/26] | Epoch [122/160] |	nca: 1.3953008875250816, flat: 0.8009612113237381, pod: 24.09878134727478, loss: 26.295043349266052 
Train [18/26] | Epoch [123/160] |	nca: 1.3132369965314865, flat: 0.8566237557679415, pod: 24.665958166122437, loss: 26.835818886756897 
Train [18/26] | Epoch [124/160] |	nca: 1.2905072048306465, flat: 0.7463666759431362, pod: 23.93619614839554, loss: 25.97307002544403 
Train [18/26] | Epoch [125/160] |	nca: 1.3361796867102385, flat: 0.7362152971327305, pod: 23.926133394241333, loss: 25.998528242111206 
Train [18/26] | Epoch [126/160] |	nca: 1.276445534080267, flat: 0.722293097525835, pod: 23.056953489780426, loss: 25.055692195892334 
Train [18/26] | Epoch [127/160] |	nca: 1.2817718759179115, flat: 0.7946931812912226, pod: 24.179431974887848, loss: 26.255897045135498 
Train [18/26] | Epoch [128/160] |	nca: 1.4217247292399406, flat: 0.7611687798053026, pod: 23.610559105873108, loss: 25.793452739715576 
Train [18/26] | Epoch [129/160] |	nca: 1.2709429934620857, flat: 0.6600687708705664, pod: 21.556319415569305, loss: 23.48733127117157 
Train [18/26] | Epoch [130/160] |	nca: 1.355143491178751, flat: 0.6997455451637506, pod: 22.860640108585358, loss: 24.915529131889343 
Train [18/26] | Epoch [131/160] |	nca: 1.3162991628050804, flat: 0.6636542621999979, pod: 21.67586362361908, loss: 23.65581703186035 
Train [18/26] | Epoch [132/160] |	nca: 1.3259049765765667, flat: 0.7115433663129807, pod: 22.518750727176666, loss: 24.55619913339615 
Train [18/26] | Epoch [133/160] |	nca: 1.3514196760952473, flat: 0.6844540052115917, pod: 22.108513355255127, loss: 24.14438706636429 
Train [18/26] | Epoch [134/160] |	nca: 1.410453625023365, flat: 0.6546959485858679, pod: 21.33228051662445, loss: 23.39743000268936 
Train [18/26] | Epoch [135/160] |	nca: 1.3920799270272255, flat: 0.6593219488859177, pod: 20.598241806030273, loss: 22.649643659591675 
Train [18/26] | Epoch [136/160] |	nca: 1.3182904161512852, flat: 0.6757893245667219, pod: 21.623348653316498, loss: 23.617428421974182 
Train [18/26] | Epoch [137/160] |	nca: 1.2197665721178055, flat: 0.5985674615949392, pod: 20.151292085647583, loss: 21.969626307487488 
Train [18/26] | Epoch [138/160] |	nca: 1.3122733980417252, flat: 0.6334933117032051, pod: 20.161652147769928, loss: 22.107418656349182 
Train [18/26] | Epoch [139/160] |	nca: 1.3227845691144466, flat: 0.6470352578908205, pod: 21.322934806346893, loss: 23.292754650115967 
Train [18/26] | Epoch [140/160] |	nca: 1.281712494790554, flat: 0.6088253669440746, pod: 19.813292741775513, loss: 21.703830540180206 
Train [18/26] | Epoch [141/160] |	nca: 1.3718922920525074, flat: 0.6387591026723385, pod: 20.362278699874878, loss: 22.37292993068695 
Train [18/26] | Epoch [142/160] |	nca: 1.387502957135439, flat: 0.6414114031940699, pod: 20.397355675697327, loss: 22.426269829273224 
Train [18/26] | Epoch [143/160] |	nca: 1.3004816584289074, flat: 0.5710134319961071, pod: 19.400821924209595, loss: 21.272317111492157 
Train [18/26] | Epoch [144/160] |	nca: 1.31366753205657, flat: 0.6000715121626854, pod: 19.85233038663864, loss: 21.766069650650024 
Train [18/26] | Epoch [145/160] |	nca: 1.2498231306672096, flat: 0.6341884322464466, pod: 20.22565060853958, loss: 22.109662234783173 
Train [18/26] | Epoch [146/160] |	nca: 1.2477655000984669, flat: 0.5346405189484358, pod: 18.66696459054947, loss: 20.449370622634888 
Train [18/26] | Epoch [147/160] |	nca: 1.2965269647538662, flat: 0.5613809060305357, pod: 18.61108762025833, loss: 20.468995332717896 
Train [18/26] | Epoch [148/160] |	nca: 1.27775077521801, flat: 0.6038795281201601, pod: 19.482662320137024, loss: 21.36429274082184 
Train [18/26] | Epoch [149/160] |	nca: 1.243284486234188, flat: 0.5176217798143625, pod: 18.18932044506073, loss: 19.95022678375244 
Train [18/26] | Epoch [150/160] |	nca: 1.269141260534525, flat: 0.5606400445103645, pod: 19.366944015026093, loss: 21.196725130081177 
Train [18/26] | Epoch [151/160] |	nca: 1.2546265125274658, flat: 0.566898999735713, pod: 18.9558048248291, loss: 20.777330338954926 
Train [18/26] | Epoch [152/160] |	nca: 1.337257832288742, flat: 0.5061935074627399, pod: 18.039181232452393, loss: 19.882632553577423 
Train [18/26] | Epoch [153/160] |	nca: 1.2776267975568771, flat: 0.515358455479145, pod: 18.11871647834778, loss: 19.91170185804367 
Train [18/26] | Epoch [154/160] |	nca: 1.3142281025648117, flat: 0.5252461582422256, pod: 17.688328206539154, loss: 19.527802526950836 
Train [18/26] | Epoch [155/160] |	nca: 1.3020844459533691, flat: 0.4860423943027854, pod: 16.546419382095337, loss: 18.334546327590942 
Train [18/26] | Epoch [156/160] |	nca: 1.3034779280424118, flat: 0.5370224667713046, pod: 17.586802780628204, loss: 19.42730313539505 
Train [18/26] | Epoch [157/160] |	nca: 1.2519941367208958, flat: 0.5492878928780556, pod: 18.860698640346527, loss: 20.661980748176575 
Train [18/26] | Epoch [158/160] |	nca: 1.288142029196024, flat: 0.5033314656466246, pod: 17.468600869178772, loss: 19.260074496269226 
Train [18/26] | Epoch [159/160] |	nca: 1.1914374940097332, flat: 0.5113091226667166, pod: 18.049359798431396, loss: 19.752106308937073 
Train [18/26] | Epoch [160/160] |	nca: 1.339049320667982, flat: 0.49150331504642963, pod: 17.09406179189682, loss: 18.924614250659943 
Fine-tuning
Building & updating memory.
Train [18/26] | Epoch [161/180] |	nca: 1.3410505130887032, flat: 1.0031787045300007, pod: 20.348464369773865, loss: 22.69269347190857 
Train [18/26] | Epoch [162/180] |	nca: 0.9176469221711159, flat: 0.990297507494688, pod: 19.862030506134033, loss: 21.76997470855713 
Train [18/26] | Epoch [163/180] |	nca: 0.8884524144232273, flat: 1.0299837440252304, pod: 20.090354442596436, loss: 22.008790850639343 
Train [18/26] | Epoch [164/180] |	nca: 0.8797309473156929, flat: 1.0538275167346, pod: 20.031666040420532, loss: 21.965224504470825 
Train [18/26] | Epoch [165/180] |	nca: 0.8493324853479862, flat: 0.9870701022446156, pod: 19.691565990447998, loss: 21.527968287467957 
Train [18/26] | Epoch [166/180] |	nca: 1.0628131590783596, flat: 1.100539643317461, pod: 20.76626718044281, loss: 22.929619789123535 
Train [18/26] | Epoch [167/180] |	nca: 1.2789263688027859, flat: 1.0367089547216892, pod: 20.002456545829773, loss: 22.318091869354248 
Train [18/26] | Epoch [168/180] |	nca: 1.0242382027208805, flat: 1.0571791231632233, pod: 20.23454225063324, loss: 22.315959572792053 
Train [18/26] | Epoch [169/180] |	nca: 0.9354784525930882, flat: 1.0375445745885372, pod: 20.0573308467865, loss: 22.030353665351868 
Train [18/26] | Epoch [170/180] |	nca: 0.9020758718252182, flat: 1.0010059922933578, pod: 20.090171813964844, loss: 21.99325382709503 
Train [18/26] | Epoch [171/180] |	nca: 1.045399036258459, flat: 0.9995228163897991, pod: 19.978240966796875, loss: 22.023162841796875 
Train [18/26] | Epoch [172/180] |	nca: 0.8516516089439392, flat: 1.0613827519118786, pod: 20.194562077522278, loss: 22.107596516609192 
Train [18/26] | Epoch [173/180] |	nca: 0.7855015434324741, flat: 1.1442341171205044, pod: 20.704617261886597, loss: 22.634353041648865 
Train [18/26] | Epoch [174/180] |	nca: 0.83726666867733, flat: 1.1315385960042477, pod: 20.712125658988953, loss: 22.680930852890015 
Train [18/26] | Epoch [175/180] |	nca: 0.7838494591414928, flat: 1.0140924751758575, pod: 20.03181767463684, loss: 21.82975935935974 
Train [18/26] | Epoch [176/180] |	nca: 0.6924943290650845, flat: 1.0690013580024242, pod: 20.22673511505127, loss: 21.98823082447052 
Train [18/26] | Epoch [177/180] |	nca: 0.7863774225115776, flat: 1.1189037524163723, pod: 20.993533730506897, loss: 22.898814916610718 
Train [18/26] | Epoch [178/180] |	nca: 0.7403821907937527, flat: 1.0861071646213531, pod: 20.22781777381897, loss: 22.054307103157043 
Train [18/26] | Epoch [179/180] |	nca: 0.7696776613593102, flat: 1.0067186392843723, pod: 20.19151484966278, loss: 21.96791100502014 
Train [18/26] | Epoch [180/180] |	nca: 0.6446554847061634, flat: 1.0059565007686615, pod: 20.02410876750946, loss: 21.674720764160156 
after task
Building & updating memory.
after task
Eval on 0->84.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6208888888888889.
Current acc: {'total': 0.545, '00-09': 0.607, '10-19': 0.551, '20-29': 0.476, '30-39': 0.503, '40-49': 0.545, '50-59': 0.567, '60-69': 0.475, '70-79': 0.607, '80-89': 0.623}.
Avg inc acc top5: 0.8667777777777776.
Current acc top5: {'total': 0.821}.
Forgetting: 0.13599999999999998.
Cord metric: 0.61.
Old accuracy: 0.54, mean: 0.61.
New accuracy: 0.74, mean: 0.65.
================Task 18 Start!================
Testing on False unseen tasks (max class = 86).
Set memory of size: 1680.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 18 Training!================
The training samples number: 2680
Train on 84->86.
train task
nb 2680.
Train [19/26] | Epoch [1/160] |	nca: 10.082140147686005, flat: 4.979813031852245, pod: 53.34439837932587, loss: 68.40635108947754 
Train [19/26] | Epoch [2/160] |	nca: 5.894712209701538, flat: 4.472759693861008, pod: 58.403223752975464, loss: 68.77069592475891 
Train [19/26] | Epoch [3/160] |	nca: 5.100665174424648, flat: 3.7704890966415405, pod: 54.62276554107666, loss: 63.49391984939575 
Train [19/26] | Epoch [4/160] |	nca: 3.8973343670368195, flat: 3.250076323747635, pod: 51.14538097381592, loss: 58.29279136657715 
Train [19/26] | Epoch [5/160] |	nca: 3.075645811855793, flat: 2.7798148691654205, pod: 49.14973282814026, loss: 55.00519371032715 
Train [19/26] | Epoch [6/160] |	nca: 3.0682789236307144, flat: 2.522670716047287, pod: 46.90899848937988, loss: 52.499948263168335 
Train [19/26] | Epoch [7/160] |	nca: 3.1552701890468597, flat: 2.6926794722676277, pod: 49.94665026664734, loss: 55.794599533081055 
Train [19/26] | Epoch [8/160] |	nca: 3.2856700867414474, flat: 2.5192887634038925, pod: 48.17868900299072, loss: 53.98364734649658 
Train [19/26] | Epoch [9/160] |	nca: 2.778330959379673, flat: 2.3275038972496986, pod: 45.41828918457031, loss: 50.52412390708923 
Train [19/26] | Epoch [10/160] |	nca: 2.9955116137862206, flat: 2.526566006243229, pod: 46.89534246921539, loss: 52.41742014884949 
Train [19/26] | Epoch [11/160] |	nca: 2.6448510885238647, flat: 2.429005928337574, pod: 47.547849893569946, loss: 52.62170672416687 
Train [19/26] | Epoch [12/160] |	nca: 2.488299608230591, flat: 2.2796545401215553, pod: 45.924819231033325, loss: 50.69277358055115 
Train [19/26] | Epoch [13/160] |	nca: 2.7301115170121193, flat: 2.2277762293815613, pod: 44.239205837249756, loss: 49.19709324836731 
Train [19/26] | Epoch [14/160] |	nca: 2.8847497701644897, flat: 2.5456235855817795, pod: 48.25674021244049, loss: 53.687113523483276 
Train [19/26] | Epoch [15/160] |	nca: 2.8907985165715218, flat: 2.529733397066593, pod: 48.37425136566162, loss: 53.794782876968384 
Train [19/26] | Epoch [16/160] |	nca: 2.7613444924354553, flat: 2.462373360991478, pod: 46.54179763793945, loss: 51.76551604270935 
Train [19/26] | Epoch [17/160] |	nca: 2.314984291791916, flat: 2.372847944498062, pod: 47.13610029220581, loss: 51.82393217086792 
Train [19/26] | Epoch [18/160] |	nca: 2.431865081191063, flat: 2.3125925585627556, pod: 46.418527483940125, loss: 51.16298508644104 
Train [19/26] | Epoch [19/160] |	nca: 2.354711703956127, flat: 2.1850433573126793, pod: 44.514748334884644, loss: 49.054502964019775 
Train [19/26] | Epoch [20/160] |	nca: 2.4087025560438633, flat: 2.0638382881879807, pod: 44.02085793018341, loss: 48.493398904800415 
Train [19/26] | Epoch [21/160] |	nca: 2.388045735657215, flat: 2.0526627004146576, pod: 44.28943407535553, loss: 48.73014235496521 
Train [19/26] | Epoch [22/160] |	nca: 2.5213887728750706, flat: 2.172321707010269, pod: 43.692991614341736, loss: 48.38670206069946 
Train [19/26] | Epoch [23/160] |	nca: 2.3507670164108276, flat: 2.126621037721634, pod: 43.768964409828186, loss: 48.246352195739746 
Train [19/26] | Epoch [24/160] |	nca: 2.300758980214596, flat: 2.170447528362274, pod: 44.96532440185547, loss: 49.43653082847595 
Train [19/26] | Epoch [25/160] |	nca: 2.3143969625234604, flat: 1.9833109080791473, pod: 42.71436297893524, loss: 47.012070655822754 
Train [19/26] | Epoch [26/160] |	nca: 2.3178868889808655, flat: 2.001848950982094, pod: 42.26369500160217, loss: 46.58343064785004 
Train [19/26] | Epoch [27/160] |	nca: 2.493294805288315, flat: 2.1702532172203064, pod: 44.52965533733368, loss: 49.19320344924927 
Train [19/26] | Epoch [28/160] |	nca: 2.5101418271660805, flat: 2.142738461494446, pod: 43.65888202190399, loss: 48.31176257133484 
Train [19/26] | Epoch [29/160] |	nca: 2.3156195506453514, flat: 1.9291346669197083, pod: 40.68756437301636, loss: 44.932318449020386 
Train [19/26] | Epoch [30/160] |	nca: 1.9878641217947006, flat: 1.824259102344513, pod: 40.48197400569916, loss: 44.29409670829773 
Train [19/26] | Epoch [31/160] |	nca: 2.1507361233234406, flat: 1.8792540654540062, pod: 41.439311027526855, loss: 45.469300627708435 
Train [19/26] | Epoch [32/160] |	nca: 2.211949896067381, flat: 1.8596875667572021, pod: 41.83034121990204, loss: 45.901978492736816 
Train [19/26] | Epoch [33/160] |	nca: 2.2975544817745686, flat: 2.03717303276062, pod: 42.791696429252625, loss: 47.126423835754395 
Train [19/26] | Epoch [34/160] |	nca: 2.1019234508275986, flat: 1.9082476943731308, pod: 42.26962065696716, loss: 46.279791831970215 
Train [19/26] | Epoch [35/160] |	nca: 2.0706110298633575, flat: 1.9460771009325981, pod: 42.50429975986481, loss: 46.52098762989044 
Train [19/26] | Epoch [36/160] |	nca: 2.2644762322306633, flat: 1.8878182992339134, pod: 41.17279601097107, loss: 45.325090408325195 
Train [19/26] | Epoch [37/160] |	nca: 2.1715328581631184, flat: 1.9596644937992096, pod: 42.58321285247803, loss: 46.71441030502319 
Train [19/26] | Epoch [38/160] |	nca: 2.2653854452073574, flat: 2.110051207244396, pod: 44.7322860956192, loss: 49.107722759246826 
Train [19/26] | Epoch [39/160] |	nca: 2.19656590372324, flat: 1.8779030740261078, pod: 41.28338027000427, loss: 45.3578497171402 
Train [19/26] | Epoch [40/160] |	nca: 2.043386049568653, flat: 1.7876421436667442, pod: 40.26045095920563, loss: 44.0914785861969 
Train [19/26] | Epoch [41/160] |	nca: 2.083700869232416, flat: 1.8377825990319252, pod: 41.175809025764465, loss: 45.09729254245758 
Train [19/26] | Epoch [42/160] |	nca: 2.2073153108358383, flat: 1.9345563352108002, pod: 41.50204277038574, loss: 45.643913984298706 
Train [19/26] | Epoch [43/160] |	nca: 2.166607778519392, flat: 1.8823125958442688, pod: 40.728408217430115, loss: 44.777328968048096 
Train [19/26] | Epoch [44/160] |	nca: 2.090293936431408, flat: 1.782629832625389, pod: 39.96484911441803, loss: 43.837772727012634 
Train [19/26] | Epoch [45/160] |	nca: 2.13825586438179, flat: 1.8023005947470665, pod: 39.58282554149628, loss: 43.52338230609894 
Train [19/26] | Epoch [46/160] |	nca: 2.222121387720108, flat: 1.8841282650828362, pod: 41.36373698711395, loss: 45.46998655796051 
Train [19/26] | Epoch [47/160] |	nca: 2.0229760706424713, flat: 1.7907435446977615, pod: 39.95574188232422, loss: 43.769461274147034 
Train [19/26] | Epoch [48/160] |	nca: 2.0224007442593575, flat: 1.7715654522180557, pod: 40.168988823890686, loss: 43.96295499801636 
Train [19/26] | Epoch [49/160] |	nca: 1.717626690864563, flat: 1.6285620480775833, pod: 38.06103503704071, loss: 41.40722405910492 
Train [19/26] | Epoch [50/160] |	nca: 1.974104605615139, flat: 1.7007096782326698, pod: 38.596529841423035, loss: 42.27134382724762 
Train [19/26] | Epoch [51/160] |	nca: 2.1317420713603497, flat: 1.632166974246502, pod: 37.891154766082764, loss: 41.6550635099411 
Train [19/26] | Epoch [52/160] |	nca: 2.102709487080574, flat: 1.6298425272107124, pod: 37.24136781692505, loss: 40.97392010688782 
Train [19/26] | Epoch [53/160] |	nca: 1.9962590150535107, flat: 1.615135096013546, pod: 38.27051782608032, loss: 41.881911754608154 
Train [19/26] | Epoch [54/160] |	nca: 2.0792739391326904, flat: 1.6467400565743446, pod: 37.872182726860046, loss: 41.598196387290955 
Train [19/26] | Epoch [55/160] |	nca: 2.2703207656741142, flat: 1.7917822822928429, pod: 40.055792927742004, loss: 44.11789584159851 
Train [19/26] | Epoch [56/160] |	nca: 1.8711931109428406, flat: 1.6976595744490623, pod: 38.739221692085266, loss: 42.30807423591614 
Train [19/26] | Epoch [57/160] |	nca: 2.0574430152773857, flat: 1.6576248183846474, pod: 39.359800696372986, loss: 43.07486820220947 
Train [19/26] | Epoch [58/160] |	nca: 1.9312373995780945, flat: 1.7087907940149307, pod: 38.29528224468231, loss: 41.93531012535095 
Train [19/26] | Epoch [59/160] |	nca: 1.9037398733198643, flat: 1.6483701020479202, pod: 38.66323637962341, loss: 42.215346336364746 
Train [19/26] | Epoch [60/160] |	nca: 2.0351965576410294, flat: 1.7408959493041039, pod: 40.40484535694122, loss: 44.18093752861023 
Train [19/26] | Epoch [61/160] |	nca: 1.7405701465904713, flat: 1.5267911888659, pod: 36.79475283622742, loss: 40.062114119529724 
Train [19/26] | Epoch [62/160] |	nca: 1.8612476959824562, flat: 1.626236166805029, pod: 38.500420808792114, loss: 41.98790442943573 
Train [19/26] | Epoch [63/160] |	nca: 1.8854378536343575, flat: 1.4929904267191887, pod: 35.580811858177185, loss: 38.959240078926086 
Train [19/26] | Epoch [64/160] |	nca: 1.8629029616713524, flat: 1.6199520900845528, pod: 38.409024357795715, loss: 41.89187932014465 
Train [19/26] | Epoch [65/160] |	nca: 2.0066623017191887, flat: 1.5488837212324142, pod: 35.687413811683655, loss: 39.24295973777771 
Train [19/26] | Epoch [66/160] |	nca: 1.8947985656559467, flat: 1.609367772936821, pod: 37.398122668266296, loss: 40.90228867530823 
Train [19/26] | Epoch [67/160] |	nca: 1.9393032863736153, flat: 1.5004684403538704, pod: 36.78948271274567, loss: 40.22925424575806 
Train [19/26] | Epoch [68/160] |	nca: 1.879176888614893, flat: 1.553986333310604, pod: 36.732688784599304, loss: 40.16585183143616 
Train [19/26] | Epoch [69/160] |	nca: 1.709728080779314, flat: 1.5360556319355965, pod: 37.92909002304077, loss: 41.17487335205078 
Train [19/26] | Epoch [70/160] |	nca: 1.7976174280047417, flat: 1.4901735410094261, pod: 37.44503676891327, loss: 40.73282754421234 
Train [19/26] | Epoch [71/160] |	nca: 1.762945394963026, flat: 1.406210858374834, pod: 35.25502419471741, loss: 38.42418038845062 
Train [19/26] | Epoch [72/160] |	nca: 1.84006392583251, flat: 1.3458014987409115, pod: 34.50699818134308, loss: 37.69286382198334 
Train [19/26] | Epoch [73/160] |	nca: 1.829054269939661, flat: 1.3957873582839966, pod: 34.87177884578705, loss: 38.09662067890167 
Train [19/26] | Epoch [74/160] |	nca: 1.8981901109218597, flat: 1.4067021943628788, pod: 34.78830373287201, loss: 38.09319603443146 
Train [19/26] | Epoch [75/160] |	nca: 1.738478921353817, flat: 1.559240747243166, pod: 37.22563660144806, loss: 40.523356318473816 
Train [19/26] | Epoch [76/160] |	nca: 1.746936235576868, flat: 1.257601324468851, pod: 33.226324915885925, loss: 36.230862498283386 
Train [19/26] | Epoch [77/160] |	nca: 1.8491600416600704, flat: 1.4403213858604431, pod: 36.538137912750244, loss: 39.827619194984436 
Train [19/26] | Epoch [78/160] |	nca: 1.8139419630169868, flat: 1.2966046370565891, pod: 33.85065221786499, loss: 36.961198687553406 
Train [19/26] | Epoch [79/160] |	nca: 1.7913547828793526, flat: 1.3235699981451035, pod: 34.4706791639328, loss: 37.585604190826416 
Train [19/26] | Epoch [80/160] |	nca: 1.933764636516571, flat: 1.3739605881273746, pod: 34.75352346897125, loss: 38.061248898506165 
Train [19/26] | Epoch [81/160] |	nca: 1.710375003516674, flat: 1.3739816397428513, pod: 35.497750878334045, loss: 38.5821076631546 
Train [19/26] | Epoch [82/160] |	nca: 1.7066150791943073, flat: 1.262862652540207, pod: 33.10539996623993, loss: 36.074877977371216 
Train [19/26] | Epoch [83/160] |	nca: 1.965427115559578, flat: 1.4020964168012142, pod: 36.10567033290863, loss: 39.47319424152374 
Train [19/26] | Epoch [84/160] |	nca: 1.7399463504552841, flat: 1.3537839613854885, pod: 35.18120455741882, loss: 38.27493500709534 
Train [19/26] | Epoch [85/160] |	nca: 1.7603690065443516, flat: 1.2801403626799583, pod: 33.22815489768982, loss: 36.2686642408371 
Train [19/26] | Epoch [86/160] |	nca: 1.6617629379034042, flat: 1.1918168179690838, pod: 31.9479740858078, loss: 34.80155408382416 
Train [19/26] | Epoch [87/160] |	nca: 1.761607326567173, flat: 1.168597687035799, pod: 31.736165761947632, loss: 34.66637074947357 
Train [19/26] | Epoch [88/160] |	nca: 1.5990495420992374, flat: 1.174455251544714, pod: 31.5588800907135, loss: 34.33238470554352 
Train [19/26] | Epoch [89/160] |	nca: 1.656234160065651, flat: 1.1343155018985271, pod: 31.072970032691956, loss: 33.86351943016052 
Train [19/26] | Epoch [90/160] |	nca: 1.592703927308321, flat: 1.12443295866251, pod: 30.337121963500977, loss: 33.054258704185486 
Train [19/26] | Epoch [91/160] |	nca: 1.7695675007998943, flat: 1.116964180022478, pod: 31.174038410186768, loss: 34.06057012081146 
Train [19/26] | Epoch [92/160] |	nca: 1.5953049585223198, flat: 1.1449447013437748, pod: 30.56184756755829, loss: 33.30209720134735 
Train [19/26] | Epoch [93/160] |	nca: 1.7357159592211246, flat: 1.256324641406536, pod: 32.63357484340668, loss: 35.62561535835266 
Train [19/26] | Epoch [94/160] |	nca: 1.6632118038833141, flat: 1.1283095329999924, pod: 31.045743584632874, loss: 33.83726489543915 
Train [19/26] | Epoch [95/160] |	nca: 1.7955612912774086, flat: 1.1693356521427631, pod: 32.0705189704895, loss: 35.03541600704193 
Train [19/26] | Epoch [96/160] |	nca: 1.6777690164744854, flat: 1.0477956719696522, pod: 29.650051951408386, loss: 32.375616669654846 
Train [19/26] | Epoch [97/160] |	nca: 1.7310748919844627, flat: 1.0950676761567593, pod: 31.218811750411987, loss: 34.04495418071747 
Train [19/26] | Epoch [98/160] |	nca: 1.6150205582380295, flat: 1.0563047528266907, pod: 29.500083327293396, loss: 32.17140829563141 
Train [19/26] | Epoch [99/160] |	nca: 1.7039638310670853, flat: 1.1062162518501282, pod: 30.97985827922821, loss: 33.79003858566284 
Train [19/26] | Epoch [100/160] |	nca: 1.6305262744426727, flat: 1.056101467460394, pod: 30.439250111579895, loss: 33.12587785720825 
Train [19/26] | Epoch [101/160] |	nca: 1.644764307886362, flat: 1.0546317994594574, pod: 29.868818879127502, loss: 32.568215012550354 
Train [19/26] | Epoch [102/160] |	nca: 1.5728647969663143, flat: 0.9959352873265743, pod: 29.167637944221497, loss: 31.736438274383545 
Train [19/26] | Epoch [103/160] |	nca: 1.7383003532886505, flat: 1.02303995937109, pod: 29.02596342563629, loss: 31.787303686141968 
Train [19/26] | Epoch [104/160] |	nca: 1.5533546432852745, flat: 0.9479971192777157, pod: 27.921870231628418, loss: 30.423222184181213 
Train [19/26] | Epoch [105/160] |	nca: 1.5526704266667366, flat: 0.9319701828062534, pod: 27.115902304649353, loss: 29.600542902946472 
Train [19/26] | Epoch [106/160] |	nca: 1.5935350731015205, flat: 0.9377102591097355, pod: 27.05298924446106, loss: 29.584234714508057 
Train [19/26] | Epoch [107/160] |	nca: 1.725300658494234, flat: 0.973408505320549, pod: 28.702488660812378, loss: 31.401197910308838 
Train [19/26] | Epoch [108/160] |	nca: 1.5878385715186596, flat: 0.9913608878850937, pod: 28.351287841796875, loss: 30.930487394332886 
Train [19/26] | Epoch [109/160] |	nca: 1.6899126172065735, flat: 0.9577536694705486, pod: 28.257928013801575, loss: 30.90559422969818 
Train [19/26] | Epoch [110/160] |	nca: 1.7242432460188866, flat: 0.9214060641825199, pod: 26.930570006370544, loss: 29.57621920108795 
Train [19/26] | Epoch [111/160] |	nca: 1.6403257474303246, flat: 0.9433430023491383, pod: 27.276706337928772, loss: 29.86037516593933 
Train [19/26] | Epoch [112/160] |	nca: 1.5231903307139874, flat: 0.8543984089046717, pod: 26.149184584617615, loss: 28.5267733335495 
Train [19/26] | Epoch [113/160] |	nca: 1.5952334478497505, flat: 0.8156592696905136, pod: 25.09611827135086, loss: 27.50701093673706 
Train [19/26] | Epoch [114/160] |	nca: 1.5332935899496078, flat: 0.8590770401060581, pod: 26.399911403656006, loss: 28.792282223701477 
Train [19/26] | Epoch [115/160] |	nca: 1.554227489978075, flat: 0.8224520739167929, pod: 24.9155216217041, loss: 27.29220151901245 
Train [19/26] | Epoch [116/160] |	nca: 1.470308143645525, flat: 0.776772839948535, pod: 24.418152809143066, loss: 26.665233969688416 
Train [19/26] | Epoch [117/160] |	nca: 1.5760433040559292, flat: 0.7731387540698051, pod: 24.417444586753845, loss: 26.766626596450806 
Train [19/26] | Epoch [118/160] |	nca: 1.5625021122395992, flat: 0.767951188609004, pod: 24.591284036636353, loss: 26.92173743247986 
Train [19/26] | Epoch [119/160] |	nca: 1.6157048642635345, flat: 0.7910246178507805, pod: 24.72146075963974, loss: 27.12819004058838 
Train [19/26] | Epoch [120/160] |	nca: 1.5868386141955853, flat: 0.7351901512593031, pod: 23.338915050029755, loss: 25.66094398498535 
Train [19/26] | Epoch [121/160] |	nca: 1.44358591735363, flat: 0.7130606919527054, pod: 22.789309799671173, loss: 24.945956707000732 
Train [19/26] | Epoch [122/160] |	nca: 1.5495102144777775, flat: 0.706194443628192, pod: 22.62552171945572, loss: 24.881226539611816 
Train [19/26] | Epoch [123/160] |	nca: 1.4417665414512157, flat: 0.674490699544549, pod: 22.080941140651703, loss: 24.197198271751404 
Train [19/26] | Epoch [124/160] |	nca: 1.609924826771021, flat: 0.7217514626681805, pod: 23.218690514564514, loss: 25.55036687850952 
Train [19/26] | Epoch [125/160] |	nca: 1.6642847061157227, flat: 0.708135973662138, pod: 22.533985912799835, loss: 24.90640640258789 
Train [19/26] | Epoch [126/160] |	nca: 1.5902456864714622, flat: 0.6993111856281757, pod: 22.445550620555878, loss: 24.73510766029358 
Train [19/26] | Epoch [127/160] |	nca: 1.5399091467261314, flat: 0.6898650471121073, pod: 23.24538654088974, loss: 25.475160717964172 
Train [19/26] | Epoch [128/160] |	nca: 1.5243214964866638, flat: 0.6452970989048481, pod: 21.604087114334106, loss: 23.77370595932007 
Train [19/26] | Epoch [129/160] |	nca: 1.6663188338279724, flat: 0.6912224311381578, pod: 22.145833432674408, loss: 24.503374755382538 
Train [19/26] | Epoch [130/160] |	nca: 1.5632401369512081, flat: 0.6430954020470381, pod: 21.371120989322662, loss: 23.57745659351349 
Train [19/26] | Epoch [131/160] |	nca: 1.506914984434843, flat: 0.6635031327605247, pod: 21.243727207183838, loss: 23.41414523124695 
Train [19/26] | Epoch [132/160] |	nca: 1.6233299411833286, flat: 0.7184257563203573, pod: 22.54884386062622, loss: 24.890599489212036 
Train [19/26] | Epoch [133/160] |	nca: 1.4889369159936905, flat: 0.6473577581346035, pod: 21.651214718818665, loss: 23.787509322166443 
Train [19/26] | Epoch [134/160] |	nca: 1.5397829301655293, flat: 0.6368360538035631, pod: 21.464671671390533, loss: 23.64129090309143 
Train [19/26] | Epoch [135/160] |	nca: 1.5106791146099567, flat: 0.58512900210917, pod: 19.85032069683075, loss: 21.9461287856102 
Train [19/26] | Epoch [136/160] |	nca: 1.5260076485574245, flat: 0.6216983180493116, pod: 20.12564778327942, loss: 22.273353695869446 
Train [19/26] | Epoch [137/160] |	nca: 1.592981431633234, flat: 0.6125546265393496, pod: 19.989779353141785, loss: 22.195315301418304 
Train [19/26] | Epoch [138/160] |	nca: 1.5943268053233624, flat: 0.5831969119608402, pod: 19.441760540008545, loss: 21.619284331798553 
Train [19/26] | Epoch [139/160] |	nca: 1.4984884895384312, flat: 0.5940750129520893, pod: 19.48160868883133, loss: 21.57417231798172 
Train [19/26] | Epoch [140/160] |	nca: 1.520958747714758, flat: 0.5820695329457521, pod: 19.32784253358841, loss: 21.43087089061737 
Train [19/26] | Epoch [141/160] |	nca: 1.488797552883625, flat: 0.6106967478990555, pod: 19.9193434715271, loss: 22.018837690353394 
Train [19/26] | Epoch [142/160] |	nca: 1.5597076751291752, flat: 0.5803602356463671, pod: 19.369003891944885, loss: 21.50907152891159 
Train [19/26] | Epoch [143/160] |	nca: 1.5834576487541199, flat: 0.5785602424293756, pod: 19.302346348762512, loss: 21.46436434984207 
Train [19/26] | Epoch [144/160] |	nca: 1.585613388568163, flat: 0.5616548471152782, pod: 18.447486877441406, loss: 20.594754993915558 
Train [19/26] | Epoch [145/160] |	nca: 1.404183380305767, flat: 0.5381835121661425, pod: 18.284763634204865, loss: 20.227130591869354 
Train [19/26] | Epoch [146/160] |	nca: 1.4653738625347614, flat: 0.5584671497344971, pod: 19.084932029247284, loss: 21.108772933483124 
Train [19/26] | Epoch [147/160] |	nca: 1.5184192135930061, flat: 0.5543563719838858, pod: 19.006358087062836, loss: 21.079133450984955 
Train [19/26] | Epoch [148/160] |	nca: 1.4601004794239998, flat: 0.553648579865694, pod: 18.31593918800354, loss: 20.329688251018524 
Train [19/26] | Epoch [149/160] |	nca: 1.456428799778223, flat: 0.542467687278986, pod: 19.014896869659424, loss: 21.013793528079987 
Train [19/26] | Epoch [150/160] |	nca: 1.597180213779211, flat: 0.5577141810208559, pod: 18.71354079246521, loss: 20.868435204029083 
Train [19/26] | Epoch [151/160] |	nca: 1.615779809653759, flat: 0.5825567599385977, pod: 18.809035003185272, loss: 21.007371425628662 
Train [19/26] | Epoch [152/160] |	nca: 1.574742041528225, flat: 0.5305639430880547, pod: 18.20119446516037, loss: 20.306500375270844 
Train [19/26] | Epoch [153/160] |	nca: 1.432294424623251, flat: 0.5310217384248972, pod: 18.068090736865997, loss: 20.031406819820404 
Train [19/26] | Epoch [154/160] |	nca: 1.503443919122219, flat: 0.5461585503071547, pod: 18.182040512561798, loss: 20.231642842292786 
Train [19/26] | Epoch [155/160] |	nca: 1.3576437905430794, flat: 0.4944578167051077, pod: 17.222709715366364, loss: 19.074811398983 
Train [19/26] | Epoch [156/160] |	nca: 1.4642983637750149, flat: 0.5016647446900606, pod: 17.19521790742874, loss: 19.161181092262268 
Train [19/26] | Epoch [157/160] |	nca: 1.429720401763916, flat: 0.52329470962286, pod: 17.587806284427643, loss: 19.540821433067322 
Train [19/26] | Epoch [158/160] |	nca: 1.5256718136370182, flat: 0.5226467261090875, pod: 17.9875710606575, loss: 20.035889625549316 
Train [19/26] | Epoch [159/160] |	nca: 1.5004544369876385, flat: 0.5253008622676134, pod: 17.875077307224274, loss: 19.90083259344101 
Train [19/26] | Epoch [160/160] |	nca: 1.494682502001524, flat: 0.49908779188990593, pod: 17.21634143590927, loss: 19.210111677646637 
Fine-tuning
Building & updating memory.
Train [19/26] | Epoch [161/180] |	nca: 1.1867567747831345, flat: 0.7573546003550291, pod: 18.908328890800476, loss: 20.85244047641754 
Train [19/26] | Epoch [162/180] |	nca: 0.7836423926055431, flat: 0.7627395614981651, pod: 19.002559900283813, loss: 20.54894196987152 
Train [19/26] | Epoch [163/180] |	nca: 0.7443615086376667, flat: 0.799596481025219, pod: 19.464051723480225, loss: 21.008009672164917 
Train [19/26] | Epoch [164/180] |	nca: 0.6490829288959503, flat: 0.7217930294573307, pod: 18.669009923934937, loss: 20.039885878562927 
Train [19/26] | Epoch [165/180] |	nca: 0.661846574395895, flat: 0.8068361170589924, pod: 19.29352855682373, loss: 20.762210965156555 
Train [19/26] | Epoch [166/180] |	nca: 0.6113191023468971, flat: 0.74818404763937, pod: 18.945378184318542, loss: 20.3048814535141 
Train [19/26] | Epoch [167/180] |	nca: 0.5736830998212099, flat: 0.7804389856755733, pod: 18.879244208335876, loss: 20.2333664894104 
Train [19/26] | Epoch [168/180] |	nca: 0.5858028419315815, flat: 0.7878897339105606, pod: 19.173371076583862, loss: 20.54706382751465 
Train [19/26] | Epoch [169/180] |	nca: 0.5946033112704754, flat: 0.7714374959468842, pod: 19.07672381401062, loss: 20.44276463985443 
Train [19/26] | Epoch [170/180] |	nca: 0.5421404577791691, flat: 0.7695190291851759, pod: 19.34138286113739, loss: 20.653042554855347 
Train [19/26] | Epoch [171/180] |	nca: 0.6161740757524967, flat: 0.7617283016443253, pod: 18.706464290618896, loss: 20.08436667919159 
Train [19/26] | Epoch [172/180] |	nca: 0.5731297135353088, flat: 0.7376503888517618, pod: 18.704817056655884, loss: 20.015597105026245 
Train [19/26] | Epoch [173/180] |	nca: 0.6042409762740135, flat: 0.7913690730929375, pod: 19.52979326248169, loss: 20.925403237342834 
Train [19/26] | Epoch [174/180] |	nca: 0.5814170017838478, flat: 0.7856639139354229, pod: 18.982811331748962, loss: 20.349892377853394 
Train [19/26] | Epoch [175/180] |	nca: 0.5917877219617367, flat: 0.7191766276955605, pod: 18.6156405210495, loss: 19.926604866981506 
Train [19/26] | Epoch [176/180] |	nca: 0.5547506101429462, flat: 0.7887287400662899, pod: 19.258280754089355, loss: 20.601759910583496 
Train [19/26] | Epoch [177/180] |	nca: 0.5808363109827042, flat: 0.7595783099532127, pod: 18.933931946754456, loss: 20.274346590042114 
Train [19/26] | Epoch [178/180] |	nca: 0.5049299616366625, flat: 0.7766093350946903, pod: 19.120767831802368, loss: 20.40230703353882 
Train [19/26] | Epoch [179/180] |	nca: 0.531208822503686, flat: 0.7412128280848265, pod: 18.73784875869751, loss: 20.01027023792267 
Train [19/26] | Epoch [180/180] |	nca: 0.5526478830724955, flat: 0.7247112840414047, pod: 18.610180139541626, loss: 19.887539386749268 
after task
Building & updating memory.
after task
Eval on 0->86.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.616578947368421.
Current acc: {'total': 0.539, '00-09': 0.604, '10-19': 0.544, '20-29': 0.472, '30-39': 0.498, '40-49': 0.548, '50-59': 0.554, '60-69': 0.473, '70-79': 0.599, '80-89': 0.572}.
Avg inc acc top5: 0.864315789473684.
Current acc top5: {'total': 0.82}.
Forgetting: 0.1548.
Cord metric: 0.60.
Old accuracy: 0.54, mean: 0.61.
New accuracy: 0.56, mean: 0.64.
================Task 19 Start!================
Testing on False unseen tasks (max class = 88).
Set memory of size: 1720.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 19 Training!================
The training samples number: 2720
Train on 86->88.
train task
nb 2720.
Train [20/26] | Epoch [1/160] |	nca: 9.480431541800499, flat: 6.013975828886032, pod: 58.02916061878204, loss: 73.52356791496277 
Train [20/26] | Epoch [2/160] |	nca: 6.031397879123688, flat: 5.674931228160858, pod: 64.44372200965881, loss: 76.15005087852478 
Train [20/26] | Epoch [3/160] |	nca: 5.2195833921432495, flat: 5.120636239647865, pod: 63.420684814453125, loss: 73.76090502738953 
Train [20/26] | Epoch [4/160] |	nca: 2.860215298831463, flat: 3.9977296590805054, pod: 57.55824065208435, loss: 64.41618537902832 
Train [20/26] | Epoch [5/160] |	nca: 2.5953322872519493, flat: 3.0670256912708282, pod: 50.65540528297424, loss: 56.31776309013367 
Train [20/26] | Epoch [6/160] |	nca: 2.846624992787838, flat: 3.4115672409534454, pod: 52.646798849105835, loss: 58.904990911483765 
Train [20/26] | Epoch [7/160] |	nca: 2.0559906847774982, flat: 2.655272364616394, pod: 47.0573765039444, loss: 51.76863932609558 
Train [20/26] | Epoch [8/160] |	nca: 2.1871494315564632, flat: 2.639400951564312, pod: 48.181681632995605, loss: 53.00823211669922 
Train [20/26] | Epoch [9/160] |	nca: 1.887597143650055, flat: 2.3562586531043053, pod: 46.468833565711975, loss: 50.71268916130066 
Train [20/26] | Epoch [10/160] |	nca: 2.1439884305000305, flat: 2.674589216709137, pod: 49.94502902030945, loss: 54.763606548309326 
Train [20/26] | Epoch [11/160] |	nca: 2.1207397244870663, flat: 2.785758875310421, pod: 51.09768629074097, loss: 56.00418543815613 
Train [20/26] | Epoch [12/160] |	nca: 2.1801393814384937, flat: 2.4255354553461075, pod: 46.9220244884491, loss: 51.52769947052002 
Train [20/26] | Epoch [13/160] |	nca: 2.235057532787323, flat: 2.9363496154546738, pod: 49.327133893966675, loss: 54.49854111671448 
Train [20/26] | Epoch [14/160] |	nca: 1.9310594387352467, flat: 2.5161801278591156, pod: 47.012279629707336, loss: 51.459519386291504 
Train [20/26] | Epoch [15/160] |	nca: 2.329515479505062, flat: 2.739672377705574, pod: 50.18338680267334, loss: 55.25257396697998 
Train [20/26] | Epoch [16/160] |	nca: 1.9811072535812855, flat: 2.4947206750512123, pod: 45.515682339668274, loss: 49.99151027202606 
Train [20/26] | Epoch [17/160] |	nca: 1.7692123092710972, flat: 2.317477509379387, pod: 47.353010416030884, loss: 51.43970012664795 
Train [20/26] | Epoch [18/160] |	nca: 1.7726317010819912, flat: 2.0993547663092613, pod: 43.993465185165405, loss: 47.86545121669769 
Train [20/26] | Epoch [19/160] |	nca: 2.548653293401003, flat: 2.9143717736005783, pod: 49.222620725631714, loss: 54.685646057128906 
Train [20/26] | Epoch [20/160] |	nca: 2.0241693928837776, flat: 2.471935585141182, pod: 46.55131733417511, loss: 51.04742217063904 
Train [20/26] | Epoch [21/160] |	nca: 1.8277555592358112, flat: 2.587149277329445, pod: 48.33709514141083, loss: 52.751999378204346 
Train [20/26] | Epoch [22/160] |	nca: 1.6036587692797184, flat: 2.114170104265213, pod: 42.6113315820694, loss: 46.32916057109833 
Train [20/26] | Epoch [23/160] |	nca: 1.764084491878748, flat: 2.187176004052162, pod: 44.733795523643494, loss: 48.68505656719208 
Train [20/26] | Epoch [24/160] |	nca: 1.7399213016033173, flat: 2.234939858317375, pod: 44.41105246543884, loss: 48.385913372039795 
Train [20/26] | Epoch [25/160] |	nca: 1.7232785783708096, flat: 2.215108647942543, pod: 47.174790382385254, loss: 51.11317753791809 
Train [20/26] | Epoch [26/160] |	nca: 1.7826247289776802, flat: 2.2956258729100227, pod: 46.772372364997864, loss: 50.85062289237976 
Train [20/26] | Epoch [27/160] |	nca: 1.7364076636731625, flat: 2.2828434705734253, pod: 45.40025520324707, loss: 49.419506549835205 
Train [20/26] | Epoch [28/160] |	nca: 1.710697177797556, flat: 2.1380804628133774, pod: 43.23071086406708, loss: 47.07948815822601 
Train [20/26] | Epoch [29/160] |	nca: 1.6623761914670467, flat: 2.0061073154211044, pod: 42.1796760559082, loss: 45.848159074783325 
Train [20/26] | Epoch [30/160] |	nca: 1.6453688964247704, flat: 1.968784637749195, pod: 42.92076539993286, loss: 46.53491938114166 
Train [20/26] | Epoch [31/160] |	nca: 1.7792519442737103, flat: 2.2102202996611595, pod: 44.33936095237732, loss: 48.32883274555206 
Train [20/26] | Epoch [32/160] |	nca: 2.1884054094552994, flat: 2.5698475912213326, pod: 47.78599989414215, loss: 52.54425263404846 
Train [20/26] | Epoch [33/160] |	nca: 1.8471046909689903, flat: 2.3041313141584396, pod: 44.62630844116211, loss: 48.77754485607147 
Train [20/26] | Epoch [34/160] |	nca: 1.6726432591676712, flat: 2.1750339567661285, pod: 43.522252202034, loss: 47.36992907524109 
Train [20/26] | Epoch [35/160] |	nca: 1.5002652276307344, flat: 1.7990538477897644, pod: 40.876848101615906, loss: 44.17616665363312 
Train [20/26] | Epoch [36/160] |	nca: 1.5137705579400063, flat: 1.9268503412604332, pod: 42.00909686088562, loss: 45.44971776008606 
Train [20/26] | Epoch [37/160] |	nca: 1.4392910487949848, flat: 1.8241204768419266, pod: 40.23532235622406, loss: 43.49873375892639 
Train [20/26] | Epoch [38/160] |	nca: 1.6227334514260292, flat: 1.9243991151452065, pod: 41.513675689697266, loss: 45.060808420181274 
Train [20/26] | Epoch [39/160] |	nca: 1.7875314578413963, flat: 2.042139418423176, pod: 42.536983370780945, loss: 46.36665463447571 
Train [20/26] | Epoch [40/160] |	nca: 1.814947996288538, flat: 2.1800266727805138, pod: 43.358514189720154, loss: 47.35348880290985 
Train [20/26] | Epoch [41/160] |	nca: 1.5544359236955643, flat: 2.042079836130142, pod: 45.33802127838135, loss: 48.934536814689636 
Train [20/26] | Epoch [42/160] |	nca: 1.8179640509188175, flat: 2.186647742986679, pod: 44.0394481420517, loss: 48.04405951499939 
Train [20/26] | Epoch [43/160] |	nca: 1.7638349048793316, flat: 2.1298121362924576, pod: 44.14154624938965, loss: 48.03519320487976 
Train [20/26] | Epoch [44/160] |	nca: 2.073022037744522, flat: 2.489054076373577, pod: 47.21929728984833, loss: 51.781373262405396 
Train [20/26] | Epoch [45/160] |	nca: 1.9629607126116753, flat: 2.301598198711872, pod: 44.26240038871765, loss: 48.52695941925049 
Train [20/26] | Epoch [46/160] |	nca: 1.7506596446037292, flat: 2.1229459047317505, pod: 44.36373567581177, loss: 48.23734128475189 
Train [20/26] | Epoch [47/160] |	nca: 1.7089402824640274, flat: 1.9341030567884445, pod: 40.6769357919693, loss: 44.31997907161713 
Train [20/26] | Epoch [48/160] |	nca: 1.4831503368914127, flat: 1.8249532133340836, pod: 39.83755612373352, loss: 43.14565968513489 
Train [20/26] | Epoch [49/160] |	nca: 1.527268923819065, flat: 1.7505289018154144, pod: 39.342743039131165, loss: 42.620540738105774 
Train [20/26] | Epoch [50/160] |	nca: 1.7518399059772491, flat: 1.9093265533447266, pod: 42.12258005142212, loss: 45.78374695777893 
Train [20/26] | Epoch [51/160] |	nca: 1.6740448363125324, flat: 2.082039475440979, pod: 42.33283185958862, loss: 46.088916301727295 
Train [20/26] | Epoch [52/160] |	nca: 1.4495666064321995, flat: 1.800438567996025, pod: 39.423487067222595, loss: 42.673492312431335 
Train [20/26] | Epoch [53/160] |	nca: 1.5228483453392982, flat: 1.6663069389760494, pod: 38.557838916778564, loss: 41.746994495391846 
Train [20/26] | Epoch [54/160] |	nca: 1.5008776560425758, flat: 1.9688329100608826, pod: 42.20651161670685, loss: 45.67622232437134 
Train [20/26] | Epoch [55/160] |	nca: 1.6631851829588413, flat: 1.85231102257967, pod: 40.85240423679352, loss: 44.367900013923645 
Train [20/26] | Epoch [56/160] |	nca: 1.4071507304906845, flat: 1.7326771207153797, pod: 39.602861523628235, loss: 42.74268925189972 
Train [20/26] | Epoch [57/160] |	nca: 1.4056573063135147, flat: 1.6235485263168812, pod: 37.182682394981384, loss: 40.21188843250275 
Train [20/26] | Epoch [58/160] |	nca: 1.5875698700547218, flat: 1.704229824244976, pod: 38.176074385643005, loss: 41.46787464618683 
Train [20/26] | Epoch [59/160] |	nca: 1.6809572726488113, flat: 1.9775075316429138, pod: 41.096346855163574, loss: 44.75481116771698 
Train [20/26] | Epoch [60/160] |	nca: 1.6998990625143051, flat: 1.8497272059321404, pod: 38.62080907821655, loss: 42.170435667037964 
Train [20/26] | Epoch [61/160] |	nca: 1.5864403247833252, flat: 1.7125116884708405, pod: 39.17632472515106, loss: 42.475276470184326 
Train [20/26] | Epoch [62/160] |	nca: 1.3742193430662155, flat: 1.628162607550621, pod: 38.09302282333374, loss: 41.095404863357544 
Train [20/26] | Epoch [63/160] |	nca: 1.4744656831026077, flat: 1.7433440387248993, pod: 39.55977010726929, loss: 42.77757966518402 
Train [20/26] | Epoch [64/160] |	nca: 1.4313719645142555, flat: 1.5763261392712593, pod: 37.519622564315796, loss: 40.52732038497925 
Train [20/26] | Epoch [65/160] |	nca: 1.5222409330308437, flat: 1.7136684581637383, pod: 39.69017493724823, loss: 42.92608392238617 
Train [20/26] | Epoch [66/160] |	nca: 1.6701215207576752, flat: 1.7690119072794914, pod: 39.96484911441803, loss: 43.403982162475586 
Train [20/26] | Epoch [67/160] |	nca: 1.456882793456316, flat: 1.5963088795542717, pod: 37.94746816158295, loss: 41.00066018104553 
Train [20/26] | Epoch [68/160] |	nca: 1.6194678656756878, flat: 1.5392344817519188, pod: 38.42929542064667, loss: 41.58799767494202 
Train [20/26] | Epoch [69/160] |	nca: 1.5594666674733162, flat: 1.7015374153852463, pod: 38.7161728143692, loss: 41.977176785469055 
Train [20/26] | Epoch [70/160] |	nca: 1.6306909509003162, flat: 1.6099813282489777, pod: 38.74068260192871, loss: 41.98135495185852 
Train [20/26] | Epoch [71/160] |	nca: 1.3526320084929466, flat: 1.5808149352669716, pod: 37.00934541225433, loss: 39.942792654037476 
Train [20/26] | Epoch [72/160] |	nca: 1.3438239768147469, flat: 1.541077621281147, pod: 37.925071239471436, loss: 40.80997288227081 
Train [20/26] | Epoch [73/160] |	nca: 1.3915213979780674, flat: 1.4491878934204578, pod: 36.895371317863464, loss: 39.73608040809631 
Train [20/26] | Epoch [74/160] |	nca: 1.3892882317304611, flat: 1.4611379839479923, pod: 36.66498160362244, loss: 39.51540768146515 
Train [20/26] | Epoch [75/160] |	nca: 1.4359118677675724, flat: 1.4273126684129238, pod: 35.90413439273834, loss: 38.76735866069794 
Train [20/26] | Epoch [76/160] |	nca: 1.673026081174612, flat: 1.6467525959014893, pod: 37.52435874938965, loss: 40.84413778781891 
Train [20/26] | Epoch [77/160] |	nca: 1.4822734519839287, flat: 1.4988561049103737, pod: 35.506311655044556, loss: 38.487441062927246 
Train [20/26] | Epoch [78/160] |	nca: 1.4034308195114136, flat: 1.3840067610144615, pod: 35.83830714225769, loss: 38.625744462013245 
Train [20/26] | Epoch [79/160] |	nca: 1.2708678878843784, flat: 1.4734990671277046, pod: 35.854656457901, loss: 38.59902346134186 
Train [20/26] | Epoch [80/160] |	nca: 1.6234248578548431, flat: 1.2918096631765366, pod: 33.87483370304108, loss: 36.79006779193878 
Train [20/26] | Epoch [81/160] |	nca: 1.662296712398529, flat: 1.7595384269952774, pod: 38.00334584712982, loss: 41.42518103122711 
Train [20/26] | Epoch [82/160] |	nca: 1.4860502667725086, flat: 1.620808381587267, pod: 36.80211007595062, loss: 39.908968448638916 
Train [20/26] | Epoch [83/160] |	nca: 1.3934930264949799, flat: 1.2982515059411526, pod: 32.232712626457214, loss: 34.92445707321167 
Train [20/26] | Epoch [84/160] |	nca: 1.3014608025550842, flat: 1.4016538821160793, pod: 33.6183055639267, loss: 36.321420311927795 
Train [20/26] | Epoch [85/160] |	nca: 1.6925722397863865, flat: 1.3781635500490665, pod: 33.80696213245392, loss: 36.8776980638504 
Train [20/26] | Epoch [86/160] |	nca: 1.687215331941843, flat: 1.4995046332478523, pod: 35.22763109207153, loss: 38.41435086727142 
Train [20/26] | Epoch [87/160] |	nca: 1.4308324828743935, flat: 1.3514203242957592, pod: 33.54930400848389, loss: 36.33155679702759 
Train [20/26] | Epoch [88/160] |	nca: 1.4441042430698872, flat: 1.3185277692973614, pod: 32.44404196739197, loss: 35.206674337387085 
Train [20/26] | Epoch [89/160] |	nca: 1.2793812081217766, flat: 1.3743322379887104, pod: 33.092886090278625, loss: 35.746599435806274 
Train [20/26] | Epoch [90/160] |	nca: 1.3771797865629196, flat: 1.1428907066583633, pod: 30.20035970211029, loss: 32.72043025493622 
Train [20/26] | Epoch [91/160] |	nca: 1.5486639887094498, flat: 1.3223333433270454, pod: 34.2480229139328, loss: 37.11902034282684 
Train [20/26] | Epoch [92/160] |	nca: 1.3847796320915222, flat: 1.2718074582517147, pod: 32.389572858810425, loss: 35.046160101890564 
Train [20/26] | Epoch [93/160] |	nca: 1.3930063918232918, flat: 1.2175810784101486, pod: 33.07196915149689, loss: 35.68255650997162 
Train [20/26] | Epoch [94/160] |	nca: 1.4191439896821976, flat: 1.3153750821948051, pod: 33.745960116386414, loss: 36.48047912120819 
Train [20/26] | Epoch [95/160] |	nca: 1.306559532880783, flat: 1.1594924330711365, pod: 30.51198387145996, loss: 32.97803568840027 
Train [20/26] | Epoch [96/160] |	nca: 1.3573518842458725, flat: 1.1652550250291824, pod: 30.653037309646606, loss: 33.175644278526306 
Train [20/26] | Epoch [97/160] |	nca: 1.2660654559731483, flat: 1.1391754895448685, pod: 31.426857233047485, loss: 33.83209824562073 
Train [20/26] | Epoch [98/160] |	nca: 1.3429035544395447, flat: 1.2657214812934399, pod: 32.367932081222534, loss: 34.97655701637268 
Train [20/26] | Epoch [99/160] |	nca: 1.3291780166327953, flat: 1.121821079403162, pod: 30.441773533821106, loss: 32.89277255535126 
Train [20/26] | Epoch [100/160] |	nca: 1.3814140930771828, flat: 1.0958968177437782, pod: 30.088683485984802, loss: 32.56599426269531 
Train [20/26] | Epoch [101/160] |	nca: 1.3562719747424126, flat: 1.0964063443243504, pod: 29.31047260761261, loss: 31.763151049613953 
Train [20/26] | Epoch [102/160] |	nca: 1.3018668442964554, flat: 1.180231660604477, pod: 31.206292033195496, loss: 33.688390493392944 
Train [20/26] | Epoch [103/160] |	nca: 1.2066152691841125, flat: 1.0832929536700249, pod: 29.651719212532043, loss: 31.941627383232117 
Train [20/26] | Epoch [104/160] |	nca: 1.3160947225987911, flat: 1.0323858093470335, pod: 29.2299964427948, loss: 31.578476905822754 
Train [20/26] | Epoch [105/160] |	nca: 1.3155757635831833, flat: 1.0057339556515217, pod: 27.98429763317108, loss: 30.305607199668884 
Train [20/26] | Epoch [106/160] |	nca: 1.3322007730603218, flat: 0.9658568911254406, pod: 27.753755807876587, loss: 30.05181348323822 
Train [20/26] | Epoch [107/160] |	nca: 1.314092267304659, flat: 1.0242806691676378, pod: 28.25303876399994, loss: 30.59141170978546 
Train [20/26] | Epoch [108/160] |	nca: 1.3511513993144035, flat: 1.0257399342954159, pod: 30.003918766975403, loss: 32.380810260772705 
Train [20/26] | Epoch [109/160] |	nca: 1.2301701754331589, flat: 1.0382286608219147, pod: 29.03308069705963, loss: 31.30147957801819 
Train [20/26] | Epoch [110/160] |	nca: 1.2412482425570488, flat: 0.9661241099238396, pod: 27.251400470733643, loss: 29.458773016929626 
Train [20/26] | Epoch [111/160] |	nca: 1.2243655398488045, flat: 0.8674842715263367, pod: 26.78918731212616, loss: 28.88103723526001 
Train [20/26] | Epoch [112/160] |	nca: 1.33065502718091, flat: 1.0088129919022322, pod: 27.356167674064636, loss: 29.695635676383972 
Train [20/26] | Epoch [113/160] |	nca: 1.2123418673872948, flat: 0.9217548873275518, pod: 25.82119059562683, loss: 27.95528733730316 
Train [20/26] | Epoch [114/160] |	nca: 1.2754512466490269, flat: 0.9618609249591827, pod: 26.881964683532715, loss: 29.119276881217957 
Train [20/26] | Epoch [115/160] |	nca: 1.2729113847017288, flat: 0.8677264451980591, pod: 25.525124430656433, loss: 27.665762305259705 
Train [20/26] | Epoch [116/160] |	nca: 1.2513340450823307, flat: 0.8629401158541441, pod: 26.268748462200165, loss: 28.38302230834961 
Train [20/26] | Epoch [117/160] |	nca: 1.3843054957687855, flat: 0.9096716716885567, pod: 26.196034967899323, loss: 28.490012049674988 
Train [20/26] | Epoch [118/160] |	nca: 1.3795771151781082, flat: 1.0435285083949566, pod: 27.20410978794098, loss: 29.62721562385559 
Train [20/26] | Epoch [119/160] |	nca: 1.1586199142038822, flat: 0.8848555237054825, pod: 25.509145498275757, loss: 27.552620768547058 
Train [20/26] | Epoch [120/160] |	nca: 1.2288604564964771, flat: 0.8776637259870768, pod: 25.31066632270813, loss: 27.417190670967102 
Train [20/26] | Epoch [121/160] |	nca: 1.3846253231167793, flat: 0.8776071723550558, pod: 26.30778932571411, loss: 28.570021748542786 
Train [20/26] | Epoch [122/160] |	nca: 1.2194793075323105, flat: 0.8687252216041088, pod: 25.712587893009186, loss: 27.800792455673218 
Train [20/26] | Epoch [123/160] |	nca: 1.2926207296550274, flat: 0.8092214781790972, pod: 24.400142073631287, loss: 26.501984238624573 
Train [20/26] | Epoch [124/160] |	nca: 1.1954521276056767, flat: 0.7850732076913118, pod: 24.004042983055115, loss: 25.984568417072296 
Train [20/26] | Epoch [125/160] |	nca: 1.2930443100631237, flat: 0.7436770685017109, pod: 23.16587394475937, loss: 25.20259529352188 
Train [20/26] | Epoch [126/160] |	nca: 1.2486978769302368, flat: 0.7266368716955185, pod: 23.473163187503815, loss: 25.44849807024002 
Train [20/26] | Epoch [127/160] |	nca: 1.2542370930314064, flat: 0.7333349622786045, pod: 22.95641702413559, loss: 24.94398921728134 
Train [20/26] | Epoch [128/160] |	nca: 1.3093980066478252, flat: 0.8294111993163824, pod: 23.973798155784607, loss: 26.112607717514038 
Train [20/26] | Epoch [129/160] |	nca: 1.33538868278265, flat: 0.8442195821553469, pod: 24.932973742485046, loss: 27.11258226633072 
Train [20/26] | Epoch [130/160] |	nca: 1.1761771328747272, flat: 0.6618045922368765, pod: 21.905797004699707, loss: 23.74377876520157 
Train [20/26] | Epoch [131/160] |	nca: 1.2081763427704573, flat: 0.7347079087048769, pod: 22.304272949695587, loss: 24.247157275676727 
Train [20/26] | Epoch [132/160] |	nca: 1.251881368458271, flat: 0.806922560557723, pod: 23.330070197582245, loss: 25.388874173164368 
Train [20/26] | Epoch [133/160] |	nca: 1.2575089000165462, flat: 0.721226554363966, pod: 23.084347546100616, loss: 25.063083171844482 
Train [20/26] | Epoch [134/160] |	nca: 1.324812863022089, flat: 0.7363679353147745, pod: 22.066312074661255, loss: 24.12749308347702 
Train [20/26] | Epoch [135/160] |	nca: 1.1904618572443724, flat: 0.743370583280921, pod: 22.907367706298828, loss: 24.841200053691864 
Train [20/26] | Epoch [136/160] |	nca: 1.3018816746771336, flat: 0.6891239415854216, pod: 21.446039378643036, loss: 23.43704491853714 
Train [20/26] | Epoch [137/160] |	nca: 1.1980211846530437, flat: 0.707598902285099, pod: 22.240189492702484, loss: 24.145809710025787 
Train [20/26] | Epoch [138/160] |	nca: 1.1770302578806877, flat: 0.6449509542435408, pod: 20.850516378879547, loss: 22.67249757051468 
Train [20/26] | Epoch [139/160] |	nca: 1.268298450857401, flat: 0.6790829207748175, pod: 20.702351331710815, loss: 22.649732649326324 
Train [20/26] | Epoch [140/160] |	nca: 1.2182526960968971, flat: 0.6813994944095612, pod: 20.741993188858032, loss: 22.641645193099976 
Train [20/26] | Epoch [141/160] |	nca: 1.2310927249491215, flat: 0.6348876096308231, pod: 20.553349494934082, loss: 22.419329941272736 
Train [20/26] | Epoch [142/160] |	nca: 1.1498251557350159, flat: 0.6011126581579447, pod: 19.726519286632538, loss: 21.477457106113434 
Train [20/26] | Epoch [143/160] |	nca: 1.3850670568645, flat: 0.7184382434934378, pod: 21.398092448711395, loss: 23.50159788131714 
Train [20/26] | Epoch [144/160] |	nca: 1.1250976920127869, flat: 0.6485919263213873, pod: 19.932927012443542, loss: 21.706616640090942 
Train [20/26] | Epoch [145/160] |	nca: 1.2395057901740074, flat: 0.6327867675572634, pod: 20.102051079273224, loss: 21.97434365749359 
Train [20/26] | Epoch [146/160] |	nca: 1.3556781858205795, flat: 0.6536397486925125, pod: 19.624894380569458, loss: 21.63421219587326 
Train [20/26] | Epoch [147/160] |	nca: 1.2731612734496593, flat: 0.6250310149043798, pod: 19.67197722196579, loss: 21.570169508457184 
Train [20/26] | Epoch [148/160] |	nca: 1.1525976732373238, flat: 0.5597038511186838, pod: 18.323554635047913, loss: 20.035856246948242 
Train [20/26] | Epoch [149/160] |	nca: 1.2723357044160366, flat: 0.6428320482373238, pod: 19.913825154304504, loss: 21.82899284362793 
Train [20/26] | Epoch [150/160] |	nca: 1.1786585189402103, flat: 0.573232002556324, pod: 18.45103085041046, loss: 20.202921211719513 
Train [20/26] | Epoch [151/160] |	nca: 1.2307377308607101, flat: 0.6352146659046412, pod: 18.668180406093597, loss: 20.53413277864456 
Train [20/26] | Epoch [152/160] |	nca: 1.1780677884817123, flat: 0.5811308845877647, pod: 18.780969858169556, loss: 20.540168583393097 
Train [20/26] | Epoch [153/160] |	nca: 1.266176264733076, flat: 0.5935311149805784, pod: 18.28914302587509, loss: 20.14885050058365 
Train [20/26] | Epoch [154/160] |	nca: 1.2641446962952614, flat: 0.5854490231722593, pod: 18.092273473739624, loss: 19.94186705350876 
Train [20/26] | Epoch [155/160] |	nca: 1.3202934749424458, flat: 0.5932475756853819, pod: 18.621777832508087, loss: 20.535318791866302 
Train [20/26] | Epoch [156/160] |	nca: 1.1490341015160084, flat: 0.5685407239943743, pod: 17.513402462005615, loss: 19.23097735643387 
Train [20/26] | Epoch [157/160] |	nca: 1.1771160326898098, flat: 0.6082552894949913, pod: 18.71684020757675, loss: 20.5022115111351 
Train [20/26] | Epoch [158/160] |	nca: 1.1513672694563866, flat: 0.6191713074222207, pod: 18.651216089725494, loss: 20.421754837036133 
Train [20/26] | Epoch [159/160] |	nca: 1.3323639370501041, flat: 0.6458709184080362, pod: 19.476770401000977, loss: 21.45500499010086 
Train [20/26] | Epoch [160/160] |	nca: 1.2979253120720387, flat: 0.5712455995380878, pod: 17.662257850170135, loss: 19.531428813934326 
Fine-tuning
Building & updating memory.
Train [20/26] | Epoch [161/180] |	nca: 1.0219668112695217, flat: 0.8743974305689335, pod: 18.10713243484497, loss: 20.003496646881104 
Train [20/26] | Epoch [162/180] |	nca: 0.682847311720252, flat: 0.9051165729761124, pod: 18.563339293003082, loss: 20.151302814483643 
Train [20/26] | Epoch [163/180] |	nca: 0.5925953425467014, flat: 0.9367605820298195, pod: 18.84127175807953, loss: 20.370627641677856 
Train [20/26] | Epoch [164/180] |	nca: 0.5783700663596392, flat: 0.9109297916293144, pod: 18.832134008407593, loss: 20.321434020996094 
Train [20/26] | Epoch [165/180] |	nca: 0.5351018104702234, flat: 0.895839162170887, pod: 18.531349301338196, loss: 19.962290287017822 
Train [20/26] | Epoch [166/180] |	nca: 0.5206655412912369, flat: 0.918107133358717, pod: 18.48292076587677, loss: 19.921693444252014 
Train [20/26] | Epoch [167/180] |	nca: 0.5007567033171654, flat: 0.8676535785198212, pod: 18.12761116027832, loss: 19.496021509170532 
Train [20/26] | Epoch [168/180] |	nca: 0.5429410934448242, flat: 0.9462632276117802, pod: 18.881950974464417, loss: 20.371155381202698 
Train [20/26] | Epoch [169/180] |	nca: 0.5270473025739193, flat: 0.8911172971129417, pod: 18.288538217544556, loss: 19.706702709197998 
Train [20/26] | Epoch [170/180] |	nca: 0.5468896627426147, flat: 0.9248305931687355, pod: 18.93309235572815, loss: 20.404812455177307 
Train [20/26] | Epoch [171/180] |	nca: 0.5213499143719673, flat: 0.8916543982923031, pod: 18.826963543891907, loss: 20.239967942237854 
Train [20/26] | Epoch [172/180] |	nca: 0.5027307346463203, flat: 0.9033593311905861, pod: 18.466143488883972, loss: 19.872233390808105 
Train [20/26] | Epoch [173/180] |	nca: 0.477176321670413, flat: 0.9091605916619301, pod: 18.478568077087402, loss: 19.86490523815155 
Train [20/26] | Epoch [174/180] |	nca: 0.4588242191821337, flat: 0.8809614330530167, pod: 18.713005661964417, loss: 20.052791357040405 
Train [20/26] | Epoch [175/180] |	nca: 0.49745185673236847, flat: 0.9085843898355961, pod: 18.669527053833008, loss: 20.075563073158264 
Train [20/26] | Epoch [176/180] |	nca: 0.496514480561018, flat: 0.9223166741430759, pod: 19.02276384830475, loss: 20.44159483909607 
Train [20/26] | Epoch [177/180] |	nca: 0.4674013517796993, flat: 0.8885877765715122, pod: 18.5967777967453, loss: 19.9527667760849 
Train [20/26] | Epoch [178/180] |	nca: 0.4489867817610502, flat: 0.8806406408548355, pod: 18.472819328308105, loss: 19.802446961402893 
Train [20/26] | Epoch [179/180] |	nca: 0.49086558632552624, flat: 0.9376705326139927, pod: 19.27491295337677, loss: 20.703449249267578 
Train [20/26] | Epoch [180/180] |	nca: 0.49201974272727966, flat: 0.9178433828055859, pod: 18.396838068962097, loss: 19.806701183319092 
after task
Building & updating memory.
after task
Eval on 0->88.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6127499999999999.
Current acc: {'total': 0.54, '00-09': 0.606, '10-19': 0.535, '20-29': 0.469, '30-39': 0.493, '40-49': 0.545, '50-59': 0.546, '60-69': 0.469, '70-79': 0.599, '80-89': 0.609}.
Avg inc acc top5: 0.86215.
Current acc top5: {'total': 0.821}.
Forgetting: 0.1541.
Cord metric: 0.60.
Old accuracy: 0.54, mean: 0.60.
New accuracy: 0.72, mean: 0.64.
================Task 20 Start!================
Testing on False unseen tasks (max class = 90).
Set memory of size: 1760.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 20 Training!================
The training samples number: 2760
Train on 88->90.
train task
nb 2760.
Train [21/26] | Epoch [1/160] |	nca: 11.207206174731255, flat: 5.676036931574345, pod: 60.978835582733154, loss: 77.86207866668701 
Train [21/26] | Epoch [2/160] |	nca: 6.790115520358086, flat: 4.98907046020031, pod: 63.36819672584534, loss: 75.14738249778748 
Train [21/26] | Epoch [3/160] |	nca: 5.452457875013351, flat: 4.430489227175713, pod: 62.14553451538086, loss: 72.0284812450409 
Train [21/26] | Epoch [4/160] |	nca: 4.242327764630318, flat: 3.862010434269905, pod: 58.770315408706665, loss: 66.87465357780457 
Train [21/26] | Epoch [5/160] |	nca: 3.667654849588871, flat: 3.289224609732628, pod: 55.07845449447632, loss: 62.03533387184143 
Train [21/26] | Epoch [6/160] |	nca: 3.340878613293171, flat: 2.9045967906713486, pod: 52.24657845497131, loss: 58.492053508758545 
Train [21/26] | Epoch [7/160] |	nca: 3.016886353492737, flat: 2.8125593960285187, pod: 53.112685680389404, loss: 58.942131757736206 
Train [21/26] | Epoch [8/160] |	nca: 3.0263271182775497, flat: 2.926339514553547, pod: 55.69259786605835, loss: 61.64526438713074 
Train [21/26] | Epoch [9/160] |	nca: 2.8449930399656296, flat: 2.659839406609535, pod: 50.79606366157532, loss: 56.300896406173706 
Train [21/26] | Epoch [10/160] |	nca: 2.7499805986881256, flat: 2.7742494493722916, pod: 52.409698247909546, loss: 57.9339280128479 
Train [21/26] | Epoch [11/160] |	nca: 2.718844451010227, flat: 2.3295628428459167, pod: 47.45156812667847, loss: 52.49997591972351 
Train [21/26] | Epoch [12/160] |	nca: 2.583629384636879, flat: 2.44846747815609, pod: 49.17594265937805, loss: 54.2080397605896 
Train [21/26] | Epoch [13/160] |	nca: 2.8510673865675926, flat: 2.6239146888256073, pod: 50.44263672828674, loss: 55.9176185131073 
Train [21/26] | Epoch [14/160] |	nca: 3.232003502547741, flat: 3.0600738525390625, pod: 55.8520667552948, loss: 62.14414358139038 
Train [21/26] | Epoch [15/160] |	nca: 2.9588261991739273, flat: 2.6456771343946457, pod: 51.394224882125854, loss: 56.99872803688049 
Train [21/26] | Epoch [16/160] |	nca: 2.6305493265390396, flat: 2.6301906928420067, pod: 49.99521851539612, loss: 55.255958795547485 
Train [21/26] | Epoch [17/160] |	nca: 2.5559290647506714, flat: 2.64644967764616, pod: 50.114588499069214, loss: 55.31696677207947 
Train [21/26] | Epoch [18/160] |	nca: 2.194001667201519, flat: 2.3406092822551727, pod: 47.782461404800415, loss: 52.31707215309143 
Train [21/26] | Epoch [19/160] |	nca: 2.5463672131299973, flat: 2.3754664957523346, pod: 49.6390722990036, loss: 54.560906171798706 
Train [21/26] | Epoch [20/160] |	nca: 2.6229277178645134, flat: 2.462528869509697, pod: 49.73326587677002, loss: 54.81872200965881 
Train [21/26] | Epoch [21/160] |	nca: 2.6608899980783463, flat: 2.5859824046492577, pod: 49.844128489494324, loss: 55.09100079536438 
Train [21/26] | Epoch [22/160] |	nca: 2.7851265594363213, flat: 2.737738274037838, pod: 50.70464110374451, loss: 56.227505922317505 
Train [21/26] | Epoch [23/160] |	nca: 2.659381076693535, flat: 2.6757970675826073, pod: 52.396451473236084, loss: 57.731629848480225 
Train [21/26] | Epoch [24/160] |	nca: 2.6784563288092613, flat: 2.744936302304268, pod: 51.68116068840027, loss: 57.10455322265625 
Train [21/26] | Epoch [25/160] |	nca: 2.6457494646310806, flat: 2.6777011826634407, pod: 51.43989884853363, loss: 56.763349771499634 
Train [21/26] | Epoch [26/160] |	nca: 2.4443268328905106, flat: 2.4821897596120834, pod: 50.375757694244385, loss: 55.30227494239807 
Train [21/26] | Epoch [27/160] |	nca: 2.091098591685295, flat: 2.114985764026642, pod: 45.89326322078705, loss: 50.099347710609436 
Train [21/26] | Epoch [28/160] |	nca: 2.235562562942505, flat: 2.2340119555592537, pod: 47.084951996803284, loss: 51.554526567459106 
Train [21/26] | Epoch [29/160] |	nca: 2.2500440925359726, flat: 2.158386267721653, pod: 46.654616594314575, loss: 51.06304693222046 
Train [21/26] | Epoch [30/160] |	nca: 2.1150600872933865, flat: 2.180178962647915, pod: 45.88740670681, loss: 50.18264603614807 
Train [21/26] | Epoch [31/160] |	nca: 2.3345914408564568, flat: 2.293852984905243, pod: 46.89602196216583, loss: 51.524466037750244 
Train [21/26] | Epoch [32/160] |	nca: 2.434727542102337, flat: 2.2862773463129997, pod: 46.60419797897339, loss: 51.32520318031311 
Train [21/26] | Epoch [33/160] |	nca: 2.3735204115509987, flat: 2.283697433769703, pod: 47.218794107437134, loss: 51.87601161003113 
Train [21/26] | Epoch [34/160] |	nca: 2.37199779599905, flat: 2.312181808054447, pod: 48.2015814781189, loss: 52.88576078414917 
Train [21/26] | Epoch [35/160] |	nca: 2.359896346926689, flat: 2.2881943210959435, pod: 47.678006649017334, loss: 52.32609724998474 
Train [21/26] | Epoch [36/160] |	nca: 2.253998063504696, flat: 2.303424872457981, pod: 47.560744524002075, loss: 52.11816763877869 
Train [21/26] | Epoch [37/160] |	nca: 2.043350212275982, flat: 2.1548090800642967, pod: 45.169199109077454, loss: 49.367358684539795 
Train [21/26] | Epoch [38/160] |	nca: 2.143656615167856, flat: 1.9808004721999168, pod: 43.546411991119385, loss: 47.67086935043335 
Train [21/26] | Epoch [39/160] |	nca: 2.0109102576971054, flat: 1.893195278942585, pod: 42.171868443489075, loss: 46.07597374916077 
Train [21/26] | Epoch [40/160] |	nca: 2.0300486721098423, flat: 1.9694903865456581, pod: 43.55898880958557, loss: 47.55852782726288 
Train [21/26] | Epoch [41/160] |	nca: 1.8928819969296455, flat: 1.8916053399443626, pod: 42.62236678600311, loss: 46.40685427188873 
Train [21/26] | Epoch [42/160] |	nca: 2.1956473402678967, flat: 2.033612333238125, pod: 43.69827461242676, loss: 47.92753446102142 
Train [21/26] | Epoch [43/160] |	nca: 2.1161087565124035, flat: 1.938126876950264, pod: 42.969847083091736, loss: 47.02408289909363 
Train [21/26] | Epoch [44/160] |	nca: 2.159551002085209, flat: 1.99676975607872, pod: 43.69356083869934, loss: 47.849881052970886 
Train [21/26] | Epoch [45/160] |	nca: 2.248091220855713, flat: 2.021976739168167, pod: 43.18110239505768, loss: 47.451170444488525 
Train [21/26] | Epoch [46/160] |	nca: 2.2029228284955025, flat: 2.074302963912487, pod: 44.51311802864075, loss: 48.79034399986267 
Train [21/26] | Epoch [47/160] |	nca: 1.9782500863075256, flat: 2.0675116181373596, pod: 45.75159049034119, loss: 49.797351360321045 
Train [21/26] | Epoch [48/160] |	nca: 2.0174679681658745, flat: 2.0260778665542603, pod: 44.26761841773987, loss: 48.31116437911987 
Train [21/26] | Epoch [49/160] |	nca: 1.8512133210897446, flat: 2.0144427940249443, pod: 44.776190400123596, loss: 48.641845703125 
Train [21/26] | Epoch [50/160] |	nca: 2.142435312271118, flat: 1.8605821132659912, pod: 43.54066348075867, loss: 47.543681263923645 
Train [21/26] | Epoch [51/160] |	nca: 2.0414309203624725, flat: 1.9406967833638191, pod: 42.47892451286316, loss: 46.46105217933655 
Train [21/26] | Epoch [52/160] |	nca: 1.9409151040017605, flat: 1.8630998879671097, pod: 41.72398543357849, loss: 45.528000473976135 
Train [21/26] | Epoch [53/160] |	nca: 1.9235320501029491, flat: 1.836393989622593, pod: 42.31061637401581, loss: 46.07054162025452 
Train [21/26] | Epoch [54/160] |	nca: 1.9538253396749496, flat: 1.7505724355578423, pod: 40.91557788848877, loss: 44.619975566864014 
Train [21/26] | Epoch [55/160] |	nca: 1.9020806178450584, flat: 1.6970663890242577, pod: 39.41391408443451, loss: 43.01306140422821 
Train [21/26] | Epoch [56/160] |	nca: 1.9184889309108257, flat: 1.8006751090288162, pod: 41.637691497802734, loss: 45.356855392456055 
Train [21/26] | Epoch [57/160] |	nca: 1.8282632566988468, flat: 1.765629731118679, pod: 41.95275282859802, loss: 45.546645641326904 
Train [21/26] | Epoch [58/160] |	nca: 2.0707502774894238, flat: 1.9201863035559654, pod: 41.9056431055069, loss: 45.89657998085022 
Train [21/26] | Epoch [59/160] |	nca: 1.7881603054702282, flat: 1.6350213885307312, pod: 40.63544833660126, loss: 44.058629870414734 
Train [21/26] | Epoch [60/160] |	nca: 1.9233794175088406, flat: 1.6068884208798409, pod: 39.00492012500763, loss: 42.53518795967102 
Train [21/26] | Epoch [61/160] |	nca: 1.9307375997304916, flat: 1.6713430434465408, pod: 40.29181969165802, loss: 43.89390003681183 
Train [21/26] | Epoch [62/160] |	nca: 1.9525191970169544, flat: 1.7405240051448345, pod: 41.42214548587799, loss: 45.11518836021423 
Train [21/26] | Epoch [63/160] |	nca: 1.8519359230995178, flat: 1.6824693903326988, pod: 40.35748374462128, loss: 43.89188873767853 
Train [21/26] | Epoch [64/160] |	nca: 1.9795105122029781, flat: 1.6969081461429596, pod: 40.61392796039581, loss: 44.29034650325775 
Train [21/26] | Epoch [65/160] |	nca: 2.0522802770137787, flat: 1.8570678308606148, pod: 41.64075994491577, loss: 45.550108432769775 
Train [21/26] | Epoch [66/160] |	nca: 2.0966712199151516, flat: 1.6937489546835423, pod: 40.11980938911438, loss: 43.910229563713074 
Train [21/26] | Epoch [67/160] |	nca: 1.889275748282671, flat: 1.7177545949816704, pod: 40.386849999427795, loss: 43.99388027191162 
Train [21/26] | Epoch [68/160] |	nca: 1.933121733367443, flat: 1.8225095495581627, pod: 41.621904134750366, loss: 45.377535581588745 
Train [21/26] | Epoch [69/160] |	nca: 1.7860522642731667, flat: 1.619871810078621, pod: 39.42328178882599, loss: 42.82920563220978 
Train [21/26] | Epoch [70/160] |	nca: 1.7673674784600735, flat: 1.487205233424902, pod: 37.08111536502838, loss: 40.33568823337555 
Train [21/26] | Epoch [71/160] |	nca: 1.8582538738846779, flat: 1.6260562390089035, pod: 38.31051182746887, loss: 41.794822335243225 
Train [21/26] | Epoch [72/160] |	nca: 1.9142948910593987, flat: 1.4715596996247768, pod: 36.89702236652374, loss: 40.2828768491745 
Train [21/26] | Epoch [73/160] |	nca: 1.7592440247535706, flat: 1.5370609052479267, pod: 37.526031613349915, loss: 40.82233643531799 
Train [21/26] | Epoch [74/160] |	nca: 1.818924330174923, flat: 1.462008509784937, pod: 36.87710738182068, loss: 40.158040165901184 
Train [21/26] | Epoch [75/160] |	nca: 1.7942452542483807, flat: 1.6147062703967094, pod: 39.263514161109924, loss: 42.67246603965759 
Train [21/26] | Epoch [76/160] |	nca: 1.870838113129139, flat: 1.427533008158207, pod: 37.1082581281662, loss: 40.40662908554077 
Train [21/26] | Epoch [77/160] |	nca: 1.9428261369466782, flat: 1.4941047951579094, pod: 36.16067934036255, loss: 39.597610116004944 
Train [21/26] | Epoch [78/160] |	nca: 1.8029431886970997, flat: 1.4800356477499008, pod: 36.48403358459473, loss: 39.7670122385025 
Train [21/26] | Epoch [79/160] |	nca: 1.8757990151643753, flat: 1.5064500607550144, pod: 37.8368376493454, loss: 41.21908664703369 
Train [21/26] | Epoch [80/160] |	nca: 1.7004922144114971, flat: 1.463010262697935, pod: 36.03301012516022, loss: 39.1965126991272 
Train [21/26] | Epoch [81/160] |	nca: 1.7951715588569641, flat: 1.5274414010345936, pod: 38.47068536281586, loss: 41.79329872131348 
Train [21/26] | Epoch [82/160] |	nca: 1.8366733267903328, flat: 1.521510113030672, pod: 38.41169250011444, loss: 41.7698757648468 
Train [21/26] | Epoch [83/160] |	nca: 1.7280205339193344, flat: 1.3670171201229095, pod: 35.584412813186646, loss: 38.67945051193237 
Train [21/26] | Epoch [84/160] |	nca: 1.665737546980381, flat: 1.3210678398609161, pod: 34.62727439403534, loss: 37.61407995223999 
Train [21/26] | Epoch [85/160] |	nca: 1.8264517784118652, flat: 1.4087702110409737, pod: 35.53413546085358, loss: 38.769357323646545 
Train [21/26] | Epoch [86/160] |	nca: 1.5939490124583244, flat: 1.2917869426310062, pod: 35.243786096572876, loss: 38.12952196598053 
Train [21/26] | Epoch [87/160] |	nca: 1.7858137339353561, flat: 1.3564492911100388, pod: 35.14285457134247, loss: 38.285117506980896 
Train [21/26] | Epoch [88/160] |	nca: 1.6962779015302658, flat: 1.302544292062521, pod: 34.85717582702637, loss: 37.855997920036316 
Train [21/26] | Epoch [89/160] |	nca: 1.6603335663676262, flat: 1.3530730232596397, pod: 34.75583624839783, loss: 37.76924264431 
Train [21/26] | Epoch [90/160] |	nca: 1.7707931213080883, flat: 1.4457548819482327, pod: 36.74951171875, loss: 39.96605956554413 
Train [21/26] | Epoch [91/160] |	nca: 1.8597397953271866, flat: 1.3664293549954891, pod: 35.86922550201416, loss: 39.09539461135864 
Train [21/26] | Epoch [92/160] |	nca: 1.774434857070446, flat: 1.4083325564861298, pod: 36.780648827552795, loss: 39.9634165763855 
Train [21/26] | Epoch [93/160] |	nca: 1.7194445133209229, flat: 1.2244529277086258, pod: 33.59434640407562, loss: 36.538243770599365 
Train [21/26] | Epoch [94/160] |	nca: 1.6696120090782642, flat: 1.1662607230246067, pod: 32.59961295127869, loss: 35.43548560142517 
Train [21/26] | Epoch [95/160] |	nca: 1.6558495797216892, flat: 1.174928143620491, pod: 31.99239933490753, loss: 34.823177099227905 
Train [21/26] | Epoch [96/160] |	nca: 1.753272794187069, flat: 1.2916760072112083, pod: 34.23781073093414, loss: 37.28275942802429 
Train [21/26] | Epoch [97/160] |	nca: 1.7569899559020996, flat: 1.405556246638298, pod: 36.14377546310425, loss: 39.30632138252258 
Train [21/26] | Epoch [98/160] |	nca: 1.8393053114414215, flat: 1.2587181963026524, pod: 32.90603482723236, loss: 36.004058599472046 
Train [21/26] | Epoch [99/160] |	nca: 1.744835738092661, flat: 1.228408008813858, pod: 32.44627094268799, loss: 35.419514894485474 
Train [21/26] | Epoch [100/160] |	nca: 1.798632264137268, flat: 1.3149055652320385, pod: 33.36491405963898, loss: 36.47845160961151 
Train [21/26] | Epoch [101/160] |	nca: 1.5353925600647926, flat: 1.2028502598404884, pod: 33.2066775560379, loss: 35.94492065906525 
Train [21/26] | Epoch [102/160] |	nca: 1.715776301920414, flat: 1.1675655208528042, pod: 33.125996112823486, loss: 36.0093377828598 
Train [21/26] | Epoch [103/160] |	nca: 1.537790983915329, flat: 1.095004253089428, pod: 31.337769746780396, loss: 33.97056484222412 
Train [21/26] | Epoch [104/160] |	nca: 1.7248436845839024, flat: 1.147134941071272, pod: 31.389171719551086, loss: 34.26115024089813 
Train [21/26] | Epoch [105/160] |	nca: 1.6726032122969627, flat: 1.1634716279804707, pod: 31.247266054153442, loss: 34.083340883255005 
Train [21/26] | Epoch [106/160] |	nca: 1.6170473210513592, flat: 1.0480691008269787, pod: 29.799805641174316, loss: 32.464921951293945 
Train [21/26] | Epoch [107/160] |	nca: 1.7743080332875252, flat: 1.113601230084896, pod: 32.16463840007782, loss: 35.052547574043274 
Train [21/26] | Epoch [108/160] |	nca: 1.6811641156673431, flat: 1.0766360312700272, pod: 30.91067063808441, loss: 33.66847062110901 
Train [21/26] | Epoch [109/160] |	nca: 1.5199617259204388, flat: 0.9969329908490181, pod: 29.378398060798645, loss: 31.89529252052307 
Train [21/26] | Epoch [110/160] |	nca: 1.580388966947794, flat: 1.082809291779995, pod: 30.794856071472168, loss: 33.458054423332214 
Train [21/26] | Epoch [111/160] |	nca: 1.5867010094225407, flat: 0.9916269890964031, pod: 30.366498827934265, loss: 32.94482696056366 
Train [21/26] | Epoch [112/160] |	nca: 1.6223442666232586, flat: 1.0465396977961063, pod: 30.017666459083557, loss: 32.68655025959015 
Train [21/26] | Epoch [113/160] |	nca: 1.6095473319292068, flat: 0.909071234986186, pod: 27.667184233665466, loss: 30.185802817344666 
Train [21/26] | Epoch [114/160] |	nca: 1.5787962824106216, flat: 0.9540872797369957, pod: 27.818990230560303, loss: 30.351873755455017 
Train [21/26] | Epoch [115/160] |	nca: 1.541972778737545, flat: 0.9964502584189177, pod: 29.570833325386047, loss: 32.1092563867569 
Train [21/26] | Epoch [116/160] |	nca: 1.5099627263844013, flat: 0.9004897158592939, pod: 27.16457724571228, loss: 29.575029611587524 
Train [21/26] | Epoch [117/160] |	nca: 1.5739128105342388, flat: 0.9327172841876745, pod: 27.84244668483734, loss: 30.349076628684998 
Train [21/26] | Epoch [118/160] |	nca: 1.6281469352543354, flat: 0.8578434064984322, pod: 26.579064786434174, loss: 29.06505513191223 
Train [21/26] | Epoch [119/160] |	nca: 1.5511233434081078, flat: 0.9228557534515858, pod: 27.65413522720337, loss: 30.128114223480225 
Train [21/26] | Epoch [120/160] |	nca: 1.4862031042575836, flat: 0.8471323382109404, pod: 26.652677059173584, loss: 28.98601245880127 
Train [21/26] | Epoch [121/160] |	nca: 1.7196072116494179, flat: 0.8430781345814466, pod: 26.902287006378174, loss: 29.464972376823425 
Train [21/26] | Epoch [122/160] |	nca: 1.5336236618459225, flat: 0.8447802662849426, pod: 27.00674879550934, loss: 29.38515281677246 
Train [21/26] | Epoch [123/160] |	nca: 1.5869899056851864, flat: 0.8069102372974157, pod: 26.45441961288452, loss: 28.84831988811493 
Train [21/26] | Epoch [124/160] |	nca: 1.5684313774108887, flat: 0.8804929237812757, pod: 27.08977782726288, loss: 29.5387020111084 
Train [21/26] | Epoch [125/160] |	nca: 1.6685352362692356, flat: 0.8036908563226461, pod: 26.154769778251648, loss: 28.62699580192566 
Train [21/26] | Epoch [126/160] |	nca: 1.5695215463638306, flat: 0.7817117348313332, pod: 25.311359643936157, loss: 27.662593126296997 
Train [21/26] | Epoch [127/160] |	nca: 1.5542085580527782, flat: 0.7588739898055792, pod: 24.3246688246727, loss: 26.63775146007538 
Train [21/26] | Epoch [128/160] |	nca: 1.5441116020083427, flat: 0.762245237827301, pod: 25.45595544576645, loss: 27.762312293052673 
Train [21/26] | Epoch [129/160] |	nca: 1.4911437891423702, flat: 0.7060902006924152, pod: 23.96394443511963, loss: 26.161178410053253 
Train [21/26] | Epoch [130/160] |	nca: 1.5661609657108784, flat: 0.7751101385802031, pod: 24.58921205997467, loss: 26.93048322200775 
Train [21/26] | Epoch [131/160] |	nca: 1.539282489567995, flat: 0.8162283934652805, pod: 25.851047813892365, loss: 28.20655882358551 
Train [21/26] | Epoch [132/160] |	nca: 1.5534624867141247, flat: 0.7044290024787188, pod: 22.943908989429474, loss: 25.2018004655838 
Train [21/26] | Epoch [133/160] |	nca: 1.626009464263916, flat: 0.715036679059267, pod: 23.65803152322769, loss: 25.999077677726746 
Train [21/26] | Epoch [134/160] |	nca: 1.521250568330288, flat: 0.6799630858004093, pod: 22.53582501411438, loss: 24.737038731575012 
Train [21/26] | Epoch [135/160] |	nca: 1.5563628152012825, flat: 0.7241602037101984, pod: 23.654285550117493, loss: 25.934808492660522 
Train [21/26] | Epoch [136/160] |	nca: 1.5327185280621052, flat: 0.7260883543640375, pod: 23.855855584144592, loss: 26.114662647247314 
Train [21/26] | Epoch [137/160] |	nca: 1.5078220777213573, flat: 0.7140060570091009, pod: 23.136757969856262, loss: 25.35858589410782 
Train [21/26] | Epoch [138/160] |	nca: 1.5243123434484005, flat: 0.6059568244963884, pod: 21.398053288459778, loss: 23.52832269668579 
Train [21/26] | Epoch [139/160] |	nca: 1.5122526697814465, flat: 0.620648255571723, pod: 20.858043789863586, loss: 22.990944743156433 
Train [21/26] | Epoch [140/160] |	nca: 1.5118756517767906, flat: 0.6350083258002996, pod: 21.53765892982483, loss: 23.684542953968048 
Train [21/26] | Epoch [141/160] |	nca: 1.5717632956802845, flat: 0.594453576952219, pod: 20.958415806293488, loss: 23.12463253736496 
Train [21/26] | Epoch [142/160] |	nca: 1.5047321990132332, flat: 0.622527027502656, pod: 21.198605179786682, loss: 23.325864374637604 
Train [21/26] | Epoch [143/160] |	nca: 1.4701167829334736, flat: 0.555407177656889, pod: 20.590874135494232, loss: 22.616398334503174 
Train [21/26] | Epoch [144/160] |	nca: 1.4812252596020699, flat: 0.5740874614566565, pod: 20.47131597995758, loss: 22.52662855386734 
Train [21/26] | Epoch [145/160] |	nca: 1.5311186276376247, flat: 0.6232402548193932, pod: 20.692851126194, loss: 22.847210347652435 
Train [21/26] | Epoch [146/160] |	nca: 1.6544014289975166, flat: 0.5984936989843845, pod: 20.51954162120819, loss: 22.772436678409576 
Train [21/26] | Epoch [147/160] |	nca: 1.5434896275401115, flat: 0.5869449395686388, pod: 20.328747272491455, loss: 22.45918172597885 
Train [21/26] | Epoch [148/160] |	nca: 1.5488137491047382, flat: 0.5920233046635985, pod: 20.575417816638947, loss: 22.716254830360413 
Train [21/26] | Epoch [149/160] |	nca: 1.4112847447395325, flat: 0.5659597385674715, pod: 19.80502164363861, loss: 21.78226602077484 
Train [21/26] | Epoch [150/160] |	nca: 1.422982081770897, flat: 0.5846260581165552, pod: 20.25502771139145, loss: 22.26263588666916 
Train [21/26] | Epoch [151/160] |	nca: 1.6498848386108875, flat: 0.6009388081729412, pod: 20.592487573623657, loss: 22.843311369419098 
Train [21/26] | Epoch [152/160] |	nca: 1.5218135751783848, flat: 0.5827417504042387, pod: 20.05255377292633, loss: 22.157109081745148 
Train [21/26] | Epoch [153/160] |	nca: 1.4607140198349953, flat: 0.5783220864832401, pod: 19.572710812091827, loss: 21.611746609210968 
Train [21/26] | Epoch [154/160] |	nca: 1.506224025040865, flat: 0.49149982444942, pod: 18.357501447200775, loss: 20.355225265026093 
Train [21/26] | Epoch [155/160] |	nca: 1.5376268662512302, flat: 0.5740023627877235, pod: 19.72804683446884, loss: 21.83967626094818 
Train [21/26] | Epoch [156/160] |	nca: 1.5970574952661991, flat: 0.5395440142601728, pod: 19.43801724910736, loss: 21.574618756771088 
Train [21/26] | Epoch [157/160] |	nca: 1.4455768913030624, flat: 0.5524047128856182, pod: 19.55598533153534, loss: 21.553966999053955 
Train [21/26] | Epoch [158/160] |	nca: 1.4839578084647655, flat: 0.583444694057107, pod: 19.86757516860962, loss: 21.934977531433105 
Train [21/26] | Epoch [159/160] |	nca: 1.5092880055308342, flat: 0.5890478808432817, pod: 20.254214584827423, loss: 22.352550327777863 
Train [21/26] | Epoch [160/160] |	nca: 1.5877573601901531, flat: 0.530023880302906, pod: 18.646226227283478, loss: 20.764007687568665 
Fine-tuning
Building & updating memory.
Train [21/26] | Epoch [161/180] |	nca: 1.1746139079332352, flat: 1.0986856371164322, pod: 20.51843810081482, loss: 22.79173767566681 
Train [21/26] | Epoch [162/180] |	nca: 1.4108258746564388, flat: 1.212716318666935, pod: 20.645371079444885, loss: 23.26891326904297 
Train [21/26] | Epoch [163/180] |	nca: 1.5331634879112244, flat: 1.1003876011818647, pod: 20.625149369239807, loss: 23.258700370788574 
Train [21/26] | Epoch [164/180] |	nca: 1.3242455869913101, flat: 1.2259206883609295, pod: 20.854154109954834, loss: 23.40432047843933 
Train [21/26] | Epoch [165/180] |	nca: 1.8809375278651714, flat: 1.466100312769413, pod: 21.88400936126709, loss: 25.23104727268219 
Train [21/26] | Epoch [166/180] |	nca: 3.5729587450623512, flat: 1.0971780680119991, pod: 21.272501349449158, loss: 25.94263792037964 
Train [21/26] | Epoch [167/180] |	nca: 3.257309205830097, flat: 1.213615145534277, pod: 20.959967017173767, loss: 25.430891036987305 
Train [21/26] | Epoch [168/180] |	nca: 3.456512473523617, flat: 0.9359701592475176, pod: 20.19213342666626, loss: 24.58461594581604 
Train [21/26] | Epoch [169/180] |	nca: 2.9763662964105606, flat: 1.1257157735526562, pod: 21.47813642024994, loss: 25.58021831512451 
Train [21/26] | Epoch [170/180] |	nca: 3.092867024242878, flat: 1.1308665573596954, pod: 21.14289391040802, loss: 25.36662745475769 
Train [21/26] | Epoch [171/180] |	nca: 2.317879304289818, flat: 1.1689550466835499, pod: 20.85266214609146, loss: 24.339496612548828 
Train [21/26] | Epoch [172/180] |	nca: 1.903895165771246, flat: 1.1004039607942104, pod: 21.627041220664978, loss: 24.63134014606476 
Train [21/26] | Epoch [173/180] |	nca: 3.1849906370043755, flat: 1.235065408051014, pod: 21.49548703432083, loss: 25.91554319858551 
Train [21/26] | Epoch [174/180] |	nca: 4.608583435416222, flat: 1.1069805175065994, pod: 21.35453772544861, loss: 27.070101737976074 
Train [21/26] | Epoch [175/180] |	nca: 2.509990081191063, flat: 1.1647409163415432, pod: 21.756428480148315, loss: 25.431159257888794 
Train [21/26] | Epoch [176/180] |	nca: 2.2007772400975227, flat: 1.1522331275045872, pod: 20.99895465373993, loss: 24.351964712142944 
Train [21/26] | Epoch [177/180] |	nca: 2.4032567366957664, flat: 1.077283050864935, pod: 20.16652673482895, loss: 23.647066473960876 
Train [21/26] | Epoch [178/180] |	nca: 2.2164153680205345, flat: 1.325743854045868, pod: 22.605571746826172, loss: 26.147730946540833 
Train [21/26] | Epoch [179/180] |	nca: 1.945997692644596, flat: 1.1082853972911835, pod: 20.663711428642273, loss: 23.717994809150696 
Train [21/26] | Epoch [180/180] |	nca: 1.5558483004570007, flat: 1.32082225009799, pod: 22.560481429100037, loss: 25.4371520280838 
after task
Building & updating memory.
after task
Eval on 0->90.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6085714285714285.
Current acc: {'total': 0.525, '00-09': 0.589, '10-19': 0.52, '20-29': 0.462, '30-39': 0.483, '40-49': 0.539, '50-59': 0.542, '60-69': 0.45, '70-79': 0.562, '80-89': 0.577}.
Avg inc acc top5: 0.8597619047619047.
Current acc top5: {'total': 0.812}.
Forgetting: 0.1688.
Cord metric: 0.59.
Old accuracy: 0.52, mean: 0.60.
New accuracy: 0.57, mean: 0.64.
================Task 21 Start!================
Testing on False unseen tasks (max class = 92).
Set memory of size: 1800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 21 Training!================
The training samples number: 2800
Train on 90->92.
train task
nb 2800.
Train [22/26] | Epoch [1/160] |	nca: 15.49278837442398, flat: 6.887677151709795, pod: 60.60216951370239, loss: 82.98263549804688 
Train [22/26] | Epoch [2/160] |	nca: 8.718716263771057, flat: 5.5503187626600266, pod: 64.14542579650879, loss: 78.41446089744568 
Train [22/26] | Epoch [3/160] |	nca: 6.580403357744217, flat: 4.662127882242203, pod: 60.37997627258301, loss: 71.62250757217407 
Train [22/26] | Epoch [4/160] |	nca: 5.037544742226601, flat: 3.6736944764852524, pod: 54.13515615463257, loss: 62.84639501571655 
Train [22/26] | Epoch [5/160] |	nca: 4.165184915065765, flat: 3.217096358537674, pod: 52.44838333129883, loss: 59.83066439628601 
Train [22/26] | Epoch [6/160] |	nca: 3.8363122195005417, flat: 2.9278317019343376, pod: 50.25139331817627, loss: 57.01553750038147 
Train [22/26] | Epoch [7/160] |	nca: 3.3363577276468277, flat: 2.7348428517580032, pod: 49.19921064376831, loss: 55.27041172981262 
Train [22/26] | Epoch [8/160] |	nca: 3.4383717998862267, flat: 2.753709077835083, pod: 49.950576066970825, loss: 56.14265704154968 
Train [22/26] | Epoch [9/160] |	nca: 3.9416433721780777, flat: 2.842638313770294, pod: 50.94290208816528, loss: 57.72718405723572 
Train [22/26] | Epoch [10/160] |	nca: 3.701352410018444, flat: 2.803277276456356, pod: 48.215360045433044, loss: 54.71998977661133 
Train [22/26] | Epoch [11/160] |	nca: 3.662908084690571, flat: 2.862777031958103, pod: 49.31717348098755, loss: 55.84285831451416 
Train [22/26] | Epoch [12/160] |	nca: 3.0083274617791176, flat: 2.468962676823139, pod: 46.64163863658905, loss: 52.11892914772034 
Train [22/26] | Epoch [13/160] |	nca: 3.169465519487858, flat: 2.4299392253160477, pod: 46.22978138923645, loss: 51.82918620109558 
Train [22/26] | Epoch [14/160] |	nca: 3.2367923632264137, flat: 2.4438116624951363, pod: 46.12351381778717, loss: 51.80411767959595 
Train [22/26] | Epoch [15/160] |	nca: 3.171663135290146, flat: 2.5631483271718025, pod: 48.344544887542725, loss: 54.07935643196106 
Train [22/26] | Epoch [16/160] |	nca: 3.123427890241146, flat: 2.4985459819436073, pod: 47.458191871643066, loss: 53.08016586303711 
Train [22/26] | Epoch [17/160] |	nca: 3.000768758356571, flat: 2.265484608709812, pod: 43.97897469997406, loss: 49.24522852897644 
Train [22/26] | Epoch [18/160] |	nca: 3.0135642364621162, flat: 2.5246342942118645, pod: 46.56539070606232, loss: 52.103588581085205 
Train [22/26] | Epoch [19/160] |	nca: 2.926821991801262, flat: 2.441952832043171, pod: 45.99597692489624, loss: 51.3647518157959 
Train [22/26] | Epoch [20/160] |	nca: 2.7604367062449455, flat: 2.5703073740005493, pod: 48.44739294052124, loss: 53.77813720703125 
Train [22/26] | Epoch [21/160] |	nca: 2.8200435414910316, flat: 2.271993972361088, pod: 45.1732075214386, loss: 50.26524567604065 
Train [22/26] | Epoch [22/160] |	nca: 3.020971991121769, flat: 2.3196772634983063, pod: 45.345707178115845, loss: 50.68635678291321 
Train [22/26] | Epoch [23/160] |	nca: 2.6901154071092606, flat: 2.2708929777145386, pod: 45.34519398212433, loss: 50.30620217323303 
Train [22/26] | Epoch [24/160] |	nca: 2.621305614709854, flat: 2.2128250524401665, pod: 43.71981418132782, loss: 48.553945779800415 
Train [22/26] | Epoch [25/160] |	nca: 2.8592664301395416, flat: 2.182209759950638, pod: 44.07021164894104, loss: 49.11168837547302 
Train [22/26] | Epoch [26/160] |	nca: 2.702587477862835, flat: 2.128181628882885, pod: 43.31904077529907, loss: 48.14980983734131 
Train [22/26] | Epoch [27/160] |	nca: 2.8513306006789207, flat: 2.2494244426488876, pod: 43.952921628952026, loss: 49.05367684364319 
Train [22/26] | Epoch [28/160] |	nca: 2.865952156484127, flat: 2.285786934196949, pod: 45.098508477211, loss: 50.25024724006653 
Train [22/26] | Epoch [29/160] |	nca: 2.5695940107107162, flat: 2.249229222536087, pod: 44.47767186164856, loss: 49.29649519920349 
Train [22/26] | Epoch [30/160] |	nca: 2.758930094540119, flat: 2.2035179138183594, pod: 43.56560230255127, loss: 48.528050780296326 
Train [22/26] | Epoch [31/160] |	nca: 2.548395097255707, flat: 2.14480297267437, pod: 44.29005432128906, loss: 48.98325300216675 
Train [22/26] | Epoch [32/160] |	nca: 2.776358738541603, flat: 2.323117956519127, pod: 46.55317163467407, loss: 51.65264821052551 
Train [22/26] | Epoch [33/160] |	nca: 2.6315362229943275, flat: 2.344332091510296, pod: 46.24242103099823, loss: 51.21828889846802 
Train [22/26] | Epoch [34/160] |	nca: 2.741646021604538, flat: 2.278174228966236, pod: 43.47461950778961, loss: 48.49443972110748 
Train [22/26] | Epoch [35/160] |	nca: 2.5495580062270164, flat: 2.12380164116621, pod: 43.72833979129791, loss: 48.40169978141785 
Train [22/26] | Epoch [36/160] |	nca: 2.50517238676548, flat: 2.0380642786622047, pod: 43.354385018348694, loss: 47.89762198925018 
Train [22/26] | Epoch [37/160] |	nca: 2.5017621740698814, flat: 2.098860539495945, pod: 43.22097909450531, loss: 47.82160258293152 
Train [22/26] | Epoch [38/160] |	nca: 2.633665233850479, flat: 1.9463118687272072, pod: 42.05652928352356, loss: 46.6365065574646 
Train [22/26] | Epoch [39/160] |	nca: 2.7787240594625473, flat: 2.1433086171746254, pod: 43.700409054756165, loss: 48.62244164943695 
Train [22/26] | Epoch [40/160] |	nca: 2.6308284029364586, flat: 2.047955237329006, pod: 42.317161083221436, loss: 46.99594497680664 
Train [22/26] | Epoch [41/160] |	nca: 2.5159830898046494, flat: 2.0756486877799034, pod: 42.935449838638306, loss: 47.52708160877228 
Train [22/26] | Epoch [42/160] |	nca: 2.7167951613664627, flat: 2.20389062166214, pod: 44.992252707481384, loss: 49.912938594818115 
Train [22/26] | Epoch [43/160] |	nca: 2.6276187524199486, flat: 2.248637191951275, pod: 44.59832298755646, loss: 49.474579095840454 
Train [22/26] | Epoch [44/160] |	nca: 2.5438173040747643, flat: 2.0790135860443115, pod: 42.79068648815155, loss: 47.413517236709595 
Train [22/26] | Epoch [45/160] |	nca: 2.4808132499456406, flat: 1.8464590981602669, pod: 41.176698088645935, loss: 45.50397086143494 
Train [22/26] | Epoch [46/160] |	nca: 2.595608562231064, flat: 2.1984387263655663, pod: 44.79023194313049, loss: 49.584280014038086 
Train [22/26] | Epoch [47/160] |	nca: 2.4882759749889374, flat: 1.9760491251945496, pod: 42.135778069496155, loss: 46.60010290145874 
Train [22/26] | Epoch [48/160] |	nca: 2.574526473879814, flat: 2.128999337553978, pod: 44.521243929862976, loss: 49.224769711494446 
Train [22/26] | Epoch [49/160] |	nca: 2.266142576932907, flat: 1.9313807487487793, pod: 40.48613739013672, loss: 44.68366074562073 
Train [22/26] | Epoch [50/160] |	nca: 2.380395472049713, flat: 1.8196180909872055, pod: 38.844539523124695, loss: 43.04455316066742 
Train [22/26] | Epoch [51/160] |	nca: 2.5650086998939514, flat: 1.850314922630787, pod: 39.69181787967682, loss: 44.10714137554169 
Train [22/26] | Epoch [52/160] |	nca: 2.6482591331005096, flat: 1.8738496601581573, pod: 40.71054530143738, loss: 45.2326534986496 
Train [22/26] | Epoch [53/160] |	nca: 2.334224559366703, flat: 1.7999387979507446, pod: 39.64258313179016, loss: 43.77674651145935 
Train [22/26] | Epoch [54/160] |	nca: 2.5491461604833603, flat: 1.8747859597206116, pod: 40.35541391372681, loss: 44.779346108436584 
Train [22/26] | Epoch [55/160] |	nca: 2.6200964748859406, flat: 1.8733768612146378, pod: 39.107264041900635, loss: 43.60073745250702 
Train [22/26] | Epoch [56/160] |	nca: 2.3877573013305664, flat: 1.8484411835670471, pod: 40.76982378959656, loss: 45.006022453308105 
Train [22/26] | Epoch [57/160] |	nca: 2.3803777880966663, flat: 1.7804062068462372, pod: 39.763633608818054, loss: 43.92441761493683 
Train [22/26] | Epoch [58/160] |	nca: 2.2198413014411926, flat: 1.7359872683882713, pod: 39.32439887523651, loss: 43.280227065086365 
Train [22/26] | Epoch [59/160] |	nca: 2.3304951377213, flat: 1.789180189371109, pod: 39.37446188926697, loss: 43.49413740634918 
Train [22/26] | Epoch [60/160] |	nca: 2.3849691450595856, flat: 1.6308582872152328, pod: 36.76945924758911, loss: 40.78528702259064 
Train [22/26] | Epoch [61/160] |	nca: 2.203721895813942, flat: 1.6862511448562145, pod: 37.39559328556061, loss: 41.285566091537476 
Train [22/26] | Epoch [62/160] |	nca: 2.336079951375723, flat: 1.5974368676543236, pod: 37.759557127952576, loss: 41.693073749542236 
Train [22/26] | Epoch [63/160] |	nca: 2.265136554837227, flat: 1.6112403385341167, pod: 37.708033323287964, loss: 41.584410309791565 
Train [22/26] | Epoch [64/160] |	nca: 2.342109341174364, flat: 1.6674517467617989, pod: 37.812334299087524, loss: 41.821895480155945 
Train [22/26] | Epoch [65/160] |	nca: 2.19664154201746, flat: 1.6375914588570595, pod: 38.475911259651184, loss: 42.3101441860199 
Train [22/26] | Epoch [66/160] |	nca: 2.29286477714777, flat: 1.6849209442734718, pod: 38.0679007768631, loss: 42.04568636417389 
Train [22/26] | Epoch [67/160] |	nca: 2.143705189228058, flat: 1.5402273274958134, pod: 36.65965270996094, loss: 40.34358525276184 
Train [22/26] | Epoch [68/160] |	nca: 2.3990114629268646, flat: 1.601365078240633, pod: 37.779818177223206, loss: 41.78019464015961 
Train [22/26] | Epoch [69/160] |	nca: 2.3211668729782104, flat: 1.6931898221373558, pod: 37.93131875991821, loss: 41.94567549228668 
Train [22/26] | Epoch [70/160] |	nca: 2.29600677639246, flat: 1.6126054376363754, pod: 36.96713590621948, loss: 40.87574815750122 
Train [22/26] | Epoch [71/160] |	nca: 2.2343073338270187, flat: 1.612112045288086, pod: 37.303393483161926, loss: 41.14981269836426 
Train [22/26] | Epoch [72/160] |	nca: 2.2128400579094887, flat: 1.64962724968791, pod: 38.30790102481842, loss: 42.17036807537079 
Train [22/26] | Epoch [73/160] |	nca: 2.145222168415785, flat: 1.5206771902740002, pod: 35.82708668708801, loss: 39.49298596382141 
Train [22/26] | Epoch [74/160] |	nca: 2.2972405403852463, flat: 1.4799361154437065, pod: 35.527366042137146, loss: 39.304542660713196 
Train [22/26] | Epoch [75/160] |	nca: 2.2832767218351364, flat: 1.4767539128661156, pod: 34.633305311203, loss: 38.393336057662964 
Train [22/26] | Epoch [76/160] |	nca: 2.2091480642557144, flat: 1.4892204441130161, pod: 36.46393442153931, loss: 40.16230309009552 
Train [22/26] | Epoch [77/160] |	nca: 2.2652168571949005, flat: 1.473990611732006, pod: 35.20200264453888, loss: 38.94121026992798 
Train [22/26] | Epoch [78/160] |	nca: 2.1846918798983097, flat: 1.4847685024142265, pod: 35.10170555114746, loss: 38.77116596698761 
Train [22/26] | Epoch [79/160] |	nca: 2.0580516383051872, flat: 1.3995742127299309, pod: 34.283987164497375, loss: 37.7416125535965 
Train [22/26] | Epoch [80/160] |	nca: 2.2318877950310707, flat: 1.4301440343260765, pod: 35.652368664741516, loss: 39.31440031528473 
Train [22/26] | Epoch [81/160] |	nca: 2.099334254860878, flat: 1.4071299582719803, pod: 34.64231193065643, loss: 38.148775815963745 
Train [22/26] | Epoch [82/160] |	nca: 2.2314287796616554, flat: 1.3333946391940117, pod: 34.5442396402359, loss: 38.109063029289246 
Train [22/26] | Epoch [83/160] |	nca: 2.2328667119145393, flat: 1.4512330330908298, pod: 35.39115560054779, loss: 39.07525551319122 
Train [22/26] | Epoch [84/160] |	nca: 2.028555117547512, flat: 1.345993421971798, pod: 33.527257442474365, loss: 36.90180563926697 
Train [22/26] | Epoch [85/160] |	nca: 2.2513469755649567, flat: 1.4204716719686985, pod: 35.18811345100403, loss: 38.85993218421936 
Train [22/26] | Epoch [86/160] |	nca: 2.1753455884754658, flat: 1.3968823365867138, pod: 35.01195824146271, loss: 38.58418607711792 
Train [22/26] | Epoch [87/160] |	nca: 2.149574488401413, flat: 1.3514028415083885, pod: 33.563713788986206, loss: 37.06469142436981 
Train [22/26] | Epoch [88/160] |	nca: 1.9341137260198593, flat: 1.209063310176134, pod: 31.8552029132843, loss: 34.998379826545715 
Train [22/26] | Epoch [89/160] |	nca: 2.1443664357066154, flat: 1.2557581178843975, pod: 32.75915253162384, loss: 36.15927696228027 
Train [22/26] | Epoch [90/160] |	nca: 2.1377870813012123, flat: 1.2896886318922043, pod: 33.15939497947693, loss: 36.5868706703186 
Train [22/26] | Epoch [91/160] |	nca: 1.9386920370161533, flat: 1.2079798243939877, pod: 32.495996952056885, loss: 35.64266884326935 
Train [22/26] | Epoch [92/160] |	nca: 2.069295533001423, flat: 1.167343556880951, pod: 31.0144100189209, loss: 34.25104904174805 
Train [22/26] | Epoch [93/160] |	nca: 1.9781653247773647, flat: 1.1830059327185154, pod: 31.187275171279907, loss: 34.34844648838043 
Train [22/26] | Epoch [94/160] |	nca: 2.0115199014544487, flat: 1.199867945164442, pod: 31.75573968887329, loss: 34.967127561569214 
Train [22/26] | Epoch [95/160] |	nca: 2.0327576622366905, flat: 1.1666645109653473, pod: 31.534714460372925, loss: 34.73413670063019 
Train [22/26] | Epoch [96/160] |	nca: 2.0840471163392067, flat: 1.1150795966386795, pod: 29.97012436389923, loss: 33.16925132274628 
Train [22/26] | Epoch [97/160] |	nca: 2.0344479121267796, flat: 1.1801734156906605, pod: 31.15239381790161, loss: 34.3670152425766 
Train [22/26] | Epoch [98/160] |	nca: 2.0793623253703117, flat: 1.1675366833806038, pod: 31.103544235229492, loss: 34.35044276714325 
Train [22/26] | Epoch [99/160] |	nca: 2.1200202479958534, flat: 1.1085114106535912, pod: 30.2720787525177, loss: 33.5006103515625 
Train [22/26] | Epoch [100/160] |	nca: 2.014623701572418, flat: 1.1382224597036839, pod: 29.431418418884277, loss: 32.584264397621155 
Train [22/26] | Epoch [101/160] |	nca: 1.905408389866352, flat: 1.0949252434074879, pod: 29.286105036735535, loss: 32.2864385843277 
Train [22/26] | Epoch [102/160] |	nca: 2.00829353928566, flat: 1.0500259771943092, pod: 28.829423785209656, loss: 31.88774311542511 
Train [22/26] | Epoch [103/160] |	nca: 1.8833965808153152, flat: 1.0414498448371887, pod: 28.832518577575684, loss: 31.757365226745605 
Train [22/26] | Epoch [104/160] |	nca: 1.9829315543174744, flat: 1.1450730971992016, pod: 30.836729526519775, loss: 33.9647341966629 
Train [22/26] | Epoch [105/160] |	nca: 2.015811711549759, flat: 1.0669443979859352, pod: 29.980904579162598, loss: 33.063660621643066 
Train [22/26] | Epoch [106/160] |	nca: 2.065028116106987, flat: 1.1352877244353294, pod: 31.374571323394775, loss: 34.5748872756958 
Train [22/26] | Epoch [107/160] |	nca: 1.9545617774128914, flat: 1.0152904763817787, pod: 28.270872473716736, loss: 31.240724802017212 
Train [22/26] | Epoch [108/160] |	nca: 1.9804622605443, flat: 1.015999048948288, pod: 29.29608726501465, loss: 32.292548298835754 
Train [22/26] | Epoch [109/160] |	nca: 1.917416449636221, flat: 0.9603170827031136, pod: 28.49919629096985, loss: 31.376930117607117 
Train [22/26] | Epoch [110/160] |	nca: 2.0075968503952026, flat: 0.9944679476320744, pod: 28.080850481987, loss: 31.082915425300598 
Train [22/26] | Epoch [111/160] |	nca: 2.0757915154099464, flat: 1.0001308992505074, pod: 28.05121076107025, loss: 31.1271333694458 
Train [22/26] | Epoch [112/160] |	nca: 1.9395513832569122, flat: 0.9632237404584885, pod: 27.051080107688904, loss: 29.9538551568985 
Train [22/26] | Epoch [113/160] |	nca: 2.118314303457737, flat: 0.9842401295900345, pod: 28.049827098846436, loss: 31.152381539344788 
Train [22/26] | Epoch [114/160] |	nca: 1.8269606940448284, flat: 0.9458348285406828, pod: 27.430984020233154, loss: 30.203779458999634 
Train [22/26] | Epoch [115/160] |	nca: 1.8024629093706608, flat: 0.8621127940714359, pod: 26.475815773010254, loss: 29.14039134979248 
Train [22/26] | Epoch [116/160] |	nca: 1.9058502353727818, flat: 0.8647606801241636, pod: 25.273996233940125, loss: 28.044606924057007 
Train [22/26] | Epoch [117/160] |	nca: 2.0172589644789696, flat: 0.8863068111240864, pod: 25.550625681877136, loss: 28.45419156551361 
Train [22/26] | Epoch [118/160] |	nca: 2.0554256848990917, flat: 0.9201120659708977, pod: 26.317968368530273, loss: 29.293506145477295 
Train [22/26] | Epoch [119/160] |	nca: 1.928461004048586, flat: 0.8861538805067539, pod: 25.596877932548523, loss: 28.411492705345154 
Train [22/26] | Epoch [120/160] |	nca: 1.8513315543532372, flat: 0.8758343551307917, pod: 25.71607232093811, loss: 28.443238496780396 
Train [22/26] | Epoch [121/160] |	nca: 1.8752595260739326, flat: 0.7837344743311405, pod: 24.042723298072815, loss: 26.701717376708984 
Train [22/26] | Epoch [122/160] |	nca: 1.986486479640007, flat: 0.8165974952280521, pod: 24.717081248760223, loss: 27.52016508579254 
Train [22/26] | Epoch [123/160] |	nca: 1.8835316337645054, flat: 0.8262034449726343, pod: 24.195110499858856, loss: 26.904845476150513 
Train [22/26] | Epoch [124/160] |	nca: 2.0142639577388763, flat: 0.814842389896512, pod: 24.393364429473877, loss: 27.222470998764038 
Train [22/26] | Epoch [125/160] |	nca: 1.8332681842148304, flat: 0.7230883110314608, pod: 22.99419939517975, loss: 25.550556123256683 
Train [22/26] | Epoch [126/160] |	nca: 1.8910559266805649, flat: 0.7118992172181606, pod: 22.138304710388184, loss: 24.741259694099426 
Train [22/26] | Epoch [127/160] |	nca: 1.9191084504127502, flat: 0.746258407831192, pod: 23.241658329963684, loss: 25.90702533721924 
Train [22/26] | Epoch [128/160] |	nca: 1.9573936611413956, flat: 0.7373664136976004, pod: 23.171698212623596, loss: 25.86645817756653 
Train [22/26] | Epoch [129/160] |	nca: 1.8958572447299957, flat: 0.7247719429433346, pod: 22.874054431915283, loss: 25.49468368291855 
Train [22/26] | Epoch [130/160] |	nca: 2.0440792739391327, flat: 0.7069684881716967, pod: 21.49526685476303, loss: 24.246314644813538 
Train [22/26] | Epoch [131/160] |	nca: 1.8115537129342556, flat: 0.732641875743866, pod: 22.76133358478546, loss: 25.305529177188873 
Train [22/26] | Epoch [132/160] |	nca: 2.0692803114652634, flat: 0.6801762487739325, pod: 21.514141499996185, loss: 24.2635977268219 
Train [22/26] | Epoch [133/160] |	nca: 1.9823791198432446, flat: 0.7077069245278835, pod: 21.902539432048798, loss: 24.592625558376312 
Train [22/26] | Epoch [134/160] |	nca: 1.8418957442045212, flat: 0.7154718972742558, pod: 21.976318836212158, loss: 24.53368651866913 
Train [22/26] | Epoch [135/160] |	nca: 1.85546038672328, flat: 0.6885310616344213, pod: 20.9916912317276, loss: 23.53568285703659 
Train [22/26] | Epoch [136/160] |	nca: 1.8716105818748474, flat: 0.6362649314105511, pod: 20.2017023563385, loss: 22.709577918052673 
Train [22/26] | Epoch [137/160] |	nca: 1.823065396398306, flat: 0.6612127237021923, pod: 20.687307715415955, loss: 23.171585857868195 
Train [22/26] | Epoch [138/160] |	nca: 1.9230423830449581, flat: 0.6758981216698885, pod: 21.24631541967392, loss: 23.84525603055954 
Train [22/26] | Epoch [139/160] |	nca: 1.8892434388399124, flat: 0.6432509142905474, pod: 20.673928260803223, loss: 23.206422746181488 
Train [22/26] | Epoch [140/160] |	nca: 1.8248862884938717, flat: 0.5964128784835339, pod: 19.584075450897217, loss: 22.005374670028687 
Train [22/26] | Epoch [141/160] |	nca: 1.8379454985260963, flat: 0.6119859144091606, pod: 19.24264669418335, loss: 21.69257813692093 
Train [22/26] | Epoch [142/160] |	nca: 2.007184252142906, flat: 0.6316520627588034, pod: 19.941560924053192, loss: 22.580397129058838 
Train [22/26] | Epoch [143/160] |	nca: 1.9142885580658913, flat: 0.6468739937990904, pod: 20.239126801490784, loss: 22.80028921365738 
Train [22/26] | Epoch [144/160] |	nca: 1.8405360616743565, flat: 0.6344698183238506, pod: 20.205603301525116, loss: 22.680608987808228 
Train [22/26] | Epoch [145/160] |	nca: 1.9221052676439285, flat: 0.586268225684762, pod: 19.274344086647034, loss: 21.782717406749725 
Train [22/26] | Epoch [146/160] |	nca: 1.9301728047430515, flat: 0.5726230125874281, pod: 19.25325572490692, loss: 21.756051540374756 
Train [22/26] | Epoch [147/160] |	nca: 1.848359227180481, flat: 0.5965908579528332, pod: 18.880174458026886, loss: 21.32512456178665 
Train [22/26] | Epoch [148/160] |	nca: 1.8386993296444416, flat: 0.6108727380633354, pod: 19.14061176776886, loss: 21.590183913707733 
Train [22/26] | Epoch [149/160] |	nca: 1.910567469894886, flat: 0.5535747800022364, pod: 18.065051436424255, loss: 20.52919375896454 
Train [22/26] | Epoch [150/160] |	nca: 1.8881488740444183, flat: 0.5992993079125881, pod: 18.585202991962433, loss: 21.072650969028473 
Train [22/26] | Epoch [151/160] |	nca: 1.8149208426475525, flat: 0.5776621177792549, pod: 18.66618174314499, loss: 21.058764696121216 
Train [22/26] | Epoch [152/160] |	nca: 1.8065938241779804, flat: 0.5647923704236746, pod: 17.85382115840912, loss: 20.225207448005676 
Train [22/26] | Epoch [153/160] |	nca: 1.8334111608564854, flat: 0.5842016041278839, pod: 18.000551342964172, loss: 20.418164312839508 
Train [22/26] | Epoch [154/160] |	nca: 1.7804245054721832, flat: 0.5355636980384588, pod: 17.6068097949028, loss: 19.922797977924347 
Train [22/26] | Epoch [155/160] |	nca: 1.8209667913615704, flat: 0.5469946321099997, pod: 18.029468774795532, loss: 20.39743024110794 
Train [22/26] | Epoch [156/160] |	nca: 1.7923080697655678, flat: 0.5268199201673269, pod: 17.68505984544754, loss: 20.004187881946564 
Train [22/26] | Epoch [157/160] |	nca: 1.8315966241061687, flat: 0.5978529583662748, pod: 18.216003358364105, loss: 20.645452916622162 
Train [22/26] | Epoch [158/160] |	nca: 1.9181769862771034, flat: 0.6183585543185472, pod: 18.837949812412262, loss: 21.374485433101654 
Train [22/26] | Epoch [159/160] |	nca: 1.8077643550932407, flat: 0.5454583950340748, pod: 17.64567345380783, loss: 19.998896181583405 
Train [22/26] | Epoch [160/160] |	nca: 1.8361812978982925, flat: 0.5484202019870281, pod: 17.715538263320923, loss: 20.100139796733856 
Fine-tuning
Building & updating memory.
Train [22/26] | Epoch [161/180] |	nca: 1.4900630004703999, flat: 0.8570097647607327, pod: 18.0911545753479, loss: 20.43822729587555 
Train [22/26] | Epoch [162/180] |	nca: 1.0472096912562847, flat: 0.8747483044862747, pod: 18.18849229812622, loss: 20.11045014858246 
Train [22/26] | Epoch [163/180] |	nca: 0.9091118723154068, flat: 0.8464451134204865, pod: 18.084359288215637, loss: 19.839916110038757 
Train [22/26] | Epoch [164/180] |	nca: 0.9911479502916336, flat: 0.8899073712527752, pod: 18.345059990882874, loss: 20.226115226745605 
Train [22/26] | Epoch [165/180] |	nca: 0.7982031628489494, flat: 0.8854814544320107, pod: 18.668614983558655, loss: 20.352299690246582 
Train [22/26] | Epoch [166/180] |	nca: 0.8599442467093468, flat: 0.8675934709608555, pod: 18.409828066825867, loss: 20.13736581802368 
Train [22/26] | Epoch [167/180] |	nca: 0.8317908421158791, flat: 0.8947323597967625, pod: 18.127320766448975, loss: 19.853844106197357 
Train [22/26] | Epoch [168/180] |	nca: 0.7273039445281029, flat: 0.8376114368438721, pod: 18.551271498203278, loss: 20.116186916828156 
Train [22/26] | Epoch [169/180] |	nca: 0.7467433474957943, flat: 0.8553536683320999, pod: 18.235424041748047, loss: 19.837521195411682 
Train [22/26] | Epoch [170/180] |	nca: 0.7014908995479345, flat: 0.8353961296379566, pod: 17.885630011558533, loss: 19.42251694202423 
Train [22/26] | Epoch [171/180] |	nca: 0.7308355662971735, flat: 0.8504182547330856, pod: 17.950751781463623, loss: 19.532005548477173 
Train [22/26] | Epoch [172/180] |	nca: 0.6933552045375109, flat: 0.8503013737499714, pod: 18.15070331096649, loss: 19.69435977935791 
Train [22/26] | Epoch [173/180] |	nca: 0.7026071436703205, flat: 0.8844297006726265, pod: 18.681191861629486, loss: 20.26822865009308 
Train [22/26] | Epoch [174/180] |	nca: 0.6979892365634441, flat: 0.8911125846207142, pod: 18.941874027252197, loss: 20.530975937843323 
Train [22/26] | Epoch [175/180] |	nca: 0.6707321628928185, flat: 0.9069204144179821, pod: 18.742932379245758, loss: 20.320584893226624 
Train [22/26] | Epoch [176/180] |	nca: 0.6640253812074661, flat: 0.9139995817095041, pod: 19.186030447483063, loss: 20.764055371284485 
Train [22/26] | Epoch [177/180] |	nca: 0.674030739814043, flat: 0.9324714802205563, pod: 18.742032408714294, loss: 20.34853446483612 
Train [22/26] | Epoch [178/180] |	nca: 0.668101454153657, flat: 0.8742956183850765, pod: 18.434641122817993, loss: 19.977038264274597 
Train [22/26] | Epoch [179/180] |	nca: 0.6652791146188974, flat: 0.8584911338984966, pod: 18.268406808376312, loss: 19.792177081108093 
Train [22/26] | Epoch [180/180] |	nca: 0.6388640142977238, flat: 0.8639337420463562, pod: 18.255457043647766, loss: 19.758254528045654 
after task
Building & updating memory.
after task
Eval on 0->92.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.6043181818181819.
Current acc: {'total': 0.515, '00-09': 0.575, '10-19': 0.517, '20-29': 0.448, '30-39': 0.479, '40-49': 0.517, '50-59': 0.542, '60-69': 0.447, '70-79': 0.539, '80-89': 0.568, '90-99': 0.55}.
Avg inc acc top5: 0.8575454545454545.
Current acc top5: {'total': 0.811}.
Forgetting: 0.1118181818181818.
Cord metric: 0.59.
Old accuracy: 0.52, mean: 0.60.
New accuracy: 0.55, mean: 0.64.
================Task 22 Start!================
Testing on False unseen tasks (max class = 94).
Set memory of size: 1840.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 22 Training!================
The training samples number: 2840
Train on 92->94.
train task
nb 2840.
Train [23/26] | Epoch [1/160] |	nca: 15.432501494884491, flat: 6.891147306188941, pod: 66.48782181739807, loss: 88.81147003173828 
Train [23/26] | Epoch [2/160] |	nca: 13.81857317686081, flat: 8.784422278404236, pod: 83.13140296936035, loss: 105.73439884185791 
Train [23/26] | Epoch [3/160] |	nca: 11.551539957523346, flat: 8.256096303462982, pod: 81.83201289176941, loss: 101.63964891433716 
Train [23/26] | Epoch [4/160] |	nca: 9.901488035917282, flat: 7.002848953008652, pod: 75.91424179077148, loss: 92.81857752799988 
Train [23/26] | Epoch [5/160] |	nca: 7.154088422656059, flat: 5.931529119610786, pod: 70.21950268745422, loss: 83.30511975288391 
Train [23/26] | Epoch [6/160] |	nca: 6.5768449902534485, flat: 5.3143786787986755, pod: 68.06137108802795, loss: 79.9525945186615 
Train [23/26] | Epoch [7/160] |	nca: 4.759166017174721, flat: 4.504321560263634, pod: 62.21456050872803, loss: 71.47804832458496 
Train [23/26] | Epoch [8/160] |	nca: 4.804108664393425, flat: 4.103635147213936, pod: 59.88042664527893, loss: 68.78817009925842 
Train [23/26] | Epoch [9/160] |	nca: 5.1361823827028275, flat: 4.409613817930222, pod: 61.72996807098389, loss: 71.27576446533203 
Train [23/26] | Epoch [10/160] |	nca: 4.349310331046581, flat: 4.118624284863472, pod: 60.18216109275818, loss: 68.65009570121765 
Train [23/26] | Epoch [11/160] |	nca: 4.199293307960033, flat: 3.675132155418396, pod: 56.99197030067444, loss: 64.86639595031738 
Train [23/26] | Epoch [12/160] |	nca: 3.946541875600815, flat: 3.575149580836296, pod: 56.0836706161499, loss: 63.60536170005798 
Train [23/26] | Epoch [13/160] |	nca: 4.283853828907013, flat: 3.7381154894828796, pod: 58.92452311515808, loss: 66.9464921951294 
Train [23/26] | Epoch [14/160] |	nca: 4.0576373636722565, flat: 3.969605475664139, pod: 59.68137550354004, loss: 67.70861792564392 
Train [23/26] | Epoch [15/160] |	nca: 4.071521744132042, flat: 3.6469530314207077, pod: 58.777522802352905, loss: 66.49599766731262 
Train [23/26] | Epoch [16/160] |	nca: 3.937484160065651, flat: 3.5860339924693108, pod: 55.95245933532715, loss: 63.475977659225464 
Train [23/26] | Epoch [17/160] |	nca: 3.971522070467472, flat: 3.675758011639118, pod: 56.63551735877991, loss: 64.28279733657837 
Train [23/26] | Epoch [18/160] |	nca: 3.994590848684311, flat: 3.523424744606018, pod: 56.4868266582489, loss: 64.00484299659729 
Train [23/26] | Epoch [19/160] |	nca: 3.812413789331913, flat: 3.4218825697898865, pod: 56.634703159332275, loss: 63.86899924278259 
Train [23/26] | Epoch [20/160] |	nca: 4.319753661751747, flat: 4.01711468398571, pod: 58.25897693634033, loss: 66.59584546089172 
Train [23/26] | Epoch [21/160] |	nca: 3.9725436568260193, flat: 3.54501873254776, pod: 55.63855767250061, loss: 63.15612053871155 
Train [23/26] | Epoch [22/160] |	nca: 3.5438885018229485, flat: 3.380355067551136, pod: 55.58607029914856, loss: 62.510313749313354 
Train [23/26] | Epoch [23/160] |	nca: 3.6809647530317307, flat: 3.431776463985443, pod: 56.89240336418152, loss: 64.00514459609985 
Train [23/26] | Epoch [24/160] |	nca: 3.515484668314457, flat: 3.2067239060997963, pod: 54.13927960395813, loss: 60.86148810386658 
Train [23/26] | Epoch [25/160] |	nca: 3.586473137140274, flat: 3.276700183749199, pod: 54.14165186882019, loss: 61.00482535362244 
Train [23/26] | Epoch [26/160] |	nca: 3.269579827785492, flat: 2.9862582311034203, pod: 52.83004593849182, loss: 59.08588433265686 
Train [23/26] | Epoch [27/160] |	nca: 3.502264440059662, flat: 3.343352384865284, pod: 57.29487371444702, loss: 64.14049005508423 
Train [23/26] | Epoch [28/160] |	nca: 4.048288993537426, flat: 3.7504418939352036, pod: 57.67899131774902, loss: 65.47772216796875 
Train [23/26] | Epoch [29/160] |	nca: 3.6009772568941116, flat: 3.753118932247162, pod: 57.518962383270264, loss: 64.8730583190918 
Train [23/26] | Epoch [30/160] |	nca: 3.4141026735305786, flat: 3.108246922492981, pod: 51.45908057689667, loss: 57.981430768966675 
Train [23/26] | Epoch [31/160] |	nca: 3.3403762578964233, flat: 3.183784641325474, pod: 53.4537250995636, loss: 59.977885484695435 
Train [23/26] | Epoch [32/160] |	nca: 3.6101511269807816, flat: 3.4993362575769424, pod: 57.430994272232056, loss: 64.54048180580139 
Train [23/26] | Epoch [33/160] |	nca: 2.837830625474453, flat: 2.8386108353734016, pod: 52.67265772819519, loss: 58.34909915924072 
Train [23/26] | Epoch [34/160] |	nca: 3.5269034802913666, flat: 2.9182123094797134, pod: 50.30418050289154, loss: 56.749295711517334 
Train [23/26] | Epoch [35/160] |	nca: 3.1436402797698975, flat: 2.8842036947607994, pod: 51.070064187049866, loss: 57.09790873527527 
Train [23/26] | Epoch [36/160] |	nca: 3.7734240889549255, flat: 3.05145126581192, pod: 52.70358729362488, loss: 59.528462171554565 
Train [23/26] | Epoch [37/160] |	nca: 3.977312535047531, flat: 3.583325870335102, pod: 54.16010117530823, loss: 61.7207396030426 
Train [23/26] | Epoch [38/160] |	nca: 3.016928568482399, flat: 2.9763265773653984, pod: 50.87150573730469, loss: 56.864760398864746 
Train [23/26] | Epoch [39/160] |	nca: 3.4519893750548363, flat: 3.2876536697149277, pod: 53.36935615539551, loss: 60.10899877548218 
Train [23/26] | Epoch [40/160] |	nca: 3.314723752439022, flat: 2.988326817750931, pod: 51.34201943874359, loss: 57.64506959915161 
Train [23/26] | Epoch [41/160] |	nca: 3.0048585534095764, flat: 2.9156300500035286, pod: 51.299198150634766, loss: 57.21968698501587 
Train [23/26] | Epoch [42/160] |	nca: 2.919162318110466, flat: 2.6885837987065315, pod: 49.29093372821808, loss: 54.89867949485779 
Train [23/26] | Epoch [43/160] |	nca: 2.8532869592309, flat: 2.5033770725131035, pod: 47.330329179763794, loss: 52.68699371814728 
Train [23/26] | Epoch [44/160] |	nca: 2.8820277079939842, flat: 2.5807166770100594, pod: 48.45424818992615, loss: 53.91699290275574 
Train [23/26] | Epoch [45/160] |	nca: 3.293344095349312, flat: 2.9515875577926636, pod: 50.571481704711914, loss: 56.81641340255737 
Train [23/26] | Epoch [46/160] |	nca: 2.964221939444542, flat: 2.7597908675670624, pod: 49.42597043514252, loss: 55.149983644485474 
Train [23/26] | Epoch [47/160] |	nca: 2.5370888262987137, flat: 2.5618657246232033, pod: 48.208093762397766, loss: 53.30704855918884 
Train [23/26] | Epoch [48/160] |	nca: 2.9426118284463882, flat: 2.6635088473558426, pod: 49.17222511768341, loss: 54.77834606170654 
Train [23/26] | Epoch [49/160] |	nca: 2.7532508969306946, flat: 2.6630549654364586, pod: 49.296074867248535, loss: 54.71238112449646 
Train [23/26] | Epoch [50/160] |	nca: 2.9296323508024216, flat: 2.666713237762451, pod: 52.482768535614014, loss: 58.07911419868469 
Train [23/26] | Epoch [51/160] |	nca: 3.2320425882935524, flat: 2.8256512954831123, pod: 50.56477463245392, loss: 56.6224684715271 
Train [23/26] | Epoch [52/160] |	nca: 3.284974478185177, flat: 2.878506302833557, pod: 50.1935476064682, loss: 56.35702896118164 
Train [23/26] | Epoch [53/160] |	nca: 3.0293824449181557, flat: 2.9110513776540756, pod: 50.6952223777771, loss: 56.635656118392944 
Train [23/26] | Epoch [54/160] |	nca: 2.703439213335514, flat: 2.4128426164388657, pod: 47.674924492836, loss: 52.79120635986328 
Train [23/26] | Epoch [55/160] |	nca: 2.6228193044662476, flat: 2.4557138681411743, pod: 45.88329255580902, loss: 50.96182572841644 
Train [23/26] | Epoch [56/160] |	nca: 2.5708550065755844, flat: 2.1317851170897484, pod: 43.075061202049255, loss: 47.77770161628723 
Train [23/26] | Epoch [57/160] |	nca: 2.6902714148163795, flat: 2.60143531113863, pod: 49.57945895195007, loss: 54.87116587162018 
Train [23/26] | Epoch [58/160] |	nca: 2.7948435693979263, flat: 2.4172972291707993, pod: 45.504030585289, loss: 50.71617078781128 
Train [23/26] | Epoch [59/160] |	nca: 2.881457105278969, flat: 2.479089543223381, pod: 46.07461762428284, loss: 51.43516397476196 
Train [23/26] | Epoch [60/160] |	nca: 2.723166301846504, flat: 2.4560867846012115, pod: 46.26028823852539, loss: 51.43954074382782 
Train [23/26] | Epoch [61/160] |	nca: 2.9760927110910416, flat: 2.350171595811844, pod: 45.43533265590668, loss: 50.76159632205963 
Train [23/26] | Epoch [62/160] |	nca: 2.642317071557045, flat: 2.3897308632731438, pod: 45.59589374065399, loss: 50.627941608428955 
Train [23/26] | Epoch [63/160] |	nca: 2.7300213649868965, flat: 2.492530643939972, pod: 45.79113173484802, loss: 51.013683795928955 
Train [23/26] | Epoch [64/160] |	nca: 2.7284926921129227, flat: 2.3237496986985207, pod: 46.46989703178406, loss: 51.52213907241821 
Train [23/26] | Epoch [65/160] |	nca: 3.10257488489151, flat: 2.642708405852318, pod: 48.11927509307861, loss: 53.864559054374695 
Train [23/26] | Epoch [66/160] |	nca: 3.215346686542034, flat: 2.7346513122320175, pod: 48.5601087808609, loss: 54.51010704040527 
Train [23/26] | Epoch [67/160] |	nca: 3.022887334227562, flat: 2.7375579103827477, pod: 47.67266321182251, loss: 53.43310832977295 
Train [23/26] | Epoch [68/160] |	nca: 2.651923857629299, flat: 2.208317294716835, pod: 43.31756508350372, loss: 48.17780566215515 
Train [23/26] | Epoch [69/160] |	nca: 2.671780027449131, flat: 2.081480920314789, pod: 43.31110405921936, loss: 48.064364552497864 
Train [23/26] | Epoch [70/160] |	nca: 2.513352431356907, flat: 2.2011733427643776, pod: 43.68880879878998, loss: 48.403334617614746 
Train [23/26] | Epoch [71/160] |	nca: 2.547322817146778, flat: 2.045821115374565, pod: 43.2053941488266, loss: 47.79853808879852 
Train [23/26] | Epoch [72/160] |	nca: 2.60703057795763, flat: 2.2140543088316917, pod: 45.02619731426239, loss: 49.84728217124939 
Train [23/26] | Epoch [73/160] |	nca: 2.6343105882406235, flat: 1.9943789839744568, pod: 42.2601193189621, loss: 46.88880896568298 
Train [23/26] | Epoch [74/160] |	nca: 2.9188166558742523, flat: 2.2441312596201897, pod: 44.47763812541962, loss: 49.64058589935303 
Train [23/26] | Epoch [75/160] |	nca: 2.5101454332470894, flat: 2.140821173787117, pod: 43.96197044849396, loss: 48.61293709278107 
Train [23/26] | Epoch [76/160] |	nca: 2.412281207740307, flat: 1.9508748278021812, pod: 42.20352780818939, loss: 46.566683650016785 
Train [23/26] | Epoch [77/160] |	nca: 2.4079933762550354, flat: 1.8098945766687393, pod: 39.830405831336975, loss: 44.04829406738281 
Train [23/26] | Epoch [78/160] |	nca: 2.5697476863861084, flat: 1.9573158472776413, pod: 42.399304032325745, loss: 46.92636740207672 
Train [23/26] | Epoch [79/160] |	nca: 2.213753432035446, flat: 1.9363727271556854, pod: 40.35107612609863, loss: 44.50120234489441 
Train [23/26] | Epoch [80/160] |	nca: 2.6892492473125458, flat: 1.8644582070410252, pod: 41.787461280822754, loss: 46.3411682844162 
Train [23/26] | Epoch [81/160] |	nca: 2.7651267647743225, flat: 1.9927956648170948, pod: 40.8079776763916, loss: 45.56589996814728 
Train [23/26] | Epoch [82/160] |	nca: 2.407111868262291, flat: 1.9569894522428513, pod: 39.89543104171753, loss: 44.25953257083893 
Train [23/26] | Epoch [83/160] |	nca: 2.6521076932549477, flat: 2.061782844364643, pod: 42.194597244262695, loss: 46.90848755836487 
Train [23/26] | Epoch [84/160] |	nca: 2.4617749229073524, flat: 1.877446487545967, pod: 39.91618752479553, loss: 44.25540900230408 
Train [23/26] | Epoch [85/160] |	nca: 2.2691405043005943, flat: 1.870311439037323, pod: 40.05466711521149, loss: 44.19411897659302 
Train [23/26] | Epoch [86/160] |	nca: 2.389046810567379, flat: 1.7887985706329346, pod: 40.50494623184204, loss: 44.68279206752777 
Train [23/26] | Epoch [87/160] |	nca: 2.3716892302036285, flat: 1.7197236195206642, pod: 38.42591059207916, loss: 42.51732361316681 
Train [23/26] | Epoch [88/160] |	nca: 2.5779597386717796, flat: 1.8229636773467064, pod: 40.16940486431122, loss: 44.57032835483551 
Train [23/26] | Epoch [89/160] |	nca: 2.3225899413228035, flat: 1.7695527970790863, pod: 37.932958483695984, loss: 42.02510118484497 
Train [23/26] | Epoch [90/160] |	nca: 2.289274677634239, flat: 1.7024953700602055, pod: 38.24612367153168, loss: 42.23789370059967 
Train [23/26] | Epoch [91/160] |	nca: 2.2787569351494312, flat: 1.861745748668909, pod: 40.3996080160141, loss: 44.54011070728302 
Train [23/26] | Epoch [92/160] |	nca: 2.3468921780586243, flat: 1.6177247874438763, pod: 38.01999354362488, loss: 41.98461055755615 
Train [23/26] | Epoch [93/160] |	nca: 2.245980605483055, flat: 1.5167396031320095, pod: 36.1446408033371, loss: 39.9073611497879 
Train [23/26] | Epoch [94/160] |	nca: 2.569345347583294, flat: 1.6913727521896362, pod: 37.65155339241028, loss: 41.91227173805237 
Train [23/26] | Epoch [95/160] |	nca: 2.6740366145968437, flat: 1.8197120428085327, pod: 38.080909967422485, loss: 42.57465863227844 
Train [23/26] | Epoch [96/160] |	nca: 2.301874600350857, flat: 1.6136832349002361, pod: 36.49002981185913, loss: 40.40558743476868 
Train [23/26] | Epoch [97/160] |	nca: 2.152914248406887, flat: 1.5553283840417862, pod: 37.561317563056946, loss: 41.26956009864807 
Train [23/26] | Epoch [98/160] |	nca: 2.3909717313945293, flat: 1.6673566587269306, pod: 38.103607177734375, loss: 42.161935925483704 
Train [23/26] | Epoch [99/160] |	nca: 2.4079349786043167, flat: 1.6538923159241676, pod: 36.46829450130463, loss: 40.53012192249298 
Train [23/26] | Epoch [100/160] |	nca: 2.1987032741308212, flat: 1.6126981601119041, pod: 37.24067234992981, loss: 41.0520738363266 
Train [23/26] | Epoch [101/160] |	nca: 2.180219106376171, flat: 1.3575374148786068, pod: 33.57371377944946, loss: 37.111470103263855 
Train [23/26] | Epoch [102/160] |	nca: 2.2988103590905666, flat: 1.4585687518119812, pod: 35.0236953496933, loss: 38.78107452392578 
Train [23/26] | Epoch [103/160] |	nca: 2.4063469395041466, flat: 1.5732410252094269, pod: 35.951502084732056, loss: 39.931089878082275 
Train [23/26] | Epoch [104/160] |	nca: 2.1130768582224846, flat: 1.445707943290472, pod: 33.73778557777405, loss: 37.2965704202652 
Train [23/26] | Epoch [105/160] |	nca: 2.2537682503461838, flat: 1.4142073541879654, pod: 33.595967531204224, loss: 37.26394307613373 
Train [23/26] | Epoch [106/160] |	nca: 2.393662504851818, flat: 1.4131891839206219, pod: 34.29088318347931, loss: 38.097734689712524 
Train [23/26] | Epoch [107/160] |	nca: 2.174171596765518, flat: 1.4015856944024563, pod: 34.76944029331207, loss: 38.345197677612305 
Train [23/26] | Epoch [108/160] |	nca: 2.286810450255871, flat: 1.301699135452509, pod: 32.363752126693726, loss: 35.95226204395294 
Train [23/26] | Epoch [109/160] |	nca: 2.32402253895998, flat: 1.3927753642201424, pod: 33.67939078807831, loss: 37.396188139915466 
Train [23/26] | Epoch [110/160] |	nca: 2.196119286119938, flat: 1.443861123174429, pod: 32.82973647117615, loss: 36.46971666812897 
Train [23/26] | Epoch [111/160] |	nca: 2.2829916067421436, flat: 1.192160464823246, pod: 30.44343090057373, loss: 33.918583035469055 
Train [23/26] | Epoch [112/160] |	nca: 2.0887600779533386, flat: 1.3120824061334133, pod: 31.953614234924316, loss: 35.354456782341 
Train [23/26] | Epoch [113/160] |	nca: 2.418335683643818, flat: 1.3645318821072578, pod: 32.40709340572357, loss: 36.189961194992065 
Train [23/26] | Epoch [114/160] |	nca: 2.1946044340729713, flat: 1.236263606697321, pod: 31.449706435203552, loss: 34.880574464797974 
Train [23/26] | Epoch [115/160] |	nca: 2.150099031627178, flat: 1.2772537879645824, pod: 31.132566452026367, loss: 34.559919357299805 
Train [23/26] | Epoch [116/160] |	nca: 2.1287178695201874, flat: 1.253949347883463, pod: 31.62500822544098, loss: 35.00767540931702 
Train [23/26] | Epoch [117/160] |	nca: 2.1792125329375267, flat: 1.1756098940968513, pod: 31.494420886039734, loss: 34.84924352169037 
Train [23/26] | Epoch [118/160] |	nca: 2.1821061335504055, flat: 1.33345827460289, pod: 33.042916893959045, loss: 36.55848145484924 
Train [23/26] | Epoch [119/160] |	nca: 2.2520777881145477, flat: 1.188298013061285, pod: 30.141380429267883, loss: 33.58175551891327 
Train [23/26] | Epoch [120/160] |	nca: 2.012964189052582, flat: 1.1991645582020283, pod: 30.360724925994873, loss: 33.572853684425354 
Train [23/26] | Epoch [121/160] |	nca: 2.2035771310329437, flat: 1.193584781140089, pod: 30.164785385131836, loss: 33.56194734573364 
Train [23/26] | Epoch [122/160] |	nca: 2.0352901220321655, flat: 1.069541946053505, pod: 27.677642464637756, loss: 30.782474398612976 
Train [23/26] | Epoch [123/160] |	nca: 2.183958798646927, flat: 1.142309546470642, pod: 29.46135151386261, loss: 32.787619948387146 
Train [23/26] | Epoch [124/160] |	nca: 2.105471171438694, flat: 1.0838103760033846, pod: 27.650286614894867, loss: 30.839568257331848 
Train [23/26] | Epoch [125/160] |	nca: 2.013589084148407, flat: 1.0356860719621181, pod: 28.060032904148102, loss: 31.109308004379272 
Train [23/26] | Epoch [126/160] |	nca: 2.130587924271822, flat: 1.133364301174879, pod: 28.772549271583557, loss: 32.03650164604187 
Train [23/26] | Epoch [127/160] |	nca: 2.067648947238922, flat: 1.0490568056702614, pod: 27.57115399837494, loss: 30.687859535217285 
Train [23/26] | Epoch [128/160] |	nca: 2.1246400736272335, flat: 1.062404716387391, pod: 27.03288996219635, loss: 30.219934821128845 
Train [23/26] | Epoch [129/160] |	nca: 1.9762139804661274, flat: 1.0474325623363256, pod: 27.692391216754913, loss: 30.71603786945343 
Train [23/26] | Epoch [130/160] |	nca: 2.2272995077073574, flat: 1.0025253370404243, pod: 27.548315346240997, loss: 30.7781400680542 
Train [23/26] | Epoch [131/160] |	nca: 2.196524042636156, flat: 0.9972746763378382, pod: 26.577685356140137, loss: 29.771483898162842 
Train [23/26] | Epoch [132/160] |	nca: 2.105973035097122, flat: 0.9767820537090302, pod: 26.696736693382263, loss: 29.779492020606995 
Train [23/26] | Epoch [133/160] |	nca: 2.1099198050796986, flat: 1.0451771523803473, pod: 27.107481479644775, loss: 30.26257824897766 
Train [23/26] | Epoch [134/160] |	nca: 2.038220416754484, flat: 0.9456759300082922, pod: 25.91500747203827, loss: 28.898903608322144 
Train [23/26] | Epoch [135/160] |	nca: 2.0622973889112473, flat: 0.8997513521462679, pod: 24.852877736091614, loss: 27.814926505088806 
Train [23/26] | Epoch [136/160] |	nca: 2.308503970503807, flat: 0.9559367597103119, pod: 25.056036829948425, loss: 28.320477783679962 
Train [23/26] | Epoch [137/160] |	nca: 2.1286043152213097, flat: 0.9359006080776453, pod: 24.831476151943207, loss: 27.895981311798096 
Train [23/26] | Epoch [138/160] |	nca: 1.9876678846776485, flat: 0.9200311116874218, pod: 25.51117640733719, loss: 28.418875455856323 
Train [23/26] | Epoch [139/160] |	nca: 1.9942826218903065, flat: 0.9198047108948231, pod: 24.956994235515594, loss: 27.871081590652466 
Train [23/26] | Epoch [140/160] |	nca: 2.013116203248501, flat: 0.9715610779821873, pod: 25.48343253135681, loss: 28.468109786510468 
Train [23/26] | Epoch [141/160] |	nca: 2.201589196920395, flat: 0.8759632539004087, pod: 23.50089979171753, loss: 26.578452050685883 
Train [23/26] | Epoch [142/160] |	nca: 2.1318439841270447, flat: 0.8771588541567326, pod: 23.68716073036194, loss: 26.696163833141327 
Train [23/26] | Epoch [143/160] |	nca: 2.211425017565489, flat: 0.9419100992381573, pod: 24.364137053489685, loss: 27.5174720287323 
Train [23/26] | Epoch [144/160] |	nca: 1.952295921742916, flat: 0.7995381392538548, pod: 22.168229162693024, loss: 24.920063257217407 
Train [23/26] | Epoch [145/160] |	nca: 2.046510625630617, flat: 0.8022253345698118, pod: 23.14351087808609, loss: 25.992246866226196 
Train [23/26] | Epoch [146/160] |	nca: 1.9461421109735966, flat: 0.7803860604763031, pod: 22.453557014465332, loss: 25.180084943771362 
Train [23/26] | Epoch [147/160] |	nca: 1.9522038102149963, flat: 0.8185148630291224, pod: 22.14802986383438, loss: 24.91874861717224 
Train [23/26] | Epoch [148/160] |	nca: 2.0076933577656746, flat: 0.7921995799988508, pod: 22.08030527830124, loss: 24.880198299884796 
Train [23/26] | Epoch [149/160] |	nca: 2.217615194618702, flat: 0.8930275123566389, pod: 23.15247815847397, loss: 26.263120889663696 
Train [23/26] | Epoch [150/160] |	nca: 2.1182240396738052, flat: 0.7574088461697102, pod: 21.54340785741806, loss: 24.41904103755951 
Train [23/26] | Epoch [151/160] |	nca: 1.958507064729929, flat: 0.8712933715432882, pod: 23.666865289211273, loss: 26.49666553735733 
Train [23/26] | Epoch [152/160] |	nca: 1.9437916651368141, flat: 0.8332101050764322, pod: 22.233986794948578, loss: 25.010988533496857 
Train [23/26] | Epoch [153/160] |	nca: 1.887012168765068, flat: 0.7828296180814505, pod: 21.732427179813385, loss: 24.40226912498474 
Train [23/26] | Epoch [154/160] |	nca: 1.9463040195405483, flat: 0.8396282885223627, pod: 22.531529247760773, loss: 25.31746196746826 
Train [23/26] | Epoch [155/160] |	nca: 2.207973551005125, flat: 0.8319321032613516, pod: 22.20904839038849, loss: 25.24895417690277 
Train [23/26] | Epoch [156/160] |	nca: 1.8701641708612442, flat: 0.813232546672225, pod: 22.429097294807434, loss: 25.112493991851807 
Train [23/26] | Epoch [157/160] |	nca: 2.0153157748281956, flat: 0.7946391440927982, pod: 21.807972013950348, loss: 24.617926955223083 
Train [23/26] | Epoch [158/160] |	nca: 1.8776236027479172, flat: 0.7545662149786949, pod: 21.946294963359833, loss: 24.57848483324051 
Train [23/26] | Epoch [159/160] |	nca: 2.2170629128813744, flat: 0.8094603940844536, pod: 22.872387945652008, loss: 25.89891117811203 
Train [23/26] | Epoch [160/160] |	nca: 2.0767007246613503, flat: 0.7497267629951239, pod: 21.56222277879715, loss: 24.38865029811859 
Fine-tuning
Building & updating memory.
Train [23/26] | Epoch [161/180] |	nca: 1.0959798023104668, flat: 0.8170211538672447, pod: 16.90228909254074, loss: 18.815289974212646 
Train [23/26] | Epoch [162/180] |	nca: 0.751187976449728, flat: 0.8168324753642082, pod: 16.92868411540985, loss: 18.49670445919037 
Train [23/26] | Epoch [163/180] |	nca: 0.6920949518680573, flat: 0.8215943314135075, pod: 16.941157341003418, loss: 18.454846620559692 
Train [23/26] | Epoch [164/180] |	nca: 0.6662724278867245, flat: 0.7810831405222416, pod: 16.23657101392746, loss: 17.68392676115036 
Train [23/26] | Epoch [165/180] |	nca: 0.5931853782385588, flat: 0.8174902312457561, pod: 16.617545127868652, loss: 18.028220534324646 
Train [23/26] | Epoch [166/180] |	nca: 0.633620472624898, flat: 0.8415011093020439, pod: 16.86805272102356, loss: 18.34317409992218 
Train [23/26] | Epoch [167/180] |	nca: 0.6087537668645382, flat: 0.8065067082643509, pod: 16.79284703731537, loss: 18.208107471466064 
Train [23/26] | Epoch [168/180] |	nca: 0.5727292690426111, flat: 0.8303796127438545, pod: 16.657352089881897, loss: 18.060461163520813 
Train [23/26] | Epoch [169/180] |	nca: 0.5956205800175667, flat: 0.8298995047807693, pod: 17.131816744804382, loss: 18.557336807250977 
Train [23/26] | Epoch [170/180] |	nca: 0.5583320800215006, flat: 0.8501450680196285, pod: 17.319390177726746, loss: 18.727867364883423 
Train [23/26] | Epoch [171/180] |	nca: 0.5318077839910984, flat: 0.8122545219957829, pod: 16.55172848701477, loss: 17.895790696144104 
Train [23/26] | Epoch [172/180] |	nca: 0.5399775635451078, flat: 0.8365542367100716, pod: 16.924809992313385, loss: 18.301342010498047 
Train [23/26] | Epoch [173/180] |	nca: 0.5115147680044174, flat: 0.8276580050587654, pod: 16.86597388982773, loss: 18.205146491527557 
Train [23/26] | Epoch [174/180] |	nca: 0.4950523879379034, flat: 0.8382508978247643, pod: 16.839984893798828, loss: 18.173288226127625 
Train [23/26] | Epoch [175/180] |	nca: 0.5115184206515551, flat: 0.8286773525178432, pod: 16.58430588245392, loss: 17.924501657485962 
Train [23/26] | Epoch [176/180] |	nca: 0.5026720874011517, flat: 0.8412861973047256, pod: 17.04293781518936, loss: 18.386896014213562 
Train [23/26] | Epoch [177/180] |	nca: 0.47841732390224934, flat: 0.8093212805688381, pod: 16.57566910982132, loss: 17.863407731056213 
Train [23/26] | Epoch [178/180] |	nca: 0.48334076069295406, flat: 0.7867049761116505, pod: 16.17693692445755, loss: 17.446982741355896 
Train [23/26] | Epoch [179/180] |	nca: 0.49983309768140316, flat: 0.8173445947468281, pod: 16.795222759246826, loss: 18.11240029335022 
Train [23/26] | Epoch [180/180] |	nca: 0.507196918129921, flat: 0.8092159666121006, pod: 16.569220662117004, loss: 17.88563370704651 
after task
Building & updating memory.
after task
Eval on 0->94.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.600304347826087.
Current acc: {'total': 0.512, '00-09': 0.576, '10-19': 0.514, '20-29': 0.434, '30-39': 0.476, '40-49': 0.522, '50-59': 0.535, '60-69': 0.457, '70-79': 0.546, '80-89': 0.563, '90-99': 0.482}.
Avg inc acc top5: 0.8554782608695651.
Current acc top5: {'total': 0.81}.
Forgetting: 0.1688181818181818.
Cord metric: 0.58.
Old accuracy: 0.51, mean: 0.59.
New accuracy: 0.42, mean: 0.63.
================Task 23 Start!================
Testing on False unseen tasks (max class = 96).
Set memory of size: 1880.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 23 Training!================
The training samples number: 2880
Train on 94->96.
train task
nb 2880.
Train [24/26] | Epoch [1/160] |	nca: 15.92699819803238, flat: 5.912260163575411, pod: 59.544642865657806, loss: 81.38390064239502 
Train [24/26] | Epoch [2/160] |	nca: 9.712592780590057, flat: 5.6789084523916245, pod: 66.82304453849792, loss: 82.21454501152039 
Train [24/26] | Epoch [3/160] |	nca: 6.911274284124374, flat: 4.776792719960213, pod: 64.38845920562744, loss: 76.07652640342712 
Train [24/26] | Epoch [4/160] |	nca: 5.582148730754852, flat: 4.007032155990601, pod: 58.66799974441528, loss: 68.2571804523468 
Train [24/26] | Epoch [5/160] |	nca: 5.758610561490059, flat: 3.668437734246254, pod: 57.271162033081055, loss: 66.69821047782898 
Train [24/26] | Epoch [6/160] |	nca: 5.073663175106049, flat: 3.5989185571670532, pod: 58.894619941711426, loss: 67.56720161437988 
Train [24/26] | Epoch [7/160] |	nca: 4.235937371850014, flat: 3.080410785973072, pod: 53.729790925979614, loss: 61.04613947868347 
Train [24/26] | Epoch [8/160] |	nca: 4.471280142664909, flat: 3.2380546629428864, pod: 55.463016510009766, loss: 63.172351598739624 
Train [24/26] | Epoch [9/160] |	nca: 4.0187613517045975, flat: 3.0499678626656532, pod: 52.92940044403076, loss: 59.998130083084106 
Train [24/26] | Epoch [10/160] |	nca: 4.163994386792183, flat: 2.891698196530342, pod: 51.61534357070923, loss: 58.67103624343872 
Train [24/26] | Epoch [11/160] |	nca: 3.777706429362297, flat: 2.6881242245435715, pod: 50.49387288093567, loss: 56.95970392227173 
Train [24/26] | Epoch [12/160] |	nca: 3.604600243270397, flat: 2.623313456773758, pod: 49.09672737121582, loss: 55.32464146614075 
Train [24/26] | Epoch [13/160] |	nca: 3.7545106932520866, flat: 2.766273617744446, pod: 51.311564803123474, loss: 57.832348585128784 
Train [24/26] | Epoch [14/160] |	nca: 3.7860898450016975, flat: 2.7781205028295517, pod: 51.66862964630127, loss: 58.2328405380249 
Train [24/26] | Epoch [15/160] |	nca: 3.958082750439644, flat: 2.881529785692692, pod: 51.20612454414368, loss: 58.04573726654053 
Train [24/26] | Epoch [16/160] |	nca: 3.962113179266453, flat: 2.9397993460297585, pod: 51.35835146903992, loss: 58.26026391983032 
Train [24/26] | Epoch [17/160] |	nca: 3.6271114125847816, flat: 2.982384644448757, pod: 52.45441031455994, loss: 59.0639066696167 
Train [24/26] | Epoch [18/160] |	nca: 3.678956560790539, flat: 2.750753529369831, pod: 51.40374684333801, loss: 57.83345627784729 
Train [24/26] | Epoch [19/160] |	nca: 3.3900995701551437, flat: 2.601980537176132, pod: 50.73885750770569, loss: 56.73093771934509 
Train [24/26] | Epoch [20/160] |	nca: 3.7800982743501663, flat: 2.829406663775444, pod: 53.03987979888916, loss: 59.64938473701477 
Train [24/26] | Epoch [21/160] |	nca: 3.4641278013587, flat: 2.685175620019436, pod: 50.38755393028259, loss: 56.53685760498047 
Train [24/26] | Epoch [22/160] |	nca: 3.6254608780145645, flat: 2.8626255244016647, pod: 51.35317897796631, loss: 57.841264963150024 
Train [24/26] | Epoch [23/160] |	nca: 3.308131515979767, flat: 2.8293312266469, pod: 52.61567950248718, loss: 58.7531418800354 
Train [24/26] | Epoch [24/160] |	nca: 3.1839251816272736, flat: 2.487876236438751, pod: 48.334341168403625, loss: 54.00614333152771 
Train [24/26] | Epoch [25/160] |	nca: 3.7109173387289047, flat: 2.5800670832395554, pod: 49.50468182563782, loss: 55.795665979385376 
Train [24/26] | Epoch [26/160] |	nca: 3.2445382699370384, flat: 2.61997202783823, pod: 50.364869356155396, loss: 56.22938013076782 
Train [24/26] | Epoch [27/160] |	nca: 3.5835482850670815, flat: 2.531656935811043, pod: 47.58828341960907, loss: 53.70348858833313 
Train [24/26] | Epoch [28/160] |	nca: 3.5346964821219444, flat: 2.570774845778942, pod: 49.2992947101593, loss: 55.40476608276367 
Train [24/26] | Epoch [29/160] |	nca: 3.011825703084469, flat: 2.4298534393310547, pod: 47.72998511791229, loss: 53.171664237976074 
Train [24/26] | Epoch [30/160] |	nca: 3.3836307525634766, flat: 2.4347566217184067, pod: 47.446322202682495, loss: 53.26470971107483 
Train [24/26] | Epoch [31/160] |	nca: 3.293662339448929, flat: 2.689479000866413, pod: 50.17418074607849, loss: 56.15732169151306 
Train [24/26] | Epoch [32/160] |	nca: 3.289026267826557, flat: 2.414848081767559, pod: 48.02024734020233, loss: 53.72412180900574 
Train [24/26] | Epoch [33/160] |	nca: 3.070711597800255, flat: 2.158149980008602, pod: 44.278876185417175, loss: 49.50773763656616 
Train [24/26] | Epoch [34/160] |	nca: 3.0263889729976654, flat: 2.2063312083482742, pod: 45.0570969581604, loss: 50.289817333221436 
Train [24/26] | Epoch [35/160] |	nca: 2.9535624906420708, flat: 2.3820923939347267, pod: 47.87809669971466, loss: 53.21375131607056 
Train [24/26] | Epoch [36/160] |	nca: 3.4374808967113495, flat: 2.4138408601284027, pod: 47.177942991256714, loss: 53.0292649269104 
Train [24/26] | Epoch [37/160] |	nca: 3.2089396938681602, flat: 2.4339253306388855, pod: 46.468215107917786, loss: 52.111079454422 
Train [24/26] | Epoch [38/160] |	nca: 3.284249357879162, flat: 2.5181073397397995, pod: 48.293837785720825, loss: 54.09619450569153 
Train [24/26] | Epoch [39/160] |	nca: 3.0828826650977135, flat: 2.522037699818611, pod: 48.52660870552063, loss: 54.131529331207275 
Train [24/26] | Epoch [40/160] |	nca: 3.1602136492729187, flat: 2.3777861893177032, pod: 46.03443956375122, loss: 51.572439670562744 
Train [24/26] | Epoch [41/160] |	nca: 3.041765049099922, flat: 2.278115436434746, pod: 45.31628131866455, loss: 50.63616168498993 
Train [24/26] | Epoch [42/160] |	nca: 2.800314649939537, flat: 2.09671101719141, pod: 44.235764145851135, loss: 49.13278949260712 
Train [24/26] | Epoch [43/160] |	nca: 2.947107322514057, flat: 2.1697057634592056, pod: 43.9715234041214, loss: 49.08833622932434 
Train [24/26] | Epoch [44/160] |	nca: 2.894228018820286, flat: 2.1325888261198997, pod: 43.5814528465271, loss: 48.608269691467285 
Train [24/26] | Epoch [45/160] |	nca: 3.1177788004279137, flat: 2.2868762835860252, pod: 45.73335313796997, loss: 51.13800811767578 
Train [24/26] | Epoch [46/160] |	nca: 3.1750657185912132, flat: 2.35884627699852, pod: 45.66887140274048, loss: 51.20278322696686 
Train [24/26] | Epoch [47/160] |	nca: 2.8124369606375694, flat: 2.167176842689514, pod: 45.05138599872589, loss: 50.03100037574768 
Train [24/26] | Epoch [48/160] |	nca: 3.1909495666623116, flat: 2.3275360837578773, pod: 46.453622698783875, loss: 51.97210884094238 
Train [24/26] | Epoch [49/160] |	nca: 3.1701537743210793, flat: 2.2672205567359924, pod: 45.631948471069336, loss: 51.06932282447815 
Train [24/26] | Epoch [50/160] |	nca: 2.827066294848919, flat: 2.072978302836418, pod: 42.37260925769806, loss: 47.27265405654907 
Train [24/26] | Epoch [51/160] |	nca: 2.828556038439274, flat: 2.066397987306118, pod: 43.53813695907593, loss: 48.43309164047241 
Train [24/26] | Epoch [52/160] |	nca: 2.6415849551558495, flat: 2.0927183404564857, pod: 43.42018735408783, loss: 48.15449011325836 
Train [24/26] | Epoch [53/160] |	nca: 2.847937248647213, flat: 2.0920765325427055, pod: 43.75946819782257, loss: 48.69948196411133 
Train [24/26] | Epoch [54/160] |	nca: 2.9653385207057, flat: 2.2653681710362434, pod: 45.802717089653015, loss: 51.03342366218567 
Train [24/26] | Epoch [55/160] |	nca: 2.6777134090662003, flat: 2.054754890501499, pod: 44.661155462265015, loss: 49.39362382888794 
Train [24/26] | Epoch [56/160] |	nca: 2.7810375690460205, flat: 2.045846313238144, pod: 44.11918127536774, loss: 48.946064829826355 
Train [24/26] | Epoch [57/160] |	nca: 2.725377157330513, flat: 2.0177486687898636, pod: 42.31569564342499, loss: 47.05882120132446 
Train [24/26] | Epoch [58/160] |	nca: 2.7491643205285072, flat: 1.926021121442318, pod: 40.978814482688904, loss: 45.6540002822876 
Train [24/26] | Epoch [59/160] |	nca: 2.5640762373805046, flat: 1.9431119039654732, pod: 41.50255370140076, loss: 46.00974154472351 
Train [24/26] | Epoch [60/160] |	nca: 2.7939036041498184, flat: 1.980271376669407, pod: 41.50446677207947, loss: 46.27864193916321 
Train [24/26] | Epoch [61/160] |	nca: 3.012155145406723, flat: 2.1100506335496902, pod: 44.00248694419861, loss: 49.124693393707275 
Train [24/26] | Epoch [62/160] |	nca: 3.040599100291729, flat: 2.151932455599308, pod: 44.75033509731293, loss: 49.94286668300629 
Train [24/26] | Epoch [63/160] |	nca: 3.077021859586239, flat: 2.1009823456406593, pod: 43.95656681060791, loss: 49.13457119464874 
Train [24/26] | Epoch [64/160] |	nca: 3.0151148959994316, flat: 2.1631699353456497, pod: 44.21050691604614, loss: 49.38879179954529 
Train [24/26] | Epoch [65/160] |	nca: 2.7197051271796227, flat: 2.04057826846838, pod: 42.96041250228882, loss: 47.720696210861206 
Train [24/26] | Epoch [66/160] |	nca: 2.701664336025715, flat: 2.1012360230088234, pod: 44.19471764564514, loss: 48.997617959976196 
Train [24/26] | Epoch [67/160] |	nca: 2.479739263653755, flat: 1.859456606209278, pod: 41.424901723861694, loss: 45.764097452163696 
Train [24/26] | Epoch [68/160] |	nca: 2.7082215398550034, flat: 1.9686394482851028, pod: 42.219181537628174, loss: 46.896042585372925 
Train [24/26] | Epoch [69/160] |	nca: 2.5149897038936615, flat: 1.8036169409751892, pod: 40.11156129837036, loss: 44.43016791343689 
Train [24/26] | Epoch [70/160] |	nca: 2.510022446513176, flat: 1.8151836395263672, pod: 40.323007106781006, loss: 44.648213624954224 
Train [24/26] | Epoch [71/160] |	nca: 2.758377604186535, flat: 1.870129056274891, pod: 40.955204010009766, loss: 45.58371043205261 
Train [24/26] | Epoch [72/160] |	nca: 2.653701715171337, flat: 1.7460171803832054, pod: 38.8808296918869, loss: 43.280548453330994 
Train [24/26] | Epoch [73/160] |	nca: 2.7350832372903824, flat: 1.923923820257187, pod: 41.38608229160309, loss: 46.04508948326111 
Train [24/26] | Epoch [74/160] |	nca: 2.6732001900672913, flat: 1.822782576084137, pod: 40.65182387828827, loss: 45.14780616760254 
Train [24/26] | Epoch [75/160] |	nca: 2.5793014839291573, flat: 1.7708205096423626, pod: 39.47727310657501, loss: 43.82739496231079 
Train [24/26] | Epoch [76/160] |	nca: 2.4399049058556557, flat: 1.6685198843479156, pod: 38.52933704853058, loss: 42.63776218891144 
Train [24/26] | Epoch [77/160] |	nca: 2.6127152517437935, flat: 1.6642207354307175, pod: 38.3276184797287, loss: 42.604554414749146 
Train [24/26] | Epoch [78/160] |	nca: 2.570276640355587, flat: 1.7471871189773083, pod: 38.856200218200684, loss: 43.17366409301758 
Train [24/26] | Epoch [79/160] |	nca: 2.6692902594804764, flat: 1.6858328990638256, pod: 39.00329506397247, loss: 43.358418583869934 
Train [24/26] | Epoch [80/160] |	nca: 2.4933078065514565, flat: 1.6613004319369793, pod: 37.04492545127869, loss: 41.199533581733704 
Train [24/26] | Epoch [81/160] |	nca: 2.3596458807587624, flat: 1.5248040221631527, pod: 36.66253674030304, loss: 40.54698705673218 
Train [24/26] | Epoch [82/160] |	nca: 2.2002416774630547, flat: 1.529613509774208, pod: 37.075053691864014, loss: 40.804908752441406 
Train [24/26] | Epoch [83/160] |	nca: 2.4164252877235413, flat: 1.410226620733738, pod: 35.03200829029083, loss: 38.858659982681274 
Train [24/26] | Epoch [84/160] |	nca: 2.4238658249378204, flat: 1.5765071548521519, pod: 37.56392753124237, loss: 41.564300537109375 
Train [24/26] | Epoch [85/160] |	nca: 2.6914203241467476, flat: 1.6127591282129288, pod: 37.672128438949585, loss: 41.97630798816681 
Train [24/26] | Epoch [86/160] |	nca: 2.6588859856128693, flat: 1.6550644114613533, pod: 38.20514488220215, loss: 42.51909518241882 
Train [24/26] | Epoch [87/160] |	nca: 2.4782457426190376, flat: 1.6342176124453545, pod: 39.205031633377075, loss: 43.31749510765076 
Train [24/26] | Epoch [88/160] |	nca: 2.404613606631756, flat: 1.4543513879179955, pod: 34.502084374427795, loss: 38.36104965209961 
Train [24/26] | Epoch [89/160] |	nca: 2.572731539607048, flat: 1.498011227697134, pod: 35.71210479736328, loss: 39.78284764289856 
Train [24/26] | Epoch [90/160] |	nca: 2.4897743090987206, flat: 1.508958451449871, pod: 36.225719571113586, loss: 40.22445261478424 
Train [24/26] | Epoch [91/160] |	nca: 2.425807647407055, flat: 1.5605947263538837, pod: 37.60476469993591, loss: 41.5911670923233 
Train [24/26] | Epoch [92/160] |	nca: 2.293607398867607, flat: 1.5244453847408295, pod: 37.07000911235809, loss: 40.88806164264679 
Train [24/26] | Epoch [93/160] |	nca: 2.2772968113422394, flat: 1.4058479145169258, pod: 35.11888337135315, loss: 38.80202829837799 
Train [24/26] | Epoch [94/160] |	nca: 2.3243217319250107, flat: 1.352265127003193, pod: 34.02181053161621, loss: 37.698397278785706 
Train [24/26] | Epoch [95/160] |	nca: 2.3966029509902, flat: 1.2646350339055061, pod: 32.700037240982056, loss: 36.36127519607544 
Train [24/26] | Epoch [96/160] |	nca: 2.397525329142809, flat: 1.3684893436729908, pod: 35.07708275318146, loss: 38.843097448349 
Train [24/26] | Epoch [97/160] |	nca: 2.1584878638386726, flat: 1.415494255721569, pod: 35.636270403862, loss: 39.21025252342224 
Train [24/26] | Epoch [98/160] |	nca: 2.372151553630829, flat: 1.2370702102780342, pod: 33.050554037094116, loss: 36.659775733947754 
Train [24/26] | Epoch [99/160] |	nca: 2.3995852768421173, flat: 1.3690274506807327, pod: 34.225547313690186, loss: 37.9941600561142 
Train [24/26] | Epoch [100/160] |	nca: 2.3644600957632065, flat: 1.3177329264581203, pod: 33.548324942588806, loss: 37.230517864227295 
Train [24/26] | Epoch [101/160] |	nca: 2.244683153927326, flat: 1.2592434994876385, pod: 32.57779347896576, loss: 36.08172011375427 
Train [24/26] | Epoch [102/160] |	nca: 2.2778990864753723, flat: 1.215231191366911, pod: 32.06947994232178, loss: 35.562610387802124 
Train [24/26] | Epoch [103/160] |	nca: 2.410021096467972, flat: 1.1621857546269894, pod: 31.305510878562927, loss: 34.87771761417389 
Train [24/26] | Epoch [104/160] |	nca: 2.353080704808235, flat: 1.1983341947197914, pod: 31.825090527534485, loss: 35.376505613327026 
Train [24/26] | Epoch [105/160] |	nca: 2.2922561019659042, flat: 1.1686557866632938, pod: 30.43487513065338, loss: 33.89578688144684 
Train [24/26] | Epoch [106/160] |	nca: 2.42983291298151, flat: 1.1966968514025211, pod: 31.438003063201904, loss: 35.06453251838684 
Train [24/26] | Epoch [107/160] |	nca: 2.215358778834343, flat: 1.183478269726038, pod: 32.315751791000366, loss: 35.71458864212036 
Train [24/26] | Epoch [108/160] |	nca: 2.250807896256447, flat: 1.2132489159703255, pod: 31.418554544448853, loss: 34.88261115550995 
Train [24/26] | Epoch [109/160] |	nca: 2.2564828991889954, flat: 1.2212057039141655, pod: 32.216949701309204, loss: 35.69463837146759 
Train [24/26] | Epoch [110/160] |	nca: 2.0459333062171936, flat: 1.0809960775077343, pod: 30.126779913902283, loss: 33.25370967388153 
Train [24/26] | Epoch [111/160] |	nca: 2.334916189312935, flat: 1.160070177167654, pod: 31.852686166763306, loss: 35.34767246246338 
Train [24/26] | Epoch [112/160] |	nca: 2.214366540312767, flat: 1.0006310101598501, pod: 28.908939719200134, loss: 32.123937368392944 
Train [24/26] | Epoch [113/160] |	nca: 2.0532917082309723, flat: 1.0612014569342136, pod: 28.91180443763733, loss: 32.02629768848419 
Train [24/26] | Epoch [114/160] |	nca: 2.282739832997322, flat: 1.0617285668849945, pod: 28.67535662651062, loss: 32.01982533931732 
Train [24/26] | Epoch [115/160] |	nca: 2.190466456115246, flat: 1.1363335028290749, pod: 31.434211254119873, loss: 34.761011242866516 
Train [24/26] | Epoch [116/160] |	nca: 2.3563848212361336, flat: 1.087323073297739, pod: 30.892708659172058, loss: 34.336416602134705 
Train [24/26] | Epoch [117/160] |	nca: 2.1563954539597034, flat: 1.0381665043532848, pod: 28.40698993206024, loss: 31.60155200958252 
Train [24/26] | Epoch [118/160] |	nca: 2.343212392181158, flat: 1.0973954051733017, pod: 28.776998281478882, loss: 32.21760594844818 
Train [24/26] | Epoch [119/160] |	nca: 2.2674844190478325, flat: 1.0704707317054272, pod: 29.23138463497162, loss: 32.569339871406555 
Train [24/26] | Epoch [120/160] |	nca: 2.2403963655233383, flat: 0.9955181628465652, pod: 27.87755596637726, loss: 31.113470554351807 
Train [24/26] | Epoch [121/160] |	nca: 2.138337839394808, flat: 0.934169065207243, pod: 27.081628441810608, loss: 30.15413546562195 
Train [24/26] | Epoch [122/160] |	nca: 2.2236013785004616, flat: 0.9083370789885521, pod: 26.070642173290253, loss: 29.20258069038391 
Train [24/26] | Epoch [123/160] |	nca: 2.409226171672344, flat: 0.9995700307190418, pod: 27.504801869392395, loss: 30.91359782218933 
Train [24/26] | Epoch [124/160] |	nca: 2.1176377050578594, flat: 0.9250554703176022, pod: 27.013220191001892, loss: 30.05591344833374 
Train [24/26] | Epoch [125/160] |	nca: 2.125460423529148, flat: 0.859704976901412, pod: 24.767863988876343, loss: 27.753029346466064 
Train [24/26] | Epoch [126/160] |	nca: 2.266521356999874, flat: 0.8388945329934359, pod: 24.740177989006042, loss: 27.84559416770935 
Train [24/26] | Epoch [127/160] |	nca: 2.3050663098692894, flat: 0.9203796740621328, pod: 26.101080656051636, loss: 29.326526880264282 
Train [24/26] | Epoch [128/160] |	nca: 2.2994969189167023, flat: 0.8223147261887789, pod: 24.699552536010742, loss: 27.821364283561707 
Train [24/26] | Epoch [129/160] |	nca: 2.1448690705001354, flat: 0.8620998524129391, pod: 24.920557022094727, loss: 27.927526116371155 
Train [24/26] | Epoch [130/160] |	nca: 2.1024086996912956, flat: 0.7564838957041502, pod: 23.216478407382965, loss: 26.075370967388153 
Train [24/26] | Epoch [131/160] |	nca: 2.2252054661512375, flat: 0.8441367261111736, pod: 25.344937801361084, loss: 28.414279997348785 
Train [24/26] | Epoch [132/160] |	nca: 2.1464339569211006, flat: 0.8405936993658543, pod: 25.240606009960175, loss: 28.227634012699127 
Train [24/26] | Epoch [133/160] |	nca: 2.15534894913435, flat: 0.786337673664093, pod: 23.520153880119324, loss: 26.461840510368347 
Train [24/26] | Epoch [134/160] |	nca: 2.168770231306553, flat: 0.8177630845457315, pod: 23.751308619976044, loss: 26.73784202337265 
Train [24/26] | Epoch [135/160] |	nca: 2.22755266726017, flat: 0.756590373814106, pod: 23.12783831357956, loss: 26.111981213092804 
Train [24/26] | Epoch [136/160] |	nca: 2.1413616091012955, flat: 0.7981314435601234, pod: 23.534568190574646, loss: 26.474060893058777 
Train [24/26] | Epoch [137/160] |	nca: 2.009276770055294, flat: 0.7529616244137287, pod: 23.268917858600616, loss: 26.031156301498413 
Train [24/26] | Epoch [138/160] |	nca: 2.1550923585891724, flat: 0.7469072174280882, pod: 23.16842555999756, loss: 26.070424914360046 
Train [24/26] | Epoch [139/160] |	nca: 2.2460133880376816, flat: 0.6992008797824383, pod: 21.445116937160492, loss: 24.390331149101257 
Train [24/26] | Epoch [140/160] |	nca: 2.2085245326161385, flat: 0.7709443178027868, pod: 22.471051573753357, loss: 25.450520396232605 
Train [24/26] | Epoch [141/160] |	nca: 2.2126698940992355, flat: 0.7206463683396578, pod: 21.940613865852356, loss: 24.873929977416992 
Train [24/26] | Epoch [142/160] |	nca: 2.120911218225956, flat: 0.7204695772379637, pod: 22.016299605369568, loss: 24.85768038034439 
Train [24/26] | Epoch [143/160] |	nca: 2.155618965625763, flat: 0.7053643967956305, pod: 21.67320889234543, loss: 24.534192323684692 
Train [24/26] | Epoch [144/160] |	nca: 2.0524298399686813, flat: 0.6824733801186085, pod: 21.24874097108841, loss: 23.983644127845764 
Train [24/26] | Epoch [145/160] |	nca: 2.3373091965913773, flat: 0.7158315926790237, pod: 21.617495238780975, loss: 24.670635998249054 
Train [24/26] | Epoch [146/160] |	nca: 2.1150824204087257, flat: 0.6799019612371922, pod: 20.591765761375427, loss: 23.386750102043152 
Train [24/26] | Epoch [147/160] |	nca: 2.084831342101097, flat: 0.6741816028952599, pod: 20.5065940618515, loss: 23.265606999397278 
Train [24/26] | Epoch [148/160] |	nca: 2.2255022525787354, flat: 0.7118750456720591, pod: 21.591624081134796, loss: 24.529001235961914 
Train [24/26] | Epoch [149/160] |	nca: 2.1739153787493706, flat: 0.7254563700407743, pod: 21.568332254886627, loss: 24.467703759670258 
Train [24/26] | Epoch [150/160] |	nca: 2.145896792411804, flat: 0.6862617321312428, pod: 20.33088254928589, loss: 23.16304123401642 
Train [24/26] | Epoch [151/160] |	nca: 2.1809138879179955, flat: 0.6362642422318459, pod: 19.595167219638824, loss: 22.412345349788666 
Train [24/26] | Epoch [152/160] |	nca: 2.222363017499447, flat: 0.660077067092061, pod: 20.10595327615738, loss: 22.988393247127533 
Train [24/26] | Epoch [153/160] |	nca: 2.089642908424139, flat: 0.6455520801246166, pod: 20.27973461151123, loss: 23.014929831027985 
Train [24/26] | Epoch [154/160] |	nca: 2.095807209610939, flat: 0.6710733473300934, pod: 19.932604908943176, loss: 22.699485301971436 
Train [24/26] | Epoch [155/160] |	nca: 2.0263696499168873, flat: 0.6334470305591822, pod: 19.904943704605103, loss: 22.564760327339172 
Train [24/26] | Epoch [156/160] |	nca: 2.2057354748249054, flat: 0.655345655977726, pod: 19.955028653144836, loss: 22.816109716892242 
Train [24/26] | Epoch [157/160] |	nca: 2.237751394510269, flat: 0.6686314586549997, pod: 20.025144040584564, loss: 22.93152678012848 
Train [24/26] | Epoch [158/160] |	nca: 2.0759572237730026, flat: 0.6397148575633764, pod: 19.815891921520233, loss: 22.531563997268677 
Train [24/26] | Epoch [159/160] |	nca: 2.1424229592084885, flat: 0.6197189949452877, pod: 19.312828063964844, loss: 22.07497000694275 
Train [24/26] | Epoch [160/160] |	nca: 2.1863492131233215, flat: 0.6659827046096325, pod: 19.937228202819824, loss: 22.78956037759781 
Fine-tuning
Building & updating memory.
Train [24/26] | Epoch [161/180] |	nca: 1.0485969111323357, flat: 0.6634628549218178, pod: 15.83976835012436, loss: 17.551827907562256 
Train [24/26] | Epoch [162/180] |	nca: 0.8476337231695652, flat: 0.6795297600328922, pod: 16.029581129550934, loss: 17.556744635105133 
Train [24/26] | Epoch [163/180] |	nca: 0.6469125598669052, flat: 0.6664620470255613, pod: 15.81478351354599, loss: 17.128158032894135 
Train [24/26] | Epoch [164/180] |	nca: 0.7075885608792305, flat: 0.7158869095146656, pod: 16.46385258436203, loss: 17.887328326702118 
Train [24/26] | Epoch [165/180] |	nca: 0.589644392952323, flat: 0.648733040317893, pod: 15.821207225322723, loss: 17.059584498405457 
Train [24/26] | Epoch [166/180] |	nca: 0.6253388933837414, flat: 0.6882195677608252, pod: 15.97232335805893, loss: 17.28588181734085 
Train [24/26] | Epoch [167/180] |	nca: 0.6771295890212059, flat: 0.7021748367697, pod: 15.86165064573288, loss: 17.24095529317856 
Train [24/26] | Epoch [168/180] |	nca: 0.6205970793962479, flat: 0.6721835359930992, pod: 16.059259474277496, loss: 17.352040112018585 
Train [24/26] | Epoch [169/180] |	nca: 0.6124174296855927, flat: 0.6793430931866169, pod: 16.185755610466003, loss: 17.477515935897827 
Train [24/26] | Epoch [170/180] |	nca: 0.5862710475921631, flat: 0.6649372577667236, pod: 15.893904983997345, loss: 17.145113170146942 
Train [24/26] | Epoch [171/180] |	nca: 0.5730880703777075, flat: 0.6506348252296448, pod: 16.136581003665924, loss: 17.360303819179535 
Train [24/26] | Epoch [172/180] |	nca: 0.5786315556615591, flat: 0.6819681152701378, pod: 15.440393924713135, loss: 16.700993597507477 
Train [24/26] | Epoch [173/180] |	nca: 0.5594851169735193, flat: 0.65225450694561, pod: 15.461718440055847, loss: 16.673458218574524 
Train [24/26] | Epoch [174/180] |	nca: 0.5511832889169455, flat: 0.716743279248476, pod: 16.5284041762352, loss: 17.79633057117462 
Train [24/26] | Epoch [175/180] |	nca: 0.556899493560195, flat: 0.6781228445470333, pod: 15.927450895309448, loss: 17.162473261356354 
Train [24/26] | Epoch [176/180] |	nca: 0.5286958999931812, flat: 0.6960468627512455, pod: 15.86822384595871, loss: 17.092966556549072 
Train [24/26] | Epoch [177/180] |	nca: 0.5325090829282999, flat: 0.6742269471287727, pod: 15.68808102607727, loss: 16.894816994667053 
Train [24/26] | Epoch [178/180] |	nca: 0.4949823245406151, flat: 0.6665770225226879, pod: 15.75440263748169, loss: 16.915962278842926 
Train [24/26] | Epoch [179/180] |	nca: 0.5210443269461393, flat: 0.7280923649668694, pod: 16.278511464595795, loss: 17.52764803171158 
Train [24/26] | Epoch [180/180] |	nca: 0.5237779635936022, flat: 0.6703424230217934, pod: 15.797952651977539, loss: 16.99207293987274 
after task
Building & updating memory.
after task
Eval on 0->96.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.5962083333333333.
Current acc: {'total': 0.502, '00-09': 0.575, '10-19': 0.503, '20-29': 0.411, '30-39': 0.474, '40-49': 0.517, '50-59': 0.533, '60-69': 0.441, '70-79': 0.533, '80-89': 0.548, '90-99': 0.47}.
Avg inc acc top5: 0.8530416666666666.
Current acc top5: {'total': 0.797}.
Forgetting: 0.1779090909090909.
Cord metric: 0.57.
Old accuracy: 0.50, mean: 0.59.
New accuracy: 0.47, mean: 0.62.
================Task 24 Start!================
Testing on False unseen tasks (max class = 98).
Set memory of size: 1920.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 24 Training!================
The training samples number: 2920
Train on 96->98.
train task
nb 2920.
Train [25/26] | Epoch [1/160] |	nca: 14.819078385829926, flat: 6.4301618039608, pod: 62.491310119628906, loss: 83.74055027961731 
Train [25/26] | Epoch [2/160] |	nca: 8.652250498533249, flat: 6.119335725903511, pod: 69.22631645202637, loss: 83.99790263175964 
Train [25/26] | Epoch [3/160] |	nca: 6.400986865162849, flat: 5.000495836138725, pod: 64.66074538230896, loss: 76.0622284412384 
Train [25/26] | Epoch [4/160] |	nca: 5.06758040189743, flat: 4.145007893443108, pod: 59.43737721443176, loss: 68.64996528625488 
Train [25/26] | Epoch [5/160] |	nca: 4.215789519250393, flat: 3.5905489176511765, pod: 57.94237947463989, loss: 65.74871778488159 
Train [25/26] | Epoch [6/160] |	nca: 3.5422195121645927, flat: 3.4074882566928864, pod: 56.94744801521301, loss: 63.89715528488159 
Train [25/26] | Epoch [7/160] |	nca: 3.782631330192089, flat: 3.4535667672753334, pod: 56.613648414611816, loss: 63.84984731674194 
Train [25/26] | Epoch [8/160] |	nca: 3.430831655859947, flat: 3.049505688250065, pod: 53.90644717216492, loss: 60.38678431510925 
Train [25/26] | Epoch [9/160] |	nca: 3.5226529762148857, flat: 2.989972487092018, pod: 52.62638711929321, loss: 59.139012813568115 
Train [25/26] | Epoch [10/160] |	nca: 3.0107292085886, flat: 2.6735554710030556, pod: 49.39761734008789, loss: 55.08190202713013 
Train [25/26] | Epoch [11/160] |	nca: 2.961680829524994, flat: 2.7751807868480682, pod: 53.172361612319946, loss: 58.909223556518555 
Train [25/26] | Epoch [12/160] |	nca: 3.268700197339058, flat: 2.9099100679159164, pod: 53.890400886535645, loss: 60.069010972976685 
Train [25/26] | Epoch [13/160] |	nca: 3.0650030225515366, flat: 2.600158967077732, pod: 50.08867430686951, loss: 55.753836154937744 
Train [25/26] | Epoch [14/160] |	nca: 3.0659841299057007, flat: 2.8122576624155045, pod: 52.50582838058472, loss: 58.38407111167908 
Train [25/26] | Epoch [15/160] |	nca: 3.021418623626232, flat: 2.856576345860958, pod: 53.878164529800415, loss: 59.75616002082825 
Train [25/26] | Epoch [16/160] |	nca: 2.772268168628216, flat: 2.5385094955563545, pod: 48.99373114109039, loss: 54.30450892448425 
Train [25/26] | Epoch [17/160] |	nca: 2.933979094028473, flat: 2.7277281433343887, pod: 50.90497326850891, loss: 56.56667995452881 
Train [25/26] | Epoch [18/160] |	nca: 2.983213670551777, flat: 2.614561475813389, pod: 49.49969661235809, loss: 55.097472190856934 
Train [25/26] | Epoch [19/160] |	nca: 2.896697722375393, flat: 2.7568318247795105, pod: 50.03467512130737, loss: 55.6882050037384 
Train [25/26] | Epoch [20/160] |	nca: 3.0757763385772705, flat: 2.9516268745064735, pod: 53.108534812927246, loss: 59.13593864440918 
Train [25/26] | Epoch [21/160] |	nca: 2.621674917638302, flat: 2.5980965942144394, pod: 50.14785671234131, loss: 55.36762833595276 
Train [25/26] | Epoch [22/160] |	nca: 2.8774558901786804, flat: 2.6399428993463516, pod: 48.764252066612244, loss: 54.28165078163147 
Train [25/26] | Epoch [23/160] |	nca: 2.627409867942333, flat: 2.4456015303730965, pod: 47.536250948905945, loss: 52.609262466430664 
Train [25/26] | Epoch [24/160] |	nca: 2.888168402016163, flat: 2.4551029056310654, pod: 48.41771674156189, loss: 53.76098823547363 
Train [25/26] | Epoch [25/160] |	nca: 2.786128841340542, flat: 2.5401812344789505, pod: 49.800493240356445, loss: 55.1268036365509 
Train [25/26] | Epoch [26/160] |	nca: 2.6354664713144302, flat: 2.283335968852043, pod: 47.0572190284729, loss: 51.9760217666626 
Train [25/26] | Epoch [27/160] |	nca: 2.477739118039608, flat: 2.3132810592651367, pod: 47.33999729156494, loss: 52.131016969680786 
Train [25/26] | Epoch [28/160] |	nca: 2.6150505617260933, flat: 2.345892183482647, pod: 46.77770972251892, loss: 51.73865258693695 
Train [25/26] | Epoch [29/160] |	nca: 2.7637710496783257, flat: 2.4880480021238327, pod: 50.26916027069092, loss: 55.520979166030884 
Train [25/26] | Epoch [30/160] |	nca: 2.8783408030867577, flat: 2.547824241220951, pod: 48.86904764175415, loss: 54.295212507247925 
Train [25/26] | Epoch [31/160] |	nca: 2.7320316582918167, flat: 2.3831765577197075, pod: 46.93393158912659, loss: 52.049139738082886 
Train [25/26] | Epoch [32/160] |	nca: 2.9141498655080795, flat: 2.49180955439806, pod: 49.21570026874542, loss: 54.62165951728821 
Train [25/26] | Epoch [33/160] |	nca: 2.530749350786209, flat: 2.305342748761177, pod: 45.99558687210083, loss: 50.83167922496796 
Train [25/26] | Epoch [34/160] |	nca: 2.643666736781597, flat: 2.2450920790433884, pod: 45.766363859176636, loss: 50.65512311458588 
Train [25/26] | Epoch [35/160] |	nca: 2.530918210744858, flat: 2.3449897095561028, pod: 47.286041498184204, loss: 52.161949634552 
Train [25/26] | Epoch [36/160] |	nca: 2.4333498030900955, flat: 2.2006643414497375, pod: 46.76957321166992, loss: 51.403587102890015 
Train [25/26] | Epoch [37/160] |	nca: 3.191433772444725, flat: 2.5653845444321632, pod: 50.807758927345276, loss: 56.56457734107971 
Train [25/26] | Epoch [38/160] |	nca: 2.7361304238438606, flat: 2.6157934367656708, pod: 48.860862493515015, loss: 54.21278619766235 
Train [25/26] | Epoch [39/160] |	nca: 2.6910537108778954, flat: 2.3047360107302666, pod: 46.67711126804352, loss: 51.67290139198303 
Train [25/26] | Epoch [40/160] |	nca: 2.4474484100937843, flat: 2.131178595125675, pod: 43.7506058216095, loss: 48.32923340797424 
Train [25/26] | Epoch [41/160] |	nca: 2.4237593337893486, flat: 2.1914534643292427, pod: 45.541598200798035, loss: 50.156811475753784 
Train [25/26] | Epoch [42/160] |	nca: 2.694490145891905, flat: 2.3554393723607063, pod: 47.83457887172699, loss: 52.88450884819031 
Train [25/26] | Epoch [43/160] |	nca: 2.2775897160172462, flat: 2.1846625432372093, pod: 45.808857560157776, loss: 50.27110993862152 
Train [25/26] | Epoch [44/160] |	nca: 2.4172766879200935, flat: 2.145024947822094, pod: 44.04063284397125, loss: 48.60293459892273 
Train [25/26] | Epoch [45/160] |	nca: 2.5126014426350594, flat: 2.059654548764229, pod: 43.592840909957886, loss: 48.16509687900543 
Train [25/26] | Epoch [46/160] |	nca: 2.573640838265419, flat: 2.2255137860774994, pod: 46.00133013725281, loss: 50.800485134124756 
Train [25/26] | Epoch [47/160] |	nca: 2.444866508245468, flat: 2.161164566874504, pod: 45.14367616176605, loss: 49.749706506729126 
Train [25/26] | Epoch [48/160] |	nca: 2.3278476893901825, flat: 1.9379507154226303, pod: 41.701019287109375, loss: 45.96681797504425 
Train [25/26] | Epoch [49/160] |	nca: 2.4729335829615593, flat: 2.0519324615597725, pod: 43.339362382888794, loss: 47.86422872543335 
Train [25/26] | Epoch [50/160] |	nca: 2.336286999285221, flat: 1.9620562866330147, pod: 41.692360281944275, loss: 45.99070405960083 
Train [25/26] | Epoch [51/160] |	nca: 2.618381753563881, flat: 2.113809660077095, pod: 44.92852067947388, loss: 49.660712122917175 
Train [25/26] | Epoch [52/160] |	nca: 2.279960200190544, flat: 2.0677163302898407, pod: 45.07308483123779, loss: 49.420761823654175 
Train [25/26] | Epoch [53/160] |	nca: 2.318323530256748, flat: 2.003101594746113, pod: 43.629579305648804, loss: 47.95100462436676 
Train [25/26] | Epoch [54/160] |	nca: 2.6281043738126755, flat: 2.051883541047573, pod: 42.344613432884216, loss: 47.024601459503174 
Train [25/26] | Epoch [55/160] |	nca: 2.3157548680901527, flat: 2.071478433907032, pod: 43.6139372587204, loss: 48.0011705160141 
Train [25/26] | Epoch [56/160] |	nca: 2.5734520256519318, flat: 2.011701926589012, pod: 43.5538330078125, loss: 48.13898742198944 
Train [25/26] | Epoch [57/160] |	nca: 2.318317908793688, flat: 2.039130039513111, pod: 44.16101825237274, loss: 48.518465995788574 
Train [25/26] | Epoch [58/160] |	nca: 2.236180067062378, flat: 1.8527343943715096, pod: 42.452879309654236, loss: 46.54179382324219 
Train [25/26] | Epoch [59/160] |	nca: 2.1876733861863613, flat: 1.9001438543200493, pod: 41.085835576057434, loss: 45.17365264892578 
Train [25/26] | Epoch [60/160] |	nca: 2.3342358767986298, flat: 1.7155116945505142, pod: 38.75535571575165, loss: 42.805102944374084 
Train [25/26] | Epoch [61/160] |	nca: 2.162606470286846, flat: 1.7100012451410294, pod: 40.406506180763245, loss: 44.27911388874054 
Train [25/26] | Epoch [62/160] |	nca: 2.2405635192990303, flat: 1.8127788379788399, pod: 40.45029807090759, loss: 44.50364065170288 
Train [25/26] | Epoch [63/160] |	nca: 2.3194870725274086, flat: 1.9469176232814789, pod: 43.0224746465683, loss: 47.28887927532196 
Train [25/26] | Epoch [64/160] |	nca: 2.425813391804695, flat: 2.1238521561026573, pod: 44.558029890060425, loss: 49.10769581794739 
Train [25/26] | Epoch [65/160] |	nca: 2.334188248962164, flat: 1.9107400923967361, pod: 41.77171862125397, loss: 46.01664710044861 
Train [25/26] | Epoch [66/160] |	nca: 2.246976226568222, flat: 1.859327308833599, pod: 41.676655292510986, loss: 45.78295886516571 
Train [25/26] | Epoch [67/160] |	nca: 2.1622873842716217, flat: 1.9086777940392494, pod: 43.21354699134827, loss: 47.2845116853714 
Train [25/26] | Epoch [68/160] |	nca: 2.1173666641116142, flat: 1.7598783001303673, pod: 40.83720123767853, loss: 44.71444606781006 
Train [25/26] | Epoch [69/160] |	nca: 2.0525209680199623, flat: 1.7117186337709427, pod: 39.17056095600128, loss: 42.93480086326599 
Train [25/26] | Epoch [70/160] |	nca: 2.2195717692375183, flat: 1.5802340880036354, pod: 38.71568500995636, loss: 42.515490889549255 
Train [25/26] | Epoch [71/160] |	nca: 2.324096590280533, flat: 1.738111287355423, pod: 40.252697587013245, loss: 44.31490516662598 
Train [25/26] | Epoch [72/160] |	nca: 2.2230608761310577, flat: 1.810093566775322, pod: 41.95755136013031, loss: 45.99070584774017 
Train [25/26] | Epoch [73/160] |	nca: 2.328542545437813, flat: 1.8050614297389984, pod: 40.19793164730072, loss: 44.33153569698334 
Train [25/26] | Epoch [74/160] |	nca: 2.291484773159027, flat: 1.73775252699852, pod: 41.474923849105835, loss: 45.5041606426239 
Train [25/26] | Epoch [75/160] |	nca: 2.514104276895523, flat: 1.9755574613809586, pod: 43.12837839126587, loss: 47.61804020404816 
Train [25/26] | Epoch [76/160] |	nca: 2.2081670984625816, flat: 1.7357608303427696, pod: 39.384899973869324, loss: 43.32882833480835 
Train [25/26] | Epoch [77/160] |	nca: 2.3643610924482346, flat: 1.5383236445486546, pod: 36.45119118690491, loss: 40.35387587547302 
Train [25/26] | Epoch [78/160] |	nca: 2.1873686015605927, flat: 1.6144647151231766, pod: 37.37835681438446, loss: 41.180190205574036 
Train [25/26] | Epoch [79/160] |	nca: 2.0980673879384995, flat: 1.5908529572188854, pod: 39.40914595127106, loss: 43.098066091537476 
Train [25/26] | Epoch [80/160] |	nca: 2.153001468628645, flat: 1.6937991864979267, pod: 39.938305616378784, loss: 43.78510582447052 
Train [25/26] | Epoch [81/160] |	nca: 2.1410312950611115, flat: 1.6463449150323868, pod: 38.528653144836426, loss: 42.31602895259857 
Train [25/26] | Epoch [82/160] |	nca: 2.1500678434967995, flat: 1.5888403952121735, pod: 38.51939296722412, loss: 42.25830125808716 
Train [25/26] | Epoch [83/160] |	nca: 1.9912922196090221, flat: 1.5187455490231514, pod: 36.52515935897827, loss: 40.035197019577026 
Train [25/26] | Epoch [84/160] |	nca: 2.125770431011915, flat: 1.4115337990224361, pod: 35.05112624168396, loss: 38.588430523872375 
Train [25/26] | Epoch [85/160] |	nca: 2.0731777250766754, flat: 1.4293434508144855, pod: 35.12105643749237, loss: 38.62357759475708 
Train [25/26] | Epoch [86/160] |	nca: 2.103824108839035, flat: 1.3697430118918419, pod: 35.2603223323822, loss: 38.73388922214508 
Train [25/26] | Epoch [87/160] |	nca: 2.021532643586397, flat: 1.4918591678142548, pod: 35.99324834346771, loss: 39.50664019584656 
Train [25/26] | Epoch [88/160] |	nca: 2.105576567351818, flat: 1.4378230832517147, pod: 35.92953705787659, loss: 39.47293663024902 
Train [25/26] | Epoch [89/160] |	nca: 1.9756299331784248, flat: 1.3714450560510159, pod: 35.173815846443176, loss: 38.520890951156616 
Train [25/26] | Epoch [90/160] |	nca: 2.088480118662119, flat: 1.3435945771634579, pod: 33.75071656703949, loss: 37.182791352272034 
Train [25/26] | Epoch [91/160] |	nca: 2.1048072278499603, flat: 1.3160736076533794, pod: 32.7515389919281, loss: 36.17241978645325 
Train [25/26] | Epoch [92/160] |	nca: 2.120824120938778, flat: 1.3938082493841648, pod: 35.421416878700256, loss: 38.9360488653183 
Train [25/26] | Epoch [93/160] |	nca: 2.0558583550155163, flat: 1.283527784049511, pod: 33.78864359855652, loss: 37.12802982330322 
Train [25/26] | Epoch [94/160] |	nca: 2.057567771524191, flat: 1.2852010019123554, pod: 33.504576683044434, loss: 36.84734559059143 
Train [25/26] | Epoch [95/160] |	nca: 2.003434680402279, flat: 1.2765003368258476, pod: 33.36476218700409, loss: 36.644696831703186 
Train [25/26] | Epoch [96/160] |	nca: 1.8822348341345787, flat: 1.222312469035387, pod: 33.369444489479065, loss: 36.47399163246155 
Train [25/26] | Epoch [97/160] |	nca: 2.0072614662349224, flat: 1.1909596771001816, pod: 32.30230271816254, loss: 35.500523805618286 
Train [25/26] | Epoch [98/160] |	nca: 2.0128247924149036, flat: 1.1807825490832329, pod: 31.431028962135315, loss: 34.62463653087616 
Train [25/26] | Epoch [99/160] |	nca: 2.048515908420086, flat: 1.2036820761859417, pod: 32.2905455827713, loss: 35.54274356365204 
Train [25/26] | Epoch [100/160] |	nca: 1.9903048798441887, flat: 1.153814360499382, pod: 31.016379594802856, loss: 34.16049885749817 
Train [25/26] | Epoch [101/160] |	nca: 1.9873360842466354, flat: 1.1659931652247906, pod: 32.2075297832489, loss: 35.36085915565491 
Train [25/26] | Epoch [102/160] |	nca: 1.9670448377728462, flat: 1.1391732729971409, pod: 31.166227340698242, loss: 34.27244508266449 
Train [25/26] | Epoch [103/160] |	nca: 2.152258299291134, flat: 1.1873706057667732, pod: 31.800415992736816, loss: 35.140044808387756 
Train [25/26] | Epoch [104/160] |	nca: 2.1366640105843544, flat: 1.2279238514602184, pod: 31.71340847015381, loss: 35.077996373176575 
Train [25/26] | Epoch [105/160] |	nca: 1.8918542973697186, flat: 1.1095983758568764, pod: 30.37217128276825, loss: 33.373624324798584 
Train [25/26] | Epoch [106/160] |	nca: 2.0686120018363, flat: 1.2231843546032906, pod: 32.568960428237915, loss: 35.86075711250305 
Train [25/26] | Epoch [107/160] |	nca: 2.139854356646538, flat: 1.2313814796507359, pod: 33.03626596927643, loss: 36.40750181674957 
Train [25/26] | Epoch [108/160] |	nca: 1.8656602948904037, flat: 1.099708616733551, pod: 30.92112958431244, loss: 33.88649845123291 
Train [25/26] | Epoch [109/160] |	nca: 1.9364114254713058, flat: 1.0697759315371513, pod: 30.516454815864563, loss: 33.52264225482941 
Train [25/26] | Epoch [110/160] |	nca: 1.877855435013771, flat: 1.0647025145590305, pod: 31.393325328826904, loss: 34.335883259773254 
Train [25/26] | Epoch [111/160] |	nca: 1.896899051964283, flat: 1.0502804145216942, pod: 30.12289273738861, loss: 33.070072531700134 
Train [25/26] | Epoch [112/160] |	nca: 2.0892290845513344, flat: 1.0360395982861519, pod: 29.5455139875412, loss: 32.67078256607056 
Train [25/26] | Epoch [113/160] |	nca: 1.9245217368006706, flat: 1.0260869897902012, pod: 29.047101616859436, loss: 31.997710466384888 
Train [25/26] | Epoch [114/160] |	nca: 1.9538259282708168, flat: 0.9505754224956036, pod: 28.11020863056183, loss: 31.014610052108765 
Train [25/26] | Epoch [115/160] |	nca: 1.9207504577934742, flat: 0.9947936534881592, pod: 27.925861120224, loss: 30.841405272483826 
Train [25/26] | Epoch [116/160] |	nca: 1.8614308685064316, flat: 0.9438286051154137, pod: 27.186561286449432, loss: 29.991820454597473 
Train [25/26] | Epoch [117/160] |	nca: 1.8831262812018394, flat: 0.9607060551643372, pod: 28.24802827835083, loss: 31.09186041355133 
Train [25/26] | Epoch [118/160] |	nca: 1.8354850821197033, flat: 0.8898335285484791, pod: 25.441779732704163, loss: 28.16709852218628 
Train [25/26] | Epoch [119/160] |	nca: 1.953633427619934, flat: 0.9086172245442867, pod: 26.38652801513672, loss: 29.248778581619263 
Train [25/26] | Epoch [120/160] |	nca: 1.9792967028915882, flat: 0.8946246691048145, pod: 26.557446897029877, loss: 29.431368350982666 
Train [25/26] | Epoch [121/160] |	nca: 1.9938544183969498, flat: 0.9016003832221031, pod: 26.514122545719147, loss: 29.40957748889923 
Train [25/26] | Epoch [122/160] |	nca: 2.0808778032660484, flat: 0.8710739184170961, pod: 25.983179032802582, loss: 28.93513059616089 
Train [25/26] | Epoch [123/160] |	nca: 1.8255250602960587, flat: 0.8912169970571995, pod: 26.54859745502472, loss: 29.265339851379395 
Train [25/26] | Epoch [124/160] |	nca: 1.863015715032816, flat: 0.857372572645545, pod: 26.08767145872116, loss: 28.808059811592102 
Train [25/26] | Epoch [125/160] |	nca: 1.8076482824981213, flat: 0.787480790168047, pod: 24.508196115493774, loss: 27.103325366973877 
Train [25/26] | Epoch [126/160] |	nca: 2.0005125738680363, flat: 0.8990635927766562, pod: 27.069205820560455, loss: 29.9687819480896 
Train [25/26] | Epoch [127/160] |	nca: 1.9067375846207142, flat: 0.8305798023939133, pod: 25.419665098190308, loss: 28.15698254108429 
Train [25/26] | Epoch [128/160] |	nca: 1.9322808273136616, flat: 0.8332178071141243, pod: 25.464741051197052, loss: 28.230239629745483 
Train [25/26] | Epoch [129/160] |	nca: 1.8976338729262352, flat: 0.8192652016878128, pod: 24.935022473335266, loss: 27.65192151069641 
Train [25/26] | Epoch [130/160] |	nca: 1.8612603023648262, flat: 0.8371084984391928, pod: 24.97155898809433, loss: 27.669927835464478 
Train [25/26] | Epoch [131/160] |	nca: 1.8265911228954792, flat: 0.8507674615830183, pod: 25.32456773519516, loss: 28.00192642211914 
Train [25/26] | Epoch [132/160] |	nca: 1.8153808116912842, flat: 0.7361389826983213, pod: 22.682186901569366, loss: 25.233706653118134 
Train [25/26] | Epoch [133/160] |	nca: 1.8823569677770138, flat: 0.7867755200713873, pod: 24.61762624979019, loss: 27.286758840084076 
Train [25/26] | Epoch [134/160] |	nca: 1.9524594396352768, flat: 0.7174779586493969, pod: 22.264780521392822, loss: 24.93471783399582 
Train [25/26] | Epoch [135/160] |	nca: 1.874831948429346, flat: 0.7619205974042416, pod: 22.896011531352997, loss: 25.532764077186584 
Train [25/26] | Epoch [136/160] |	nca: 1.8814467042684555, flat: 0.7050787471234798, pod: 22.45511543750763, loss: 25.041641235351562 
Train [25/26] | Epoch [137/160] |	nca: 1.9124464690685272, flat: 0.7257190346717834, pod: 22.355792343616486, loss: 24.993958115577698 
Train [25/26] | Epoch [138/160] |	nca: 2.0237105041742325, flat: 0.7356699667870998, pod: 22.091474771499634, loss: 24.85085517168045 
Train [25/26] | Epoch [139/160] |	nca: 1.9707591645419598, flat: 0.6903960611671209, pod: 21.733490884304047, loss: 24.394646048545837 
Train [25/26] | Epoch [140/160] |	nca: 1.8090305738151073, flat: 0.6889818534255028, pod: 21.300411641597748, loss: 23.798424005508423 
Train [25/26] | Epoch [141/160] |	nca: 1.933550413697958, flat: 0.6432324554771185, pod: 20.785485684871674, loss: 23.36226862668991 
Train [25/26] | Epoch [142/160] |	nca: 1.813851684331894, flat: 0.6702973488718271, pod: 21.792131900787354, loss: 24.27628058195114 
Train [25/26] | Epoch [143/160] |	nca: 1.8303947038948536, flat: 0.6612853165715933, pod: 20.811359763145447, loss: 23.303040087223053 
Train [25/26] | Epoch [144/160] |	nca: 1.879153911024332, flat: 0.6851101480424404, pod: 21.570476055145264, loss: 24.13474029302597 
Train [25/26] | Epoch [145/160] |	nca: 1.878346711397171, flat: 0.6953965779393911, pod: 21.6722314953804, loss: 24.245975017547607 
Train [25/26] | Epoch [146/160] |	nca: 1.833414375782013, flat: 0.6569803915917873, pod: 20.77291887998581, loss: 23.26331377029419 
Train [25/26] | Epoch [147/160] |	nca: 1.8089966550469398, flat: 0.6195310950279236, pod: 20.09025502204895, loss: 22.518782675266266 
Train [25/26] | Epoch [148/160] |	nca: 1.8579886071383953, flat: 0.6288891341537237, pod: 19.914015889167786, loss: 22.40089374780655 
Train [25/26] | Epoch [149/160] |	nca: 2.012565243989229, flat: 0.5948254056274891, pod: 19.52478015422821, loss: 22.132170855998993 
Train [25/26] | Epoch [150/160] |	nca: 1.9819847159087658, flat: 0.6334234531968832, pod: 19.54864662885666, loss: 22.16405487060547 
Train [25/26] | Epoch [151/160] |	nca: 1.9125773683190346, flat: 0.6431944165378809, pod: 20.044168651103973, loss: 22.59994065761566 
Train [25/26] | Epoch [152/160] |	nca: 1.8246553726494312, flat: 0.6314853802323341, pod: 20.022207140922546, loss: 22.478347897529602 
Train [25/26] | Epoch [153/160] |	nca: 1.8623405694961548, flat: 0.6343307681381702, pod: 19.876056611537933, loss: 22.37272799015045 
Train [25/26] | Epoch [154/160] |	nca: 1.928859069943428, flat: 0.6140630450099707, pod: 18.882631301879883, loss: 21.425553381443024 
Train [25/26] | Epoch [155/160] |	nca: 2.140275999903679, flat: 0.6644866857677698, pod: 20.37930566072464, loss: 23.184068262577057 
Train [25/26] | Epoch [156/160] |	nca: 1.787897452712059, flat: 0.5846527796238661, pod: 19.09780842065811, loss: 21.4703586101532 
Train [25/26] | Epoch [157/160] |	nca: 1.7542567811906338, flat: 0.5897605493664742, pod: 19.45823961496353, loss: 21.80225682258606 
Train [25/26] | Epoch [158/160] |	nca: 1.8464866057038307, flat: 0.6065521501004696, pod: 19.574419856071472, loss: 22.027458488941193 
Train [25/26] | Epoch [159/160] |	nca: 1.9286514222621918, flat: 0.6538885999470949, pod: 19.715575456619263, loss: 22.29811543226242 
Train [25/26] | Epoch [160/160] |	nca: 1.9844298548996449, flat: 0.6127287913113832, pod: 19.227659583091736, loss: 21.82481825351715 
Fine-tuning
Building & updating memory.
Train [25/26] | Epoch [161/180] |	nca: 1.140624027699232, flat: 0.814594428986311, pod: 19.571433424949646, loss: 21.526651740074158 
Train [25/26] | Epoch [162/180] |	nca: 0.960470050573349, flat: 0.7857116721570492, pod: 18.540357053279877, loss: 20.28653883934021 
Train [25/26] | Epoch [163/180] |	nca: 0.8735886290669441, flat: 0.8114920854568481, pod: 19.353898108005524, loss: 21.038978695869446 
Train [25/26] | Epoch [164/180] |	nca: 0.8374822810292244, flat: 0.7576161958277225, pod: 18.722345232963562, loss: 20.31744360923767 
Train [25/26] | Epoch [165/180] |	nca: 0.8434831760823727, flat: 0.7989679370075464, pod: 19.369274258613586, loss: 21.011725544929504 
Train [25/26] | Epoch [166/180] |	nca: 0.7213701605796814, flat: 0.7970354035496712, pod: 18.907244980335236, loss: 20.425650477409363 
Train [25/26] | Epoch [167/180] |	nca: 0.735897671431303, flat: 0.8189637400209904, pod: 19.120775938034058, loss: 20.675637364387512 
Train [25/26] | Epoch [168/180] |	nca: 0.7512185759842396, flat: 0.7979529947042465, pod: 18.766516387462616, loss: 20.315688014030457 
Train [25/26] | Epoch [169/180] |	nca: 0.649745998904109, flat: 0.8119942955672741, pod: 19.108274936676025, loss: 20.57001543045044 
Train [25/26] | Epoch [170/180] |	nca: 0.6650298144668341, flat: 0.8309462461620569, pod: 19.289446771144867, loss: 20.785422801971436 
Train [25/26] | Epoch [171/180] |	nca: 0.6220764573663473, flat: 0.7658782638609409, pod: 18.5236297249794, loss: 19.911584496498108 
Train [25/26] | Epoch [172/180] |	nca: 0.6444657016545534, flat: 0.7851640954613686, pod: 18.593909442424774, loss: 20.023539304733276 
Train [25/26] | Epoch [173/180] |	nca: 0.7027815543115139, flat: 0.8425482250750065, pod: 19.257819294929504, loss: 20.803148984909058 
Train [25/26] | Epoch [174/180] |	nca: 0.679064430296421, flat: 0.810702420771122, pod: 19.09898352622986, loss: 20.58875048160553 
Train [25/26] | Epoch [175/180] |	nca: 0.636252649128437, flat: 0.7868467681109905, pod: 18.78564190864563, loss: 20.208741545677185 
Train [25/26] | Epoch [176/180] |	nca: 0.6645786873996258, flat: 0.8085673153400421, pod: 19.16044306755066, loss: 20.633588910102844 
Train [25/26] | Epoch [177/180] |	nca: 0.5998344980180264, flat: 0.814421022310853, pod: 19.063529074192047, loss: 20.47778469324112 
Train [25/26] | Epoch [178/180] |	nca: 0.6176068969070911, flat: 0.7975338064134121, pod: 18.472245812416077, loss: 19.887386798858643 
Train [25/26] | Epoch [179/180] |	nca: 0.649967510253191, flat: 0.8074746336787939, pod: 19.186283111572266, loss: 20.643725275993347 
Train [25/26] | Epoch [180/180] |	nca: 0.6468131057918072, flat: 0.8376374803483486, pod: 20.16852557659149, loss: 21.652976036071777 
after task
Building & updating memory.
after task
Eval on 0->98.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.59224.
Current acc: {'total': 0.497, '00-09': 0.575, '10-19': 0.49, '20-29': 0.406, '30-39': 0.468, '40-49': 0.517, '50-59': 0.528, '60-69': 0.435, '70-79': 0.514, '80-89': 0.55, '90-99': 0.479}.
Avg inc acc top5: 0.85056.
Current acc top5: {'total': 0.791}.
Forgetting: 0.18181818181818182.
Cord metric: 0.57.
Old accuracy: 0.50, mean: 0.58.
New accuracy: 0.51, mean: 0.61.
================Task 25 Start!================
Testing on False unseen tasks (max class = 100).
Set memory of size: 1960.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 25 Training!================
The training samples number: 2960
Train on 98->100.
train task
nb 2960.
Train [26/26] | Epoch [1/160] |	nca: 18.182228803634644, flat: 9.401919476687908, pod: 75.6883636713028, loss: 103.27251148223877 
Train [26/26] | Epoch [2/160] |	nca: 17.58523803949356, flat: 10.391981393098831, pod: 91.65099430084229, loss: 119.62821531295776 
Train [26/26] | Epoch [3/160] |	nca: 13.753647416830063, flat: 9.579708188772202, pod: 89.21463441848755, loss: 112.54798984527588 
Train [26/26] | Epoch [4/160] |	nca: 14.002836376428604, flat: 10.179902136325836, pod: 92.10687375068665, loss: 116.28961038589478 
Train [26/26] | Epoch [5/160] |	nca: 9.366779506206512, flat: 7.640824913978577, pod: 81.5632791519165, loss: 98.57088422775269 
Train [26/26] | Epoch [6/160] |	nca: 7.905769661068916, flat: 6.97590346634388, pod: 77.66221833229065, loss: 92.5438916683197 
Train [26/26] | Epoch [7/160] |	nca: 8.2981086820364, flat: 7.198286905884743, pod: 79.82474255561829, loss: 95.32113766670227 
Train [26/26] | Epoch [8/160] |	nca: 6.36772346496582, flat: 6.140216276049614, pod: 74.62820386886597, loss: 87.13614416122437 
Train [26/26] | Epoch [9/160] |	nca: 4.6127690970897675, flat: 4.597578287124634, pod: 64.13031196594238, loss: 73.3406593799591 
Train [26/26] | Epoch [10/160] |	nca: 4.298371195793152, flat: 4.163393810391426, pod: 63.2266104221344, loss: 71.68837547302246 
Train [26/26] | Epoch [11/160] |	nca: 4.589825242757797, flat: 4.38111187517643, pod: 65.1308867931366, loss: 74.1018238067627 
Train [26/26] | Epoch [12/160] |	nca: 3.869956724345684, flat: 3.7819400280714035, pod: 60.617626667022705, loss: 68.26952385902405 
Train [26/26] | Epoch [13/160] |	nca: 4.924210160970688, flat: 4.333779141306877, pod: 64.54135298728943, loss: 73.79934215545654 
Train [26/26] | Epoch [14/160] |	nca: 5.4688816368579865, flat: 4.993768081068993, pod: 67.1426751613617, loss: 77.60532402992249 
Train [26/26] | Epoch [15/160] |	nca: 4.079506054520607, flat: 4.082000553607941, pod: 62.4750292301178, loss: 70.63653564453125 
Train [26/26] | Epoch [16/160] |	nca: 4.039916284382343, flat: 3.6251819506287575, pod: 59.99846863746643, loss: 67.66356754302979 
Train [26/26] | Epoch [17/160] |	nca: 3.715218238532543, flat: 3.8844857960939407, pod: 60.11045598983765, loss: 67.71015977859497 
Train [26/26] | Epoch [18/160] |	nca: 3.792543224990368, flat: 3.7358338683843613, pod: 60.941235303878784, loss: 68.46961259841919 
Train [26/26] | Epoch [19/160] |	nca: 6.453806221485138, flat: 5.657208204269409, pod: 70.6272189617157, loss: 82.73823356628418 
Train [26/26] | Epoch [20/160] |	nca: 4.953433603048325, flat: 4.873930141329765, pod: 67.49594759941101, loss: 77.3233118057251 
Train [26/26] | Epoch [21/160] |	nca: 3.344194892793894, flat: 3.669033996760845, pod: 58.73913860321045, loss: 65.75236749649048 
Train [26/26] | Epoch [22/160] |	nca: 3.6888816133141518, flat: 3.293004311621189, pod: 57.840702056884766, loss: 64.8225884437561 
Train [26/26] | Epoch [23/160] |	nca: 4.379233509302139, flat: 4.189626708626747, pod: 63.131245851516724, loss: 71.70010614395142 
Train [26/26] | Epoch [24/160] |	nca: 4.15488101541996, flat: 4.1400090754032135, pod: 63.25120139122009, loss: 71.5460913181305 
Train [26/26] | Epoch [25/160] |	nca: 3.5849006325006485, flat: 3.5747020170092583, pod: 58.08274221420288, loss: 65.24234509468079 
Train [26/26] | Epoch [26/160] |	nca: 3.5462434589862823, flat: 3.6200070679187775, pod: 58.61912989616394, loss: 65.78538036346436 
Train [26/26] | Epoch [27/160] |	nca: 4.00917311757803, flat: 3.8330261185765266, pod: 62.71166205406189, loss: 70.55386161804199 
Train [26/26] | Epoch [28/160] |	nca: 4.793448902666569, flat: 4.6906594187021255, pod: 64.62191367149353, loss: 74.1060221195221 
Train [26/26] | Epoch [29/160] |	nca: 3.6549636125564575, flat: 3.969522148370743, pod: 60.51155185699463, loss: 68.1360375881195 
Train [26/26] | Epoch [30/160] |	nca: 4.059112004935741, flat: 4.023659706115723, pod: 64.82751441001892, loss: 72.91028571128845 
Train [26/26] | Epoch [31/160] |	nca: 3.5283690840005875, flat: 3.4806947335600853, pod: 57.46998333930969, loss: 64.47904682159424 
Train [26/26] | Epoch [32/160] |	nca: 3.806909590959549, flat: 3.6930656507611275, pod: 59.20455503463745, loss: 66.70452952384949 
Train [26/26] | Epoch [33/160] |	nca: 3.410282716155052, flat: 3.391836740076542, pod: 58.81300330162048, loss: 65.61512303352356 
Train [26/26] | Epoch [34/160] |	nca: 3.1773852854967117, flat: 3.3889119178056717, pod: 57.63240718841553, loss: 64.1987042427063 
Train [26/26] | Epoch [35/160] |	nca: 3.586722932755947, flat: 3.123731479048729, pod: 56.545182943344116, loss: 63.25563716888428 
Train [26/26] | Epoch [36/160] |	nca: 6.556780636310577, flat: 5.8184914737939835, pod: 70.22478008270264, loss: 82.60005235671997 
Train [26/26] | Epoch [37/160] |	nca: 5.035743817687035, flat: 5.132489278912544, pod: 65.69170665740967, loss: 75.85993957519531 
Train [26/26] | Epoch [38/160] |	nca: 4.435380533337593, flat: 4.660219758749008, pod: 64.28332710266113, loss: 73.37892746925354 
Train [26/26] | Epoch [39/160] |	nca: 3.0344203114509583, flat: 3.460135966539383, pod: 56.3174045085907, loss: 62.81196141242981 
Train [26/26] | Epoch [40/160] |	nca: 3.067186087369919, flat: 3.1351133286952972, pod: 53.45776665210724, loss: 59.66006541252136 
Train [26/26] | Epoch [41/160] |	nca: 3.3719878867268562, flat: 3.1594148948788643, pod: 55.014790773391724, loss: 61.54619336128235 
Train [26/26] | Epoch [42/160] |	nca: 3.7157206535339355, flat: 3.4891940504312515, pod: 56.31023812294006, loss: 63.5151526927948 
Train [26/26] | Epoch [43/160] |	nca: 3.4603033363819122, flat: 3.6263424456119537, pod: 56.054893016815186, loss: 63.14153861999512 
Train [26/26] | Epoch [44/160] |	nca: 3.2078837230801582, flat: 3.198230594396591, pod: 54.60951375961304, loss: 61.01562762260437 
Train [26/26] | Epoch [45/160] |	nca: 3.1341963037848473, flat: 3.182783894240856, pod: 55.1943598985672, loss: 61.511340379714966 
Train [26/26] | Epoch [46/160] |	nca: 3.122836194932461, flat: 3.322946824133396, pod: 54.68006932735443, loss: 61.12585210800171 
Train [26/26] | Epoch [47/160] |	nca: 2.727554067969322, flat: 2.7697665840387344, pod: 50.935428857803345, loss: 56.43274974822998 
Train [26/26] | Epoch [48/160] |	nca: 3.8922648802399635, flat: 3.473719522356987, pod: 54.940587759017944, loss: 62.30657196044922 
Train [26/26] | Epoch [49/160] |	nca: 3.2818297632038593, flat: 3.318946547806263, pod: 55.93141198158264, loss: 62.532187938690186 
Train [26/26] | Epoch [50/160] |	nca: 3.5773692056536674, flat: 3.1764615550637245, pod: 53.08475959300995, loss: 59.83859038352966 
Train [26/26] | Epoch [51/160] |	nca: 3.354865662753582, flat: 3.5358791053295135, pod: 55.52098214626312, loss: 62.4117271900177 
Train [26/26] | Epoch [52/160] |	nca: 2.9242599606513977, flat: 2.8618337139487267, pod: 50.25930297374725, loss: 56.04539680480957 
Train [26/26] | Epoch [53/160] |	nca: 3.4084766656160355, flat: 3.272185280919075, pod: 54.432093143463135, loss: 61.1127552986145 
Train [26/26] | Epoch [54/160] |	nca: 3.6613711938261986, flat: 3.5939638540148735, pod: 56.60804557800293, loss: 63.863380908966064 
Train [26/26] | Epoch [55/160] |	nca: 3.1741489619016647, flat: 3.1536401957273483, pod: 54.52767205238342, loss: 60.85546088218689 
Train [26/26] | Epoch [56/160] |	nca: 4.054328963160515, flat: 3.9505652636289597, pod: 57.95289659500122, loss: 65.95779037475586 
Train [26/26] | Epoch [57/160] |	nca: 3.0555590465664864, flat: 3.2818309739232063, pod: 55.23648500442505, loss: 61.573874950408936 
Train [26/26] | Epoch [58/160] |	nca: 3.190219394862652, flat: 2.8201409056782722, pod: 52.27395212650299, loss: 58.28431177139282 
Train [26/26] | Epoch [59/160] |	nca: 4.066169202327728, flat: 3.9484729915857315, pod: 60.4804961681366, loss: 68.49513816833496 
Train [26/26] | Epoch [60/160] |	nca: 3.100546643137932, flat: 3.0600113421678543, pod: 52.21795320510864, loss: 58.37851119041443 
Train [26/26] | Epoch [61/160] |	nca: 2.727655179798603, flat: 2.7542748525738716, pod: 49.675238370895386, loss: 55.1571683883667 
Train [26/26] | Epoch [62/160] |	nca: 2.6389239579439163, flat: 2.784147709608078, pod: 51.54600942134857, loss: 56.96908116340637 
Train [26/26] | Epoch [63/160] |	nca: 3.0608718171715736, flat: 2.815498284995556, pod: 50.10196495056152, loss: 55.97833490371704 
Train [26/26] | Epoch [64/160] |	nca: 3.069994017481804, flat: 2.867176800966263, pod: 50.83387744426727, loss: 56.771047830581665 
Train [26/26] | Epoch [65/160] |	nca: 3.343063749372959, flat: 3.135851629078388, pod: 51.73676645755768, loss: 58.21568179130554 
Train [26/26] | Epoch [66/160] |	nca: 2.86635472625494, flat: 2.8242026790976524, pod: 49.839771151542664, loss: 55.53032827377319 
Train [26/26] | Epoch [67/160] |	nca: 2.9383469000458717, flat: 2.7297376468777657, pod: 49.20578944683075, loss: 54.873873829841614 
Train [26/26] | Epoch [68/160] |	nca: 2.754279136657715, flat: 2.664468176662922, pod: 49.33729028701782, loss: 54.75603747367859 
Train [26/26] | Epoch [69/160] |	nca: 2.642234981060028, flat: 2.633898541331291, pod: 49.242391705513, loss: 54.51852488517761 
Train [26/26] | Epoch [70/160] |	nca: 2.486628048121929, flat: 2.4648003727197647, pod: 47.69179594516754, loss: 52.643224477767944 
Train [26/26] | Epoch [71/160] |	nca: 2.524323083460331, flat: 2.342261955142021, pod: 47.65659844875336, loss: 52.523184180259705 
Train [26/26] | Epoch [72/160] |	nca: 2.945577956736088, flat: 2.5518624410033226, pod: 47.59605598449707, loss: 53.093496322631836 
Train [26/26] | Epoch [73/160] |	nca: 2.881909392774105, flat: 2.643442139029503, pod: 48.18448579311371, loss: 53.709837198257446 
Train [26/26] | Epoch [74/160] |	nca: 2.674557790160179, flat: 2.319803796708584, pod: 45.7487633228302, loss: 50.74312448501587 
Train [26/26] | Epoch [75/160] |	nca: 2.6377237141132355, flat: 2.5262756794691086, pod: 47.63123118877411, loss: 52.79523003101349 
Train [26/26] | Epoch [76/160] |	nca: 2.477139890193939, flat: 2.3301603347063065, pod: 47.2645617723465, loss: 52.07186245918274 
Train [26/26] | Epoch [77/160] |	nca: 2.532820038497448, flat: 2.1348676532506943, pod: 44.71272397041321, loss: 49.38041114807129 
Train [26/26] | Epoch [78/160] |	nca: 2.9028183445334435, flat: 2.685737758874893, pod: 48.934736490249634, loss: 54.523293018341064 
Train [26/26] | Epoch [79/160] |	nca: 2.870193727314472, flat: 2.548713617026806, pod: 45.40118157863617, loss: 50.82008898258209 
Train [26/26] | Epoch [80/160] |	nca: 2.4635011702775955, flat: 2.1986019238829613, pod: 43.82364618778229, loss: 48.48574900627136 
Train [26/26] | Epoch [81/160] |	nca: 2.5959082022309303, flat: 2.240485079586506, pod: 44.77705192565918, loss: 49.613444805145264 
Train [26/26] | Epoch [82/160] |	nca: 2.716426394879818, flat: 2.4226409941911697, pod: 46.51237332820892, loss: 51.65144073963165 
Train [26/26] | Epoch [83/160] |	nca: 2.4798185750842094, flat: 2.1867281831800938, pod: 45.14079463481903, loss: 49.80734193325043 
Train [26/26] | Epoch [84/160] |	nca: 2.400521069765091, flat: 2.0575983934104443, pod: 43.664156556129456, loss: 48.122276186943054 
Train [26/26] | Epoch [85/160] |	nca: 2.431530326604843, flat: 2.1737792044878006, pod: 43.686269998550415, loss: 48.291579604148865 
Train [26/26] | Epoch [86/160] |	nca: 2.6524999514222145, flat: 2.1490303054451942, pod: 43.994086503982544, loss: 48.7956166267395 
Train [26/26] | Epoch [87/160] |	nca: 2.7479066886007786, flat: 2.2463024109601974, pod: 44.54331612586975, loss: 49.53752565383911 
Train [26/26] | Epoch [88/160] |	nca: 2.456231601536274, flat: 2.0882343277335167, pod: 42.87730133533478, loss: 47.421767234802246 
Train [26/26] | Epoch [89/160] |	nca: 2.7201369404792786, flat: 2.1091104224324226, pod: 44.34981596469879, loss: 49.17906320095062 
Train [26/26] | Epoch [90/160] |	nca: 3.031482607126236, flat: 2.1616380736231804, pod: 42.3331857919693, loss: 47.5263067483902 
Train [26/26] | Epoch [91/160] |	nca: 2.5406714528799057, flat: 1.9733431451022625, pod: 40.53420805931091, loss: 45.0482223033905 
Train [26/26] | Epoch [92/160] |	nca: 2.3494639471173286, flat: 2.011874243617058, pod: 41.55344581604004, loss: 45.91478395462036 
Train [26/26] | Epoch [93/160] |	nca: 2.229649744927883, flat: 1.8784844800829887, pod: 41.078012466430664, loss: 45.18614637851715 
Train [26/26] | Epoch [94/160] |	nca: 2.429102770984173, flat: 1.8089447654783726, pod: 39.50306475162506, loss: 43.74111258983612 
Train [26/26] | Epoch [95/160] |	nca: 2.3591179251670837, flat: 1.9883013777434826, pod: 40.390949726104736, loss: 44.73836898803711 
Train [26/26] | Epoch [96/160] |	nca: 2.5868912786245346, flat: 1.9292535446584225, pod: 41.78667366504669, loss: 46.30281841754913 
Train [26/26] | Epoch [97/160] |	nca: 2.7695609778165817, flat: 2.2975646145641804, pod: 42.45659387111664, loss: 47.52371954917908 
Train [26/26] | Epoch [98/160] |	nca: 2.5658354088664055, flat: 2.082034043967724, pod: 42.57825565338135, loss: 47.22612512111664 
Train [26/26] | Epoch [99/160] |	nca: 2.2849499695003033, flat: 1.887785878032446, pod: 40.478243589401245, loss: 44.6509792804718 
Train [26/26] | Epoch [100/160] |	nca: 2.191195696592331, flat: 1.8627344593405724, pod: 40.30732464790344, loss: 44.36125457286835 
Train [26/26] | Epoch [101/160] |	nca: 2.7219343967735767, flat: 1.9127120152115822, pod: 40.71163249015808, loss: 45.34627902507782 
Train [26/26] | Epoch [102/160] |	nca: 2.7794319689273834, flat: 2.350136235356331, pod: 43.382317543029785, loss: 48.51188552379608 
Train [26/26] | Epoch [103/160] |	nca: 3.01657572388649, flat: 1.7912762574851513, pod: 38.82878267765045, loss: 43.636634826660156 
Train [26/26] | Epoch [104/160] |	nca: 2.4562453478574753, flat: 1.8309111222624779, pod: 37.28397750854492, loss: 41.57113420963287 
Train [26/26] | Epoch [105/160] |	nca: 2.229562394320965, flat: 1.7329544201493263, pod: 38.50426983833313, loss: 42.46678686141968 
Train [26/26] | Epoch [106/160] |	nca: 2.183821029961109, flat: 1.635371569544077, pod: 36.71571910381317, loss: 40.53491127490997 
Train [26/26] | Epoch [107/160] |	nca: 2.200480718165636, flat: 1.680540356785059, pod: 36.74531579017639, loss: 40.62633693218231 
Train [26/26] | Epoch [108/160] |	nca: 2.333803430199623, flat: 1.7225009389221668, pod: 37.502098083496094, loss: 41.55840229988098 
Train [26/26] | Epoch [109/160] |	nca: 2.166352402418852, flat: 1.7177178487181664, pod: 35.67951512336731, loss: 39.56358551979065 
Train [26/26] | Epoch [110/160] |	nca: 2.3116154223680496, flat: 1.556202843785286, pod: 34.69616425037384, loss: 38.563982367515564 
Train [26/26] | Epoch [111/160] |	nca: 3.1562323197722435, flat: 1.7866817824542522, pod: 37.73400318622589, loss: 42.67691743373871 
Train [26/26] | Epoch [112/160] |	nca: 2.5815645679831505, flat: 1.8990571685135365, pod: 38.44156622886658, loss: 42.92218828201294 
Train [26/26] | Epoch [113/160] |	nca: 2.221389561891556, flat: 1.5735174678266048, pod: 34.93656539916992, loss: 38.7314727306366 
Train [26/26] | Epoch [114/160] |	nca: 2.13792372867465, flat: 1.5026316419243813, pod: 34.21559202671051, loss: 37.85614717006683 
Train [26/26] | Epoch [115/160] |	nca: 2.215250890702009, flat: 1.5118772499263287, pod: 34.87979447841644, loss: 38.60692262649536 
Train [26/26] | Epoch [116/160] |	nca: 2.1542011834681034, flat: 1.4013741314411163, pod: 34.29228615760803, loss: 37.847861528396606 
Train [26/26] | Epoch [117/160] |	nca: 2.228663459420204, flat: 1.5983646661043167, pod: 35.53389024734497, loss: 39.3609185218811 
Train [26/26] | Epoch [118/160] |	nca: 2.192320268601179, flat: 1.4991345070302486, pod: 33.46526741981506, loss: 37.1567223072052 
Train [26/26] | Epoch [119/160] |	nca: 2.7443804778158665, flat: 1.5768515355885029, pod: 35.59338700771332, loss: 39.91461896896362 
Train [26/26] | Epoch [120/160] |	nca: 2.317756325006485, flat: 1.5494893491268158, pod: 34.52250897884369, loss: 38.38975465297699 
Train [26/26] | Epoch [121/160] |	nca: 2.1257125437259674, flat: 1.5197026543319225, pod: 34.77342736721039, loss: 38.41884231567383 
Train [26/26] | Epoch [122/160] |	nca: 2.206237867474556, flat: 1.4715253934264183, pod: 32.43402564525604, loss: 36.1117889881134 
Train [26/26] | Epoch [123/160] |	nca: 2.1129692755639553, flat: 1.3166499882936478, pod: 31.39774799346924, loss: 34.827367424964905 
Train [26/26] | Epoch [124/160] |	nca: 2.313949480652809, flat: 1.3337578475475311, pod: 31.688512921333313, loss: 35.336220383644104 
Train [26/26] | Epoch [125/160] |	nca: 2.1829671002924442, flat: 1.332433458417654, pod: 31.527787804603577, loss: 35.04318821430206 
Train [26/26] | Epoch [126/160] |	nca: 2.0921202562749386, flat: 1.5108624249696732, pod: 32.510618567466736, loss: 36.113600850105286 
Train [26/26] | Epoch [127/160] |	nca: 2.7465787529945374, flat: 1.4844005927443504, pod: 31.69386625289917, loss: 35.924845576286316 
Train [26/26] | Epoch [128/160] |	nca: 2.3463137447834015, flat: 1.393651194870472, pod: 31.247543811798096, loss: 34.98750841617584 
Train [26/26] | Epoch [129/160] |	nca: 2.157681990414858, flat: 1.3224080987274647, pod: 30.87212061882019, loss: 34.35221040248871 
Train [26/26] | Epoch [130/160] |	nca: 2.167850863188505, flat: 1.3133841082453728, pod: 31.92586362361908, loss: 35.40709865093231 
Train [26/26] | Epoch [131/160] |	nca: 2.41727102920413, flat: 1.2400675490498543, pod: 29.72289550304413, loss: 33.380234479904175 
Train [26/26] | Epoch [132/160] |	nca: 2.1126993149518967, flat: 1.3807980120182037, pod: 31.47505533695221, loss: 34.96855282783508 
Train [26/26] | Epoch [133/160] |	nca: 2.0196422562003136, flat: 1.226096136495471, pod: 29.196827352046967, loss: 32.44256579875946 
Train [26/26] | Epoch [134/160] |	nca: 2.015296094119549, flat: 1.238264549523592, pod: 28.386693060398102, loss: 31.64025354385376 
Train [26/26] | Epoch [135/160] |	nca: 2.159359320998192, flat: 1.168754082173109, pod: 28.39850252866745, loss: 31.72661566734314 
Train [26/26] | Epoch [136/160] |	nca: 2.1022104024887085, flat: 1.164740076288581, pod: 28.09316313266754, loss: 31.360113501548767 
Train [26/26] | Epoch [137/160] |	nca: 1.9739282168447971, flat: 1.1058326438069344, pod: 27.877800464630127, loss: 30.957561373710632 
Train [26/26] | Epoch [138/160] |	nca: 2.2816802226006985, flat: 1.0956381410360336, pod: 27.637234807014465, loss: 31.01455330848694 
Train [26/26] | Epoch [139/160] |	nca: 2.2665053755044937, flat: 1.1786277927458286, pod: 27.777637660503387, loss: 31.222771048545837 
Train [26/26] | Epoch [140/160] |	nca: 2.1540705263614655, flat: 1.1427495777606964, pod: 27.935034453868866, loss: 31.23185420036316 
Train [26/26] | Epoch [141/160] |	nca: 2.2306588888168335, flat: 1.1252334583550692, pod: 27.16983139514923, loss: 30.525723576545715 
Train [26/26] | Epoch [142/160] |	nca: 2.113745477050543, flat: 1.1452820152044296, pod: 27.29114532470703, loss: 30.550172805786133 
Train [26/26] | Epoch [143/160] |	nca: 1.948943804949522, flat: 1.1153095103800297, pod: 26.88325697183609, loss: 29.947509944438934 
Train [26/26] | Epoch [144/160] |	nca: 2.015473648905754, flat: 1.0867539253085852, pod: 26.440628170967102, loss: 29.542855381965637 
Train [26/26] | Epoch [145/160] |	nca: 2.186006262898445, flat: 1.1133584752678871, pod: 26.57014310359955, loss: 29.869508028030396 
Train [26/26] | Epoch [146/160] |	nca: 1.8709941282868385, flat: 1.0568383187055588, pod: 25.649875819683075, loss: 28.57770824432373 
Train [26/26] | Epoch [147/160] |	nca: 1.9418857097625732, flat: 1.1017104778438807, pod: 26.849985420703888, loss: 29.893581569194794 
Train [26/26] | Epoch [148/160] |	nca: 2.0135639794170856, flat: 1.0894863586872816, pod: 26.241727471351624, loss: 29.344777941703796 
Train [26/26] | Epoch [149/160] |	nca: 2.060602780431509, flat: 1.0511311572045088, pod: 25.649146258831024, loss: 28.760880172252655 
Train [26/26] | Epoch [150/160] |	nca: 2.0237237960100174, flat: 1.04057683236897, pod: 24.99878227710724, loss: 28.06308275461197 
Train [26/26] | Epoch [151/160] |	nca: 2.231116957962513, flat: 1.1030908692628145, pod: 26.71535062789917, loss: 30.049558341503143 
Train [26/26] | Epoch [152/160] |	nca: 2.0777963139116764, flat: 1.1318819932639599, pod: 26.52458393573761, loss: 29.73426204919815 
Train [26/26] | Epoch [153/160] |	nca: 2.0491827465593815, flat: 1.050845654681325, pod: 25.236559212207794, loss: 28.336587488651276 
Train [26/26] | Epoch [154/160] |	nca: 2.0208324044942856, flat: 1.0041717495769262, pod: 24.573144853115082, loss: 27.598148941993713 
Train [26/26] | Epoch [155/160] |	nca: 1.8352210447192192, flat: 1.0399085823446512, pod: 25.615140974521637, loss: 28.490270912647247 
Train [26/26] | Epoch [156/160] |	nca: 2.1076498180627823, flat: 0.969515597447753, pod: 24.643784642219543, loss: 27.72095000743866 
Train [26/26] | Epoch [157/160] |	nca: 2.0192505940794945, flat: 1.0290236454457045, pod: 24.6526859998703, loss: 27.700960516929626 
Train [26/26] | Epoch [158/160] |	nca: 2.0445933789014816, flat: 1.0608995016664267, pod: 25.379346311092377, loss: 28.48483920097351 
Train [26/26] | Epoch [159/160] |	nca: 2.011346187442541, flat: 0.9919072054326534, pod: 24.756114959716797, loss: 27.759368240833282 
Train [26/26] | Epoch [160/160] |	nca: 2.2419041469693184, flat: 1.0491285733878613, pod: 25.26571935415268, loss: 28.55675184726715 
Fine-tuning
Building & updating memory.
Train [26/26] | Epoch [161/180] |	nca: 1.3795461058616638, flat: 0.9618150517344475, pod: 19.806714057922363, loss: 22.148075342178345 
Train [26/26] | Epoch [162/180] |	nca: 0.9702716879546642, flat: 0.9693954065442085, pod: 19.861231327056885, loss: 21.80089831352234 
Train [26/26] | Epoch [163/180] |	nca: 0.8469464890658855, flat: 0.9783624112606049, pod: 19.940942645072937, loss: 21.76625144481659 
Train [26/26] | Epoch [164/180] |	nca: 0.8547470662742853, flat: 0.9962417632341385, pod: 20.253138542175293, loss: 22.104127287864685 
Train [26/26] | Epoch [165/180] |	nca: 0.7974766902625561, flat: 0.9713742211461067, pod: 19.540161848068237, loss: 21.30901277065277 
Train [26/26] | Epoch [166/180] |	nca: 0.7919060327112675, flat: 0.9820448346436024, pod: 19.65735250711441, loss: 21.43130314350128 
Train [26/26] | Epoch [167/180] |	nca: 0.7235860861837864, flat: 0.9820881150662899, pod: 19.87393081188202, loss: 21.579604923725128 
Train [26/26] | Epoch [168/180] |	nca: 0.7512096166610718, flat: 0.9627832844853401, pod: 20.02393352985382, loss: 21.737926483154297 
Train [26/26] | Epoch [169/180] |	nca: 0.6980476658791304, flat: 0.9687376953661442, pod: 19.78716069459915, loss: 21.453946232795715 
Train [26/26] | Epoch [170/180] |	nca: 0.7021136283874512, flat: 0.9536596275866032, pod: 19.57948327064514, loss: 21.23525643348694 
Train [26/26] | Epoch [171/180] |	nca: 0.6787788234651089, flat: 0.9986390918493271, pod: 19.882306396961212, loss: 21.559724271297455 
Train [26/26] | Epoch [172/180] |	nca: 0.6787751764059067, flat: 0.952533345669508, pod: 19.89803659915924, loss: 21.529345154762268 
Train [26/26] | Epoch [173/180] |	nca: 0.6718613635748625, flat: 1.0054855421185493, pod: 20.294636487960815, loss: 21.971983313560486 
Train [26/26] | Epoch [174/180] |	nca: 0.6982678063213825, flat: 0.9496272690594196, pod: 19.675341486930847, loss: 21.3232364654541 
Train [26/26] | Epoch [175/180] |	nca: 0.6639948077499866, flat: 0.9829077832400799, pod: 19.960703015327454, loss: 21.607605695724487 
Train [26/26] | Epoch [176/180] |	nca: 0.6084645725786686, flat: 0.9769346490502357, pod: 19.80554485321045, loss: 21.390944123268127 
Train [26/26] | Epoch [177/180] |	nca: 0.66000553406775, flat: 1.0190097466111183, pod: 20.181673049926758, loss: 21.86068832874298 
Train [26/26] | Epoch [178/180] |	nca: 0.6827040128409863, flat: 0.9650833457708359, pod: 19.843459367752075, loss: 21.491246938705444 
Train [26/26] | Epoch [179/180] |	nca: 0.6485796831548214, flat: 1.026066642254591, pod: 20.274478673934937, loss: 21.949125289916992 
Train [26/26] | Epoch [180/180] |	nca: 0.6573842018842697, flat: 0.9907651655375957, pod: 20.093578219413757, loss: 21.741727471351624 
after task
Building & updating memory.
after task
Saving model at results\dev\podnet\202401\week_1\20240103_podnet_nme_cifar100_25steps\net_0_task_25.pth.
Saving metadata at results\dev\podnet\202401\week_1\20240103_podnet_nme_cifar100_25steps\meta_0_task_25.pkl.
Eval on 0->100.
eval task
podnet_nme_cifar100_25steps
Avg inc acc: 0.5883846153846155.
Current acc: {'total': 0.492, '00-09': 0.569, '10-19': 0.498, '20-29': 0.402, '30-39': 0.458, '40-49': 0.521, '50-59': 0.531, '60-69': 0.433, '70-79': 0.523, '80-89': 0.535, '90-99': 0.453}.
Avg inc acc top5: 0.8481538461538461.
Current acc top5: {'total': 0.788}.
Forgetting: 0.18536363636363634.
Cord metric: 0.56.
Old accuracy: 0.49, mean: 0.58.
New accuracy: 0.49, mean: 0.61.
Average Incremental Accuracy: 0.5883846153846155.
Label was: podnet_nme_cifar100_25steps
Results done on 1 seeds: avg: 58.84, last: 49.2, forgetting: 18.54
Individual results avg: [58.84]
Individual results last: [49.2]
Individual results forget: [18.54]
Command was D:/go_to_D/ML/Final/LibContinual/run_trainer.py
Time cost :  12525.099592924118
