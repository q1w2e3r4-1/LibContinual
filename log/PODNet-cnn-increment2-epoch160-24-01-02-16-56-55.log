Label: podnet_cnn_cifar100_25steps
orders : None
{'model': 'podnet', 'convnet': 'rebuffi', 'dropout': 0.0, 'herding': None, 'memory_size': 2000, 'temperature': 1, 'fixed_memory': True, 'dataset': 'cifar100', 'increment': 2, 'batch_size': 128, 'workers': 0, 'threads': 1, 'validation': 0.0, 'random_classes': False, 'max_task': None, 'onehot': False, 'initial_increment': 50, 'sampler': None, 'data_path': '/data/douillard/', 'lr': 0.1, 'weight_decay': 0.0005, 'scheduling': 'cosine', 'lr_decay': 0.1, 'optimizer': 'sgd', 'epochs': 160, 'device': [0], 'label': 'podnet_cnn_cifar100_25steps', 'autolabel': False, 'seed': [1], 'seed_range': None, 'options': None, 'save_model': 'last', 'dump_predictions': False, 'logging': 'info', 'resume': None, 'resume_first': False, 'recompute_meta': False, 'no_benchmark': False, 'detect_anomaly': False, 'dummy': 1, 'includes': ['headers/dummy.yaml'], 'data_root': 'D:/data/douillard/cifar100/cifar100', 'save_path': '.', 'eval_type': 'cnn', 'backbone': {'name': 'resnet18'}, 'classifier': {'name': 'PODNet'}, 'classifier_config': {'type': 'cosine', 'proxy_per_class': 10, 'distance': 'neg_stable_cosine_distance'}, 'postprocessor_config': {'type': 'learned_scaling', 'initial_value': 1.0}, 'pod_flat': {'scheduled_factor': 1.0}, 'pod_spatial': {'scheduled_factor': 3.0, 'collapse_channels': 'spatial'}, 'nca': {'margin': 0.6, 'scale': 1.0, 'exclude_pos_denominator': True}, 'groupwise_factors': {'old_weights': 0.0}, 'finetuning_config': {'sampling': 'undersampling', 'tuning': 'classifier', 'lr': 0.05, 'epochs': 20, 'scaling': None}, 'proxy_per_class': 1, 'weight_generation': {'type': 'imprinted', 'multi_class_diff': 'kmeans'}, 'dataset_transforms': {'color_jitter': True}}
Launching run 1/1
Set seed 1
CUDA algos are determinists but very slow!
Files already downloaded and verified
Files already downloaded and verified
Dataset iCIFAR100: class ordering: [87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39].
Downsampling type stride
Using 10 proxies per class.
Model will be save at this rythm: last.
================Task 0 Start!================
Testing on False unseen tasks (max class = 50).
Before task
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 0 Training!================
The training samples number: 25000
Train on 0->50.
train task
nb 25000.
Train [1/26] | Epoch [1/160] |	nca: 713.3327896595001, loss: 713.3327896595001 
Train [1/26] | Epoch [2/160] |	nca: 628.3272082805634, loss: 628.3272082805634 
Train [1/26] | Epoch [3/160] |	nca: 577.3014988899231, loss: 577.3014988899231 
Train [1/26] | Epoch [4/160] |	nca: 526.8762035369873, loss: 526.8762035369873 
Train [1/26] | Epoch [5/160] |	nca: 476.29854345321655, loss: 476.29854345321655 
Train [1/26] | Epoch [6/160] |	nca: 434.7580976486206, loss: 434.7580976486206 
Train [1/26] | Epoch [7/160] |	nca: 402.5476222038269, loss: 402.5476222038269 
Train [1/26] | Epoch [8/160] |	nca: 377.4512165784836, loss: 377.4512165784836 
Train [1/26] | Epoch [9/160] |	nca: 353.6950296163559, loss: 353.6950296163559 
Train [1/26] | Epoch [10/160] |	nca: 336.0271567106247, loss: 336.0271567106247 
Train [1/26] | Epoch [11/160] |	nca: 321.7692594528198, loss: 321.7692594528198 
Train [1/26] | Epoch [12/160] |	nca: 307.366485953331, loss: 307.366485953331 
Train [1/26] | Epoch [13/160] |	nca: 296.94387340545654, loss: 296.94387340545654 
Train [1/26] | Epoch [14/160] |	nca: 283.57997834682465, loss: 283.57997834682465 
Train [1/26] | Epoch [15/160] |	nca: 276.33422088623047, loss: 276.33422088623047 
Train [1/26] | Epoch [16/160] |	nca: 269.538682281971, loss: 269.538682281971 
Train [1/26] | Epoch [17/160] |	nca: 260.63066178560257, loss: 260.63066178560257 
Train [1/26] | Epoch [18/160] |	nca: 255.72941929101944, loss: 255.72941929101944 
Train [1/26] | Epoch [19/160] |	nca: 249.51113486289978, loss: 249.51113486289978 
Train [1/26] | Epoch [20/160] |	nca: 245.21639907360077, loss: 245.21639907360077 
Train [1/26] | Epoch [21/160] |	nca: 240.58327144384384, loss: 240.58327144384384 
Train [1/26] | Epoch [22/160] |	nca: 234.851029753685, loss: 234.851029753685 
Train [1/26] | Epoch [23/160] |	nca: 229.5619357228279, loss: 229.5619357228279 
Train [1/26] | Epoch [24/160] |	nca: 227.39953714609146, loss: 227.39953714609146 
Train [1/26] | Epoch [25/160] |	nca: 225.92353534698486, loss: 225.92353534698486 
Train [1/26] | Epoch [26/160] |	nca: 224.4534970521927, loss: 224.4534970521927 
Train [1/26] | Epoch [27/160] |	nca: 218.82597184181213, loss: 218.82597184181213 
Train [1/26] | Epoch [28/160] |	nca: 215.67581927776337, loss: 215.67581927776337 
Train [1/26] | Epoch [29/160] |	nca: 214.22910696268082, loss: 214.22910696268082 
Train [1/26] | Epoch [30/160] |	nca: 208.95660364627838, loss: 208.95660364627838 
Train [1/26] | Epoch [31/160] |	nca: 208.31956696510315, loss: 208.31956696510315 
Train [1/26] | Epoch [32/160] |	nca: 207.4496636390686, loss: 207.4496636390686 
Train [1/26] | Epoch [33/160] |	nca: 204.83086824417114, loss: 204.83086824417114 
Train [1/26] | Epoch [34/160] |	nca: 201.23127967119217, loss: 201.23127967119217 
Train [1/26] | Epoch [35/160] |	nca: 198.8278951048851, loss: 198.8278951048851 
Train [1/26] | Epoch [36/160] |	nca: 198.81195271015167, loss: 198.81195271015167 
Train [1/26] | Epoch [37/160] |	nca: 196.14235365390778, loss: 196.14235365390778 
Train [1/26] | Epoch [38/160] |	nca: 194.89857476949692, loss: 194.89857476949692 
Train [1/26] | Epoch [39/160] |	nca: 193.55962252616882, loss: 193.55962252616882 
Train [1/26] | Epoch [40/160] |	nca: 190.9399191737175, loss: 190.9399191737175 
Train [1/26] | Epoch [41/160] |	nca: 187.34536558389664, loss: 187.34536558389664 
Train [1/26] | Epoch [42/160] |	nca: 187.48681211471558, loss: 187.48681211471558 
Train [1/26] | Epoch [43/160] |	nca: 185.3807254433632, loss: 185.3807254433632 
Train [1/26] | Epoch [44/160] |	nca: 184.43927454948425, loss: 184.43927454948425 
Train [1/26] | Epoch [45/160] |	nca: 182.7836490869522, loss: 182.7836490869522 
Train [1/26] | Epoch [46/160] |	nca: 181.450568318367, loss: 181.450568318367 
Train [1/26] | Epoch [47/160] |	nca: 179.74228709936142, loss: 179.74228709936142 
Train [1/26] | Epoch [48/160] |	nca: 178.42179036140442, loss: 178.42179036140442 
Train [1/26] | Epoch [49/160] |	nca: 176.03643441200256, loss: 176.03643441200256 
Train [1/26] | Epoch [50/160] |	nca: 175.0701225399971, loss: 175.0701225399971 
Train [1/26] | Epoch [51/160] |	nca: 171.93328022956848, loss: 171.93328022956848 
Train [1/26] | Epoch [52/160] |	nca: 173.0624572634697, loss: 173.0624572634697 
Train [1/26] | Epoch [53/160] |	nca: 171.13881087303162, loss: 171.13881087303162 
Train [1/26] | Epoch [54/160] |	nca: 168.72464233636856, loss: 168.72464233636856 
Train [1/26] | Epoch [55/160] |	nca: 166.40503245592117, loss: 166.40503245592117 
Train [1/26] | Epoch [56/160] |	nca: 166.6114398241043, loss: 166.6114398241043 
Train [1/26] | Epoch [57/160] |	nca: 164.7209848165512, loss: 164.7209848165512 
Train [1/26] | Epoch [58/160] |	nca: 165.2437545657158, loss: 165.2437545657158 
Train [1/26] | Epoch [59/160] |	nca: 160.34131610393524, loss: 160.34131610393524 
Train [1/26] | Epoch [60/160] |	nca: 159.8929790854454, loss: 159.8929790854454 
Train [1/26] | Epoch [61/160] |	nca: 158.29413586854935, loss: 158.29413586854935 
Train [1/26] | Epoch [62/160] |	nca: 155.9051371216774, loss: 155.9051371216774 
Train [1/26] | Epoch [63/160] |	nca: 153.7566249370575, loss: 153.7566249370575 
Train [1/26] | Epoch [64/160] |	nca: 153.68936771154404, loss: 153.68936771154404 
Train [1/26] | Epoch [65/160] |	nca: 153.4047490954399, loss: 153.4047490954399 
Train [1/26] | Epoch [66/160] |	nca: 151.56537348031998, loss: 151.56537348031998 
Train [1/26] | Epoch [67/160] |	nca: 148.75851994752884, loss: 148.75851994752884 
Train [1/26] | Epoch [68/160] |	nca: 147.51756301522255, loss: 147.51756301522255 
Train [1/26] | Epoch [69/160] |	nca: 146.30455884337425, loss: 146.30455884337425 
Train [1/26] | Epoch [70/160] |	nca: 143.0518063902855, loss: 143.0518063902855 
Train [1/26] | Epoch [71/160] |	nca: 143.66043788194656, loss: 143.66043788194656 
Train [1/26] | Epoch [72/160] |	nca: 141.77636450529099, loss: 141.77636450529099 
Train [1/26] | Epoch [73/160] |	nca: 138.3265722990036, loss: 138.3265722990036 
Train [1/26] | Epoch [74/160] |	nca: 137.67495024204254, loss: 137.67495024204254 
Train [1/26] | Epoch [75/160] |	nca: 132.87086096405983, loss: 132.87086096405983 
Train [1/26] | Epoch [76/160] |	nca: 134.18844732642174, loss: 134.18844732642174 
Train [1/26] | Epoch [77/160] |	nca: 133.50189155340195, loss: 133.50189155340195 
Train [1/26] | Epoch [78/160] |	nca: 132.0957913994789, loss: 132.0957913994789 
Train [1/26] | Epoch [79/160] |	nca: 127.07700455188751, loss: 127.07700455188751 
Train [1/26] | Epoch [80/160] |	nca: 127.07174655795097, loss: 127.07174655795097 
Train [1/26] | Epoch [81/160] |	nca: 123.74156421422958, loss: 123.74156421422958 
Train [1/26] | Epoch [82/160] |	nca: 123.90107759833336, loss: 123.90107759833336 
Train [1/26] | Epoch [83/160] |	nca: 121.97603172063828, loss: 121.97603172063828 
Train [1/26] | Epoch [84/160] |	nca: 123.80399852991104, loss: 123.80399852991104 
Train [1/26] | Epoch [85/160] |	nca: 116.79370433092117, loss: 116.79370433092117 
Train [1/26] | Epoch [86/160] |	nca: 116.38980433344841, loss: 116.38980433344841 
Train [1/26] | Epoch [87/160] |	nca: 115.36340895295143, loss: 115.36340895295143 
Train [1/26] | Epoch [88/160] |	nca: 115.2871961593628, loss: 115.2871961593628 
Train [1/26] | Epoch [89/160] |	nca: 108.65250897407532, loss: 108.65250897407532 
Train [1/26] | Epoch [90/160] |	nca: 110.4365925192833, loss: 110.4365925192833 
Train [1/26] | Epoch [91/160] |	nca: 107.5756873190403, loss: 107.5756873190403 
Train [1/26] | Epoch [92/160] |	nca: 104.66497823596, loss: 104.66497823596 
Train [1/26] | Epoch [93/160] |	nca: 103.09185037016869, loss: 103.09185037016869 
Train [1/26] | Epoch [94/160] |	nca: 100.91307777166367, loss: 100.91307777166367 
Train [1/26] | Epoch [95/160] |	nca: 97.4835898578167, loss: 97.4835898578167 
Train [1/26] | Epoch [96/160] |	nca: 95.36611405014992, loss: 95.36611405014992 
Train [1/26] | Epoch [97/160] |	nca: 94.45547607541084, loss: 94.45547607541084 
Train [1/26] | Epoch [98/160] |	nca: 92.78098738193512, loss: 92.78098738193512 
Train [1/26] | Epoch [99/160] |	nca: 89.88006410002708, loss: 89.88006410002708 
Train [1/26] | Epoch [100/160] |	nca: 87.28178153932095, loss: 87.28178153932095 
Train [1/26] | Epoch [101/160] |	nca: 86.17139855027199, loss: 86.17139855027199 
Train [1/26] | Epoch [102/160] |	nca: 83.83576968312263, loss: 83.83576968312263 
Train [1/26] | Epoch [103/160] |	nca: 82.79320979118347, loss: 82.79320979118347 
Train [1/26] | Epoch [104/160] |	nca: 78.75321497023106, loss: 78.75321497023106 
Train [1/26] | Epoch [105/160] |	nca: 77.20094732940197, loss: 77.20094732940197 
Train [1/26] | Epoch [106/160] |	nca: 76.33898851275444, loss: 76.33898851275444 
Train [1/26] | Epoch [107/160] |	nca: 74.33535605669022, loss: 74.33535605669022 
Train [1/26] | Epoch [108/160] |	nca: 68.5239096134901, loss: 68.5239096134901 
Train [1/26] | Epoch [109/160] |	nca: 66.0238929092884, loss: 66.0238929092884 
Train [1/26] | Epoch [110/160] |	nca: 66.33979533612728, loss: 66.33979533612728 
Train [1/26] | Epoch [111/160] |	nca: 63.10850632190704, loss: 63.10850632190704 
Train [1/26] | Epoch [112/160] |	nca: 59.01657736301422, loss: 59.01657736301422 
Train [1/26] | Epoch [113/160] |	nca: 61.38683134317398, loss: 61.38683134317398 
Train [1/26] | Epoch [114/160] |	nca: 56.02525256574154, loss: 56.02525256574154 
Train [1/26] | Epoch [115/160] |	nca: 54.60176957398653, loss: 54.60176957398653 
Train [1/26] | Epoch [116/160] |	nca: 52.920237585902214, loss: 52.920237585902214 
Train [1/26] | Epoch [117/160] |	nca: 47.87032424658537, loss: 47.87032424658537 
Train [1/26] | Epoch [118/160] |	nca: 46.34751504659653, loss: 46.34751504659653 
Train [1/26] | Epoch [119/160] |	nca: 43.893037743866444, loss: 43.893037743866444 
Train [1/26] | Epoch [120/160] |	nca: 42.154924653470516, loss: 42.154924653470516 
Train [1/26] | Epoch [121/160] |	nca: 39.264733999967575, loss: 39.264733999967575 
Train [1/26] | Epoch [122/160] |	nca: 37.5985152721405, loss: 37.5985152721405 
Train [1/26] | Epoch [123/160] |	nca: 34.628487318754196, loss: 34.628487318754196 
Train [1/26] | Epoch [124/160] |	nca: 31.611117266118526, loss: 31.611117266118526 
Train [1/26] | Epoch [125/160] |	nca: 30.25796215236187, loss: 30.25796215236187 
Train [1/26] | Epoch [126/160] |	nca: 28.510173119604588, loss: 28.510173119604588 
Train [1/26] | Epoch [127/160] |	nca: 26.445318151265383, loss: 26.445318151265383 
Train [1/26] | Epoch [128/160] |	nca: 25.679393850266933, loss: 25.679393850266933 
Train [1/26] | Epoch [129/160] |	nca: 23.922975715249777, loss: 23.922975715249777 
Train [1/26] | Epoch [130/160] |	nca: 22.21016512438655, loss: 22.21016512438655 
Train [1/26] | Epoch [131/160] |	nca: 19.160147547721863, loss: 19.160147547721863 
Train [1/26] | Epoch [132/160] |	nca: 15.978505600243807, loss: 15.978505600243807 
Train [1/26] | Epoch [133/160] |	nca: 16.28939313814044, loss: 16.28939313814044 
Train [1/26] | Epoch [134/160] |	nca: 14.093004209920764, loss: 14.093004209920764 
Train [1/26] | Epoch [135/160] |	nca: 12.767893871292472, loss: 12.767893871292472 
Train [1/26] | Epoch [136/160] |	nca: 11.609669141471386, loss: 11.609669141471386 
Train [1/26] | Epoch [137/160] |	nca: 11.282149538397789, loss: 11.282149538397789 
Train [1/26] | Epoch [138/160] |	nca: 10.696467734873295, loss: 10.696467734873295 
Train [1/26] | Epoch [139/160] |	nca: 10.10805257037282, loss: 10.10805257037282 
Train [1/26] | Epoch [140/160] |	nca: 8.560256831347942, loss: 8.560256831347942 
Train [1/26] | Epoch [141/160] |	nca: 8.601945415139198, loss: 8.601945415139198 
Train [1/26] | Epoch [142/160] |	nca: 7.601029606536031, loss: 7.601029606536031 
Train [1/26] | Epoch [143/160] |	nca: 6.772992568090558, loss: 6.772992568090558 
Train [1/26] | Epoch [144/160] |	nca: 6.812276614829898, loss: 6.812276614829898 
Train [1/26] | Epoch [145/160] |	nca: 6.969553804025054, loss: 6.969553804025054 
Train [1/26] | Epoch [146/160] |	nca: 6.191593151539564, loss: 6.191593151539564 
Train [1/26] | Epoch [147/160] |	nca: 6.029349545016885, loss: 6.029349545016885 
Train [1/26] | Epoch [148/160] |	nca: 5.932551399804652, loss: 5.932551399804652 
Train [1/26] | Epoch [149/160] |	nca: 5.611372150480747, loss: 5.611372150480747 
Train [1/26] | Epoch [150/160] |	nca: 5.535832030698657, loss: 5.535832030698657 
Train [1/26] | Epoch [151/160] |	nca: 5.201608191244304, loss: 5.201608191244304 
Train [1/26] | Epoch [152/160] |	nca: 5.328458424657583, loss: 5.328458424657583 
Train [1/26] | Epoch [153/160] |	nca: 5.380773556418717, loss: 5.380773556418717 
Train [1/26] | Epoch [154/160] |	nca: 5.128821241669357, loss: 5.128821241669357 
Train [1/26] | Epoch [155/160] |	nca: 5.086992840282619, loss: 5.086992840282619 
Train [1/26] | Epoch [156/160] |	nca: 4.876865268684924, loss: 4.876865268684924 
Train [1/26] | Epoch [157/160] |	nca: 4.72267859056592, loss: 4.72267859056592 
Train [1/26] | Epoch [158/160] |	nca: 4.802229950204492, loss: 4.802229950204492 
Train [1/26] | Epoch [159/160] |	nca: 4.912193146534264, loss: 4.912193146534264 
Train [1/26] | Epoch [160/160] |	nca: 4.936569069512188, loss: 4.936569069512188 
after task
Building & updating memory.
after task
Eval on 0->50.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.779.
Current acc: {'total': 0.779, '00-09': 0.81, '10-19': 0.789, '20-29': 0.73, '30-39': 0.759, '40-49': 0.809}.
Avg inc acc top5: 0.949.
Current acc top5: {'total': 0.949}.
Forgetting: 0.0.
Cord metric: 0.78.
================Task 1 Start!================
Testing on False unseen tasks (max class = 52).
Set memory of size: 1000.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 1 Training!================
The training samples number: 2000
Train on 50->52.
train task
nb 2000.
Train [2/26] | Epoch [1/160] |	nca: 22.432330906391144, flat: 29.903375685214996, pod: 120.09636461734772, loss: 172.43207025527954 
Train [2/26] | Epoch [2/160] |	nca: 19.558522582054138, flat: 31.836645483970642, pod: 118.41225624084473, loss: 169.80742359161377 
Train [2/26] | Epoch [3/160] |	nca: 11.873962581157684, flat: 25.87347185611725, pod: 103.17827987670898, loss: 140.92571449279785 
Train [2/26] | Epoch [4/160] |	nca: 6.938842236995697, flat: 20.707171320915222, pod: 91.86310815811157, loss: 119.50912094116211 
Train [2/26] | Epoch [5/160] |	nca: 4.334779500961304, flat: 16.789416074752808, pod: 82.25077104568481, loss: 103.37496757507324 
Train [2/26] | Epoch [6/160] |	nca: 2.8990884572267532, flat: 13.777873158454895, pod: 74.15763807296753, loss: 90.83459901809692 
Train [2/26] | Epoch [7/160] |	nca: 2.380975604057312, flat: 11.717182755470276, pod: 69.26186466217041, loss: 83.36002397537231 
Train [2/26] | Epoch [8/160] |	nca: 2.3988679572939873, flat: 10.601298570632935, pod: 66.26004934310913, loss: 79.26021575927734 
Train [2/26] | Epoch [9/160] |	nca: 2.08529956638813, flat: 9.510294079780579, pod: 62.73070693016052, loss: 74.32630109786987 
Train [2/26] | Epoch [10/160] |	nca: 1.733079843223095, flat: 8.732775628566742, pod: 62.332916259765625, loss: 72.79877185821533 
Train [2/26] | Epoch [11/160] |	nca: 1.6879598051309586, flat: 8.120057880878448, pod: 58.879963636398315, loss: 68.68798065185547 
Train [2/26] | Epoch [12/160] |	nca: 1.7637236677110195, flat: 7.893722593784332, pod: 57.01773023605347, loss: 66.67517566680908 
Train [2/26] | Epoch [13/160] |	nca: 1.726226232945919, flat: 7.085657984018326, pod: 53.613720178604126, loss: 62.425604820251465 
Train [2/26] | Epoch [14/160] |	nca: 1.9134172350168228, flat: 6.927899152040482, pod: 54.30799198150635, loss: 63.149309158325195 
Train [2/26] | Epoch [15/160] |	nca: 1.7696666866540909, flat: 7.172071397304535, pod: 55.25785541534424, loss: 64.19959330558777 
Train [2/26] | Epoch [16/160] |	nca: 1.649303201586008, flat: 6.570373505353928, pod: 53.21436333656311, loss: 61.434040546417236 
Train [2/26] | Epoch [17/160] |	nca: 1.5637300573289394, flat: 6.544561743736267, pod: 52.763941287994385, loss: 60.872233152389526 
Train [2/26] | Epoch [18/160] |	nca: 1.5855863690376282, flat: 6.14410600066185, pod: 51.253276348114014, loss: 58.98296856880188 
Train [2/26] | Epoch [19/160] |	nca: 1.7214900478720665, flat: 5.899125844240189, pod: 49.6061270236969, loss: 57.22674369812012 
Train [2/26] | Epoch [20/160] |	nca: 1.5004375278949738, flat: 5.778294146060944, pod: 48.827144384384155, loss: 56.10587668418884 
Train [2/26] | Epoch [21/160] |	nca: 1.4900002218782902, flat: 5.889258831739426, pod: 49.695213079452515, loss: 57.074472188949585 
Train [2/26] | Epoch [22/160] |	nca: 1.5356168635189533, flat: 5.700521022081375, pod: 49.595158100128174, loss: 56.83129596710205 
Train [2/26] | Epoch [23/160] |	nca: 1.3916340209543705, flat: 5.5134841203689575, pod: 47.887370109558105, loss: 54.79248809814453 
Train [2/26] | Epoch [24/160] |	nca: 1.3988605625927448, flat: 5.211382329463959, pod: 46.088346004486084, loss: 52.69858908653259 
Train [2/26] | Epoch [25/160] |	nca: 1.622110016644001, flat: 5.54994535446167, pod: 48.593043088912964, loss: 55.765098333358765 
Train [2/26] | Epoch [26/160] |	nca: 1.6443948149681091, flat: 5.398739814758301, pod: 47.542009353637695, loss: 54.58514380455017 
Train [2/26] | Epoch [27/160] |	nca: 1.487673856317997, flat: 5.668516635894775, pod: 48.976285219192505, loss: 56.13247609138489 
Train [2/26] | Epoch [28/160] |	nca: 1.7099987342953682, flat: 5.638971120119095, pod: 48.45119643211365, loss: 55.8001663684845 
Train [2/26] | Epoch [29/160] |	nca: 1.239158809185028, flat: 5.198949217796326, pod: 46.087387561798096, loss: 52.525495529174805 
Train [2/26] | Epoch [30/160] |	nca: 1.2805749140679836, flat: 5.150456786155701, pod: 47.07756042480469, loss: 53.50859189033508 
Train [2/26] | Epoch [31/160] |	nca: 1.308970369398594, flat: 4.927512913942337, pod: 45.15300726890564, loss: 51.389490842819214 
Train [2/26] | Epoch [32/160] |	nca: 1.426134143024683, flat: 5.045106887817383, pod: 45.51406955718994, loss: 51.985310792922974 
Train [2/26] | Epoch [33/160] |	nca: 1.5875056087970734, flat: 5.192126005887985, pod: 46.7093346118927, loss: 53.48896622657776 
Train [2/26] | Epoch [34/160] |	nca: 1.3631323277950287, flat: 5.071869850158691, pod: 45.18618369102478, loss: 51.62118625640869 
Train [2/26] | Epoch [35/160] |	nca: 1.2905522286891937, flat: 4.826776444911957, pod: 43.28148150444031, loss: 49.398810148239136 
Train [2/26] | Epoch [36/160] |	nca: 1.3698275797069073, flat: 4.8322339951992035, pod: 43.62450551986694, loss: 49.82656717300415 
Train [2/26] | Epoch [37/160] |	nca: 1.2580213025212288, flat: 4.643930733203888, pod: 42.26569962501526, loss: 48.167651891708374 
Train [2/26] | Epoch [38/160] |	nca: 1.3267792649567127, flat: 4.707628011703491, pod: 44.39733386039734, loss: 50.43174076080322 
Train [2/26] | Epoch [39/160] |	nca: 1.6104239858686924, flat: 4.706471353769302, pod: 43.11888885498047, loss: 49.435784339904785 
Train [2/26] | Epoch [40/160] |	nca: 1.2987742125988007, flat: 4.802734047174454, pod: 43.07935643196106, loss: 49.18086504936218 
Train [2/26] | Epoch [41/160] |	nca: 1.279724344611168, flat: 4.584868848323822, pod: 42.003960609436035, loss: 47.86855387687683 
Train [2/26] | Epoch [42/160] |	nca: 1.3967741467058659, flat: 4.552825599908829, pod: 42.965542793273926, loss: 48.91514253616333 
Train [2/26] | Epoch [43/160] |	nca: 1.181411262601614, flat: 4.343730628490448, pod: 41.494515895843506, loss: 47.0196578502655 
Train [2/26] | Epoch [44/160] |	nca: 1.3026122227311134, flat: 4.363912209868431, pod: 42.17163968086243, loss: 47.83816432952881 
Train [2/26] | Epoch [45/160] |	nca: 1.1124768797308207, flat: 4.108950808644295, pod: 40.78211569786072, loss: 46.003543853759766 
Train [2/26] | Epoch [46/160] |	nca: 1.1914946921169758, flat: 4.257545754313469, pod: 40.77632164955139, loss: 46.225362062454224 
Train [2/26] | Epoch [47/160] |	nca: 1.387107502669096, flat: 4.24313959479332, pod: 40.68229389190674, loss: 46.312541007995605 
Train [2/26] | Epoch [48/160] |	nca: 1.049611333757639, flat: 4.022576451301575, pod: 39.943485260009766, loss: 45.01567316055298 
Train [2/26] | Epoch [49/160] |	nca: 1.4017351157963276, flat: 4.228907570242882, pod: 41.378817081451416, loss: 47.00945997238159 
Train [2/26] | Epoch [50/160] |	nca: 1.3263125568628311, flat: 4.416842848062515, pod: 42.72076058387756, loss: 48.463916063308716 
Train [2/26] | Epoch [51/160] |	nca: 1.3472965024411678, flat: 4.3199886828660965, pod: 40.904911518096924, loss: 46.57219696044922 
Train [2/26] | Epoch [52/160] |	nca: 1.2064937427639961, flat: 4.119198650121689, pod: 40.32339930534363, loss: 45.6490912437439 
Train [2/26] | Epoch [53/160] |	nca: 1.0841814428567886, flat: 4.004108756780624, pod: 40.00009202957153, loss: 45.088382720947266 
Train [2/26] | Epoch [54/160] |	nca: 1.1722878813743591, flat: 4.076334610581398, pod: 40.8960325717926, loss: 46.144654989242554 
Train [2/26] | Epoch [55/160] |	nca: 1.285503577440977, flat: 4.155918225646019, pod: 40.57765555381775, loss: 46.01907753944397 
Train [2/26] | Epoch [56/160] |	nca: 1.1992246769368649, flat: 4.022888541221619, pod: 41.68702745437622, loss: 46.90914058685303 
Train [2/26] | Epoch [57/160] |	nca: 1.2612909711897373, flat: 4.178272694349289, pod: 41.502445936203, loss: 46.942009925842285 
Train [2/26] | Epoch [58/160] |	nca: 1.10885526612401, flat: 3.829552635550499, pod: 38.73952651023865, loss: 43.67793416976929 
Train [2/26] | Epoch [59/160] |	nca: 1.2182211820036173, flat: 4.030095860362053, pod: 41.4452965259552, loss: 46.6936137676239 
Train [2/26] | Epoch [60/160] |	nca: 1.1017499938607216, flat: 3.8964869379997253, pod: 39.077821493148804, loss: 44.07605814933777 
Train [2/26] | Epoch [61/160] |	nca: 1.4114236496388912, flat: 3.8681049942970276, pod: 38.45385456085205, loss: 43.73338317871094 
Train [2/26] | Epoch [62/160] |	nca: 1.137140728533268, flat: 3.891860380768776, pod: 38.07368850708008, loss: 43.102689266204834 
Train [2/26] | Epoch [63/160] |	nca: 1.15511816740036, flat: 3.6235367357730865, pod: 36.77048182487488, loss: 41.54913663864136 
Train [2/26] | Epoch [64/160] |	nca: 1.207604169845581, flat: 3.5925998836755753, pod: 37.67184638977051, loss: 42.472050189971924 
Train [2/26] | Epoch [65/160] |	nca: 1.065506935119629, flat: 3.696522831916809, pod: 37.6140501499176, loss: 42.37607979774475 
Train [2/26] | Epoch [66/160] |	nca: 1.1842352971434593, flat: 3.5597060322761536, pod: 37.91994261741638, loss: 42.663883686065674 
Train [2/26] | Epoch [67/160] |	nca: 1.125000275671482, flat: 3.644667938351631, pod: 37.083619594573975, loss: 41.8532874584198 
Train [2/26] | Epoch [68/160] |	nca: 1.2403826676309109, flat: 3.576318696141243, pod: 36.394930839538574, loss: 41.2116322517395 
Train [2/26] | Epoch [69/160] |	nca: 1.2370879165828228, flat: 3.6554651707410812, pod: 39.442819595336914, loss: 44.33537268638611 
Train [2/26] | Epoch [70/160] |	nca: 1.1651065051555634, flat: 3.6977586150169373, pod: 40.046462535858154, loss: 44.90932774543762 
Train [2/26] | Epoch [71/160] |	nca: 1.1081748381257057, flat: 3.5639042258262634, pod: 36.78624939918518, loss: 41.458327770233154 
Train [2/26] | Epoch [72/160] |	nca: 1.0483758710324764, flat: 3.3533173352479935, pod: 36.733630657196045, loss: 41.1353235244751 
Train [2/26] | Epoch [73/160] |	nca: 1.1327363885939121, flat: 3.3651609867811203, pod: 35.9888551235199, loss: 40.48675227165222 
Train [2/26] | Epoch [74/160] |	nca: 1.0124427378177643, flat: 3.2880225628614426, pod: 35.73866105079651, loss: 40.0391263961792 
Train [2/26] | Epoch [75/160] |	nca: 1.129095995798707, flat: 3.217906892299652, pod: 35.59654974937439, loss: 39.94355297088623 
Train [2/26] | Epoch [76/160] |	nca: 0.9965524934232235, flat: 3.1544141322374344, pod: 34.427990794181824, loss: 38.578957080841064 
Train [2/26] | Epoch [77/160] |	nca: 1.182777140289545, flat: 3.0567516535520554, pod: 34.03999698162079, loss: 38.27952599525452 
Train [2/26] | Epoch [78/160] |	nca: 1.1312604323029518, flat: 3.1620026528835297, pod: 36.23892903327942, loss: 40.53219223022461 
Train [2/26] | Epoch [79/160] |	nca: 1.2733658365905285, flat: 3.3465402871370316, pod: 35.792151927948, loss: 40.412057876586914 
Train [2/26] | Epoch [80/160] |	nca: 1.2457910664379597, flat: 3.351534381508827, pod: 36.91688632965088, loss: 41.51421141624451 
Train [2/26] | Epoch [81/160] |	nca: 0.9599140677601099, flat: 3.299423396587372, pod: 35.72591185569763, loss: 39.985249519348145 
Train [2/26] | Epoch [82/160] |	nca: 1.0944743603467941, flat: 3.071062833070755, pod: 34.04527938365936, loss: 38.210816860198975 
Train [2/26] | Epoch [83/160] |	nca: 1.186477804556489, flat: 3.0610901713371277, pod: 33.89059805870056, loss: 38.13816595077515 
Train [2/26] | Epoch [84/160] |	nca: 1.2809338737279177, flat: 3.068477511405945, pod: 33.321139335632324, loss: 37.67055058479309 
Train [2/26] | Epoch [85/160] |	nca: 1.0400702953338623, flat: 2.9794967025518417, pod: 32.88043701648712, loss: 36.900004386901855 
Train [2/26] | Epoch [86/160] |	nca: 1.2128863781690598, flat: 2.991485506296158, pod: 33.37848091125488, loss: 37.582852602005005 
Train [2/26] | Epoch [87/160] |	nca: 1.0317130200564861, flat: 2.902424678206444, pod: 33.08363926410675, loss: 37.01777720451355 
Train [2/26] | Epoch [88/160] |	nca: 1.1163365244865417, flat: 2.8515593856573105, pod: 32.922913670539856, loss: 36.890809774398804 
Train [2/26] | Epoch [89/160] |	nca: 0.9379753693938255, flat: 2.8176322877407074, pod: 32.601913928985596, loss: 36.357521772384644 
Train [2/26] | Epoch [90/160] |	nca: 1.1055268626660109, flat: 2.9585708379745483, pod: 33.64463138580322, loss: 37.7087287902832 
Train [2/26] | Epoch [91/160] |	nca: 1.068935789167881, flat: 2.8561689853668213, pod: 32.259588956832886, loss: 36.184693813323975 
Train [2/26] | Epoch [92/160] |	nca: 1.1438033655285835, flat: 2.809548959136009, pod: 32.546788573265076, loss: 36.50014090538025 
Train [2/26] | Epoch [93/160] |	nca: 1.224895067512989, flat: 2.8774549812078476, pod: 32.29220914840698, loss: 36.394559144973755 
Train [2/26] | Epoch [94/160] |	nca: 1.0142837576568127, flat: 2.8622156530618668, pod: 33.17698347568512, loss: 37.05348300933838 
Train [2/26] | Epoch [95/160] |	nca: 0.9813405498862267, flat: 2.6929529905319214, pod: 31.390800952911377, loss: 35.06509447097778 
Train [2/26] | Epoch [96/160] |	nca: 1.0179765708744526, flat: 2.6392340064048767, pod: 31.33047044277191, loss: 34.98768126964569 
Train [2/26] | Epoch [97/160] |	nca: 0.9970550537109375, flat: 2.5985149890184402, pod: 30.498124837875366, loss: 34.09369516372681 
Train [2/26] | Epoch [98/160] |	nca: 1.0867718569934368, flat: 2.577516943216324, pod: 30.452588200569153, loss: 34.11687695980072 
Train [2/26] | Epoch [99/160] |	nca: 1.0336154084652662, flat: 2.5394833981990814, pod: 31.14156210422516, loss: 34.71466088294983 
Train [2/26] | Epoch [100/160] |	nca: 1.0099705662578344, flat: 2.587441101670265, pod: 30.869890689849854, loss: 34.46730196475983 
Train [2/26] | Epoch [101/160] |	nca: 1.1062665656208992, flat: 2.522842049598694, pod: 30.208828926086426, loss: 33.837937355041504 
Train [2/26] | Epoch [102/160] |	nca: 1.029523378238082, flat: 2.481581389904022, pod: 29.99147891998291, loss: 33.50258409976959 
Train [2/26] | Epoch [103/160] |	nca: 1.0188641361892223, flat: 2.381646364927292, pod: 29.263503432273865, loss: 32.664013743400574 
Train [2/26] | Epoch [104/160] |	nca: 1.064856082201004, flat: 2.404797062277794, pod: 30.234408736228943, loss: 33.70406198501587 
Train [2/26] | Epoch [105/160] |	nca: 0.9426618479192257, flat: 2.3402005285024643, pod: 28.369709134101868, loss: 31.652571320533752 
Train [2/26] | Epoch [106/160] |	nca: 1.079987358301878, flat: 2.2837286591529846, pod: 28.227298855781555, loss: 31.591014742851257 
Train [2/26] | Epoch [107/160] |	nca: 0.9539649821817875, flat: 2.3324443995952606, pod: 28.745980501174927, loss: 32.032389879226685 
Train [2/26] | Epoch [108/160] |	nca: 1.0049127377569675, flat: 2.263698749244213, pod: 28.224231243133545, loss: 31.49284303188324 
Train [2/26] | Epoch [109/160] |	nca: 0.975554071366787, flat: 2.4208353012800217, pod: 29.42641544342041, loss: 32.82280516624451 
Train [2/26] | Epoch [110/160] |	nca: 1.108152486383915, flat: 2.341936707496643, pod: 29.137654066085815, loss: 32.587743401527405 
Train [2/26] | Epoch [111/160] |	nca: 0.8721499294042587, flat: 2.211118161678314, pod: 27.392050862312317, loss: 30.475319385528564 
Train [2/26] | Epoch [112/160] |	nca: 1.0332459714263678, flat: 2.2000038996338844, pod: 27.503369450569153, loss: 30.73661959171295 
Train [2/26] | Epoch [113/160] |	nca: 1.1368745528161526, flat: 2.1764330938458443, pod: 27.52316904067993, loss: 30.83647656440735 
Train [2/26] | Epoch [114/160] |	nca: 0.8768883645534515, flat: 2.262672133743763, pod: 27.26913547515869, loss: 30.408695936203003 
Train [2/26] | Epoch [115/160] |	nca: 0.979588944464922, flat: 2.031809128820896, pod: 26.960154056549072, loss: 29.97155225276947 
Train [2/26] | Epoch [116/160] |	nca: 1.0346321947872639, flat: 2.136445179581642, pod: 27.281888246536255, loss: 30.45296549797058 
Train [2/26] | Epoch [117/160] |	nca: 0.9786867406219244, flat: 2.071262389421463, pod: 26.089938759803772, loss: 29.13988757133484 
Train [2/26] | Epoch [118/160] |	nca: 1.0333768017590046, flat: 2.1288733407855034, pod: 26.83028495311737, loss: 29.99253511428833 
Train [2/26] | Epoch [119/160] |	nca: 1.0102480612695217, flat: 2.0607821494340897, pod: 26.39032733440399, loss: 29.461357474327087 
Train [2/26] | Epoch [120/160] |	nca: 1.0310530290007591, flat: 1.932819813489914, pod: 25.39541006088257, loss: 28.359282851219177 
Train [2/26] | Epoch [121/160] |	nca: 0.9698974266648293, flat: 1.8702849447727203, pod: 24.31300175189972, loss: 27.153183937072754 
Train [2/26] | Epoch [122/160] |	nca: 0.9674698077142239, flat: 1.970932200551033, pod: 25.389294385910034, loss: 28.327696442604065 
Train [2/26] | Epoch [123/160] |	nca: 1.2001307606697083, flat: 2.0287377908825874, pod: 25.997563004493713, loss: 29.226431727409363 
Train [2/26] | Epoch [124/160] |	nca: 0.9026887528598309, flat: 1.9955513998866081, pod: 25.131500124931335, loss: 28.02974021434784 
Train [2/26] | Epoch [125/160] |	nca: 1.0085282772779465, flat: 1.965954065322876, pod: 25.577717661857605, loss: 28.552199959754944 
Train [2/26] | Epoch [126/160] |	nca: 0.9388116486370564, flat: 1.8174809515476227, pod: 24.48323392868042, loss: 27.239526629447937 
Train [2/26] | Epoch [127/160] |	nca: 1.0727602802217007, flat: 1.845127560198307, pod: 24.363516211509705, loss: 27.28140413761139 
Train [2/26] | Epoch [128/160] |	nca: 0.8851490337401628, flat: 1.8169725388288498, pod: 23.665746808052063, loss: 26.367868423461914 
Train [2/26] | Epoch [129/160] |	nca: 0.9175823517143726, flat: 1.7805230990052223, pod: 24.165600180625916, loss: 26.86370551586151 
Train [2/26] | Epoch [130/160] |	nca: 0.9859727956354618, flat: 1.7590614333748817, pod: 23.433307647705078, loss: 26.17834198474884 
Train [2/26] | Epoch [131/160] |	nca: 1.067369781434536, flat: 1.8114481046795845, pod: 23.815496921539307, loss: 26.69431483745575 
Train [2/26] | Epoch [132/160] |	nca: 1.0452021732926369, flat: 1.7937668040394783, pod: 24.211163759231567, loss: 27.050132513046265 
Train [2/26] | Epoch [133/160] |	nca: 1.046604111790657, flat: 1.765068769454956, pod: 23.295483231544495, loss: 26.1071560382843 
Train [2/26] | Epoch [134/160] |	nca: 0.8795254901051521, flat: 1.7475231289863586, pod: 22.90385401248932, loss: 25.53090274333954 
Train [2/26] | Epoch [135/160] |	nca: 0.9531064853072166, flat: 1.7858234196901321, pod: 23.177677035331726, loss: 25.91660702228546 
Train [2/26] | Epoch [136/160] |	nca: 1.0971295945346355, flat: 1.7214578539133072, pod: 23.051989555358887, loss: 25.870577096939087 
Train [2/26] | Epoch [137/160] |	nca: 0.8689507469534874, flat: 1.7248143032193184, pod: 23.02181315422058, loss: 25.615578055381775 
Train [2/26] | Epoch [138/160] |	nca: 0.9144342951476574, flat: 1.6892267614603043, pod: 23.041620016098022, loss: 25.645281076431274 
Train [2/26] | Epoch [139/160] |	nca: 0.9118186645209789, flat: 1.698804184794426, pod: 22.8173189163208, loss: 25.42794179916382 
Train [2/26] | Epoch [140/160] |	nca: 0.9499472267925739, flat: 1.597633771598339, pod: 21.658822059631348, loss: 24.206403136253357 
Train [2/26] | Epoch [141/160] |	nca: 0.9867485165596008, flat: 1.642066240310669, pod: 22.284549832344055, loss: 24.91336476802826 
Train [2/26] | Epoch [142/160] |	nca: 0.9865884520113468, flat: 1.5906543731689453, pod: 21.716789484024048, loss: 24.294032335281372 
Train [2/26] | Epoch [143/160] |	nca: 0.9278541058301926, flat: 1.576747015118599, pod: 21.33476722240448, loss: 23.83936834335327 
Train [2/26] | Epoch [144/160] |	nca: 0.9010435659438372, flat: 1.5666201561689377, pod: 21.42590355873108, loss: 23.893566966056824 
Train [2/26] | Epoch [145/160] |	nca: 0.9398582354187965, flat: 1.599369503557682, pod: 21.867621302604675, loss: 24.406849026679993 
Train [2/26] | Epoch [146/160] |	nca: 1.0102876238524914, flat: 1.6074984446167946, pod: 21.595288395881653, loss: 24.213074445724487 
Train [2/26] | Epoch [147/160] |	nca: 0.9536145403981209, flat: 1.5447386130690575, pod: 21.000702738761902, loss: 23.499055862426758 
Train [2/26] | Epoch [148/160] |	nca: 0.92536461353302, flat: 1.595157966017723, pod: 21.057044982910156, loss: 23.57756733894348 
Train [2/26] | Epoch [149/160] |	nca: 0.8695493936538696, flat: 1.526462882757187, pod: 20.324192881584167, loss: 22.720205187797546 
Train [2/26] | Epoch [150/160] |	nca: 0.9419339224696159, flat: 1.5729995146393776, pod: 21.246625900268555, loss: 23.76155936717987 
Train [2/26] | Epoch [151/160] |	nca: 1.0379925854504108, flat: 1.6160560473799706, pod: 20.818252086639404, loss: 23.47230076789856 
Train [2/26] | Epoch [152/160] |	nca: 1.099400032311678, flat: 1.576904945075512, pod: 21.172343015670776, loss: 23.848648190498352 
Train [2/26] | Epoch [153/160] |	nca: 0.9028803147375584, flat: 1.6125864833593369, pod: 21.138246178627014, loss: 23.65371298789978 
Train [2/26] | Epoch [154/160] |	nca: 0.8147137593477964, flat: 1.5279342457652092, pod: 20.16499090194702, loss: 22.507638931274414 
Train [2/26] | Epoch [155/160] |	nca: 0.9184132441878319, flat: 1.5974990651011467, pod: 20.75522255897522, loss: 23.271134734153748 
Train [2/26] | Epoch [156/160] |	nca: 0.9507266413420439, flat: 1.5606626272201538, pod: 20.550157070159912, loss: 23.061546087265015 
Train [2/26] | Epoch [157/160] |	nca: 0.925630196928978, flat: 1.551127128303051, pod: 20.594997882843018, loss: 23.071755170822144 
Train [2/26] | Epoch [158/160] |	nca: 0.943758849054575, flat: 1.54656233638525, pod: 20.655965566635132, loss: 23.146286606788635 
Train [2/26] | Epoch [159/160] |	nca: 1.027540173381567, flat: 1.6068838611245155, pod: 20.586341381072998, loss: 23.220765233039856 
Train [2/26] | Epoch [160/160] |	nca: 0.8754620254039764, flat: 1.5501469671726227, pod: 20.702866792678833, loss: 23.12847590446472 
Fine-tuning
Building & updating memory.
Train [2/26] | Epoch [161/180] |	nca: 1.2443200647830963, flat: 1.842752292752266, pod: 16.644792199134827, loss: 19.73186433315277 
Train [2/26] | Epoch [162/180] |	nca: 1.2107770591974258, flat: 1.9898636937141418, pod: 16.095348238945007, loss: 19.29598867893219 
Train [2/26] | Epoch [163/180] |	nca: 0.4355265237390995, flat: 1.7225156277418137, pod: 16.324371576309204, loss: 18.48241353034973 
Train [2/26] | Epoch [164/180] |	nca: 0.48517249524593353, flat: 1.7986140698194504, pod: 16.28453230857849, loss: 18.568318843841553 
Train [2/26] | Epoch [165/180] |	nca: 0.3308202940970659, flat: 1.647660255432129, pod: 16.229770302772522, loss: 18.208250880241394 
Train [2/26] | Epoch [166/180] |	nca: 0.32987445779144764, flat: 1.6543352752923965, pod: 15.883490800857544, loss: 17.867700457572937 
Train [2/26] | Epoch [167/180] |	nca: 0.6904575843364, flat: 1.8045677691698074, pod: 16.02952802181244, loss: 18.524553537368774 
Train [2/26] | Epoch [168/180] |	nca: 0.3103174436837435, flat: 1.7082507386803627, pod: 16.259266138076782, loss: 18.2778342962265 
Train [2/26] | Epoch [169/180] |	nca: 0.3479063492268324, flat: 1.6430126801133156, pod: 15.961555123329163, loss: 17.952474117279053 
Train [2/26] | Epoch [170/180] |	nca: 0.2820378225296736, flat: 1.6657694876194, pod: 15.922370433807373, loss: 17.87017786502838 
Train [2/26] | Epoch [171/180] |	nca: 0.3752849819138646, flat: 1.7409068793058395, pod: 16.44528841972351, loss: 18.56148052215576 
Train [2/26] | Epoch [172/180] |	nca: 0.24333933554589748, flat: 1.7254112511873245, pod: 16.22740137577057, loss: 18.196151852607727 
Train [2/26] | Epoch [173/180] |	nca: 0.24505330435931683, flat: 1.6878192722797394, pod: 15.789066195487976, loss: 17.721938729286194 
Train [2/26] | Epoch [174/180] |	nca: 0.3262412566691637, flat: 1.691851943731308, pod: 16.09221088886261, loss: 18.11030423641205 
Train [2/26] | Epoch [175/180] |	nca: 0.23485223203897476, flat: 1.7104198634624481, pod: 15.922299027442932, loss: 17.867571353912354 
Train [2/26] | Epoch [176/180] |	nca: 0.2819576533511281, flat: 1.7311606258153915, pod: 16.449939966201782, loss: 18.46305823326111 
Train [2/26] | Epoch [177/180] |	nca: 0.233088631182909, flat: 1.6729695349931717, pod: 16.21820592880249, loss: 18.124264001846313 
Train [2/26] | Epoch [178/180] |	nca: 0.49252478778362274, flat: 1.8095187842845917, pod: 16.346559286117554, loss: 18.648602724075317 
Train [2/26] | Epoch [179/180] |	nca: 0.28060944750905037, flat: 1.8045156002044678, pod: 15.76334023475647, loss: 17.84846544265747 
Train [2/26] | Epoch [180/180] |	nca: 0.2981860851868987, flat: 1.7555788159370422, pod: 16.02815067768097, loss: 18.081915616989136 
after task
Building & updating memory.
after task
Eval on 0->52.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.761.
Current acc: {'total': 0.743, '00-09': 0.758, '10-19': 0.746, '20-29': 0.675, '30-39': 0.715, '40-49': 0.796, '50-59': 0.855}.
Avg inc acc top5: 0.9415.
Current acc top5: {'total': 0.934}.
Forgetting: -0.09257142857142855.
Cord metric: 0.76.
Old accuracy: 0.74, mean: 0.74.
New accuracy: 0.85, mean: 0.85.
================Task 2 Start!================
Testing on False unseen tasks (max class = 54).
Set memory of size: 1040.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 2 Training!================
The training samples number: 2040
Train on 52->54.
train task
nb 2040.
Train [3/26] | Epoch [1/160] |	nca: 6.7630883902311325, flat: 4.839107543230057, pod: 42.9716340303421, loss: 54.573829650878906 
Train [3/26] | Epoch [2/160] |	nca: 4.9522258043289185, flat: 7.193560838699341, pod: 54.70949840545654, loss: 66.85528492927551 
Train [3/26] | Epoch [3/160] |	nca: 3.5942331552505493, flat: 7.013318449258804, pod: 53.69868302345276, loss: 64.30623412132263 
Train [3/26] | Epoch [4/160] |	nca: 2.6122104674577713, flat: 5.445767879486084, pod: 48.00717043876648, loss: 56.06514859199524 
Train [3/26] | Epoch [5/160] |	nca: 1.8721901029348373, flat: 4.614160060882568, pod: 44.04087686538696, loss: 50.52722692489624 
Train [3/26] | Epoch [6/160] |	nca: 2.0570384189486504, flat: 4.120118245482445, pod: 42.581923961639404, loss: 48.75908088684082 
Train [3/26] | Epoch [7/160] |	nca: 1.7558726072311401, flat: 3.8960534185171127, pod: 41.28832650184631, loss: 46.94025278091431 
Train [3/26] | Epoch [8/160] |	nca: 1.9604536667466164, flat: 3.7348555624485016, pod: 39.50773358345032, loss: 45.20304298400879 
Train [3/26] | Epoch [9/160] |	nca: 2.316192425787449, flat: 3.877698764204979, pod: 40.82286715507507, loss: 47.01675796508789 
Train [3/26] | Epoch [10/160] |	nca: 2.1103754490613937, flat: 4.20565564930439, pod: 42.33488941192627, loss: 48.65092062950134 
Train [3/26] | Epoch [11/160] |	nca: 2.171481728553772, flat: 4.234617248177528, pod: 43.543434143066406, loss: 49.949532985687256 
Train [3/26] | Epoch [12/160] |	nca: 1.5024385899305344, flat: 4.00721076130867, pod: 41.86908411979675, loss: 47.37873363494873 
Train [3/26] | Epoch [13/160] |	nca: 1.6513460129499435, flat: 3.4993665665388107, pod: 37.96504044532776, loss: 43.115753412246704 
Train [3/26] | Epoch [14/160] |	nca: 1.7517406307160854, flat: 3.5208466947078705, pod: 39.468505859375, loss: 44.741092920303345 
Train [3/26] | Epoch [15/160] |	nca: 1.7295133955776691, flat: 3.5783912539482117, pod: 39.60279130935669, loss: 44.910696029663086 
Train [3/26] | Epoch [16/160] |	nca: 1.6856566593050957, flat: 3.6792747527360916, pod: 40.084341049194336, loss: 45.4492723941803 
Train [3/26] | Epoch [17/160] |	nca: 1.6268180571496487, flat: 3.583578422665596, pod: 39.331069469451904, loss: 44.541465520858765 
Train [3/26] | Epoch [18/160] |	nca: 2.0355347618460655, flat: 3.737237900495529, pod: 41.10162544250488, loss: 46.87439799308777 
Train [3/26] | Epoch [19/160] |	nca: 1.9304177910089493, flat: 3.9644009470939636, pod: 41.413604974746704, loss: 47.30842328071594 
Train [3/26] | Epoch [20/160] |	nca: 1.8695670403540134, flat: 3.8513214886188507, pod: 41.769585609436035, loss: 47.490474462509155 
Train [3/26] | Epoch [21/160] |	nca: 1.5810248963534832, flat: 3.6811174750328064, pod: 39.426960706710815, loss: 44.6891028881073 
Train [3/26] | Epoch [22/160] |	nca: 1.6837980300188065, flat: 3.4316808879375458, pod: 38.23286509513855, loss: 43.34834384918213 
Train [3/26] | Epoch [23/160] |	nca: 1.4838820397853851, flat: 3.5363304167985916, pod: 40.65903377532959, loss: 45.67924618721008 
Train [3/26] | Epoch [24/160] |	nca: 1.5196196623146534, flat: 3.3044887334108353, pod: 37.901734590530396, loss: 42.72584247589111 
Train [3/26] | Epoch [25/160] |	nca: 1.4854110963642597, flat: 3.1646466702222824, pod: 37.043675661087036, loss: 41.69373297691345 
Train [3/26] | Epoch [26/160] |	nca: 1.6717297844588757, flat: 3.448054924607277, pod: 39.42779350280762, loss: 44.54757809638977 
Train [3/26] | Epoch [27/160] |	nca: 1.5994038321077824, flat: 3.435075804591179, pod: 38.64014410972595, loss: 43.67462396621704 
Train [3/26] | Epoch [28/160] |	nca: 1.5202505812048912, flat: 3.351336255669594, pod: 39.31852388381958, loss: 44.19011068344116 
Train [3/26] | Epoch [29/160] |	nca: 1.8345496580004692, flat: 3.377623364329338, pod: 39.09288501739502, loss: 44.305057764053345 
Train [3/26] | Epoch [30/160] |	nca: 1.519407108426094, flat: 3.339614376425743, pod: 37.76835346221924, loss: 42.62737488746643 
Train [3/26] | Epoch [31/160] |	nca: 1.4938131906092167, flat: 3.13494111597538, pod: 36.480647802352905, loss: 41.1094024181366 
Train [3/26] | Epoch [32/160] |	nca: 1.6159242987632751, flat: 3.245773807168007, pod: 37.20937943458557, loss: 42.07107710838318 
Train [3/26] | Epoch [33/160] |	nca: 1.483265321701765, flat: 3.1714900135993958, pod: 37.95691132545471, loss: 42.611666679382324 
Train [3/26] | Epoch [34/160] |	nca: 1.6559651531279087, flat: 3.118284523487091, pod: 36.776087284088135, loss: 41.550337076187134 
Train [3/26] | Epoch [35/160] |	nca: 1.47325299680233, flat: 3.2083630114793777, pod: 37.00575280189514, loss: 41.687368869781494 
Train [3/26] | Epoch [36/160] |	nca: 1.639895111322403, flat: 3.055703803896904, pod: 35.3706396818161, loss: 40.06623840332031 
Train [3/26] | Epoch [37/160] |	nca: 1.5467833206057549, flat: 3.115676239132881, pod: 36.14730477333069, loss: 40.80976414680481 
Train [3/26] | Epoch [38/160] |	nca: 1.5589966736733913, flat: 3.371913194656372, pod: 38.223050594329834, loss: 43.153960943222046 
Train [3/26] | Epoch [39/160] |	nca: 1.4433668404817581, flat: 3.2964689880609512, pod: 38.453327655792236, loss: 43.1931631565094 
Train [3/26] | Epoch [40/160] |	nca: 1.5094200447201729, flat: 3.0686558932065964, pod: 36.337937116622925, loss: 40.91601324081421 
Train [3/26] | Epoch [41/160] |	nca: 1.29852394759655, flat: 2.8822775930166245, pod: 34.779059290885925, loss: 38.95986032485962 
Train [3/26] | Epoch [42/160] |	nca: 1.5164461210370064, flat: 3.035863235592842, pod: 36.88278317451477, loss: 41.43509292602539 
Train [3/26] | Epoch [43/160] |	nca: 1.3753938414156437, flat: 3.308701127767563, pod: 38.90002965927124, loss: 43.58412480354309 
Train [3/26] | Epoch [44/160] |	nca: 1.4031293988227844, flat: 2.987490564584732, pod: 37.23029375076294, loss: 41.62091398239136 
Train [3/26] | Epoch [45/160] |	nca: 1.6968566998839378, flat: 3.08376744389534, pod: 36.754265785217285, loss: 41.534889936447144 
Train [3/26] | Epoch [46/160] |	nca: 1.4196745567023754, flat: 3.037739083170891, pod: 35.85023307800293, loss: 40.30764675140381 
Train [3/26] | Epoch [47/160] |	nca: 1.5583517104387283, flat: 2.869726210832596, pod: 35.52333998680115, loss: 39.951417684555054 
Train [3/26] | Epoch [48/160] |	nca: 1.449830800294876, flat: 3.0413570553064346, pod: 37.00071048736572, loss: 41.49189853668213 
Train [3/26] | Epoch [49/160] |	nca: 1.3698262982070446, flat: 2.8187808245420456, pod: 35.49655199050903, loss: 39.68515920639038 
Train [3/26] | Epoch [50/160] |	nca: 1.385350126773119, flat: 2.808749333024025, pod: 34.94513785839081, loss: 39.13923716545105 
Train [3/26] | Epoch [51/160] |	nca: 1.3122923895716667, flat: 2.712087705731392, pod: 33.98438215255737, loss: 38.00876259803772 
Train [3/26] | Epoch [52/160] |	nca: 1.6561409160494804, flat: 2.9021396040916443, pod: 35.25147080421448, loss: 39.809751987457275 
Train [3/26] | Epoch [53/160] |	nca: 1.3346373848617077, flat: 2.8892973512411118, pod: 35.99109923839569, loss: 40.21503400802612 
Train [3/26] | Epoch [54/160] |	nca: 1.4923695288598537, flat: 2.8390168249607086, pod: 36.67918658256531, loss: 41.01057314872742 
Train [3/26] | Epoch [55/160] |	nca: 1.3262191638350487, flat: 2.6222522258758545, pod: 33.43221700191498, loss: 37.380688190460205 
Train [3/26] | Epoch [56/160] |	nca: 1.2858961075544357, flat: 2.6577370017766953, pod: 33.69606578350067, loss: 37.63969826698303 
Train [3/26] | Epoch [57/160] |	nca: 1.4117943607270718, flat: 2.691061571240425, pod: 33.354671478271484, loss: 37.45752763748169 
Train [3/26] | Epoch [58/160] |	nca: 1.2555102929472923, flat: 2.540101021528244, pod: 32.95299673080444, loss: 36.74860906600952 
Train [3/26] | Epoch [59/160] |	nca: 1.4926779940724373, flat: 2.5892286151647568, pod: 32.74027955532074, loss: 36.82218647003174 
Train [3/26] | Epoch [60/160] |	nca: 1.363985788077116, flat: 2.6679341197013855, pod: 33.82073700428009, loss: 37.8526566028595 
Train [3/26] | Epoch [61/160] |	nca: 1.4577161185443401, flat: 2.7471893876791, pod: 35.06586718559265, loss: 39.27077269554138 
Train [3/26] | Epoch [62/160] |	nca: 1.4703938774764538, flat: 2.5511259585618973, pod: 32.75013864040375, loss: 36.771658182144165 
Train [3/26] | Epoch [63/160] |	nca: 1.3128280378878117, flat: 2.431263417005539, pod: 32.02392637729645, loss: 35.76801812648773 
Train [3/26] | Epoch [64/160] |	nca: 1.3499817550182343, flat: 2.4019453153014183, pod: 31.7049343585968, loss: 35.45686078071594 
Train [3/26] | Epoch [65/160] |	nca: 1.1668500490486622, flat: 2.2701229825615883, pod: 31.106308817863464, loss: 34.54328179359436 
Train [3/26] | Epoch [66/160] |	nca: 1.335723228752613, flat: 2.3595981895923615, pod: 31.709123134613037, loss: 35.404444456100464 
Train [3/26] | Epoch [67/160] |	nca: 1.2966577261686325, flat: 2.3499894067645073, pod: 32.213703751564026, loss: 35.8603515625 
Train [3/26] | Epoch [68/160] |	nca: 1.2927690111100674, flat: 2.2722522169351578, pod: 30.862346529960632, loss: 34.42736792564392 
Train [3/26] | Epoch [69/160] |	nca: 1.4913730919361115, flat: 2.385657384991646, pod: 31.305612444877625, loss: 35.182642698287964 
Train [3/26] | Epoch [70/160] |	nca: 1.4378589019179344, flat: 2.2428750321269035, pod: 30.16960895061493, loss: 33.850342988967896 
Train [3/26] | Epoch [71/160] |	nca: 1.3544989973306656, flat: 2.3087031468749046, pod: 29.942608952522278, loss: 33.60581111907959 
Train [3/26] | Epoch [72/160] |	nca: 1.2751738205552101, flat: 2.2546819746494293, pod: 30.939043879508972, loss: 34.468899726867676 
Train [3/26] | Epoch [73/160] |	nca: 1.2233096398413181, flat: 2.083613008260727, pod: 29.586380124092102, loss: 32.89330279827118 
Train [3/26] | Epoch [74/160] |	nca: 1.2008391618728638, flat: 2.0873161926865578, pod: 29.832674741744995, loss: 33.120829939842224 
Train [3/26] | Epoch [75/160] |	nca: 1.1727975346148014, flat: 2.1056985929608345, pod: 29.809321522712708, loss: 33.087817549705505 
Train [3/26] | Epoch [76/160] |	nca: 1.3152019418776035, flat: 2.0026111230254173, pod: 28.61896824836731, loss: 31.936781525611877 
Train [3/26] | Epoch [77/160] |	nca: 1.3255577273666859, flat: 2.175755113363266, pod: 30.514919638633728, loss: 34.01623260974884 
Train [3/26] | Epoch [78/160] |	nca: 1.2970138229429722, flat: 2.1610318198800087, pod: 29.482373118400574, loss: 32.94041883945465 
Train [3/26] | Epoch [79/160] |	nca: 1.2482632994651794, flat: 2.1277959644794464, pod: 29.387486219406128, loss: 32.76354539394379 
Train [3/26] | Epoch [80/160] |	nca: 1.291526883840561, flat: 2.050609268248081, pod: 29.274895668029785, loss: 32.61703157424927 
Train [3/26] | Epoch [81/160] |	nca: 1.3309467434883118, flat: 2.018306441605091, pod: 29.367945551872253, loss: 32.717198729515076 
Train [3/26] | Epoch [82/160] |	nca: 1.3031723089516163, flat: 2.2360882088541985, pod: 31.15323269367218, loss: 34.692492961883545 
Train [3/26] | Epoch [83/160] |	nca: 1.3231995441019535, flat: 2.318992719054222, pod: 31.263407349586487, loss: 34.90559983253479 
Train [3/26] | Epoch [84/160] |	nca: 1.2244151905179024, flat: 2.0962706431746483, pod: 29.359801769256592, loss: 32.680487632751465 
Train [3/26] | Epoch [85/160] |	nca: 1.2068946100771427, flat: 1.9402438029646873, pod: 27.850045680999756, loss: 30.99718403816223 
Train [3/26] | Epoch [86/160] |	nca: 1.4165943004190922, flat: 1.8688368275761604, pod: 28.259524703025818, loss: 31.544955849647522 
Train [3/26] | Epoch [87/160] |	nca: 1.2364141829311848, flat: 1.9564233049750328, pod: 28.425909161567688, loss: 31.618746757507324 
Train [3/26] | Epoch [88/160] |	nca: 1.2140801139175892, flat: 2.0379756465554237, pod: 29.075350880622864, loss: 32.32740676403046 
Train [3/26] | Epoch [89/160] |	nca: 1.2802547551691532, flat: 1.8913951441645622, pod: 27.802393078804016, loss: 30.974043250083923 
Train [3/26] | Epoch [90/160] |	nca: 1.3361136093735695, flat: 2.034733407199383, pod: 28.85290837287903, loss: 32.22375500202179 
Train [3/26] | Epoch [91/160] |	nca: 1.2932922393083572, flat: 1.9087439626455307, pod: 27.735730409622192, loss: 30.937766790390015 
Train [3/26] | Epoch [92/160] |	nca: 1.2618051655590534, flat: 1.817782424390316, pod: 27.149179697036743, loss: 30.228767156600952 
Train [3/26] | Epoch [93/160] |	nca: 1.3206367045640945, flat: 1.8668904080986977, pod: 27.444581389427185, loss: 30.632108449935913 
Train [3/26] | Epoch [94/160] |	nca: 1.2943462207913399, flat: 1.8088103756308556, pod: 26.486624598503113, loss: 29.589781284332275 
Train [3/26] | Epoch [95/160] |	nca: 1.166349470615387, flat: 1.7889984920620918, pod: 26.406638145446777, loss: 29.36198616027832 
Train [3/26] | Epoch [96/160] |	nca: 1.1399965435266495, flat: 1.82333292812109, pod: 27.155039310455322, loss: 30.118368983268738 
Train [3/26] | Epoch [97/160] |	nca: 1.3783436380326748, flat: 1.7415088042616844, pod: 26.43783736228943, loss: 29.557689905166626 
Train [3/26] | Epoch [98/160] |	nca: 1.1917228549718857, flat: 1.623074747622013, pod: 25.165231943130493, loss: 27.980029463768005 
Train [3/26] | Epoch [99/160] |	nca: 1.1264540441334248, flat: 1.7079421058297157, pod: 27.102612137794495, loss: 29.937008142471313 
Train [3/26] | Epoch [100/160] |	nca: 1.2709847427904606, flat: 1.7514849454164505, pod: 27.033167123794556, loss: 30.055636882781982 
Train [3/26] | Epoch [101/160] |	nca: 1.3305313773453236, flat: 1.8622687235474586, pod: 28.674963235855103, loss: 31.86776316165924 
Train [3/26] | Epoch [102/160] |	nca: 1.3084087297320366, flat: 1.7398866638541222, pod: 27.27736794948578, loss: 30.325663328170776 
Train [3/26] | Epoch [103/160] |	nca: 1.1107864454388618, flat: 1.5899138748645782, pod: 25.16509771347046, loss: 27.865797758102417 
Train [3/26] | Epoch [104/160] |	nca: 1.1139574982225895, flat: 1.5305299013853073, pod: 24.70558226108551, loss: 27.350069642066956 
Train [3/26] | Epoch [105/160] |	nca: 1.174806997179985, flat: 1.6957052648067474, pod: 26.07000708580017, loss: 28.94051945209503 
Train [3/26] | Epoch [106/160] |	nca: 1.202474944293499, flat: 1.4980819001793861, pod: 23.962714314460754, loss: 26.66327142715454 
Train [3/26] | Epoch [107/160] |	nca: 1.2436915412545204, flat: 1.6077916622161865, pod: 25.824764251708984, loss: 28.676247596740723 
Train [3/26] | Epoch [108/160] |	nca: 1.2639561481773853, flat: 1.5370944812893867, pod: 24.236679077148438, loss: 27.037729740142822 
Train [3/26] | Epoch [109/160] |	nca: 1.1216482184827328, flat: 1.386386252939701, pod: 23.33388090133667, loss: 25.841915369033813 
Train [3/26] | Epoch [110/160] |	nca: 1.2099503800272942, flat: 1.3825874626636505, pod: 22.870820999145508, loss: 25.463358998298645 
Train [3/26] | Epoch [111/160] |	nca: 1.1828039698302746, flat: 1.4020031616091728, pod: 23.65103018283844, loss: 26.23583710193634 
Train [3/26] | Epoch [112/160] |	nca: 1.175718691200018, flat: 1.327029600739479, pod: 22.727160215377808, loss: 25.229908347129822 
Train [3/26] | Epoch [113/160] |	nca: 1.2731618583202362, flat: 1.3646469563245773, pod: 23.015860557556152, loss: 25.653669238090515 
Train [3/26] | Epoch [114/160] |	nca: 1.1828431114554405, flat: 1.3360569700598717, pod: 22.640611171722412, loss: 25.15951120853424 
Train [3/26] | Epoch [115/160] |	nca: 1.1334876641631126, flat: 1.3524219244718552, pod: 23.920660614967346, loss: 26.406570076942444 
Train [3/26] | Epoch [116/160] |	nca: 1.1559820137917995, flat: 1.3104755207896233, pod: 22.784965872764587, loss: 25.251423597335815 
Train [3/26] | Epoch [117/160] |	nca: 1.2586711719632149, flat: 1.3745863437652588, pod: 22.417624473571777, loss: 25.05088198184967 
Train [3/26] | Epoch [118/160] |	nca: 1.1680795028805733, flat: 1.2864948436617851, pod: 21.87465274333954, loss: 24.329227089881897 
Train [3/26] | Epoch [119/160] |	nca: 1.2516760863363743, flat: 1.2744290083646774, pod: 21.605138301849365, loss: 24.131243467330933 
Train [3/26] | Epoch [120/160] |	nca: 1.4361409172415733, flat: 1.3183192908763885, pod: 21.7428640127182, loss: 24.497324347496033 
Train [3/26] | Epoch [121/160] |	nca: 1.2589741870760918, flat: 1.3025247752666473, pod: 21.986313104629517, loss: 24.54781174659729 
Train [3/26] | Epoch [122/160] |	nca: 1.1735449619591236, flat: 1.28308916836977, pod: 22.14460587501526, loss: 24.601240038871765 
Train [3/26] | Epoch [123/160] |	nca: 1.2335795797407627, flat: 1.2458321154117584, pod: 21.901237726211548, loss: 24.3806494474411 
Train [3/26] | Epoch [124/160] |	nca: 1.2773047611117363, flat: 1.26129861921072, pod: 21.41115915775299, loss: 23.94976270198822 
Train [3/26] | Epoch [125/160] |	nca: 1.0531200878322124, flat: 1.1942351572215557, pod: 20.056387543678284, loss: 22.30374252796173 
Train [3/26] | Epoch [126/160] |	nca: 1.3761800602078438, flat: 1.33109300583601, pod: 22.389572381973267, loss: 25.096845269203186 
Train [3/26] | Epoch [127/160] |	nca: 1.1516540050506592, flat: 1.1761467047035694, pod: 19.82138741016388, loss: 22.149187922477722 
Train [3/26] | Epoch [128/160] |	nca: 1.0499386675655842, flat: 1.0702694840729237, pod: 19.0029479265213, loss: 21.12315607070923 
Train [3/26] | Epoch [129/160] |	nca: 1.102494716644287, flat: 1.1181638091802597, pod: 19.23441183567047, loss: 21.45507037639618 
Train [3/26] | Epoch [130/160] |	nca: 1.1698244661092758, flat: 1.0270168669521809, pod: 18.99039399623871, loss: 21.187235355377197 
Train [3/26] | Epoch [131/160] |	nca: 1.2434774041175842, flat: 1.0244153812527657, pod: 19.14931982755661, loss: 21.41721260547638 
Train [3/26] | Epoch [132/160] |	nca: 1.2321014627814293, flat: 1.0600247718393803, pod: 18.850329339504242, loss: 21.142455577850342 
Train [3/26] | Epoch [133/160] |	nca: 1.144547313451767, flat: 1.0632986426353455, pod: 18.520517587661743, loss: 20.728363275527954 
Train [3/26] | Epoch [134/160] |	nca: 1.1566571183502674, flat: 1.0087324120104313, pod: 18.56209111213684, loss: 20.72748076915741 
Train [3/26] | Epoch [135/160] |	nca: 1.1992593556642532, flat: 1.0988922640681267, pod: 18.69378435611725, loss: 20.991935968399048 
Train [3/26] | Epoch [136/160] |	nca: 1.1661549732089043, flat: 1.0561600290238857, pod: 18.063365697860718, loss: 20.285680770874023 
Train [3/26] | Epoch [137/160] |	nca: 1.1275667250156403, flat: 1.049973875284195, pod: 18.37639182806015, loss: 20.553932189941406 
Train [3/26] | Epoch [138/160] |	nca: 1.197783648967743, flat: 0.952489972114563, pod: 17.3605495095253, loss: 19.510822772979736 
Train [3/26] | Epoch [139/160] |	nca: 1.161073688417673, flat: 0.9354862347245216, pod: 16.940420866012573, loss: 19.03698068857193 
Train [3/26] | Epoch [140/160] |	nca: 1.054777268320322, flat: 0.9901129566133022, pod: 17.285952746868134, loss: 19.33084285259247 
Train [3/26] | Epoch [141/160] |	nca: 1.2506491355597973, flat: 0.9129466265439987, pod: 17.050960779190063, loss: 19.214556634426117 
Train [3/26] | Epoch [142/160] |	nca: 1.0880114883184433, flat: 0.9945280514657497, pod: 17.933293104171753, loss: 20.015832662582397 
Train [3/26] | Epoch [143/160] |	nca: 1.1266576685011387, flat: 0.9643923304975033, pod: 17.927764415740967, loss: 20.01881456375122 
Train [3/26] | Epoch [144/160] |	nca: 1.4131645616143942, flat: 0.9846996292471886, pod: 17.846038043498993, loss: 20.243902325630188 
Train [3/26] | Epoch [145/160] |	nca: 1.0983669087290764, flat: 0.9200915545225143, pod: 16.6659996509552, loss: 18.684458374977112 
Train [3/26] | Epoch [146/160] |	nca: 1.2097999192774296, flat: 0.9582587145268917, pod: 16.639158070087433, loss: 18.80721664428711 
Train [3/26] | Epoch [147/160] |	nca: 1.2354440987110138, flat: 0.9150304906070232, pod: 16.665927171707153, loss: 18.816401839256287 
Train [3/26] | Epoch [148/160] |	nca: 1.1926035210490227, flat: 0.9824912026524544, pod: 17.737995207309723, loss: 19.913089871406555 
Train [3/26] | Epoch [149/160] |	nca: 1.0313787460327148, flat: 0.9263463467359543, pod: 16.671517491340637, loss: 18.629242599010468 
Train [3/26] | Epoch [150/160] |	nca: 1.206852737814188, flat: 0.8872554786503315, pod: 16.430022537708282, loss: 18.524130702018738 
Train [3/26] | Epoch [151/160] |	nca: 1.195609599351883, flat: 0.8739517703652382, pod: 16.034761548042297, loss: 18.104322910308838 
Train [3/26] | Epoch [152/160] |	nca: 1.105737790465355, flat: 0.8869252689182758, pod: 15.90614140033722, loss: 17.898804545402527 
Train [3/26] | Epoch [153/160] |	nca: 1.1428250670433044, flat: 0.9009527415037155, pod: 16.014839708805084, loss: 18.05861735343933 
Train [3/26] | Epoch [154/160] |	nca: 1.2085218541324139, flat: 0.9328013993799686, pod: 16.717422366142273, loss: 18.85874569416046 
Train [3/26] | Epoch [155/160] |	nca: 1.1609127596020699, flat: 0.8502527549862862, pod: 15.857387363910675, loss: 17.86855286359787 
Train [3/26] | Epoch [156/160] |	nca: 1.1213843561708927, flat: 0.8743998259305954, pod: 15.480984151363373, loss: 17.476768016815186 
Train [3/26] | Epoch [157/160] |	nca: 1.1833417192101479, flat: 0.9061177223920822, pod: 16.989936411380768, loss: 19.079395651817322 
Train [3/26] | Epoch [158/160] |	nca: 1.1496007144451141, flat: 0.8748465813696384, pod: 15.931556582450867, loss: 17.956003844738007 
Train [3/26] | Epoch [159/160] |	nca: 1.2432659305632114, flat: 0.8791583329439163, pod: 16.04827493429184, loss: 18.17069911956787 
Train [3/26] | Epoch [160/160] |	nca: 1.1766374297440052, flat: 0.8975184485316277, pod: 16.399382948875427, loss: 18.473538637161255 
Fine-tuning
Building & updating memory.
Train [3/26] | Epoch [161/180] |	nca: 1.5218509584665298, flat: 1.379115842282772, pod: 14.307491779327393, loss: 17.20845854282379 
Train [3/26] | Epoch [162/180] |	nca: 0.9100040793418884, flat: 1.3954163938760757, pod: 14.684390544891357, loss: 16.989811301231384 
Train [3/26] | Epoch [163/180] |	nca: 0.6062211282551289, flat: 1.447804719209671, pod: 14.857917070388794, loss: 16.911943197250366 
Train [3/26] | Epoch [164/180] |	nca: 0.48157520592212677, flat: 1.429612673819065, pod: 15.047085404396057, loss: 16.95827329158783 
Train [3/26] | Epoch [165/180] |	nca: 0.40050897002220154, flat: 1.4030438214540482, pod: 14.702268600463867, loss: 16.505821466445923 
Train [3/26] | Epoch [166/180] |	nca: 0.3529382385313511, flat: 1.3953916504979134, pod: 14.808695554733276, loss: 16.55702543258667 
Train [3/26] | Epoch [167/180] |	nca: 0.33918224833905697, flat: 1.460735559463501, pod: 15.026039123535156, loss: 16.82595682144165 
Train [3/26] | Epoch [168/180] |	nca: 0.32814378477633, flat: 1.4015358984470367, pod: 14.488470196723938, loss: 16.2181499004364 
Train [3/26] | Epoch [169/180] |	nca: 0.33342969231307507, flat: 1.4384949207305908, pod: 15.14369547367096, loss: 16.91562008857727 
Train [3/26] | Epoch [170/180] |	nca: 0.2726108282804489, flat: 1.4408326297998428, pod: 14.809024930000305, loss: 16.522468209266663 
Train [3/26] | Epoch [171/180] |	nca: 0.3074761610478163, flat: 1.3931961730122566, pod: 14.729823112487793, loss: 16.430495500564575 
Train [3/26] | Epoch [172/180] |	nca: 0.23185014724731445, flat: 1.4049797728657722, pod: 14.597676992416382, loss: 16.234506964683533 
Train [3/26] | Epoch [173/180] |	nca: 0.26058376394212246, flat: 1.4952616393566132, pod: 15.32172954082489, loss: 17.077574968338013 
Train [3/26] | Epoch [174/180] |	nca: 0.2627608198672533, flat: 1.3858562931418419, pod: 14.44197690486908, loss: 16.090594053268433 
Train [3/26] | Epoch [175/180] |	nca: 0.22331671603024006, flat: 1.4353028535842896, pod: 14.69536304473877, loss: 16.35398256778717 
Train [3/26] | Epoch [176/180] |	nca: 0.2063849689438939, flat: 1.4011812955141068, pod: 14.549290537834167, loss: 16.156856894493103 
Train [3/26] | Epoch [177/180] |	nca: 0.20391444209963083, flat: 1.4078495129942894, pod: 14.101330876350403, loss: 15.713094592094421 
Train [3/26] | Epoch [178/180] |	nca: 0.23935257643461227, flat: 1.461990937590599, pod: 15.038381099700928, loss: 16.73972475528717 
Train [3/26] | Epoch [179/180] |	nca: 0.23413800168782473, flat: 1.4334713071584702, pod: 15.109265327453613, loss: 16.776874661445618 
Train [3/26] | Epoch [180/180] |	nca: 0.2055039331316948, flat: 1.412784419953823, pod: 14.37038779258728, loss: 15.988676071166992 
after task
Building & updating memory.
after task
Eval on 0->54.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.7483333333333334.
Current acc: {'total': 0.723, '00-09': 0.761, '10-19': 0.726, '20-29': 0.627, '30-39': 0.701, '40-49': 0.77, '50-59': 0.795}.
Avg inc acc top5: 0.9366666666666666.
Current acc top5: {'total': 0.927}.
Forgetting: 0.05314285714285716.
Cord metric: 0.75.
Old accuracy: 0.72, mean: 0.73.
New accuracy: 0.77, mean: 0.81.
================Task 3 Start!================
Testing on False unseen tasks (max class = 56).
Set memory of size: 1080.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 3 Training!================
The training samples number: 2080
Train on 54->56.
train task
nb 2080.
Train [4/26] | Epoch [1/160] |	nca: 6.991370856761932, flat: 4.387790337204933, pod: 47.42791557312012, loss: 58.80707621574402 
Train [4/26] | Epoch [2/160] |	nca: 5.131956607103348, flat: 6.6207965314388275, pod: 55.00874447822571, loss: 66.76149797439575 
Train [4/26] | Epoch [3/160] |	nca: 4.137661248445511, flat: 6.938560456037521, pod: 55.06895136833191, loss: 66.14517307281494 
Train [4/26] | Epoch [4/160] |	nca: 2.9976279363036156, flat: 5.659343630075455, pod: 51.75716733932495, loss: 60.41413879394531 
Train [4/26] | Epoch [5/160] |	nca: 2.932785950601101, flat: 5.3364240527153015, pod: 51.29939317703247, loss: 59.56860280036926 
Train [4/26] | Epoch [6/160] |	nca: 2.539206601679325, flat: 5.003153175115585, pod: 49.71595239639282, loss: 57.25831198692322 
Train [4/26] | Epoch [7/160] |	nca: 2.711945742368698, flat: 4.892069905996323, pod: 48.93678903579712, loss: 56.54080414772034 
Train [4/26] | Epoch [8/160] |	nca: 2.387459084391594, flat: 5.067394390702248, pod: 51.54303336143494, loss: 58.99788689613342 
Train [4/26] | Epoch [9/160] |	nca: 2.09807850420475, flat: 4.456456437706947, pod: 48.398070335388184, loss: 54.95260524749756 
Train [4/26] | Epoch [10/160] |	nca: 1.8918768092989922, flat: 4.171009138226509, pod: 46.21743202209473, loss: 52.28031778335571 
Train [4/26] | Epoch [11/160] |	nca: 1.9257829263806343, flat: 3.866567075252533, pod: 45.50617527961731, loss: 51.29852509498596 
Train [4/26] | Epoch [12/160] |	nca: 1.6748142838478088, flat: 3.5544373691082, pod: 44.34502410888672, loss: 49.574275493621826 
Train [4/26] | Epoch [13/160] |	nca: 1.7336189895868301, flat: 3.4756863564252853, pod: 43.08185434341431, loss: 48.291160106658936 
Train [4/26] | Epoch [14/160] |	nca: 1.7874572910368443, flat: 3.810104116797447, pod: 44.860058307647705, loss: 50.457619428634644 
Train [4/26] | Epoch [15/160] |	nca: 1.7811782993376255, flat: 3.4679170697927475, pod: 43.22093152999878, loss: 48.47002696990967 
Train [4/26] | Epoch [16/160] |	nca: 1.5327993966639042, flat: 3.0667739808559418, pod: 39.760504484176636, loss: 44.36007738113403 
Train [4/26] | Epoch [17/160] |	nca: 1.6525078602135181, flat: 3.1976745575666428, pod: 40.302377462387085, loss: 45.15255951881409 
Train [4/26] | Epoch [18/160] |	nca: 1.9479062482714653, flat: 3.6554355323314667, pod: 43.03293538093567, loss: 48.636277198791504 
Train [4/26] | Epoch [19/160] |	nca: 1.720490701496601, flat: 3.5172666907310486, pod: 42.805968046188354, loss: 48.04372596740723 
Train [4/26] | Epoch [20/160] |	nca: 1.5712836682796478, flat: 3.3980046063661575, pod: 42.63846707344055, loss: 47.607754707336426 
Train [4/26] | Epoch [21/160] |	nca: 1.8251779675483704, flat: 3.4807887375354767, pod: 42.522149324417114, loss: 47.828115940093994 
Train [4/26] | Epoch [22/160] |	nca: 1.8361837305128574, flat: 3.563816621899605, pod: 42.9595742225647, loss: 48.35957455635071 
Train [4/26] | Epoch [23/160] |	nca: 1.4851524233818054, flat: 3.4737502187490463, pod: 44.14422059059143, loss: 49.10312342643738 
Train [4/26] | Epoch [24/160] |	nca: 1.5427556857466698, flat: 3.171567142009735, pod: 40.42100143432617, loss: 45.135324239730835 
Train [4/26] | Epoch [25/160] |	nca: 1.723921924829483, flat: 3.3992858976125717, pod: 41.16383624076843, loss: 46.28704380989075 
Train [4/26] | Epoch [26/160] |	nca: 1.889063999056816, flat: 3.4994193613529205, pod: 42.51875877380371, loss: 47.90724158287048 
Train [4/26] | Epoch [27/160] |	nca: 1.828003004193306, flat: 3.445289298892021, pod: 42.395636320114136, loss: 47.668928146362305 
Train [4/26] | Epoch [28/160] |	nca: 1.5552442893385887, flat: 3.3692429214715958, pod: 41.77606153488159, loss: 46.70054864883423 
Train [4/26] | Epoch [29/160] |	nca: 1.3076632879674435, flat: 3.0003837794065475, pod: 39.36534070968628, loss: 43.6733877658844 
Train [4/26] | Epoch [30/160] |	nca: 1.507242500782013, flat: 2.9988589882850647, pod: 39.80264401435852, loss: 44.30874514579773 
Train [4/26] | Epoch [31/160] |	nca: 1.7224065214395523, flat: 3.572984218597412, pod: 42.5407874584198, loss: 47.83617854118347 
Train [4/26] | Epoch [32/160] |	nca: 1.6085242740809917, flat: 3.2399992793798447, pod: 39.488590478897095, loss: 44.337114572525024 
Train [4/26] | Epoch [33/160] |	nca: 1.457279086112976, flat: 3.158190593123436, pod: 40.094032287597656, loss: 44.70950126647949 
Train [4/26] | Epoch [34/160] |	nca: 1.4580216892063618, flat: 2.8828251361846924, pod: 39.103554487228394, loss: 43.44440150260925 
Train [4/26] | Epoch [35/160] |	nca: 1.3759118169546127, flat: 3.003735303878784, pod: 39.91898560523987, loss: 44.29863238334656 
Train [4/26] | Epoch [36/160] |	nca: 1.6692582443356514, flat: 3.018507644534111, pod: 38.442654848098755, loss: 43.13042092323303 
Train [4/26] | Epoch [37/160] |	nca: 1.5692175216972828, flat: 2.7751006335020065, pod: 37.62958788871765, loss: 41.97390580177307 
Train [4/26] | Epoch [38/160] |	nca: 1.3278876580297947, flat: 2.9229383766651154, pod: 37.745683431625366, loss: 41.99650955200195 
Train [4/26] | Epoch [39/160] |	nca: 1.554722834378481, flat: 3.022002324461937, pod: 40.28176665306091, loss: 44.85849213600159 
Train [4/26] | Epoch [40/160] |	nca: 1.4723914079368114, flat: 2.9924317449331284, pod: 38.39974248409271, loss: 42.86456608772278 
Train [4/26] | Epoch [41/160] |	nca: 1.6650344654917717, flat: 3.103251725435257, pod: 40.70523262023926, loss: 45.47351908683777 
Train [4/26] | Epoch [42/160] |	nca: 1.6873666904866695, flat: 3.515072777867317, pod: 42.02483773231506, loss: 47.22727727890015 
Train [4/26] | Epoch [43/160] |	nca: 1.3431092649698257, flat: 2.8907095044851303, pod: 38.14418029785156, loss: 42.37799906730652 
Train [4/26] | Epoch [44/160] |	nca: 1.426973469555378, flat: 2.9997483491897583, pod: 41.625412702560425, loss: 46.05213379859924 
Train [4/26] | Epoch [45/160] |	nca: 1.6441115215420723, flat: 3.0643317699432373, pod: 41.08020734786987, loss: 45.78865098953247 
Train [4/26] | Epoch [46/160] |	nca: 1.4777946770191193, flat: 3.132165864109993, pod: 41.61326813697815, loss: 46.22322869300842 
Train [4/26] | Epoch [47/160] |	nca: 1.3929578177630901, flat: 2.7899769246578217, pod: 37.521066308021545, loss: 41.70400142669678 
Train [4/26] | Epoch [48/160] |	nca: 1.3100645989179611, flat: 2.791747584939003, pod: 38.72922873497009, loss: 42.83104062080383 
Train [4/26] | Epoch [49/160] |	nca: 1.3506707064807415, flat: 2.6671501845121384, pod: 36.831422328948975, loss: 40.84924292564392 
Train [4/26] | Epoch [50/160] |	nca: 1.4763917326927185, flat: 2.667676880955696, pod: 36.46523857116699, loss: 40.609307289123535 
Train [4/26] | Epoch [51/160] |	nca: 1.5325222499668598, flat: 2.7861771136522293, pod: 38.02549934387207, loss: 42.34419846534729 
Train [4/26] | Epoch [52/160] |	nca: 1.3858348727226257, flat: 2.833957463502884, pod: 37.92559838294983, loss: 42.14539098739624 
Train [4/26] | Epoch [53/160] |	nca: 1.422330603003502, flat: 2.5569148808717728, pod: 36.15329372882843, loss: 40.13253927230835 
Train [4/26] | Epoch [54/160] |	nca: 1.3689894564449787, flat: 2.863332509994507, pod: 38.94952750205994, loss: 43.18184971809387 
Train [4/26] | Epoch [55/160] |	nca: 1.2145651578903198, flat: 2.6894281804561615, pod: 37.96622586250305, loss: 41.870219230651855 
Train [4/26] | Epoch [56/160] |	nca: 1.3837676346302032, flat: 2.6060438603162766, pod: 37.336113691329956, loss: 41.32592535018921 
Train [4/26] | Epoch [57/160] |	nca: 1.3012675680220127, flat: 2.363767109811306, pod: 34.40075767040253, loss: 38.06579232215881 
Train [4/26] | Epoch [58/160] |	nca: 1.494967833161354, flat: 2.263369955122471, pod: 33.947680950164795, loss: 37.706018924713135 
Train [4/26] | Epoch [59/160] |	nca: 1.4745345711708069, flat: 2.706285282969475, pod: 37.157540917396545, loss: 41.33836102485657 
Train [4/26] | Epoch [60/160] |	nca: 1.459653951227665, flat: 2.6114686504006386, pod: 36.389344215393066, loss: 40.46046686172485 
Train [4/26] | Epoch [61/160] |	nca: 1.4161737971007824, flat: 2.5367083102464676, pod: 34.30970597267151, loss: 38.262588143348694 
Train [4/26] | Epoch [62/160] |	nca: 1.4889945164322853, flat: 2.7925656586885452, pod: 37.385247230529785, loss: 41.66680717468262 
Train [4/26] | Epoch [63/160] |	nca: 1.334546361118555, flat: 2.5327138528227806, pod: 35.19368398189545, loss: 39.060943841934204 
Train [4/26] | Epoch [64/160] |	nca: 1.3994169868528843, flat: 2.4873372688889503, pod: 35.07794713973999, loss: 38.9647011756897 
Train [4/26] | Epoch [65/160] |	nca: 1.3063854314386845, flat: 2.614982232451439, pod: 36.37723362445831, loss: 40.29860162734985 
Train [4/26] | Epoch [66/160] |	nca: 1.527276013046503, flat: 2.5706925988197327, pod: 35.96886622905731, loss: 40.066834926605225 
Train [4/26] | Epoch [67/160] |	nca: 1.3077969402074814, flat: 2.5027799531817436, pod: 35.278136014938354, loss: 39.08871293067932 
Train [4/26] | Epoch [68/160] |	nca: 1.229429915547371, flat: 2.3519392162561417, pod: 35.07090353965759, loss: 38.65227246284485 
Train [4/26] | Epoch [69/160] |	nca: 1.3515668660402298, flat: 2.338036321103573, pod: 34.613202691078186, loss: 38.30280566215515 
Train [4/26] | Epoch [70/160] |	nca: 1.2942538298666477, flat: 2.483876571059227, pod: 36.55843985080719, loss: 40.336570501327515 
Train [4/26] | Epoch [71/160] |	nca: 1.277566034346819, flat: 2.2300146147608757, pod: 33.54320466518402, loss: 37.050785422325134 
Train [4/26] | Epoch [72/160] |	nca: 1.3151356279850006, flat: 2.118602603673935, pod: 33.29513359069824, loss: 36.72887170314789 
Train [4/26] | Epoch [73/160] |	nca: 1.3982883244752884, flat: 2.2587120682001114, pod: 33.219531774520874, loss: 36.87653183937073 
Train [4/26] | Epoch [74/160] |	nca: 1.2131057754158974, flat: 2.2998129948973656, pod: 34.4784277677536, loss: 37.9913467168808 
Train [4/26] | Epoch [75/160] |	nca: 1.1745186783373356, flat: 2.211311914026737, pod: 33.31076729297638, loss: 36.69659733772278 
Train [4/26] | Epoch [76/160] |	nca: 1.2477247826755047, flat: 2.0927549451589584, pod: 33.33532953262329, loss: 36.675809264183044 
Train [4/26] | Epoch [77/160] |	nca: 1.3478406965732574, flat: 1.9692623019218445, pod: 31.14158344268799, loss: 34.45868635177612 
Train [4/26] | Epoch [78/160] |	nca: 1.2982979826629162, flat: 2.100116401910782, pod: 32.01237618923187, loss: 35.41079092025757 
Train [4/26] | Epoch [79/160] |	nca: 1.2192830555140972, flat: 2.1628922820091248, pod: 33.123860359191895, loss: 36.506035685539246 
Train [4/26] | Epoch [80/160] |	nca: 1.1811566799879074, flat: 1.9978993386030197, pod: 31.5137859582901, loss: 34.69284212589264 
Train [4/26] | Epoch [81/160] |	nca: 1.3612587712705135, flat: 1.8789528831839561, pod: 29.89686644077301, loss: 33.137078285217285 
Train [4/26] | Epoch [82/160] |	nca: 1.3278513327240944, flat: 1.9728807881474495, pod: 30.842419385910034, loss: 34.14315164089203 
Train [4/26] | Epoch [83/160] |	nca: 1.2009909935295582, flat: 2.2308622300624847, pod: 33.53011751174927, loss: 36.961970925331116 
Train [4/26] | Epoch [84/160] |	nca: 1.2669897079467773, flat: 2.129994757473469, pod: 32.767603516578674, loss: 36.16458761692047 
Train [4/26] | Epoch [85/160] |	nca: 1.2235627248883247, flat: 2.012161687016487, pod: 32.697386503219604, loss: 35.93311047554016 
Train [4/26] | Epoch [86/160] |	nca: 1.1769164614379406, flat: 1.8742032125592232, pod: 29.790688395500183, loss: 32.841808438301086 
Train [4/26] | Epoch [87/160] |	nca: 1.232334267348051, flat: 1.8201050609350204, pod: 30.157837748527527, loss: 33.21027731895447 
Train [4/26] | Epoch [88/160] |	nca: 1.355503037571907, flat: 1.7635964527726173, pod: 29.56998872756958, loss: 32.689088106155396 
Train [4/26] | Epoch [89/160] |	nca: 1.1341424211859703, flat: 1.7535643875598907, pod: 28.54926586151123, loss: 31.43697237968445 
Train [4/26] | Epoch [90/160] |	nca: 1.2728101760149002, flat: 1.7707024663686752, pod: 30.315696239471436, loss: 33.35920870304108 
Train [4/26] | Epoch [91/160] |	nca: 1.321463704109192, flat: 1.8742642626166344, pod: 30.944735288619995, loss: 34.14046311378479 
Train [4/26] | Epoch [92/160] |	nca: 1.308948040008545, flat: 1.9265241026878357, pod: 30.444474816322327, loss: 33.67994701862335 
Train [4/26] | Epoch [93/160] |	nca: 1.4433769397437572, flat: 1.8599093481898308, pod: 29.874123692512512, loss: 33.17740988731384 
Train [4/26] | Epoch [94/160] |	nca: 1.250156942754984, flat: 1.9908445626497269, pod: 31.130460023880005, loss: 34.37146186828613 
Train [4/26] | Epoch [95/160] |	nca: 1.1317839100956917, flat: 1.673144556581974, pod: 29.31392812728882, loss: 32.11885643005371 
Train [4/26] | Epoch [96/160] |	nca: 1.0952895507216454, flat: 1.7111762464046478, pod: 28.181397914886475, loss: 30.987863779067993 
Train [4/26] | Epoch [97/160] |	nca: 1.150971096009016, flat: 1.5520696118474007, pod: 26.836678981781006, loss: 29.539719820022583 
Train [4/26] | Epoch [98/160] |	nca: 1.2266494892537594, flat: 1.5665320456027985, pod: 27.72400951385498, loss: 30.51719105243683 
Train [4/26] | Epoch [99/160] |	nca: 1.0780074670910835, flat: 1.533166952431202, pod: 26.53457760810852, loss: 29.145751953125 
Train [4/26] | Epoch [100/160] |	nca: 1.2100765444338322, flat: 1.6476252153515816, pod: 29.11960756778717, loss: 31.977309703826904 
Train [4/26] | Epoch [101/160] |	nca: 1.1933415420353413, flat: 1.5183400064706802, pod: 27.607454776763916, loss: 30.31913650035858 
Train [4/26] | Epoch [102/160] |	nca: 1.298564575612545, flat: 1.535579301416874, pod: 27.21100676059723, loss: 30.045150756835938 
Train [4/26] | Epoch [103/160] |	nca: 1.3231184482574463, flat: 1.5078841522336006, pod: 26.645939111709595, loss: 29.47694170475006 
Train [4/26] | Epoch [104/160] |	nca: 1.2575384639203548, flat: 1.5674006417393684, pod: 27.7727073431015, loss: 30.597646236419678 
Train [4/26] | Epoch [105/160] |	nca: 1.3312855176627636, flat: 1.5915231257677078, pod: 27.840887427330017, loss: 30.76369619369507 
Train [4/26] | Epoch [106/160] |	nca: 1.1326275020837784, flat: 1.398113690316677, pod: 25.620143055915833, loss: 28.15088438987732 
Train [4/26] | Epoch [107/160] |	nca: 1.2717382609844208, flat: 1.4425766915082932, pod: 26.496272325515747, loss: 29.21058702468872 
Train [4/26] | Epoch [108/160] |	nca: 1.2188425734639168, flat: 1.5386585891246796, pod: 27.205612778663635, loss: 29.96311378479004 
Train [4/26] | Epoch [109/160] |	nca: 1.2658900506794453, flat: 1.4517428800463676, pod: 26.18506407737732, loss: 28.90269672870636 
Train [4/26] | Epoch [110/160] |	nca: 1.1328805722296238, flat: 1.4132293462753296, pod: 25.65553843975067, loss: 28.201648712158203 
Train [4/26] | Epoch [111/160] |	nca: 1.1374908611178398, flat: 1.4550061710178852, pod: 25.59867286682129, loss: 28.19116997718811 
Train [4/26] | Epoch [112/160] |	nca: 1.0839248523116112, flat: 1.3994061648845673, pod: 25.446455717086792, loss: 27.929786801338196 
Train [4/26] | Epoch [113/160] |	nca: 1.1753959320485592, flat: 1.2453033328056335, pod: 25.105753898620605, loss: 27.526453137397766 
Train [4/26] | Epoch [114/160] |	nca: 1.0738892368972301, flat: 1.412053719162941, pod: 25.965482354164124, loss: 28.451425313949585 
Train [4/26] | Epoch [115/160] |	nca: 1.1919496692717075, flat: 1.2322899475693703, pod: 24.12662672996521, loss: 26.55086624622345 
Train [4/26] | Epoch [116/160] |	nca: 1.2513624839484692, flat: 1.3008995912969112, pod: 24.558672189712524, loss: 27.110934257507324 
Train [4/26] | Epoch [117/160] |	nca: 1.2088484168052673, flat: 1.3957346640527248, pod: 25.91933262348175, loss: 28.5239155292511 
Train [4/26] | Epoch [118/160] |	nca: 1.1365340389311314, flat: 1.2420832440257072, pod: 23.163066864013672, loss: 25.5416841506958 
Train [4/26] | Epoch [119/160] |	nca: 1.3040855787694454, flat: 1.25445307046175, pod: 23.993908643722534, loss: 26.552447080612183 
Train [4/26] | Epoch [120/160] |	nca: 1.1456537581980228, flat: 1.1390107236802578, pod: 22.827760100364685, loss: 25.112424492836 
Train [4/26] | Epoch [121/160] |	nca: 1.1992556415498257, flat: 1.1902207881212234, pod: 22.985336303710938, loss: 25.374812483787537 
Train [4/26] | Epoch [122/160] |	nca: 1.3158227503299713, flat: 1.27582548558712, pod: 24.081605076789856, loss: 26.673253297805786 
Train [4/26] | Epoch [123/160] |	nca: 1.1234871558845043, flat: 1.1425038501620293, pod: 22.799147367477417, loss: 25.065138578414917 
Train [4/26] | Epoch [124/160] |	nca: 1.1535076089203358, flat: 1.12764498218894, pod: 21.462003231048584, loss: 23.74315571784973 
Train [4/26] | Epoch [125/160] |	nca: 1.2234985567629337, flat: 1.1082495637238026, pod: 21.794259786605835, loss: 24.126007676124573 
Train [4/26] | Epoch [126/160] |	nca: 1.1613227911293507, flat: 1.2094586305320263, pod: 22.233724236488342, loss: 24.60450577735901 
Train [4/26] | Epoch [127/160] |	nca: 1.2648266032338142, flat: 1.0728239305317402, pod: 21.053542852401733, loss: 23.391193151474 
Train [4/26] | Epoch [128/160] |	nca: 1.2162276357412338, flat: 1.0867324583232403, pod: 20.777432322502136, loss: 23.080392241477966 
Train [4/26] | Epoch [129/160] |	nca: 1.06413509324193, flat: 1.0336035713553429, pod: 20.656916737556458, loss: 22.754655241966248 
Train [4/26] | Epoch [130/160] |	nca: 1.2708464339375496, flat: 1.0770398154854774, pod: 21.6595641374588, loss: 24.007450342178345 
Train [4/26] | Epoch [131/160] |	nca: 1.1264189071953297, flat: 1.0156957730650902, pod: 19.74666154384613, loss: 21.888776183128357 
Train [4/26] | Epoch [132/160] |	nca: 1.1419625096023083, flat: 1.0368994325399399, pod: 20.592930555343628, loss: 22.7717924118042 
Train [4/26] | Epoch [133/160] |	nca: 1.2441344670951366, flat: 1.0208856202661991, pod: 20.52718734741211, loss: 22.79220736026764 
Train [4/26] | Epoch [134/160] |	nca: 1.2606524899601936, flat: 1.01234220713377, pod: 20.405449211597443, loss: 22.678443789482117 
Train [4/26] | Epoch [135/160] |	nca: 1.2606448121368885, flat: 0.9805981181561947, pod: 19.84123384952545, loss: 22.08247661590576 
Train [4/26] | Epoch [136/160] |	nca: 1.0893639884889126, flat: 1.0558740869164467, pod: 21.117595553398132, loss: 23.26283347606659 
Train [4/26] | Epoch [137/160] |	nca: 1.182332742959261, flat: 1.0003090761601925, pod: 19.502535820007324, loss: 21.68517756462097 
Train [4/26] | Epoch [138/160] |	nca: 1.2493481487035751, flat: 1.0092629007995129, pod: 20.446358144283295, loss: 22.70496928691864 
Train [4/26] | Epoch [139/160] |	nca: 1.2103413343429565, flat: 0.9484715014696121, pod: 19.725272715091705, loss: 21.884085655212402 
Train [4/26] | Epoch [140/160] |	nca: 1.0817371979355812, flat: 0.9280690066516399, pod: 19.143191516399384, loss: 21.152997612953186 
Train [4/26] | Epoch [141/160] |	nca: 1.1449864096939564, flat: 0.9471594095230103, pod: 18.89099031686783, loss: 20.983136296272278 
Train [4/26] | Epoch [142/160] |	nca: 1.258033573627472, flat: 0.9245069026947021, pod: 18.933693528175354, loss: 21.116233944892883 
Train [4/26] | Epoch [143/160] |	nca: 1.2288113199174404, flat: 0.8966573439538479, pod: 18.951770901679993, loss: 21.07723957300186 
Train [4/26] | Epoch [144/160] |	nca: 1.1289680413901806, flat: 0.8084614314138889, pod: 17.809849560260773, loss: 19.747279107570648 
Train [4/26] | Epoch [145/160] |	nca: 1.2959695495665073, flat: 0.8926783911883831, pod: 18.96857887506485, loss: 21.15722680091858 
Train [4/26] | Epoch [146/160] |	nca: 1.1434685066342354, flat: 0.8799504898488522, pod: 18.573566734790802, loss: 20.596985399723053 
Train [4/26] | Epoch [147/160] |	nca: 1.1423608139157295, flat: 0.8845109790563583, pod: 19.016074776649475, loss: 21.042946457862854 
Train [4/26] | Epoch [148/160] |	nca: 1.2183370254933834, flat: 0.9490635804831982, pod: 19.626902103424072, loss: 21.794302821159363 
Train [4/26] | Epoch [149/160] |	nca: 1.2864431589841843, flat: 0.8704985119402409, pod: 17.718239307403564, loss: 19.875181078910828 
Train [4/26] | Epoch [150/160] |	nca: 1.0984732694923878, flat: 0.8642071187496185, pod: 18.085821390151978, loss: 20.04850196838379 
Train [4/26] | Epoch [151/160] |	nca: 1.1916021779179573, flat: 0.8157441392540932, pod: 17.097293972969055, loss: 19.1046404838562 
Train [4/26] | Epoch [152/160] |	nca: 1.1786333248019218, flat: 0.9319796040654182, pod: 18.913908064365387, loss: 21.024521231651306 
Train [4/26] | Epoch [153/160] |	nca: 1.221385896205902, flat: 0.8800245076417923, pod: 17.700482606887817, loss: 19.80189299583435 
Train [4/26] | Epoch [154/160] |	nca: 1.0980005972087383, flat: 0.835123348981142, pod: 17.52909380197525, loss: 19.46221774816513 
Train [4/26] | Epoch [155/160] |	nca: 1.1595653630793095, flat: 0.8456314280629158, pod: 17.3058061003685, loss: 19.311003029346466 
Train [4/26] | Epoch [156/160] |	nca: 1.1800021082162857, flat: 0.8365437835454941, pod: 17.120636582374573, loss: 19.137182354927063 
Train [4/26] | Epoch [157/160] |	nca: 1.1769567392766476, flat: 0.8567908331751823, pod: 17.46862554550171, loss: 19.502373099327087 
Train [4/26] | Epoch [158/160] |	nca: 1.23544517531991, flat: 0.8716724999248981, pod: 17.77973300218582, loss: 19.8868505358696 
Train [4/26] | Epoch [159/160] |	nca: 1.2286754213273525, flat: 0.9168765656650066, pod: 17.712684631347656, loss: 19.8582364320755 
Train [4/26] | Epoch [160/160] |	nca: 1.2544237412512302, flat: 0.8482758421450853, pod: 17.816357672214508, loss: 19.9190571308136 
Fine-tuning
Building & updating memory.
Train [4/26] | Epoch [161/180] |	nca: 3.2609948217868805, flat: 2.3671061992645264, pod: 28.08826494216919, loss: 33.716365814208984 
Train [4/26] | Epoch [162/180] |	nca: 1.1554581299424171, flat: 2.386718824505806, pod: 27.924133777618408, loss: 31.466310501098633 
Train [4/26] | Epoch [163/180] |	nca: 0.7670920975506306, flat: 2.398833706974983, pod: 28.046382427215576, loss: 31.212307929992676 
Train [4/26] | Epoch [164/180] |	nca: 0.6369653418660164, flat: 2.3886977434158325, pod: 27.63073706626892, loss: 30.656399965286255 
Train [4/26] | Epoch [165/180] |	nca: 0.575045969337225, flat: 2.4624533653259277, pod: 28.186049461364746, loss: 31.223548889160156 
Train [4/26] | Epoch [166/180] |	nca: 0.4329068027436733, flat: 2.3696363866329193, pod: 28.100701093673706, loss: 30.903244256973267 
Train [4/26] | Epoch [167/180] |	nca: 0.4156652204692364, flat: 2.345453694462776, pod: 27.99311065673828, loss: 30.754229068756104 
Train [4/26] | Epoch [168/180] |	nca: 0.4097663313150406, flat: 2.410283699631691, pod: 28.392870664596558, loss: 31.212920904159546 
Train [4/26] | Epoch [169/180] |	nca: 0.4588893912732601, flat: 2.360263451933861, pod: 27.742368936538696, loss: 30.561521768569946 
Train [4/26] | Epoch [170/180] |	nca: 0.4323171004652977, flat: 2.379157468676567, pod: 28.11478042602539, loss: 30.926254987716675 
Train [4/26] | Epoch [171/180] |	nca: 0.3163104560226202, flat: 2.3832553178071976, pod: 28.150772094726562, loss: 30.850338220596313 
Train [4/26] | Epoch [172/180] |	nca: 0.3606207612901926, flat: 2.417653113603592, pod: 27.87492847442627, loss: 30.653202295303345 
Train [4/26] | Epoch [173/180] |	nca: 0.3697022367268801, flat: 2.3980614244937897, pod: 28.072489261627197, loss: 30.84025263786316 
Train [4/26] | Epoch [174/180] |	nca: 0.35334472730755806, flat: 2.376703590154648, pod: 27.77359652519226, loss: 30.503645181655884 
Train [4/26] | Epoch [175/180] |	nca: 0.3668880816549063, flat: 2.380526587367058, pod: 28.04320478439331, loss: 30.790619134902954 
Train [4/26] | Epoch [176/180] |	nca: 0.3370981812477112, flat: 2.3814820051193237, pod: 27.944262504577637, loss: 30.662842750549316 
Train [4/26] | Epoch [177/180] |	nca: 0.30006043426692486, flat: 2.414399594068527, pod: 28.398213386535645, loss: 31.11267352104187 
Train [4/26] | Epoch [178/180] |	nca: 0.37826288864016533, flat: 2.368866488337517, pod: 27.706369638442993, loss: 30.45349931716919 
Train [4/26] | Epoch [179/180] |	nca: 0.30894873663783073, flat: 2.4797414243221283, pod: 28.455358028411865, loss: 31.244048595428467 
Train [4/26] | Epoch [180/180] |	nca: 0.3410123959183693, flat: 2.400764912366867, pod: 27.9915554523468, loss: 30.73333239555359 
after task
Building & updating memory.
after task
Eval on 0->56.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.736.
Current acc: {'total': 0.699, '00-09': 0.741, '10-19': 0.692, '20-29': 0.612, '30-39': 0.689, '40-49': 0.738, '50-59': 0.742}.
Avg inc acc top5: 0.93075.
Current acc top5: {'total': 0.913}.
Forgetting: 0.07685714285714289.
Cord metric: 0.74.
Old accuracy: 0.70, mean: 0.72.
New accuracy: 0.80, mean: 0.81.
================Task 4 Start!================
Testing on False unseen tasks (max class = 58).
Set memory of size: 1120.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 4 Training!================
The training samples number: 2120
Train on 56->58.
train task
nb 2120.
Train [5/26] | Epoch [1/160] |	nca: 4.748561188578606, flat: 3.2846373915672302, pod: 41.63912093639374, loss: 49.672319650650024 
Train [5/26] | Epoch [2/160] |	nca: 3.019571289420128, flat: 4.075226068496704, pod: 47.53435516357422, loss: 54.62915229797363 
Train [5/26] | Epoch [3/160] |	nca: 2.4780260398983955, flat: 3.8687863051891327, pod: 46.06825542449951, loss: 52.41506743431091 
Train [5/26] | Epoch [4/160] |	nca: 2.0170851051807404, flat: 3.5206867307424545, pod: 43.89763116836548, loss: 49.43540287017822 
Train [5/26] | Epoch [5/160] |	nca: 2.0626684948801994, flat: 3.246207118034363, pod: 43.780754804611206, loss: 49.08963060379028 
Train [5/26] | Epoch [6/160] |	nca: 1.9985501021146774, flat: 3.6046052426099777, pod: 46.273743629455566, loss: 51.876898765563965 
Train [5/26] | Epoch [7/160] |	nca: 1.8805757388472557, flat: 3.242986798286438, pod: 42.90267896652222, loss: 48.02624154090881 
Train [5/26] | Epoch [8/160] |	nca: 1.7923058345913887, flat: 3.1747857183218002, pod: 41.9047372341156, loss: 46.87182927131653 
Train [5/26] | Epoch [9/160] |	nca: 1.60380694642663, flat: 3.0098869800567627, pod: 42.02366781234741, loss: 46.637362003326416 
Train [5/26] | Epoch [10/160] |	nca: 1.5890816077589989, flat: 2.9087255150079727, pod: 40.61119365692139, loss: 45.10900115966797 
Train [5/26] | Epoch [11/160] |	nca: 1.4794048257172108, flat: 2.8863692581653595, pod: 41.55306315422058, loss: 45.91883730888367 
Train [5/26] | Epoch [12/160] |	nca: 1.6817329674959183, flat: 3.253497287631035, pod: 44.111011028289795, loss: 49.04624104499817 
Train [5/26] | Epoch [13/160] |	nca: 1.7997575178742409, flat: 3.1260118782520294, pod: 41.5928840637207, loss: 46.51865339279175 
Train [5/26] | Epoch [14/160] |	nca: 1.369105737656355, flat: 3.0303291976451874, pod: 43.587810039520264, loss: 47.987244844436646 
Train [5/26] | Epoch [15/160] |	nca: 1.47730253636837, flat: 2.9935055524110794, pod: 44.71129870414734, loss: 49.182106733322144 
Train [5/26] | Epoch [16/160] |	nca: 1.6197536028921604, flat: 2.9322433173656464, pod: 42.404768228530884, loss: 46.956764698028564 
Train [5/26] | Epoch [17/160] |	nca: 1.4213217571377754, flat: 2.9813251197338104, pod: 42.537216663360596, loss: 46.939863204956055 
Train [5/26] | Epoch [18/160] |	nca: 1.6388865560293198, flat: 2.943849056959152, pod: 41.31175923347473, loss: 45.894495248794556 
Train [5/26] | Epoch [19/160] |	nca: 1.3212437815964222, flat: 2.788373902440071, pod: 40.64396905899048, loss: 44.753586769104004 
Train [5/26] | Epoch [20/160] |	nca: 1.6108946800231934, flat: 2.861362412571907, pod: 40.883827209472656, loss: 45.35608434677124 
Train [5/26] | Epoch [21/160] |	nca: 1.4204548373818398, flat: 2.9161009341478348, pod: 40.71358370780945, loss: 45.05013942718506 
Train [5/26] | Epoch [22/160] |	nca: 1.2231470048427582, flat: 2.7551174461841583, pod: 41.042813539505005, loss: 45.02107787132263 
Train [5/26] | Epoch [23/160] |	nca: 1.486074086278677, flat: 2.783639132976532, pod: 40.84675908088684, loss: 45.116472244262695 
Train [5/26] | Epoch [24/160] |	nca: 1.5917604193091393, flat: 3.0670494735240936, pod: 42.909629106521606, loss: 47.56843852996826 
Train [5/26] | Epoch [25/160] |	nca: 1.459274884313345, flat: 2.827662944793701, pod: 40.62341618537903, loss: 44.910354137420654 
Train [5/26] | Epoch [26/160] |	nca: 1.359745118767023, flat: 2.8147576451301575, pod: 41.21856880187988, loss: 45.39307165145874 
Train [5/26] | Epoch [27/160] |	nca: 1.2277942970395088, flat: 2.7133445143699646, pod: 40.75286531448364, loss: 44.69400405883789 
Train [5/26] | Epoch [28/160] |	nca: 1.3909053020179272, flat: 2.475424312055111, pod: 37.88771462440491, loss: 41.75404405593872 
Train [5/26] | Epoch [29/160] |	nca: 1.3956189081072807, flat: 2.813353180885315, pod: 40.98480844497681, loss: 45.19378042221069 
Train [5/26] | Epoch [30/160] |	nca: 1.4966066032648087, flat: 2.851174831390381, pod: 41.68505835533142, loss: 46.03283977508545 
Train [5/26] | Epoch [31/160] |	nca: 1.3843771740794182, flat: 2.5980102121829987, pod: 39.222328901290894, loss: 43.2047164440155 
Train [5/26] | Epoch [32/160] |	nca: 1.2535317987203598, flat: 2.58076174557209, pod: 37.99677491188049, loss: 41.83106851577759 
Train [5/26] | Epoch [33/160] |	nca: 1.3033192567527294, flat: 2.504244014620781, pod: 37.906808614730835, loss: 41.71437191963196 
Train [5/26] | Epoch [34/160] |	nca: 1.225280899554491, flat: 2.555838480591774, pod: 38.6177921295166, loss: 42.398911237716675 
Train [5/26] | Epoch [35/160] |	nca: 1.5233809687197208, flat: 2.7428681701421738, pod: 40.78489089012146, loss: 45.05113983154297 
Train [5/26] | Epoch [36/160] |	nca: 1.296743180602789, flat: 2.5469952672719955, pod: 37.94822382926941, loss: 41.791961908340454 
Train [5/26] | Epoch [37/160] |	nca: 1.2956586554646492, flat: 2.4783115088939667, pod: 38.614994764328, loss: 42.38896441459656 
Train [5/26] | Epoch [38/160] |	nca: 1.0967792831361294, flat: 2.2788482159376144, pod: 35.876932978630066, loss: 39.25256037712097 
Train [5/26] | Epoch [39/160] |	nca: 1.2440301515161991, flat: 2.3484461903572083, pod: 36.33699119091034, loss: 39.92946767807007 
Train [5/26] | Epoch [40/160] |	nca: 1.3199831955134869, flat: 2.429335005581379, pod: 36.71245574951172, loss: 40.46177411079407 
Train [5/26] | Epoch [41/160] |	nca: 1.3410085998475552, flat: 2.508517563343048, pod: 37.764235734939575, loss: 41.61376214027405 
Train [5/26] | Epoch [42/160] |	nca: 1.4426684081554413, flat: 2.4696076959371567, pod: 38.09802424907684, loss: 42.010300397872925 
Train [5/26] | Epoch [43/160] |	nca: 1.2861790880560875, flat: 2.346299409866333, pod: 38.15336084365845, loss: 41.785839796066284 
Train [5/26] | Epoch [44/160] |	nca: 1.265846136957407, flat: 2.37954930216074, pod: 36.78057110309601, loss: 40.42596673965454 
Train [5/26] | Epoch [45/160] |	nca: 1.1434510126709938, flat: 2.3659453615546227, pod: 38.13994646072388, loss: 41.64934301376343 
Train [5/26] | Epoch [46/160] |	nca: 1.1816284023225307, flat: 2.1323136538267136, pod: 35.289204120635986, loss: 38.60314607620239 
Train [5/26] | Epoch [47/160] |	nca: 1.4829147532582283, flat: 2.4745910316705704, pod: 37.8039470911026, loss: 41.7614529132843 
Train [5/26] | Epoch [48/160] |	nca: 1.3923636339604855, flat: 2.597248688340187, pod: 39.1770122051239, loss: 43.166624546051025 
Train [5/26] | Epoch [49/160] |	nca: 1.2319585159420967, flat: 2.498611271381378, pod: 36.872236490249634, loss: 40.60280656814575 
Train [5/26] | Epoch [50/160] |	nca: 1.377037063241005, flat: 2.5718500316143036, pod: 38.51669919490814, loss: 42.4655864238739 
Train [5/26] | Epoch [51/160] |	nca: 1.1159907467663288, flat: 2.2910226359963417, pod: 36.15735340118408, loss: 39.564366817474365 
Train [5/26] | Epoch [52/160] |	nca: 1.0787916332483292, flat: 2.196338914334774, pod: 35.65806972980499, loss: 38.9332001209259 
Train [5/26] | Epoch [53/160] |	nca: 1.2962206937372684, flat: 2.0873224958777428, pod: 35.125694274902344, loss: 38.50923752784729 
Train [5/26] | Epoch [54/160] |	nca: 1.033480916172266, flat: 2.045948475599289, pod: 35.60557723045349, loss: 38.685007095336914 
Train [5/26] | Epoch [55/160] |	nca: 1.1297587007284164, flat: 2.001083582639694, pod: 33.774404883384705, loss: 36.90524685382843 
Train [5/26] | Epoch [56/160] |	nca: 1.1494250278919935, flat: 1.9960094168782234, pod: 33.28094232082367, loss: 36.426376700401306 
Train [5/26] | Epoch [57/160] |	nca: 1.3339629583060741, flat: 2.0473128110170364, pod: 35.01365518569946, loss: 38.394930601119995 
Train [5/26] | Epoch [58/160] |	nca: 1.1794895641505718, flat: 2.1480482891201973, pod: 34.89791405200958, loss: 38.2254524230957 
Train [5/26] | Epoch [59/160] |	nca: 1.2390121966600418, flat: 2.1077206879854202, pod: 34.98565900325775, loss: 38.33239185810089 
Train [5/26] | Epoch [60/160] |	nca: 1.1882839500904083, flat: 2.0908825621008873, pod: 34.94393980503082, loss: 38.22310650348663 
Train [5/26] | Epoch [61/160] |	nca: 1.2064727619290352, flat: 2.216359719634056, pod: 36.11077129840851, loss: 39.53360426425934 
Train [5/26] | Epoch [62/160] |	nca: 1.051979772746563, flat: 1.9641934260725975, pod: 34.39863836765289, loss: 37.41481113433838 
Train [5/26] | Epoch [63/160] |	nca: 1.3751672394573689, flat: 2.1563893109560013, pod: 35.15565621852875, loss: 38.68721270561218 
Train [5/26] | Epoch [64/160] |	nca: 1.3475200422108173, flat: 2.4598307609558105, pod: 38.36586594581604, loss: 42.173216581344604 
Train [5/26] | Epoch [65/160] |	nca: 1.2795873917639256, flat: 2.258271247148514, pod: 36.79297924041748, loss: 40.33083724975586 
Train [5/26] | Epoch [66/160] |	nca: 1.1191778108477592, flat: 2.0939827859401703, pod: 34.6889032125473, loss: 37.902063846588135 
Train [5/26] | Epoch [67/160] |	nca: 1.1841939464211464, flat: 1.9055108353495598, pod: 33.90414571762085, loss: 36.9938508272171 
Train [5/26] | Epoch [68/160] |	nca: 1.0244798474013805, flat: 1.8114233911037445, pod: 32.54853296279907, loss: 35.38443577289581 
Train [5/26] | Epoch [69/160] |	nca: 1.0851877592504025, flat: 1.9510033056139946, pod: 33.14908480644226, loss: 36.18527626991272 
Train [5/26] | Epoch [70/160] |	nca: 1.1237112507224083, flat: 1.929376669228077, pod: 33.527281284332275, loss: 36.580368876457214 
Train [5/26] | Epoch [71/160] |	nca: 0.9956992864608765, flat: 1.865559995174408, pod: 33.15761649608612, loss: 36.01887559890747 
Train [5/26] | Epoch [72/160] |	nca: 1.2237423919141293, flat: 1.9483841881155968, pod: 34.39845561981201, loss: 37.57058238983154 
Train [5/26] | Epoch [73/160] |	nca: 1.1078738868236542, flat: 1.8670814707875252, pod: 32.97678792476654, loss: 35.951743364334106 
Train [5/26] | Epoch [74/160] |	nca: 1.0042157918214798, flat: 1.963150031864643, pod: 33.97833061218262, loss: 36.945696115493774 
Train [5/26] | Epoch [75/160] |	nca: 1.0478831268846989, flat: 1.8004289641976357, pod: 32.7575489282608, loss: 35.60586094856262 
Train [5/26] | Epoch [76/160] |	nca: 1.0800228491425514, flat: 1.6552166566252708, pod: 31.268590331077576, loss: 34.00382947921753 
Train [5/26] | Epoch [77/160] |	nca: 1.0917249582707882, flat: 1.8199936375021935, pod: 32.07704770565033, loss: 34.98876631259918 
Train [5/26] | Epoch [78/160] |	nca: 1.1678805388510227, flat: 1.7669169753789902, pod: 31.653911352157593, loss: 34.58870875835419 
Train [5/26] | Epoch [79/160] |	nca: 1.0650758519768715, flat: 1.6398461014032364, pod: 30.26515281200409, loss: 32.97007489204407 
Train [5/26] | Epoch [80/160] |	nca: 1.1180787980556488, flat: 1.7932600528001785, pod: 32.04002225399017, loss: 34.95136058330536 
Train [5/26] | Epoch [81/160] |	nca: 1.2093457914888859, flat: 1.706968605518341, pod: 31.35019314289093, loss: 34.266507506370544 
Train [5/26] | Epoch [82/160] |	nca: 1.1098960489034653, flat: 1.6945453211665154, pod: 32.18669879436493, loss: 34.99113988876343 
Train [5/26] | Epoch [83/160] |	nca: 1.1522107608616352, flat: 1.6752027869224548, pod: 31.326547026634216, loss: 34.15396070480347 
Train [5/26] | Epoch [84/160] |	nca: 0.9833495393395424, flat: 1.7669824734330177, pod: 32.765188217163086, loss: 35.515520095825195 
Train [5/26] | Epoch [85/160] |	nca: 1.114794347435236, flat: 1.525012530386448, pod: 29.026581287384033, loss: 31.666388154029846 
Train [5/26] | Epoch [86/160] |	nca: 0.9864857904613018, flat: 1.5277336910367012, pod: 29.24618923664093, loss: 31.760408997535706 
Train [5/26] | Epoch [87/160] |	nca: 1.1067376844584942, flat: 1.5385109931230545, pod: 29.498034596443176, loss: 32.14328324794769 
Train [5/26] | Epoch [88/160] |	nca: 1.1057897955179214, flat: 1.4992248564958572, pod: 29.778070092201233, loss: 32.38308489322662 
Train [5/26] | Epoch [89/160] |	nca: 0.9488967508077621, flat: 1.4947622641921043, pod: 30.049968123435974, loss: 32.493627309799194 
Train [5/26] | Epoch [90/160] |	nca: 1.2806892395019531, flat: 1.6454566642642021, pod: 30.26183271408081, loss: 33.187978744506836 
Train [5/26] | Epoch [91/160] |	nca: 1.0773081593215466, flat: 1.4861174300312996, pod: 29.146339654922485, loss: 31.709765434265137 
Train [5/26] | Epoch [92/160] |	nca: 1.2223006784915924, flat: 1.574522815644741, pod: 29.780054807662964, loss: 32.57687830924988 
Train [5/26] | Epoch [93/160] |	nca: 1.0428931266069412, flat: 1.5807774811983109, pod: 30.285544276237488, loss: 32.90921485424042 
Train [5/26] | Epoch [94/160] |	nca: 1.061580616980791, flat: 1.473128281533718, pod: 29.036299228668213, loss: 31.571008324623108 
Train [5/26] | Epoch [95/160] |	nca: 1.0566199235618114, flat: 1.3572324253618717, pod: 26.79871165752411, loss: 29.21256375312805 
Train [5/26] | Epoch [96/160] |	nca: 1.0511798039078712, flat: 1.4002427384257317, pod: 27.96667516231537, loss: 30.418097615242004 
Train [5/26] | Epoch [97/160] |	nca: 0.9644300639629364, flat: 1.380158670246601, pod: 27.84001338481903, loss: 30.18460178375244 
Train [5/26] | Epoch [98/160] |	nca: 1.152011189609766, flat: 1.4749301001429558, pod: 29.258926272392273, loss: 31.885867476463318 
Train [5/26] | Epoch [99/160] |	nca: 1.1449576914310455, flat: 1.5042146816849709, pod: 29.394006609916687, loss: 32.04317915439606 
Train [5/26] | Epoch [100/160] |	nca: 0.9943357408046722, flat: 1.313099980354309, pod: 27.610288619995117, loss: 29.917724013328552 
Train [5/26] | Epoch [101/160] |	nca: 0.9415698684751987, flat: 1.2834777049720287, pod: 27.992507457733154, loss: 30.217555046081543 
Train [5/26] | Epoch [102/160] |	nca: 1.0569735504686832, flat: 1.4332182221114635, pod: 29.569427490234375, loss: 32.059619307518005 
Train [5/26] | Epoch [103/160] |	nca: 1.0826104134321213, flat: 1.2917597740888596, pod: 26.50279402732849, loss: 28.877164125442505 
Train [5/26] | Epoch [104/160] |	nca: 1.0496055521070957, flat: 1.2893280014395714, pod: 26.47453236579895, loss: 28.81346607208252 
Train [5/26] | Epoch [105/160] |	nca: 1.1034824326634407, flat: 1.3795240111649036, pod: 27.76146125793457, loss: 30.24446749687195 
Train [5/26] | Epoch [106/160] |	nca: 1.007927343249321, flat: 1.1541057713329792, pod: 25.201705813407898, loss: 27.363738894462585 
Train [5/26] | Epoch [107/160] |	nca: 1.0491975471377373, flat: 1.1334149315953255, pod: 24.716232299804688, loss: 26.898844599723816 
Train [5/26] | Epoch [108/160] |	nca: 1.0881660878658295, flat: 1.1151428036391735, pod: 24.479783535003662, loss: 26.68309223651886 
Train [5/26] | Epoch [109/160] |	nca: 0.9308559224009514, flat: 1.231936577707529, pod: 26.346454977989197, loss: 28.509247660636902 
Train [5/26] | Epoch [110/160] |	nca: 1.0607368499040604, flat: 1.1313463747501373, pod: 26.012508153915405, loss: 28.204591274261475 
Train [5/26] | Epoch [111/160] |	nca: 0.9795559048652649, flat: 1.2546542324125767, pod: 27.394694209098816, loss: 29.628904819488525 
Train [5/26] | Epoch [112/160] |	nca: 0.9925097152590752, flat: 1.2392045073211193, pod: 26.81978487968445, loss: 29.051498889923096 
Train [5/26] | Epoch [113/160] |	nca: 0.9043799228966236, flat: 1.14905995875597, pod: 26.22001028060913, loss: 28.273450016975403 
Train [5/26] | Epoch [114/160] |	nca: 1.0345450043678284, flat: 1.1096214912831783, pod: 24.496915102005005, loss: 26.64108145236969 
Train [5/26] | Epoch [115/160] |	nca: 0.9429715685546398, flat: 1.070050347596407, pod: 23.50751292705536, loss: 25.520535111427307 
Train [5/26] | Epoch [116/160] |	nca: 1.0239029116928577, flat: 0.9549965895712376, pod: 22.212597012519836, loss: 24.19149661064148 
Train [5/26] | Epoch [117/160] |	nca: 0.9743499085307121, flat: 0.973536379635334, pod: 22.145947456359863, loss: 24.093833804130554 
Train [5/26] | Epoch [118/160] |	nca: 0.9696790985763073, flat: 1.023139376193285, pod: 23.523767471313477, loss: 25.51658594608307 
Train [5/26] | Epoch [119/160] |	nca: 0.9373042173683643, flat: 1.0036590285599232, pod: 22.733103275299072, loss: 24.6740665435791 
Train [5/26] | Epoch [120/160] |	nca: 0.9570297487080097, flat: 1.0095385387539864, pod: 22.310339212417603, loss: 24.276907682418823 
Train [5/26] | Epoch [121/160] |	nca: 0.9520743004977703, flat: 0.9608665406703949, pod: 22.304507732391357, loss: 24.217448830604553 
Train [5/26] | Epoch [122/160] |	nca: 1.0570300444960594, flat: 0.984898041933775, pod: 22.703850388526917, loss: 24.745778679847717 
Train [5/26] | Epoch [123/160] |	nca: 1.0048798024654388, flat: 0.8460769429802895, pod: 20.525209546089172, loss: 22.376166105270386 
Train [5/26] | Epoch [124/160] |	nca: 0.9849904663860798, flat: 0.8777383603155613, pod: 21.339986085891724, loss: 23.202715039253235 
Train [5/26] | Epoch [125/160] |	nca: 0.9030638560652733, flat: 0.8373038917779922, pod: 20.395123600959778, loss: 22.135491132736206 
Train [5/26] | Epoch [126/160] |	nca: 0.9609765112400055, flat: 0.8905842266976833, pod: 21.43286144733429, loss: 23.284422278404236 
Train [5/26] | Epoch [127/160] |	nca: 0.9522317685186863, flat: 0.8742272965610027, pod: 21.3837571144104, loss: 23.210216164588928 
Train [5/26] | Epoch [128/160] |	nca: 0.9350762479007244, flat: 0.7760627046227455, pod: 19.949120342731476, loss: 21.66025936603546 
Train [5/26] | Epoch [129/160] |	nca: 1.0522369369864464, flat: 0.8702271468937397, pod: 21.74466836452484, loss: 23.667132258415222 
Train [5/26] | Epoch [130/160] |	nca: 1.0080971084535122, flat: 0.8188321068882942, pod: 20.76226234436035, loss: 22.589191675186157 
Train [5/26] | Epoch [131/160] |	nca: 0.9719116166234016, flat: 0.808348685503006, pod: 20.060162782669067, loss: 21.840423345565796 
Train [5/26] | Epoch [132/160] |	nca: 1.0966507159173489, flat: 0.8751642964780331, pod: 21.318307399749756, loss: 23.290122270584106 
Train [5/26] | Epoch [133/160] |	nca: 1.0331364460289478, flat: 0.8908262252807617, pod: 22.299368858337402, loss: 24.223331451416016 
Train [5/26] | Epoch [134/160] |	nca: 0.9833217263221741, flat: 0.8448082581162453, pod: 20.712039053440094, loss: 22.5401691198349 
Train [5/26] | Epoch [135/160] |	nca: 0.9200328961014748, flat: 0.7719029970467091, pod: 19.12116700410843, loss: 20.813102960586548 
Train [5/26] | Epoch [136/160] |	nca: 0.9341033101081848, flat: 0.773239903151989, pod: 18.664498388767242, loss: 20.371841728687286 
Train [5/26] | Epoch [137/160] |	nca: 0.9062642827630043, flat: 0.7398204691708088, pod: 18.62029939889908, loss: 20.26638412475586 
Train [5/26] | Epoch [138/160] |	nca: 0.9659027047455311, flat: 0.7372888289391994, pod: 19.417046785354614, loss: 21.120238184928894 
Train [5/26] | Epoch [139/160] |	nca: 1.0199705436825752, flat: 0.7746540494263172, pod: 19.01287806034088, loss: 20.807502806186676 
Train [5/26] | Epoch [140/160] |	nca: 0.9976400695741177, flat: 0.7440151274204254, pod: 19.015213310718536, loss: 20.756868720054626 
Train [5/26] | Epoch [141/160] |	nca: 0.9277988150715828, flat: 0.7433796729892492, pod: 19.10926979780197, loss: 20.78044831752777 
Train [5/26] | Epoch [142/160] |	nca: 0.9607549831271172, flat: 0.753371162340045, pod: 19.411821246147156, loss: 21.12594735622406 
Train [5/26] | Epoch [143/160] |	nca: 0.9774467516690493, flat: 0.7308177687227726, pod: 19.221233308315277, loss: 20.929497957229614 
Train [5/26] | Epoch [144/160] |	nca: 0.9831398837268353, flat: 0.7476737014949322, pod: 18.933117151260376, loss: 20.66393083333969 
Train [5/26] | Epoch [145/160] |	nca: 0.824560159817338, flat: 0.7129723951220512, pod: 18.882040858268738, loss: 20.419573307037354 
Train [5/26] | Epoch [146/160] |	nca: 1.0237008295953274, flat: 0.7106501441448927, pod: 18.52193695306778, loss: 20.25628787279129 
Train [5/26] | Epoch [147/160] |	nca: 0.9351156800985336, flat: 0.676042627543211, pod: 17.889349579811096, loss: 19.50050801038742 
Train [5/26] | Epoch [148/160] |	nca: 0.9427200928330421, flat: 0.6703280340880156, pod: 17.72468513250351, loss: 19.337733447551727 
Train [5/26] | Epoch [149/160] |	nca: 0.9506572484970093, flat: 0.7024942897260189, pod: 18.312098681926727, loss: 19.965250194072723 
Train [5/26] | Epoch [150/160] |	nca: 0.9621008858084679, flat: 0.6416337937116623, pod: 16.962022304534912, loss: 18.56575697660446 
Train [5/26] | Epoch [151/160] |	nca: 0.9554186090826988, flat: 0.6857274267822504, pod: 17.038514316082, loss: 18.679660439491272 
Train [5/26] | Epoch [152/160] |	nca: 0.899673230946064, flat: 0.6322663482278585, pod: 17.259620249271393, loss: 18.79155993461609 
Train [5/26] | Epoch [153/160] |	nca: 0.903353750705719, flat: 0.6234416328370571, pod: 16.331564366817474, loss: 17.858359813690186 
Train [5/26] | Epoch [154/160] |	nca: 0.9902279786765575, flat: 0.7367765475064516, pod: 18.61295396089554, loss: 20.339958488941193 
Train [5/26] | Epoch [155/160] |	nca: 0.9709034897387028, flat: 0.6323842462152243, pod: 16.9333398938179, loss: 18.53662770986557 
Train [5/26] | Epoch [156/160] |	nca: 0.974224291741848, flat: 0.637296486645937, pod: 16.82162618637085, loss: 18.433146953582764 
Train [5/26] | Epoch [157/160] |	nca: 1.017486896365881, flat: 0.620814735069871, pod: 16.459724009037018, loss: 18.098025619983673 
Train [5/26] | Epoch [158/160] |	nca: 1.0777309089899063, flat: 0.6844119448214769, pod: 18.057570159435272, loss: 19.819712817668915 
Train [5/26] | Epoch [159/160] |	nca: 0.8951792567968369, flat: 0.665723854675889, pod: 16.975117027759552, loss: 18.53602021932602 
Train [5/26] | Epoch [160/160] |	nca: 1.0039731040596962, flat: 0.6789008285850286, pod: 17.90989077091217, loss: 19.592764616012573 
Fine-tuning
Building & updating memory.
Train [5/26] | Epoch [161/180] |	nca: 2.7412793338298798, flat: 2.412559449672699, pod: 25.667025923728943, loss: 30.8208646774292 
Train [5/26] | Epoch [162/180] |	nca: 1.4932274967432022, flat: 2.485440969467163, pod: 26.924771070480347, loss: 30.90343952178955 
Train [5/26] | Epoch [163/180] |	nca: 1.7877273596823215, flat: 2.222645401954651, pod: 26.228530406951904, loss: 30.238903045654297 
Train [5/26] | Epoch [164/180] |	nca: 1.7878207862377167, flat: 2.2953564673662186, pod: 25.952828645706177, loss: 30.036005973815918 
Train [5/26] | Epoch [165/180] |	nca: 1.385908305644989, flat: 1.907987967133522, pod: 24.57457423210144, loss: 27.868470668792725 
Train [5/26] | Epoch [166/180] |	nca: 1.0631241351366043, flat: 2.2556525245308876, pod: 26.607717037200928, loss: 29.926493644714355 
Train [5/26] | Epoch [167/180] |	nca: 1.381861850619316, flat: 2.5721093714237213, pod: 26.54839050769806, loss: 30.50236201286316 
Train [5/26] | Epoch [168/180] |	nca: 0.8895405679941177, flat: 2.292122319340706, pod: 25.107630252838135, loss: 28.28929328918457 
Train [5/26] | Epoch [169/180] |	nca: 1.1055218204855919, flat: 2.359827369451523, pod: 25.77445888519287, loss: 29.239807844161987 
Train [5/26] | Epoch [170/180] |	nca: 1.1931760609149933, flat: 2.1738228648900986, pod: 25.843330144882202, loss: 29.210328817367554 
Train [5/26] | Epoch [171/180] |	nca: 1.216840673238039, flat: 2.5485577285289764, pod: 26.018019676208496, loss: 29.78341817855835 
Train [5/26] | Epoch [172/180] |	nca: 1.0643704906105995, flat: 2.2892413437366486, pod: 25.979540824890137, loss: 29.333152770996094 
Train [5/26] | Epoch [173/180] |	nca: 1.5727401562035084, flat: 2.4625599086284637, pod: 26.282519221305847, loss: 30.317819595336914 
Train [5/26] | Epoch [174/180] |	nca: 1.7890665456652641, flat: 2.494436264038086, pod: 26.63457417488098, loss: 30.918076992034912 
Train [5/26] | Epoch [175/180] |	nca: 1.15762110799551, flat: 2.1708196252584457, pod: 25.090333700180054, loss: 28.418774366378784 
Train [5/26] | Epoch [176/180] |	nca: 1.2149099297821522, flat: 2.140794098377228, pod: 25.786988496780396, loss: 29.14269232749939 
Train [5/26] | Epoch [177/180] |	nca: 1.2786690965294838, flat: 2.3235270977020264, pod: 25.61937117576599, loss: 29.221567153930664 
Train [5/26] | Epoch [178/180] |	nca: 2.692158952355385, flat: 2.9057444036006927, pod: 27.923675060272217, loss: 33.521578311920166 
Train [5/26] | Epoch [179/180] |	nca: 2.368790678679943, flat: 2.097346305847168, pod: 25.062829732894897, loss: 29.528966665267944 
Train [5/26] | Epoch [180/180] |	nca: 1.7860446646809578, flat: 2.4694962352514267, pod: 26.04114818572998, loss: 30.29668927192688 
after task
Building & updating memory.
after task
Eval on 0->58.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.7222.
Current acc: {'total': 0.667, '00-09': 0.691, '10-19': 0.696, '20-29': 0.592, '30-39': 0.633, '40-49': 0.711, '50-59': 0.68}.
Avg inc acc top5: 0.9219999999999999.
Current acc top5: {'total': 0.887}.
Forgetting: 0.10700000000000003.
Cord metric: 0.72.
Old accuracy: 0.66, mean: 0.70.
New accuracy: 0.77, mean: 0.80.
================Task 5 Start!================
Testing on False unseen tasks (max class = 60).
Set memory of size: 1160.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 5 Training!================
The training samples number: 2160
Train on 58->60.
train task
nb 2160.
Train [6/26] | Epoch [1/160] |	nca: 7.5739409029483795, flat: 3.8393291905522346, pod: 41.05804419517517, loss: 52.471314430236816 
Train [6/26] | Epoch [2/160] |	nca: 5.106187418103218, flat: 5.945130288600922, pod: 53.618794441223145, loss: 64.67011260986328 
Train [6/26] | Epoch [3/160] |	nca: 3.8347174897789955, flat: 5.397157073020935, pod: 51.917991161346436, loss: 61.1498658657074 
Train [6/26] | Epoch [4/160] |	nca: 3.1919057443737984, flat: 4.748007729649544, pod: 50.34876871109009, loss: 58.288681983947754 
Train [6/26] | Epoch [5/160] |	nca: 2.536967419087887, flat: 4.323288276791573, pod: 48.772704124450684, loss: 55.632959604263306 
Train [6/26] | Epoch [6/160] |	nca: 2.4776527881622314, flat: 3.8169551342725754, pod: 46.477866411209106, loss: 52.77247405052185 
Train [6/26] | Epoch [7/160] |	nca: 2.2908143997192383, flat: 3.561760812997818, pod: 42.69279670715332, loss: 48.545372009277344 
Train [6/26] | Epoch [8/160] |	nca: 2.2639296278357506, flat: 3.4175056517124176, pod: 41.59097361564636, loss: 47.272409200668335 
Train [6/26] | Epoch [9/160] |	nca: 2.1819994300603867, flat: 3.564863160252571, pod: 44.36269187927246, loss: 50.10955476760864 
Train [6/26] | Epoch [10/160] |	nca: 2.545089602470398, flat: 3.5399898886680603, pod: 43.13883090019226, loss: 49.22391057014465 
Train [6/26] | Epoch [11/160] |	nca: 2.246670126914978, flat: 3.5357030779123306, pod: 42.58430457115173, loss: 48.36667776107788 
Train [6/26] | Epoch [12/160] |	nca: 2.078054092824459, flat: 3.3335710763931274, pod: 42.676438093185425, loss: 48.08806371688843 
Train [6/26] | Epoch [13/160] |	nca: 2.1815045848488808, flat: 3.4428394436836243, pod: 42.51858186721802, loss: 48.14292597770691 
Train [6/26] | Epoch [14/160] |	nca: 2.045602571219206, flat: 3.347509413957596, pod: 41.78056001663208, loss: 47.17367196083069 
Train [6/26] | Epoch [15/160] |	nca: 1.9902841746807098, flat: 3.1515461802482605, pod: 40.01498627662659, loss: 45.156816244125366 
Train [6/26] | Epoch [16/160] |	nca: 1.9721892923116684, flat: 3.134372889995575, pod: 40.33434057235718, loss: 45.44090247154236 
Train [6/26] | Epoch [17/160] |	nca: 1.9963053688406944, flat: 3.3226218968629837, pod: 40.69787359237671, loss: 46.01680135726929 
Train [6/26] | Epoch [18/160] |	nca: 2.1576215028762817, flat: 3.2551373839378357, pod: 42.35272455215454, loss: 47.765483379364014 
Train [6/26] | Epoch [19/160] |	nca: 1.7984385341405869, flat: 3.2847276479005814, pod: 42.381226778030396, loss: 47.46439290046692 
Train [6/26] | Epoch [20/160] |	nca: 1.917722076177597, flat: 3.169232815504074, pod: 41.98584723472595, loss: 47.07280206680298 
Train [6/26] | Epoch [21/160] |	nca: 2.00634765625, flat: 3.1558806598186493, pod: 40.950400829315186, loss: 46.11262893676758 
Train [6/26] | Epoch [22/160] |	nca: 1.8898219726979733, flat: 3.0159269720315933, pod: 39.78199625015259, loss: 44.687745571136475 
Train [6/26] | Epoch [23/160] |	nca: 1.830480970442295, flat: 2.8332312256097794, pod: 38.56435775756836, loss: 43.22807002067566 
Train [6/26] | Epoch [24/160] |	nca: 1.9836283475160599, flat: 3.1034408807754517, pod: 41.110859870910645, loss: 46.19792938232422 
Train [6/26] | Epoch [25/160] |	nca: 1.8239171653985977, flat: 3.0672218203544617, pod: 41.12575149536133, loss: 46.01689076423645 
Train [6/26] | Epoch [26/160] |	nca: 1.8277129605412483, flat: 2.9577153623104095, pod: 39.59195256233215, loss: 44.37738084793091 
Train [6/26] | Epoch [27/160] |	nca: 1.9013728983700275, flat: 2.9175674617290497, pod: 39.30528783798218, loss: 44.12422823905945 
Train [6/26] | Epoch [28/160] |	nca: 1.6678071096539497, flat: 2.8548665046691895, pod: 38.00948750972748, loss: 42.532161474227905 
Train [6/26] | Epoch [29/160] |	nca: 1.741123840212822, flat: 2.6477223187685013, pod: 38.02134084701538, loss: 42.410186529159546 
Train [6/26] | Epoch [30/160] |	nca: 1.6917762756347656, flat: 2.684663698077202, pod: 37.473241090774536, loss: 41.84968018531799 
Train [6/26] | Epoch [31/160] |	nca: 1.9921409785747528, flat: 3.0176421850919724, pod: 39.928009271621704, loss: 44.9377920627594 
Train [6/26] | Epoch [32/160] |	nca: 1.774915810674429, flat: 3.0404854267835617, pod: 41.017817735672, loss: 45.833218812942505 
Train [6/26] | Epoch [33/160] |	nca: 1.840839870274067, flat: 2.9143906980752945, pod: 38.8313627243042, loss: 43.58659291267395 
Train [6/26] | Epoch [34/160] |	nca: 1.8786619938910007, flat: 3.123634457588196, pod: 41.10571503639221, loss: 46.10801148414612 
Train [6/26] | Epoch [35/160] |	nca: 1.625664934515953, flat: 2.9562667310237885, pod: 40.16593265533447, loss: 44.74786400794983 
Train [6/26] | Epoch [36/160] |	nca: 1.6983854100108147, flat: 2.852197378873825, pod: 39.76149082183838, loss: 44.312073707580566 
Train [6/26] | Epoch [37/160] |	nca: 1.5481376685202122, flat: 2.5174400806427, pod: 35.77180278301239, loss: 39.83738040924072 
Train [6/26] | Epoch [38/160] |	nca: 1.6921921446919441, flat: 2.691458284854889, pod: 38.02178382873535, loss: 42.405433893203735 
Train [6/26] | Epoch [39/160] |	nca: 1.717101540416479, flat: 2.795890733599663, pod: 38.99002170562744, loss: 43.50301432609558 
Train [6/26] | Epoch [40/160] |	nca: 1.5971535667777061, flat: 2.749162256717682, pod: 38.79162788391113, loss: 43.137943983078 
Train [6/26] | Epoch [41/160] |	nca: 1.6539908573031425, flat: 2.630907505750656, pod: 37.46687197685242, loss: 41.75177001953125 
Train [6/26] | Epoch [42/160] |	nca: 1.8683131076395512, flat: 2.596027761697769, pod: 36.50312149524689, loss: 40.967461824417114 
Train [6/26] | Epoch [43/160] |	nca: 1.9527893513441086, flat: 2.678147554397583, pod: 37.06900680065155, loss: 41.69994378089905 
Train [6/26] | Epoch [44/160] |	nca: 1.8897912874817848, flat: 2.7711609601974487, pod: 38.62714755535126, loss: 43.28809952735901 
Train [6/26] | Epoch [45/160] |	nca: 1.597497183829546, flat: 2.6877088099718094, pod: 36.99906659126282, loss: 41.28427314758301 
Train [6/26] | Epoch [46/160] |	nca: 1.5423563495278358, flat: 2.4567179679870605, pod: 35.672945976257324, loss: 39.672019481658936 
Train [6/26] | Epoch [47/160] |	nca: 1.5228504166007042, flat: 2.555119574069977, pod: 37.35373592376709, loss: 41.431705713272095 
Train [6/26] | Epoch [48/160] |	nca: 1.5933799967169762, flat: 2.4255758076906204, pod: 35.17070436477661, loss: 39.18966007232666 
Train [6/26] | Epoch [49/160] |	nca: 1.5972782745957375, flat: 2.4986970275640488, pod: 35.96061289310455, loss: 40.05658793449402 
Train [6/26] | Epoch [50/160] |	nca: 1.7087993137538433, flat: 2.4242576211690903, pod: 35.38992738723755, loss: 39.52298402786255 
Train [6/26] | Epoch [51/160] |	nca: 1.6422944404184818, flat: 2.4398723244667053, pod: 35.096893310546875, loss: 39.17905950546265 
Train [6/26] | Epoch [52/160] |	nca: 1.6381556130945683, flat: 2.358246996998787, pod: 34.40968143939972, loss: 38.40608334541321 
Train [6/26] | Epoch [53/160] |	nca: 1.7227565124630928, flat: 2.401403397321701, pod: 35.89115786552429, loss: 40.01531767845154 
Train [6/26] | Epoch [54/160] |	nca: 1.5733953416347504, flat: 2.374081499874592, pod: 36.001049399375916, loss: 39.94852638244629 
Train [6/26] | Epoch [55/160] |	nca: 1.754177913069725, flat: 2.4239658638834953, pod: 36.778844237327576, loss: 40.9569878578186 
Train [6/26] | Epoch [56/160] |	nca: 1.8822915628552437, flat: 2.581946089863777, pod: 38.290650606155396, loss: 42.75488805770874 
Train [6/26] | Epoch [57/160] |	nca: 1.6230706945061684, flat: 2.6792622804641724, pod: 37.510701060295105, loss: 41.81303358078003 
Train [6/26] | Epoch [58/160] |	nca: 1.3990743793547153, flat: 2.226796232163906, pod: 33.70325326919556, loss: 37.3291232585907 
Train [6/26] | Epoch [59/160] |	nca: 1.4054135754704475, flat: 2.2363843619823456, pod: 35.19240689277649, loss: 38.83420515060425 
Train [6/26] | Epoch [60/160] |	nca: 1.5169552601873875, flat: 2.263131968677044, pod: 34.665780544281006, loss: 38.44586801528931 
Train [6/26] | Epoch [61/160] |	nca: 1.5923701338469982, flat: 2.425819233059883, pod: 37.64187848567963, loss: 41.66006803512573 
Train [6/26] | Epoch [62/160] |	nca: 1.5011614188551903, flat: 2.3919820487499237, pod: 36.32017421722412, loss: 40.21331739425659 
Train [6/26] | Epoch [63/160] |	nca: 1.7360618487000465, flat: 2.342950187623501, pod: 35.683534383773804, loss: 39.76254653930664 
Train [6/26] | Epoch [64/160] |	nca: 1.5688236728310585, flat: 2.370678760111332, pod: 36.2744163274765, loss: 40.213918924331665 
Train [6/26] | Epoch [65/160] |	nca: 1.47524955868721, flat: 2.260182112455368, pod: 34.92754125595093, loss: 38.662973165512085 
Train [6/26] | Epoch [66/160] |	nca: 1.5271218046545982, flat: 2.2789797335863113, pod: 35.03268206119537, loss: 38.838783502578735 
Train [6/26] | Epoch [67/160] |	nca: 1.4018051624298096, flat: 2.097293511033058, pod: 33.89363706111908, loss: 37.3927356004715 
Train [6/26] | Epoch [68/160] |	nca: 1.5384299494326115, flat: 2.1289093866944313, pod: 33.500237464904785, loss: 37.16757678985596 
Train [6/26] | Epoch [69/160] |	nca: 1.5623755380511284, flat: 2.4217557460069656, pod: 36.29938864707947, loss: 40.283520221710205 
Train [6/26] | Epoch [70/160] |	nca: 1.696200642734766, flat: 2.2585860267281532, pod: 34.976242780685425, loss: 38.93102955818176 
Train [6/26] | Epoch [71/160] |	nca: 1.4445283077657223, flat: 2.10441617667675, pod: 32.97325575351715, loss: 36.52220022678375 
Train [6/26] | Epoch [72/160] |	nca: 1.410807803273201, flat: 2.1066543981432915, pod: 33.49426889419556, loss: 37.01173114776611 
Train [6/26] | Epoch [73/160] |	nca: 1.4307047501206398, flat: 1.9427527040243149, pod: 31.595136404037476, loss: 34.96859407424927 
Train [6/26] | Epoch [74/160] |	nca: 1.340839620679617, flat: 1.9746081233024597, pod: 31.937746047973633, loss: 35.253193497657776 
Train [6/26] | Epoch [75/160] |	nca: 1.4239886552095413, flat: 1.9228961169719696, pod: 31.437827110290527, loss: 34.784711956977844 
Train [6/26] | Epoch [76/160] |	nca: 1.6445461362600327, flat: 1.972359575331211, pod: 33.2645378112793, loss: 36.8814435005188 
Train [6/26] | Epoch [77/160] |	nca: 1.5839878991246223, flat: 2.138546884059906, pod: 34.53800332546234, loss: 38.26053810119629 
Train [6/26] | Epoch [78/160] |	nca: 1.2546361051499844, flat: 1.9086036011576653, pod: 31.534757256507874, loss: 34.697996854782104 
Train [6/26] | Epoch [79/160] |	nca: 1.4785466454923153, flat: 1.8702148273587227, pod: 30.4912109375, loss: 33.839972615242004 
Train [6/26] | Epoch [80/160] |	nca: 1.4177755080163479, flat: 1.828884094953537, pod: 30.446675777435303, loss: 33.69333565235138 
Train [6/26] | Epoch [81/160] |	nca: 1.6158401146531105, flat: 1.810226984322071, pod: 30.69580364227295, loss: 34.12187111377716 
Train [6/26] | Epoch [82/160] |	nca: 1.3076980486512184, flat: 1.880124218761921, pod: 31.059638142585754, loss: 34.24746060371399 
Train [6/26] | Epoch [83/160] |	nca: 1.460036937147379, flat: 1.8080907687544823, pod: 30.35626459121704, loss: 33.62439239025116 
Train [6/26] | Epoch [84/160] |	nca: 1.3162581026554108, flat: 1.693401999771595, pod: 30.38906955718994, loss: 33.39872944355011 
Train [6/26] | Epoch [85/160] |	nca: 1.4566954709589481, flat: 1.8367049172520638, pod: 32.440492033958435, loss: 35.73389208316803 
Train [6/26] | Epoch [86/160] |	nca: 1.6322071701288223, flat: 1.9476093128323555, pod: 32.11452233791351, loss: 35.69433903694153 
Train [6/26] | Epoch [87/160] |	nca: 1.4028913117945194, flat: 1.765575759112835, pod: 30.134678959846497, loss: 33.30314588546753 
Train [6/26] | Epoch [88/160] |	nca: 1.290474008768797, flat: 1.6740822941064835, pod: 29.113255620002747, loss: 32.07781207561493 
Train [6/26] | Epoch [89/160] |	nca: 1.2905219048261642, flat: 1.6932241544127464, pod: 29.118154287338257, loss: 32.10190010070801 
Train [6/26] | Epoch [90/160] |	nca: 1.2886267751455307, flat: 1.4712644442915916, pod: 27.52400243282318, loss: 30.28389346599579 
Train [6/26] | Epoch [91/160] |	nca: 1.3057007603347301, flat: 1.5957429260015488, pod: 28.422475934028625, loss: 31.323919534683228 
Train [6/26] | Epoch [92/160] |	nca: 1.4447994381189346, flat: 1.7542936950922012, pod: 30.960909366607666, loss: 34.16000258922577 
Train [6/26] | Epoch [93/160] |	nca: 1.5187277309596539, flat: 1.7532476857304573, pod: 30.76254975795746, loss: 34.03452503681183 
Train [6/26] | Epoch [94/160] |	nca: 1.421951673924923, flat: 1.680278867483139, pod: 29.53136432170868, loss: 32.63359475135803 
Train [6/26] | Epoch [95/160] |	nca: 1.3723202049732208, flat: 1.4812613502144814, pod: 27.130054116249084, loss: 29.983635783195496 
Train [6/26] | Epoch [96/160] |	nca: 1.3742912225425243, flat: 1.4181636795401573, pod: 27.294862270355225, loss: 30.08731734752655 
Train [6/26] | Epoch [97/160] |	nca: 1.3440207727253437, flat: 1.5002533867955208, pod: 27.84466576576233, loss: 30.688939929008484 
Train [6/26] | Epoch [98/160] |	nca: 1.4017927199602127, flat: 1.4257873967289925, pod: 27.445892810821533, loss: 30.273472785949707 
Train [6/26] | Epoch [99/160] |	nca: 1.440542969852686, flat: 1.4857477769255638, pod: 26.241727828979492, loss: 29.168018460273743 
Train [6/26] | Epoch [100/160] |	nca: 1.4796072654426098, flat: 1.4810064285993576, pod: 27.478060007095337, loss: 30.438673853874207 
Train [6/26] | Epoch [101/160] |	nca: 1.299275167286396, flat: 1.4108343496918678, pod: 26.76821720600128, loss: 29.478326559066772 
Train [6/26] | Epoch [102/160] |	nca: 1.23753073066473, flat: 1.4179450795054436, pod: 27.055713534355164, loss: 29.71118950843811 
Train [6/26] | Epoch [103/160] |	nca: 1.3244482427835464, flat: 1.4113815426826477, pod: 26.415034651756287, loss: 29.150864362716675 
Train [6/26] | Epoch [104/160] |	nca: 1.2424151003360748, flat: 1.4480830393731594, pod: 27.553154826164246, loss: 30.243653297424316 
Train [6/26] | Epoch [105/160] |	nca: 1.3119693137705326, flat: 1.408134326338768, pod: 26.573573112487793, loss: 29.293676733970642 
Train [6/26] | Epoch [106/160] |	nca: 1.3145492635667324, flat: 1.3077343553304672, pod: 25.542718410491943, loss: 28.16500174999237 
Train [6/26] | Epoch [107/160] |	nca: 1.3718454279005527, flat: 1.3137565329670906, pod: 25.601517915725708, loss: 28.28711986541748 
Train [6/26] | Epoch [108/160] |	nca: 1.489760298281908, flat: 1.287526797503233, pod: 24.47680962085724, loss: 27.254096627235413 
Train [6/26] | Epoch [109/160] |	nca: 1.2939066924154758, flat: 1.2996167317032814, pod: 25.39938747882843, loss: 27.992910742759705 
Train [6/26] | Epoch [110/160] |	nca: 1.46436807513237, flat: 1.3627266436815262, pod: 26.211246252059937, loss: 29.038341283798218 
Train [6/26] | Epoch [111/160] |	nca: 1.3503380194306374, flat: 1.2955661490559578, pod: 26.075826287269592, loss: 28.72173035144806 
Train [6/26] | Epoch [112/160] |	nca: 1.194057259708643, flat: 1.2110246494412422, pod: 24.506733059883118, loss: 26.91181480884552 
Train [6/26] | Epoch [113/160] |	nca: 1.3012296855449677, flat: 1.1883922293782234, pod: 23.709999561309814, loss: 26.19962167739868 
Train [6/26] | Epoch [114/160] |	nca: 1.3368266224861145, flat: 1.185371994972229, pod: 23.722846627235413, loss: 26.2450453042984 
Train [6/26] | Epoch [115/160] |	nca: 1.3137569017708302, flat: 1.224132314324379, pod: 24.431707739830017, loss: 26.96959698200226 
Train [6/26] | Epoch [116/160] |	nca: 1.2533532120287418, flat: 1.1435989663004875, pod: 23.148386478424072, loss: 25.54533851146698 
Train [6/26] | Epoch [117/160] |	nca: 1.3312350362539291, flat: 1.090805772691965, pod: 22.43088459968567, loss: 24.852925539016724 
Train [6/26] | Epoch [118/160] |	nca: 1.379824798554182, flat: 1.1743466146290302, pod: 23.631263375282288, loss: 26.185434699058533 
Train [6/26] | Epoch [119/160] |	nca: 1.2979148477315903, flat: 1.0894535705447197, pod: 22.27764105796814, loss: 24.66500961780548 
Train [6/26] | Epoch [120/160] |	nca: 1.2816790230572224, flat: 1.084118876606226, pod: 22.287025928497314, loss: 24.6528240442276 
Train [6/26] | Epoch [121/160] |	nca: 1.4385036565363407, flat: 1.1705761328339577, pod: 24.752158999443054, loss: 27.361238956451416 
Train [6/26] | Epoch [122/160] |	nca: 1.1722004860639572, flat: 1.1088709495961666, pod: 23.014309525489807, loss: 25.29538071155548 
Train [6/26] | Epoch [123/160] |	nca: 1.2711990885436535, flat: 1.1202810928225517, pod: 23.52077305316925, loss: 25.91225302219391 
Train [6/26] | Epoch [124/160] |	nca: 1.3118860721588135, flat: 1.0125639513134956, pod: 21.108208060264587, loss: 23.432658076286316 
Train [6/26] | Epoch [125/160] |	nca: 1.3450957722961903, flat: 1.090382345020771, pod: 23.302204728126526, loss: 25.737682700157166 
Train [6/26] | Epoch [126/160] |	nca: 1.3435277119278908, flat: 1.0815378986299038, pod: 22.635017037391663, loss: 25.0600825548172 
Train [6/26] | Epoch [127/160] |	nca: 1.2688679844141006, flat: 0.9780571945011616, pod: 20.96400821208954, loss: 23.210933446884155 
Train [6/26] | Epoch [128/160] |	nca: 1.3637485355138779, flat: 1.0893776938319206, pod: 22.594330430030823, loss: 25.047456741333008 
Train [6/26] | Epoch [129/160] |	nca: 1.2302548252046108, flat: 0.9042088873684406, pod: 20.272079288959503, loss: 22.406543254852295 
Train [6/26] | Epoch [130/160] |	nca: 1.2807078883051872, flat: 0.8938884697854519, pod: 20.036795735359192, loss: 22.211392164230347 
Train [6/26] | Epoch [131/160] |	nca: 1.396480817347765, flat: 0.9042923040688038, pod: 20.059394121170044, loss: 22.360167384147644 
Train [6/26] | Epoch [132/160] |	nca: 1.3528581336140633, flat: 0.9712674207985401, pod: 20.71159601211548, loss: 23.03572142124176 
Train [6/26] | Epoch [133/160] |	nca: 1.3011749051511288, flat: 0.9423250518739223, pod: 20.726163268089294, loss: 22.96966302394867 
Train [6/26] | Epoch [134/160] |	nca: 1.2751813679933548, flat: 0.9226202517747879, pod: 20.625554263591766, loss: 22.823355793952942 
Train [6/26] | Epoch [135/160] |	nca: 1.3452912420034409, flat: 0.8914676420390606, pod: 20.143545925617218, loss: 22.38030505180359 
Train [6/26] | Epoch [136/160] |	nca: 1.2372008562088013, flat: 0.862637884914875, pod: 18.833253026008606, loss: 20.933091640472412 
Train [6/26] | Epoch [137/160] |	nca: 1.25932926684618, flat: 0.8661348409950733, pod: 19.77316039800644, loss: 21.898624420166016 
Train [6/26] | Epoch [138/160] |	nca: 1.255365677177906, flat: 0.869103230535984, pod: 19.22923254966736, loss: 21.35370135307312 
Train [6/26] | Epoch [139/160] |	nca: 1.2304288297891617, flat: 0.861160509288311, pod: 19.208904087543488, loss: 21.300493478775024 
Train [6/26] | Epoch [140/160] |	nca: 1.3028847351670265, flat: 0.794305857270956, pod: 18.95232379436493, loss: 21.049514651298523 
Train [6/26] | Epoch [141/160] |	nca: 1.2823186740279198, flat: 0.840324841439724, pod: 17.92173272371292, loss: 20.044376254081726 
Train [6/26] | Epoch [142/160] |	nca: 1.3156108297407627, flat: 0.7966804876923561, pod: 18.361877620220184, loss: 20.47416925430298 
Train [6/26] | Epoch [143/160] |	nca: 1.3849433548748493, flat: 0.8429492563009262, pod: 19.215562343597412, loss: 21.443455159664154 
Train [6/26] | Epoch [144/160] |	nca: 1.2915166802704334, flat: 0.849957961589098, pod: 19.312713265419006, loss: 21.454187989234924 
Train [6/26] | Epoch [145/160] |	nca: 1.2282140254974365, flat: 0.7978144064545631, pod: 18.939786851406097, loss: 20.96581530570984 
Train [6/26] | Epoch [146/160] |	nca: 1.3421831130981445, flat: 0.8486064672470093, pod: 18.65812063217163, loss: 20.84891039133072 
Train [6/26] | Epoch [147/160] |	nca: 1.3490762561559677, flat: 0.8022778630256653, pod: 18.000727355480194, loss: 20.15208148956299 
Train [6/26] | Epoch [148/160] |	nca: 1.2905178256332874, flat: 0.7533532418310642, pod: 17.043672382831573, loss: 19.087543427944183 
Train [6/26] | Epoch [149/160] |	nca: 1.2190039344131947, flat: 0.739063985645771, pod: 17.748238682746887, loss: 19.7063068151474 
Train [6/26] | Epoch [150/160] |	nca: 1.2956506125628948, flat: 0.792143028229475, pod: 17.977835416793823, loss: 20.06562888622284 
Train [6/26] | Epoch [151/160] |	nca: 1.3110854774713516, flat: 0.8156250268220901, pod: 18.080869674682617, loss: 20.20758032798767 
Train [6/26] | Epoch [152/160] |	nca: 1.2779311649501324, flat: 0.6838904805481434, pod: 15.888214111328125, loss: 17.850035846233368 
Train [6/26] | Epoch [153/160] |	nca: 1.361161794513464, flat: 0.7715916819870472, pod: 17.509292364120483, loss: 19.642045855522156 
Train [6/26] | Epoch [154/160] |	nca: 1.2895302511751652, flat: 0.7647256143391132, pod: 17.05599445104599, loss: 19.110250174999237 
Train [6/26] | Epoch [155/160] |	nca: 1.3036733083426952, flat: 0.7508615702390671, pod: 17.094441890716553, loss: 19.148976683616638 
Train [6/26] | Epoch [156/160] |	nca: 1.2634386755526066, flat: 0.7758348658680916, pod: 17.701525807380676, loss: 19.74079918861389 
Train [6/26] | Epoch [157/160] |	nca: 1.2851929105818272, flat: 0.7552384994924068, pod: 17.302770256996155, loss: 19.34320157766342 
Train [6/26] | Epoch [158/160] |	nca: 1.2665674351155758, flat: 0.7510246653109789, pod: 16.46063083410263, loss: 18.478222846984863 
Train [6/26] | Epoch [159/160] |	nca: 1.2642800621688366, flat: 0.7739381156861782, pod: 18.069167137145996, loss: 20.107385098934174 
Train [6/26] | Epoch [160/160] |	nca: 1.304691731929779, flat: 0.7946990355849266, pod: 18.03251475095749, loss: 20.131905496120453 
Fine-tuning
Building & updating memory.
Train [6/26] | Epoch [161/180] |	nca: 1.4752272218465805, flat: 1.1781704798340797, pod: 17.21837341785431, loss: 19.871770977973938 
Train [6/26] | Epoch [162/180] |	nca: 0.5596937015652657, flat: 1.245908923447132, pod: 17.792261481285095, loss: 19.597864151000977 
Train [6/26] | Epoch [163/180] |	nca: 0.5875405296683311, flat: 1.1789865866303444, pod: 17.346168518066406, loss: 19.112695336341858 
Train [6/26] | Epoch [164/180] |	nca: 0.4993397295475006, flat: 1.2000528201460838, pod: 17.20950472354889, loss: 18.908897399902344 
Train [6/26] | Epoch [165/180] |	nca: 0.448000468313694, flat: 1.2060817629098892, pod: 17.468507528305054, loss: 19.122589707374573 
Train [6/26] | Epoch [166/180] |	nca: 0.35211461037397385, flat: 1.1408421099185944, pod: 17.131638050079346, loss: 18.624594807624817 
Train [6/26] | Epoch [167/180] |	nca: 0.3629002068191767, flat: 1.199706643819809, pod: 17.609691977500916, loss: 19.172298908233643 
Train [6/26] | Epoch [168/180] |	nca: 0.35974990390241146, flat: 1.2269994467496872, pod: 18.206109642982483, loss: 19.792859315872192 
Train [6/26] | Epoch [169/180] |	nca: 0.3195287622511387, flat: 1.1838582381606102, pod: 17.37778091430664, loss: 18.881168007850647 
Train [6/26] | Epoch [170/180] |	nca: 0.35129077918827534, flat: 1.1999194622039795, pod: 17.505791902542114, loss: 19.057002186775208 
Train [6/26] | Epoch [171/180] |	nca: 0.31784286722540855, flat: 1.2196286544203758, pod: 17.992722153663635, loss: 19.53019392490387 
Train [6/26] | Epoch [172/180] |	nca: 0.304351981729269, flat: 1.1552995964884758, pod: 17.417758107185364, loss: 18.87740993499756 
Train [6/26] | Epoch [173/180] |	nca: 0.3082359917461872, flat: 1.238515943288803, pod: 17.97551143169403, loss: 19.522263526916504 
Train [6/26] | Epoch [174/180] |	nca: 0.3120856527239084, flat: 1.1926055252552032, pod: 17.66528606414795, loss: 19.16997718811035 
Train [6/26] | Epoch [175/180] |	nca: 0.2838284894824028, flat: 1.1846530959010124, pod: 17.116950750350952, loss: 18.585432171821594 
Train [6/26] | Epoch [176/180] |	nca: 0.2731516193598509, flat: 1.2017800137400627, pod: 17.62677836418152, loss: 19.101709842681885 
Train [6/26] | Epoch [177/180] |	nca: 0.3086817320436239, flat: 1.2067975401878357, pod: 17.437875390052795, loss: 18.953354716300964 
Train [6/26] | Epoch [178/180] |	nca: 0.3343212716281414, flat: 1.207455039024353, pod: 17.638439655303955, loss: 19.180216073989868 
Train [6/26] | Epoch [179/180] |	nca: 0.2886718660593033, flat: 1.1621000990271568, pod: 17.204262018203735, loss: 18.655033946037292 
Train [6/26] | Epoch [180/180] |	nca: 0.305156946182251, flat: 1.194199487566948, pod: 17.43202030658722, loss: 18.931376814842224 
after task
Building & updating memory.
after task
Eval on 0->60.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.7133333333333333.
Current acc: {'total': 0.669, '00-09': 0.684, '10-19': 0.672, '20-29': 0.6, '30-39': 0.616, '40-49': 0.71, '50-59': 0.731}.
Avg inc acc top5: 0.9174999999999999.
Current acc top5: {'total': 0.895}.
Forgetting: 0.10557142857142858.
Cord metric: 0.72.
Old accuracy: 0.66, mean: 0.70.
New accuracy: 0.86, mean: 0.81.
================Task 6 Start!================
Testing on False unseen tasks (max class = 62).
Set memory of size: 1200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 6 Training!================
The training samples number: 2200
Train on 60->62.
train task
nb 2200.
Train [7/26] | Epoch [1/160] |	nca: 7.15864759683609, flat: 3.6198796331882477, pod: 43.4487407207489, loss: 54.22726774215698 
Train [7/26] | Epoch [2/160] |	nca: 7.169078081846237, flat: 7.59212401509285, pod: 62.46951961517334, loss: 77.23072099685669 
Train [7/26] | Epoch [3/160] |	nca: 6.755825042724609, flat: 7.771237522363663, pod: 64.25384378433228, loss: 78.7809066772461 
Train [7/26] | Epoch [4/160] |	nca: 4.677900120615959, flat: 6.449343770742416, pod: 59.74079513549805, loss: 70.86803960800171 
Train [7/26] | Epoch [5/160] |	nca: 3.589028939604759, flat: 5.712312698364258, pod: 55.576510429382324, loss: 64.87785196304321 
Train [7/26] | Epoch [6/160] |	nca: 3.2862537279725075, flat: 4.931880787014961, pod: 53.77253079414368, loss: 61.99066519737244 
Train [7/26] | Epoch [7/160] |	nca: 2.635366089642048, flat: 4.339310809969902, pod: 50.2765052318573, loss: 57.25118160247803 
Train [7/26] | Epoch [8/160] |	nca: 2.199185237288475, flat: 3.8141250014305115, pod: 47.39276313781738, loss: 53.406073570251465 
Train [7/26] | Epoch [9/160] |	nca: 2.230229340493679, flat: 3.508170425891876, pod: 45.34528660774231, loss: 51.0836865901947 
Train [7/26] | Epoch [10/160] |	nca: 2.313198335468769, flat: 3.526108667254448, pod: 47.18520402908325, loss: 53.024511098861694 
Train [7/26] | Epoch [11/160] |	nca: 2.541322708129883, flat: 3.6306699216365814, pod: 47.897504568099976, loss: 54.06949710845947 
Train [7/26] | Epoch [12/160] |	nca: 2.446251153945923, flat: 3.7545368522405624, pod: 47.25552558898926, loss: 53.45631384849548 
Train [7/26] | Epoch [13/160] |	nca: 2.5576554611325264, flat: 3.9854502975940704, pod: 49.72357773780823, loss: 56.26668334007263 
Train [7/26] | Epoch [14/160] |	nca: 2.300797201693058, flat: 3.5926813781261444, pod: 45.85429906845093, loss: 51.747777462005615 
Train [7/26] | Epoch [15/160] |	nca: 2.710311807692051, flat: 4.1683337688446045, pod: 51.10464000701904, loss: 57.983285903930664 
Train [7/26] | Epoch [16/160] |	nca: 2.1492841839790344, flat: 3.623994141817093, pod: 46.0564239025116, loss: 51.82970190048218 
Train [7/26] | Epoch [17/160] |	nca: 2.0959958285093307, flat: 3.2600542157888412, pod: 43.621018409729004, loss: 48.97706842422485 
Train [7/26] | Epoch [18/160] |	nca: 2.0559403374791145, flat: 3.2351718842983246, pod: 44.01214528083801, loss: 49.30325746536255 
Train [7/26] | Epoch [19/160] |	nca: 2.107501309365034, flat: 3.4389858096837997, pod: 45.48668384552002, loss: 51.0331711769104 
Train [7/26] | Epoch [20/160] |	nca: 2.4244698137044907, flat: 3.625839576125145, pod: 46.36012291908264, loss: 52.41043281555176 
Train [7/26] | Epoch [21/160] |	nca: 2.0370997339487076, flat: 3.429563522338867, pod: 46.05048108100891, loss: 51.517144441604614 
Train [7/26] | Epoch [22/160] |	nca: 2.138586513698101, flat: 3.2930942475795746, pod: 45.06886267662048, loss: 50.50054335594177 
Train [7/26] | Epoch [23/160] |	nca: 2.16652974486351, flat: 3.3401659727096558, pod: 43.823580741882324, loss: 49.33027672767639 
Train [7/26] | Epoch [24/160] |	nca: 2.377801664173603, flat: 3.6515674591064453, pod: 45.685065031051636, loss: 51.71443438529968 
Train [7/26] | Epoch [25/160] |	nca: 2.2675349339842796, flat: 3.3934082239866257, pod: 44.88200378417969, loss: 50.542946577072144 
Train [7/26] | Epoch [26/160] |	nca: 2.798677608370781, flat: 4.497772738337517, pod: 52.03947377204895, loss: 59.33592438697815 
Train [7/26] | Epoch [27/160] |	nca: 2.368119090795517, flat: 3.672646388411522, pod: 46.55147171020508, loss: 52.5922372341156 
Train [7/26] | Epoch [28/160] |	nca: 2.143386386334896, flat: 3.5933657735586166, pod: 45.03805637359619, loss: 50.77480864524841 
Train [7/26] | Epoch [29/160] |	nca: 2.362487331032753, flat: 3.8882672488689423, pod: 46.26877236366272, loss: 52.51952648162842 
Train [7/26] | Epoch [30/160] |	nca: 2.1533104181289673, flat: 3.5807642340660095, pod: 44.97261333465576, loss: 50.706687688827515 
Train [7/26] | Epoch [31/160] |	nca: 1.9623296856880188, flat: 3.1829269379377365, pod: 43.54732608795166, loss: 48.69258236885071 
Train [7/26] | Epoch [32/160] |	nca: 1.9374962374567986, flat: 3.255616620182991, pod: 44.773627519607544, loss: 49.96674060821533 
Train [7/26] | Epoch [33/160] |	nca: 1.8197092488408089, flat: 2.9860508739948273, pod: 42.35121703147888, loss: 47.15697741508484 
Train [7/26] | Epoch [34/160] |	nca: 1.6685158014297485, flat: 3.0364219397306442, pod: 44.063931941986084, loss: 48.76886963844299 
Train [7/26] | Epoch [35/160] |	nca: 1.793098408728838, flat: 2.916917160153389, pod: 42.898945569992065, loss: 47.60896110534668 
Train [7/26] | Epoch [36/160] |	nca: 1.6644504889845848, flat: 2.8954973369836807, pod: 41.330955028533936, loss: 45.89090299606323 
Train [7/26] | Epoch [37/160] |	nca: 1.7709570303559303, flat: 3.0839370787143707, pod: 42.4928457736969, loss: 47.347739696502686 
Train [7/26] | Epoch [38/160] |	nca: 1.8571883849799633, flat: 2.8792003095149994, pod: 42.44635009765625, loss: 47.1827392578125 
Train [7/26] | Epoch [39/160] |	nca: 1.90287209674716, flat: 2.745534412562847, pod: 39.74349570274353, loss: 44.391902685165405 
Train [7/26] | Epoch [40/160] |	nca: 2.217871118336916, flat: 2.8847476691007614, pod: 40.36085319519043, loss: 45.46347212791443 
Train [7/26] | Epoch [41/160] |	nca: 2.5407116003334522, flat: 3.1302559226751328, pod: 42.12321591377258, loss: 47.79418349266052 
Train [7/26] | Epoch [42/160] |	nca: 2.4773150980472565, flat: 3.8624716103076935, pod: 45.43056011199951, loss: 51.770347356796265 
Train [7/26] | Epoch [43/160] |	nca: 1.7677320837974548, flat: 3.2276262044906616, pod: 42.832271099090576, loss: 47.82762908935547 
Train [7/26] | Epoch [44/160] |	nca: 1.6000961028039455, flat: 2.9010413736104965, pod: 41.27276813983917, loss: 45.7739052772522 
Train [7/26] | Epoch [45/160] |	nca: 2.3165158219635487, flat: 2.9943443834781647, pod: 41.859777212142944, loss: 47.170637130737305 
Train [7/26] | Epoch [46/160] |	nca: 1.8767052069306374, flat: 2.998424917459488, pod: 41.274468660354614, loss: 46.149598360061646 
Train [7/26] | Epoch [47/160] |	nca: 2.057506076991558, flat: 3.0341853350400925, pod: 41.94210433959961, loss: 47.03379535675049 
Train [7/26] | Epoch [48/160] |	nca: 1.7529906779527664, flat: 3.095042049884796, pod: 44.07089614868164, loss: 48.9189293384552 
Train [7/26] | Epoch [49/160] |	nca: 1.9373110607266426, flat: 2.877050891518593, pod: 41.295700669288635, loss: 46.11006259918213 
Train [7/26] | Epoch [50/160] |	nca: 1.8441393487155437, flat: 2.846390649676323, pod: 41.4208083152771, loss: 46.11133813858032 
Train [7/26] | Epoch [51/160] |	nca: 1.9656255841255188, flat: 3.0616935342550278, pod: 42.02474117279053, loss: 47.0520601272583 
Train [7/26] | Epoch [52/160] |	nca: 1.6194533556699753, flat: 2.706140898168087, pod: 38.8996901512146, loss: 43.225285053253174 
Train [7/26] | Epoch [53/160] |	nca: 1.684492614120245, flat: 2.4126564860343933, pod: 38.45698821544647, loss: 42.55413770675659 
Train [7/26] | Epoch [54/160] |	nca: 1.3894676454365253, flat: 2.3787608593702316, pod: 37.89427852630615, loss: 41.66250693798065 
Train [7/26] | Epoch [55/160] |	nca: 1.4993321001529694, flat: 2.2588777244091034, pod: 37.6940541267395, loss: 41.452264070510864 
Train [7/26] | Epoch [56/160] |	nca: 1.6674134209752083, flat: 2.247052736580372, pod: 36.634753942489624, loss: 40.54921996593475 
Train [7/26] | Epoch [57/160] |	nca: 1.5482818968594074, flat: 2.405813917517662, pod: 37.40313935279846, loss: 41.357234954833984 
Train [7/26] | Epoch [58/160] |	nca: 1.9447497427463531, flat: 2.5516123101115227, pod: 39.078505516052246, loss: 43.574867486953735 
Train [7/26] | Epoch [59/160] |	nca: 1.4785548523068428, flat: 2.4323349371552467, pod: 37.789472341537476, loss: 41.70036196708679 
Train [7/26] | Epoch [60/160] |	nca: 1.7999030947685242, flat: 2.276357166469097, pod: 37.13196265697479, loss: 41.20822310447693 
Train [7/26] | Epoch [61/160] |	nca: 1.7170099206268787, flat: 2.385840028524399, pod: 37.9139084815979, loss: 42.01675844192505 
Train [7/26] | Epoch [62/160] |	nca: 1.660105638206005, flat: 2.299228347837925, pod: 37.72550845146179, loss: 41.68484282493591 
Train [7/26] | Epoch [63/160] |	nca: 1.3459375724196434, flat: 2.19131226092577, pod: 36.15297985076904, loss: 39.69022989273071 
Train [7/26] | Epoch [64/160] |	nca: 1.5574681237339973, flat: 2.153791159391403, pod: 35.91343021392822, loss: 39.62468910217285 
Train [7/26] | Epoch [65/160] |	nca: 2.0568116158246994, flat: 2.680089183151722, pod: 38.041866064071655, loss: 42.77876687049866 
Train [7/26] | Epoch [66/160] |	nca: 1.5157855674624443, flat: 2.357648104429245, pod: 37.83372950553894, loss: 41.7071635723114 
Train [7/26] | Epoch [67/160] |	nca: 1.4690972939133644, flat: 2.1694052070379257, pod: 36.577677845954895, loss: 40.216180205345154 
Train [7/26] | Epoch [68/160] |	nca: 1.4329383447766304, flat: 1.992474488914013, pod: 34.80779147148132, loss: 38.23320424556732 
Train [7/26] | Epoch [69/160] |	nca: 1.6696952171623707, flat: 2.132927857339382, pod: 35.815698862075806, loss: 39.61832237243652 
Train [7/26] | Epoch [70/160] |	nca: 1.9895083718001842, flat: 2.52286396920681, pod: 38.313594579696655, loss: 42.82596707344055 
Train [7/26] | Epoch [71/160] |	nca: 1.6591365784406662, flat: 2.240159325301647, pod: 34.39723825454712, loss: 38.296534180641174 
Train [7/26] | Epoch [72/160] |	nca: 1.6010847575962543, flat: 2.038881830871105, pod: 33.95497512817383, loss: 37.59494209289551 
Train [7/26] | Epoch [73/160] |	nca: 1.5209800861775875, flat: 2.137320213019848, pod: 35.0217570066452, loss: 38.68005669116974 
Train [7/26] | Epoch [74/160] |	nca: 1.6718839891254902, flat: 2.1194233149290085, pod: 35.79447937011719, loss: 39.58578658103943 
Train [7/26] | Epoch [75/160] |	nca: 1.5570497550070286, flat: 1.9565818011760712, pod: 33.55349802970886, loss: 37.067129015922546 
Train [7/26] | Epoch [76/160] |	nca: 1.6159639433026314, flat: 2.251671813428402, pod: 36.47038507461548, loss: 40.33802080154419 
Train [7/26] | Epoch [77/160] |	nca: 1.6790285892784595, flat: 2.018584318459034, pod: 34.97832679748535, loss: 38.67593991756439 
Train [7/26] | Epoch [78/160] |	nca: 1.6173965334892273, flat: 2.061707764863968, pod: 34.542587757110596, loss: 38.22169208526611 
Train [7/26] | Epoch [79/160] |	nca: 1.4899320974946022, flat: 1.879799485206604, pod: 33.356980323791504, loss: 36.72671186923981 
Train [7/26] | Epoch [80/160] |	nca: 1.5501673966646194, flat: 2.0694916546344757, pod: 34.48592007160187, loss: 38.105578899383545 
Train [7/26] | Epoch [81/160] |	nca: 1.4509696923196316, flat: 1.8778118342161179, pod: 33.15138399600983, loss: 36.480165243148804 
Train [7/26] | Epoch [82/160] |	nca: 1.7189758718013763, flat: 2.083812326192856, pod: 36.44450104236603, loss: 40.247288942337036 
Train [7/26] | Epoch [83/160] |	nca: 1.618912748992443, flat: 1.9579246565699577, pod: 33.48047339916229, loss: 37.057311058044434 
Train [7/26] | Epoch [84/160] |	nca: 1.643680166453123, flat: 1.799605779349804, pod: 31.40727663040161, loss: 34.85056245326996 
Train [7/26] | Epoch [85/160] |	nca: 1.737603459507227, flat: 2.0737226232886314, pod: 34.7428662776947, loss: 38.55419218540192 
Train [7/26] | Epoch [86/160] |	nca: 1.5330549366772175, flat: 1.8055591508746147, pod: 32.04097235202789, loss: 35.37958645820618 
Train [7/26] | Epoch [87/160] |	nca: 1.4908896759152412, flat: 1.762904666364193, pod: 31.452410221099854, loss: 34.706204652786255 
Train [7/26] | Epoch [88/160] |	nca: 1.47032680362463, flat: 1.8872606381773949, pod: 32.286792635917664, loss: 35.64438009262085 
Train [7/26] | Epoch [89/160] |	nca: 1.5043839290738106, flat: 1.689185045659542, pod: 31.12349510192871, loss: 34.31706404685974 
Train [7/26] | Epoch [90/160] |	nca: 1.5047257356345654, flat: 1.6595313027501106, pod: 30.678351163864136, loss: 33.84260833263397 
Train [7/26] | Epoch [91/160] |	nca: 1.6202573031187057, flat: 1.7088275700807571, pod: 31.27373707294464, loss: 34.60282218456268 
Train [7/26] | Epoch [92/160] |	nca: 1.5822158455848694, flat: 1.8290927037596703, pod: 33.625293493270874, loss: 37.03660202026367 
Train [7/26] | Epoch [93/160] |	nca: 1.4318643808364868, flat: 1.6359042823314667, pod: 30.554009914398193, loss: 33.62177860736847 
Train [7/26] | Epoch [94/160] |	nca: 1.3949440605938435, flat: 1.6087095364928246, pod: 29.60380256175995, loss: 32.60745620727539 
Train [7/26] | Epoch [95/160] |	nca: 1.3549779579043388, flat: 1.5538221895694733, pod: 29.746824502944946, loss: 32.65562450885773 
Train [7/26] | Epoch [96/160] |	nca: 1.6725435182452202, flat: 1.6028092727065086, pod: 30.98249578475952, loss: 34.257848501205444 
Train [7/26] | Epoch [97/160] |	nca: 1.733399637043476, flat: 1.6418266296386719, pod: 30.1561119556427, loss: 33.53133797645569 
Train [7/26] | Epoch [98/160] |	nca: 1.4455367401242256, flat: 1.8091979324817657, pod: 31.94317328929901, loss: 35.19790816307068 
Train [7/26] | Epoch [99/160] |	nca: 1.426679752767086, flat: 1.5159587264060974, pod: 29.88012683391571, loss: 32.822765588760376 
Train [7/26] | Epoch [100/160] |	nca: 1.5123908966779709, flat: 1.522084303200245, pod: 29.287027597427368, loss: 32.321502923965454 
Train [7/26] | Epoch [101/160] |	nca: 1.5752447992563248, flat: 1.6267480179667473, pod: 30.22831952571869, loss: 33.430312275886536 
Train [7/26] | Epoch [102/160] |	nca: 1.4447064325213432, flat: 1.4783096835017204, pod: 28.595282435417175, loss: 31.518298506736755 
Train [7/26] | Epoch [103/160] |	nca: 1.22174172103405, flat: 1.501345008611679, pod: 29.146291971206665, loss: 31.869378685951233 
Train [7/26] | Epoch [104/160] |	nca: 1.3307032622396946, flat: 1.3827868178486824, pod: 27.281883358955383, loss: 29.995373487472534 
Train [7/26] | Epoch [105/160] |	nca: 1.5621153563261032, flat: 1.3927109241485596, pod: 28.011435866355896, loss: 30.966262340545654 
Train [7/26] | Epoch [106/160] |	nca: 1.37934784963727, flat: 1.3664948679506779, pod: 27.29893469810486, loss: 30.044777393341064 
Train [7/26] | Epoch [107/160] |	nca: 1.419998086988926, flat: 1.3660661056637764, pod: 27.862948417663574, loss: 30.64901304244995 
Train [7/26] | Epoch [108/160] |	nca: 1.410832792520523, flat: 1.3457098603248596, pod: 27.482929825782776, loss: 30.23947274684906 
Train [7/26] | Epoch [109/160] |	nca: 1.6717605404555798, flat: 1.3929856829345226, pod: 27.60596477985382, loss: 30.670711040496826 
Train [7/26] | Epoch [110/160] |	nca: 1.4549476876854897, flat: 1.393416028469801, pod: 27.764715552330017, loss: 30.61307919025421 
Train [7/26] | Epoch [111/160] |	nca: 1.3676658533513546, flat: 1.2200834043323994, pod: 25.033830285072327, loss: 27.621580004692078 
Train [7/26] | Epoch [112/160] |	nca: 1.357408195734024, flat: 1.3563009724020958, pod: 26.684934496879578, loss: 29.398643732070923 
Train [7/26] | Epoch [113/160] |	nca: 1.4331612400710583, flat: 1.2913225255906582, pod: 26.424569010734558, loss: 29.14905285835266 
Train [7/26] | Epoch [114/160] |	nca: 1.521164681762457, flat: 1.3233488835394382, pod: 27.255988359451294, loss: 30.100502133369446 
Train [7/26] | Epoch [115/160] |	nca: 1.4278868474066257, flat: 1.2083943262696266, pod: 25.307371616363525, loss: 27.943652868270874 
Train [7/26] | Epoch [116/160] |	nca: 1.6032538078725338, flat: 1.327355083078146, pod: 27.441715240478516, loss: 30.372324228286743 
Train [7/26] | Epoch [117/160] |	nca: 1.4755075462162495, flat: 1.3185506910085678, pod: 24.88151490688324, loss: 27.675573110580444 
Train [7/26] | Epoch [118/160] |	nca: 1.3856710754334927, flat: 1.274175450205803, pod: 24.98104155063629, loss: 27.64088809490204 
Train [7/26] | Epoch [119/160] |	nca: 1.4298588745296001, flat: 1.2906133867800236, pod: 26.351357221603394, loss: 29.071829795837402 
Train [7/26] | Epoch [120/160] |	nca: 1.2653907164931297, flat: 1.1036296486854553, pod: 23.12362253665924, loss: 25.492642641067505 
Train [7/26] | Epoch [121/160] |	nca: 1.3922471329569817, flat: 1.1321722753345966, pod: 24.033946752548218, loss: 26.55836582183838 
Train [7/26] | Epoch [122/160] |	nca: 1.314354445785284, flat: 1.1397890523076057, pod: 24.780641317367554, loss: 27.234784483909607 
Train [7/26] | Epoch [123/160] |	nca: 1.3473602309823036, flat: 1.0552867501974106, pod: 24.167839288711548, loss: 26.570486307144165 
Train [7/26] | Epoch [124/160] |	nca: 1.3318455405533314, flat: 1.1707833297550678, pod: 24.134369015693665, loss: 26.636998057365417 
Train [7/26] | Epoch [125/160] |	nca: 1.3338650092482567, flat: 1.0407815054059029, pod: 22.37255883216858, loss: 24.747205138206482 
Train [7/26] | Epoch [126/160] |	nca: 1.3018775582313538, flat: 1.1105821020901203, pod: 24.4540855884552, loss: 26.86654543876648 
Train [7/26] | Epoch [127/160] |	nca: 1.3707808293402195, flat: 0.9808128923177719, pod: 21.99627923965454, loss: 24.347872853279114 
Train [7/26] | Epoch [128/160] |	nca: 1.3150375448167324, flat: 1.0648186653852463, pod: 23.943843722343445, loss: 26.323699831962585 
Train [7/26] | Epoch [129/160] |	nca: 1.3171625100076199, flat: 1.0438660681247711, pod: 22.771924376487732, loss: 25.13295292854309 
Train [7/26] | Epoch [130/160] |	nca: 1.3419023640453815, flat: 0.9703512378036976, pod: 22.012990355491638, loss: 24.325244069099426 
Train [7/26] | Epoch [131/160] |	nca: 1.2439081706106663, flat: 0.9617274440824986, pod: 21.55173110961914, loss: 23.757366716861725 
Train [7/26] | Epoch [132/160] |	nca: 1.2799831070005894, flat: 1.0035995282232761, pod: 23.429540753364563, loss: 25.713123440742493 
Train [7/26] | Epoch [133/160] |	nca: 1.3387884460389614, flat: 0.9139547720551491, pod: 21.36949849128723, loss: 23.622241497039795 
Train [7/26] | Epoch [134/160] |	nca: 1.2543170973658562, flat: 0.9403456896543503, pod: 20.39670604467392, loss: 22.591368794441223 
Train [7/26] | Epoch [135/160] |	nca: 1.214373480528593, flat: 0.8742460645735264, pod: 20.769046902656555, loss: 22.85766637325287 
Train [7/26] | Epoch [136/160] |	nca: 1.4567019790410995, flat: 0.8737700469791889, pod: 20.11541748046875, loss: 22.445889472961426 
Train [7/26] | Epoch [137/160] |	nca: 1.382134709507227, flat: 0.9100214168429375, pod: 21.149866819381714, loss: 23.442022800445557 
Train [7/26] | Epoch [138/160] |	nca: 1.3479361087083817, flat: 0.8998999185860157, pod: 20.486722230911255, loss: 22.73455810546875 
Train [7/26] | Epoch [139/160] |	nca: 1.301121074706316, flat: 0.9705981872975826, pod: 21.29268366098404, loss: 23.56440305709839 
Train [7/26] | Epoch [140/160] |	nca: 1.4158186502754688, flat: 0.8459310457110405, pod: 20.14971536397934, loss: 22.41146492958069 
Train [7/26] | Epoch [141/160] |	nca: 1.3262649364769459, flat: 0.9032702036201954, pod: 20.21997034549713, loss: 22.449505388736725 
Train [7/26] | Epoch [142/160] |	nca: 1.3902473226189613, flat: 0.8861252218484879, pod: 20.059492468833923, loss: 22.335864901542664 
Train [7/26] | Epoch [143/160] |	nca: 1.5109863094985485, flat: 0.8735220916569233, pod: 19.697857320308685, loss: 22.082365810871124 
Train [7/26] | Epoch [144/160] |	nca: 1.4050059095025063, flat: 0.8752903304994106, pod: 20.1003378033638, loss: 22.380633890628815 
Train [7/26] | Epoch [145/160] |	nca: 1.143209770321846, flat: 0.8534196261316538, pod: 19.755291223526, loss: 21.751920521259308 
Train [7/26] | Epoch [146/160] |	nca: 1.3923179619014263, flat: 0.8163334093987942, pod: 19.104946076869965, loss: 21.313597798347473 
Train [7/26] | Epoch [147/160] |	nca: 1.4078054018318653, flat: 0.8845531977713108, pod: 20.37781435251236, loss: 22.670172810554504 
Train [7/26] | Epoch [148/160] |	nca: 1.2694960236549377, flat: 0.8791640661656857, pod: 19.3540478348732, loss: 21.5027077794075 
Train [7/26] | Epoch [149/160] |	nca: 1.3365035876631737, flat: 0.7980379126966, pod: 19.506428241729736, loss: 21.640969574451447 
Train [7/26] | Epoch [150/160] |	nca: 1.2159513011574745, flat: 0.776962760835886, pod: 18.558177649974823, loss: 20.551091730594635 
Train [7/26] | Epoch [151/160] |	nca: 1.2393337674438953, flat: 0.7857841346412897, pod: 17.96957528591156, loss: 19.99469304084778 
Train [7/26] | Epoch [152/160] |	nca: 1.6305782534182072, flat: 0.846704887226224, pod: 19.2865452170372, loss: 21.763828575611115 
Train [7/26] | Epoch [153/160] |	nca: 1.3074140585958958, flat: 0.8100473619997501, pod: 18.97751349210739, loss: 21.09497481584549 
Train [7/26] | Epoch [154/160] |	nca: 1.2777449488639832, flat: 0.8032669387757778, pod: 18.896616399288177, loss: 20.97762829065323 
Train [7/26] | Epoch [155/160] |	nca: 1.2903988435864449, flat: 0.7280468791723251, pod: 17.7332661151886, loss: 19.751711905002594 
Train [7/26] | Epoch [156/160] |	nca: 1.3564332723617554, flat: 0.7939830347895622, pod: 18.028721868991852, loss: 20.17913806438446 
Train [7/26] | Epoch [157/160] |	nca: 1.3680995590984821, flat: 0.7559672445058823, pod: 17.5151549577713, loss: 19.639221668243408 
Train [7/26] | Epoch [158/160] |	nca: 1.3580280393362045, flat: 0.7845570240169764, pod: 18.355170726776123, loss: 20.497755706310272 
Train [7/26] | Epoch [159/160] |	nca: 1.204649519175291, flat: 0.7223597411066294, pod: 17.725691556930542, loss: 19.652701020240784 
Train [7/26] | Epoch [160/160] |	nca: 1.2053372114896774, flat: 0.7672579288482666, pod: 18.515940308570862, loss: 20.4885356426239 
Fine-tuning
Building & updating memory.
Train [7/26] | Epoch [161/180] |	nca: 1.4979135543107986, flat: 1.1662554070353508, pod: 16.885937333106995, loss: 19.550106287002563 
Train [7/26] | Epoch [162/180] |	nca: 0.5465324968099594, flat: 1.1524278447031975, pod: 16.77959144115448, loss: 18.478551506996155 
Train [7/26] | Epoch [163/180] |	nca: 0.5117602460086346, flat: 1.1177256032824516, pod: 16.549689412117004, loss: 18.17917513847351 
Train [7/26] | Epoch [164/180] |	nca: 0.4630199559032917, flat: 1.1001193076372147, pod: 16.480344414711, loss: 18.04348349571228 
Train [7/26] | Epoch [165/180] |	nca: 0.3938194625079632, flat: 1.1268525123596191, pod: 16.879746079444885, loss: 18.400418400764465 
Train [7/26] | Epoch [166/180] |	nca: 0.39909678138792515, flat: 1.1447407379746437, pod: 16.819262623786926, loss: 18.363100171089172 
Train [7/26] | Epoch [167/180] |	nca: 0.3765362575650215, flat: 1.1238004863262177, pod: 16.778932094573975, loss: 18.279268741607666 
Train [7/26] | Epoch [168/180] |	nca: 0.35641089640557766, flat: 1.120949923992157, pod: 16.790067076683044, loss: 18.267427921295166 
Train [7/26] | Epoch [169/180] |	nca: 0.32488126680254936, flat: 1.0792622789740562, pod: 16.239598512649536, loss: 17.643741965293884 
Train [7/26] | Epoch [170/180] |	nca: 0.33123696595430374, flat: 1.1085147708654404, pod: 16.512266516685486, loss: 17.95201826095581 
Train [7/26] | Epoch [171/180] |	nca: 0.2683733385056257, flat: 1.1403892561793327, pod: 16.542161464691162, loss: 17.950924158096313 
Train [7/26] | Epoch [172/180] |	nca: 0.3040611036121845, flat: 1.1129291355609894, pod: 16.591777443885803, loss: 18.00876772403717 
Train [7/26] | Epoch [173/180] |	nca: 0.2982884310185909, flat: 1.119941622018814, pod: 16.567659378051758, loss: 17.985889315605164 
Train [7/26] | Epoch [174/180] |	nca: 0.30323771946132183, flat: 1.1402157172560692, pod: 17.039165377616882, loss: 18.48261868953705 
Train [7/26] | Epoch [175/180] |	nca: 0.30974035896360874, flat: 1.1296836957335472, pod: 16.5136479139328, loss: 17.95307195186615 
Train [7/26] | Epoch [176/180] |	nca: 0.3262676913291216, flat: 1.1980914622545242, pod: 16.749605774879456, loss: 18.27396512031555 
Train [7/26] | Epoch [177/180] |	nca: 0.29831392876803875, flat: 1.1447262540459633, pod: 16.738627433776855, loss: 18.181667685508728 
Train [7/26] | Epoch [178/180] |	nca: 0.3202231340110302, flat: 1.1221397519111633, pod: 16.81296193599701, loss: 18.255324959754944 
Train [7/26] | Epoch [179/180] |	nca: 0.2794174812734127, flat: 1.1117292568087578, pod: 16.599225640296936, loss: 17.99037206172943 
Train [7/26] | Epoch [180/180] |	nca: 0.30329790711402893, flat: 1.1142464503645897, pod: 16.81136190891266, loss: 18.228906273841858 
after task
Building & updating memory.
after task
Eval on 0->62.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.705142857142857.
Current acc: {'total': 0.656, '00-09': 0.683, '10-19': 0.657, '20-29': 0.577, '30-39': 0.599, '40-49': 0.697, '50-59': 0.701, '60-69': 0.765}.
Avg inc acc top5: 0.913142857142857.
Current acc top5: {'total': 0.887}.
Forgetting: 0.009125000000000022.
Cord metric: 0.71.
Old accuracy: 0.65, mean: 0.69.
New accuracy: 0.77, mean: 0.80.
================Task 7 Start!================
Testing on False unseen tasks (max class = 64).
Set memory of size: 1240.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 7 Training!================
The training samples number: 2240
Train on 62->64.
train task
nb 2240.
Train [8/26] | Epoch [1/160] |	nca: 7.222270205616951, flat: 2.9753036126494408, pod: 41.633605003356934, loss: 51.831178188323975 
Train [8/26] | Epoch [2/160] |	nca: 5.386117368936539, flat: 4.42583954334259, pod: 49.87468123435974, loss: 59.686638593673706 
Train [8/26] | Epoch [3/160] |	nca: 4.160479232668877, flat: 4.440981417894363, pod: 52.10559320449829, loss: 60.707053899765015 
Train [8/26] | Epoch [4/160] |	nca: 3.5242752730846405, flat: 3.8403257876634598, pod: 49.176278829574585, loss: 56.54087972640991 
Train [8/26] | Epoch [5/160] |	nca: 2.880990967154503, flat: 3.387335881590843, pod: 46.6032817363739, loss: 52.87160849571228 
Train [8/26] | Epoch [6/160] |	nca: 2.879172183573246, flat: 3.080505669116974, pod: 44.906439542770386, loss: 50.86611723899841 
Train [8/26] | Epoch [7/160] |	nca: 2.919770874083042, flat: 3.2785287648439407, pod: 45.5801100730896, loss: 51.778409242630005 
Train [8/26] | Epoch [8/160] |	nca: 2.744287684559822, flat: 2.9527617841959, pod: 43.29358792304993, loss: 48.99063754081726 
Train [8/26] | Epoch [9/160] |	nca: 2.609089605510235, flat: 3.0699117183685303, pod: 44.278377532958984, loss: 49.95737886428833 
Train [8/26] | Epoch [10/160] |	nca: 2.583305709064007, flat: 2.977671965956688, pod: 42.93479919433594, loss: 48.49577713012695 
Train [8/26] | Epoch [11/160] |	nca: 2.3260642141103745, flat: 3.0032514184713364, pod: 43.25995755195618, loss: 48.58927345275879 
Train [8/26] | Epoch [12/160] |	nca: 2.5450896248221397, flat: 3.020140156149864, pod: 44.40024375915527, loss: 49.96547341346741 
Train [8/26] | Epoch [13/160] |	nca: 2.237204886972904, flat: 2.8142509013414383, pod: 42.44374752044678, loss: 47.49520301818848 
Train [8/26] | Epoch [14/160] |	nca: 2.6053675711154938, flat: 3.175467297434807, pod: 46.663323640823364, loss: 52.44415855407715 
Train [8/26] | Epoch [15/160] |	nca: 2.295516721904278, flat: 2.7358459383249283, pod: 42.667513608932495, loss: 47.69887661933899 
Train [8/26] | Epoch [16/160] |	nca: 2.313539534807205, flat: 2.6046895682811737, pod: 41.330432415008545, loss: 46.248661279678345 
Train [8/26] | Epoch [17/160] |	nca: 2.125758558511734, flat: 2.694284573197365, pod: 40.76162004470825, loss: 45.581663370132446 
Train [8/26] | Epoch [18/160] |	nca: 2.3449936136603355, flat: 2.825618267059326, pod: 41.524415254592896, loss: 46.695027351379395 
Train [8/26] | Epoch [19/160] |	nca: 2.261505536735058, flat: 2.8045280128717422, pod: 44.17111873626709, loss: 49.23715257644653 
Train [8/26] | Epoch [20/160] |	nca: 2.2593929171562195, flat: 2.744348257780075, pod: 43.45015501976013, loss: 48.45389652252197 
Train [8/26] | Epoch [21/160] |	nca: 2.1212668046355247, flat: 2.783452272415161, pod: 41.4345645904541, loss: 46.33928370475769 
Train [8/26] | Epoch [22/160] |	nca: 1.7613631561398506, flat: 2.39093030244112, pod: 39.786518931388855, loss: 43.938812255859375 
Train [8/26] | Epoch [23/160] |	nca: 2.079895056784153, flat: 2.5713921263813972, pod: 41.248295307159424, loss: 45.89958190917969 
Train [8/26] | Epoch [24/160] |	nca: 2.1964025497436523, flat: 2.8507767766714096, pod: 45.71748328208923, loss: 50.764662981033325 
Train [8/26] | Epoch [25/160] |	nca: 1.9887847527861595, flat: 2.6728615015745163, pod: 40.82401657104492, loss: 45.48566246032715 
Train [8/26] | Epoch [26/160] |	nca: 2.121990241110325, flat: 2.5347756519913673, pod: 40.045438289642334, loss: 44.70220422744751 
Train [8/26] | Epoch [27/160] |	nca: 2.3300368413329124, flat: 3.09578038752079, pod: 46.598416805267334, loss: 52.02423453330994 
Train [8/26] | Epoch [28/160] |	nca: 1.873285174369812, flat: 2.9999881982803345, pod: 45.43135166168213, loss: 50.304624795913696 
Train [8/26] | Epoch [29/160] |	nca: 1.945573404431343, flat: 2.562511220574379, pod: 40.67833995819092, loss: 45.18642497062683 
Train [8/26] | Epoch [30/160] |	nca: 2.028525747358799, flat: 2.632799915969372, pod: 40.60583519935608, loss: 45.26716113090515 
Train [8/26] | Epoch [31/160] |	nca: 1.9924024902284145, flat: 2.4232683703303337, pod: 39.17841601371765, loss: 43.59408640861511 
Train [8/26] | Epoch [32/160] |	nca: 1.8648799508810043, flat: 2.442633703351021, pod: 39.57745182514191, loss: 43.884965658187866 
Train [8/26] | Epoch [33/160] |	nca: 1.806048184633255, flat: 2.3315970823168755, pod: 38.38172245025635, loss: 42.51936745643616 
Train [8/26] | Epoch [34/160] |	nca: 1.9944599755108356, flat: 2.3816909044981003, pod: 39.20048272609711, loss: 43.57663345336914 
Train [8/26] | Epoch [35/160] |	nca: 2.085490345954895, flat: 2.4446114376187325, pod: 39.443429470062256, loss: 43.97353148460388 
Train [8/26] | Epoch [36/160] |	nca: 1.915595255792141, flat: 2.627309277653694, pod: 40.555076360702515, loss: 45.09798073768616 
Train [8/26] | Epoch [37/160] |	nca: 1.8507162854075432, flat: 2.6754342019557953, pod: 42.25640082359314, loss: 46.782551527023315 
Train [8/26] | Epoch [38/160] |	nca: 1.7568681612610817, flat: 2.257362022995949, pod: 37.82430863380432, loss: 41.838538646698 
Train [8/26] | Epoch [39/160] |	nca: 2.028104282915592, flat: 2.1741215139627457, pod: 36.58408451080322, loss: 40.78631019592285 
Train [8/26] | Epoch [40/160] |	nca: 1.8851432725787163, flat: 2.368210405111313, pod: 38.40482199192047, loss: 42.6581757068634 
Train [8/26] | Epoch [41/160] |	nca: 1.965879887342453, flat: 2.503050208091736, pod: 40.12769854068756, loss: 44.59662914276123 
Train [8/26] | Epoch [42/160] |	nca: 1.847755428403616, flat: 2.455953724682331, pod: 41.24970006942749, loss: 45.55340933799744 
Train [8/26] | Epoch [43/160] |	nca: 1.9371335618197918, flat: 2.4259932339191437, pod: 39.23355722427368, loss: 43.596684217453 
Train [8/26] | Epoch [44/160] |	nca: 1.7396886125206947, flat: 2.1852678060531616, pod: 37.927205204963684, loss: 41.85216164588928 
Train [8/26] | Epoch [45/160] |	nca: 2.0775128081440926, flat: 2.399622358381748, pod: 39.90002775192261, loss: 44.37716293334961 
Train [8/26] | Epoch [46/160] |	nca: 2.2062918841838837, flat: 2.4236977845430374, pod: 40.2650728225708, loss: 44.89506244659424 
Train [8/26] | Epoch [47/160] |	nca: 2.1596209183335304, flat: 2.7953421026468277, pod: 42.106086015701294, loss: 47.06104922294617 
Train [8/26] | Epoch [48/160] |	nca: 1.982221357524395, flat: 2.6380998119711876, pod: 42.045501947402954, loss: 46.665823221206665 
Train [8/26] | Epoch [49/160] |	nca: 1.7207438200712204, flat: 2.3046805113554, pod: 37.74403989315033, loss: 41.76946425437927 
Train [8/26] | Epoch [50/160] |	nca: 1.8525829166173935, flat: 2.1744903698563576, pod: 36.92496931552887, loss: 40.95204257965088 
Train [8/26] | Epoch [51/160] |	nca: 1.639054037630558, flat: 2.026422195136547, pod: 36.015430331230164, loss: 39.680906534194946 
Train [8/26] | Epoch [52/160] |	nca: 1.7992204539477825, flat: 2.024617522954941, pod: 36.79951620101929, loss: 40.62335395812988 
Train [8/26] | Epoch [53/160] |	nca: 1.834249086678028, flat: 2.144256442785263, pod: 36.9758425951004, loss: 40.95434832572937 
Train [8/26] | Epoch [54/160] |	nca: 1.9531554207205772, flat: 2.2299058586359024, pod: 37.91638720035553, loss: 42.099448919296265 
Train [8/26] | Epoch [55/160] |	nca: 1.5344265289604664, flat: 2.0448875799775124, pod: 35.634814500808716, loss: 39.214128255844116 
Train [8/26] | Epoch [56/160] |	nca: 1.621737189590931, flat: 1.8548131361603737, pod: 33.735509514808655, loss: 37.21205973625183 
Train [8/26] | Epoch [57/160] |	nca: 1.604820765554905, flat: 1.9824548065662384, pod: 35.91506230831146, loss: 39.50233769416809 
Train [8/26] | Epoch [58/160] |	nca: 1.8069623038172722, flat: 1.914992794394493, pod: 35.143634557724, loss: 38.86559009552002 
Train [8/26] | Epoch [59/160] |	nca: 1.7309395223855972, flat: 2.1484782323241234, pod: 37.01493847370148, loss: 40.89435601234436 
Train [8/26] | Epoch [60/160] |	nca: 2.027869835495949, flat: 2.1532780304551125, pod: 36.67893636226654, loss: 40.86008381843567 
Train [8/26] | Epoch [61/160] |	nca: 1.6478948518633842, flat: 2.173352561891079, pod: 36.79546761512756, loss: 40.61671423912048 
Train [8/26] | Epoch [62/160] |	nca: 1.8436083868145943, flat: 2.0075871869921684, pod: 35.4515745639801, loss: 39.302770256996155 
Train [8/26] | Epoch [63/160] |	nca: 1.627232402563095, flat: 1.881594955921173, pod: 34.45516359806061, loss: 37.963990926742554 
Train [8/26] | Epoch [64/160] |	nca: 1.4963847696781158, flat: 1.8730039447546005, pod: 34.87995636463165, loss: 38.24934506416321 
Train [8/26] | Epoch [65/160] |	nca: 1.6420339718461037, flat: 1.9776884987950325, pod: 37.47311174869537, loss: 41.09283471107483 
Train [8/26] | Epoch [66/160] |	nca: 1.6466423645615578, flat: 1.7476216927170753, pod: 33.70488381385803, loss: 37.09914803504944 
Train [8/26] | Epoch [67/160] |	nca: 1.7256213501095772, flat: 1.8943290784955025, pod: 34.5505211353302, loss: 38.17047154903412 
Train [8/26] | Epoch [68/160] |	nca: 1.553679183125496, flat: 1.9442901611328125, pod: 34.84324085712433, loss: 38.34121000766754 
Train [8/26] | Epoch [69/160] |	nca: 1.7558535411953926, flat: 1.7998631745576859, pod: 34.031805872917175, loss: 37.587523102760315 
Train [8/26] | Epoch [70/160] |	nca: 1.7685339972376823, flat: 1.8564676195383072, pod: 35.148608684539795, loss: 38.77361059188843 
Train [8/26] | Epoch [71/160] |	nca: 1.756976068019867, flat: 1.9583497196435928, pod: 35.03579878807068, loss: 38.751123785972595 
Train [8/26] | Epoch [72/160] |	nca: 1.5336283072829247, flat: 1.7403712049126625, pod: 32.64287626743317, loss: 35.91687560081482 
Train [8/26] | Epoch [73/160] |	nca: 1.7219509147107601, flat: 1.756463699042797, pod: 33.676331639289856, loss: 37.154746294021606 
Train [8/26] | Epoch [74/160] |	nca: 1.8187798969447613, flat: 1.9684876427054405, pod: 35.2957900762558, loss: 39.08305764198303 
Train [8/26] | Epoch [75/160] |	nca: 1.843350414186716, flat: 1.948158212006092, pod: 34.444883584976196, loss: 38.23639214038849 
Train [8/26] | Epoch [76/160] |	nca: 1.53499398753047, flat: 1.7032707631587982, pod: 32.647579312324524, loss: 35.885844588279724 
Train [8/26] | Epoch [77/160] |	nca: 1.5227120593190193, flat: 1.6236176416277885, pod: 31.77116870880127, loss: 34.91749846935272 
Train [8/26] | Epoch [78/160] |	nca: 1.6110993921756744, flat: 1.785875342786312, pod: 33.6243554353714, loss: 37.02133023738861 
Train [8/26] | Epoch [79/160] |	nca: 1.5869530141353607, flat: 1.677843302488327, pod: 32.387784242630005, loss: 35.65258073806763 
Train [8/26] | Epoch [80/160] |	nca: 1.6051982194185257, flat: 1.6391780972480774, pod: 32.15165674686432, loss: 35.39603269100189 
Train [8/26] | Epoch [81/160] |	nca: 1.557972889393568, flat: 1.5247806385159492, pod: 30.68695819377899, loss: 33.7697114944458 
Train [8/26] | Epoch [82/160] |	nca: 1.738135613501072, flat: 1.6440030634403229, pod: 31.895008444786072, loss: 35.27714693546295 
Train [8/26] | Epoch [83/160] |	nca: 1.6279392465949059, flat: 1.7208025008440018, pod: 32.39669644832611, loss: 35.74543797969818 
Train [8/26] | Epoch [84/160] |	nca: 1.5565813034772873, flat: 1.6595812663435936, pod: 32.773056626319885, loss: 35.989218950271606 
Train [8/26] | Epoch [85/160] |	nca: 1.477593295276165, flat: 1.5360876694321632, pod: 30.61248540878296, loss: 33.626166582107544 
Train [8/26] | Epoch [86/160] |	nca: 1.4780798591673374, flat: 1.476473294198513, pod: 30.773257970809937, loss: 33.727811217308044 
Train [8/26] | Epoch [87/160] |	nca: 1.5902961529791355, flat: 1.4468830525875092, pod: 29.906216740608215, loss: 32.94339573383331 
Train [8/26] | Epoch [88/160] |	nca: 1.5427484698593616, flat: 1.516011081635952, pod: 29.850505590438843, loss: 32.90926504135132 
Train [8/26] | Epoch [89/160] |	nca: 1.432458534836769, flat: 1.3978260308504105, pod: 29.821475386619568, loss: 32.65176010131836 
Train [8/26] | Epoch [90/160] |	nca: 1.7496392577886581, flat: 1.4075267165899277, pod: 29.140631437301636, loss: 32.297797322273254 
Train [8/26] | Epoch [91/160] |	nca: 1.458311129361391, flat: 1.4336657971143723, pod: 30.376081585884094, loss: 33.26805889606476 
Train [8/26] | Epoch [92/160] |	nca: 1.608666218817234, flat: 1.4452395103871822, pod: 29.800087571144104, loss: 32.85399317741394 
Train [8/26] | Epoch [93/160] |	nca: 1.4740047045052052, flat: 1.4518628753721714, pod: 29.742369174957275, loss: 32.66823637485504 
Train [8/26] | Epoch [94/160] |	nca: 1.4331349357962608, flat: 1.3138350695371628, pod: 29.226471185684204, loss: 31.97344136238098 
Train [8/26] | Epoch [95/160] |	nca: 1.5578486919403076, flat: 1.32992734760046, pod: 28.643365383148193, loss: 31.53114151954651 
Train [8/26] | Epoch [96/160] |	nca: 1.5754021108150482, flat: 1.2207029834389687, pod: 26.733806371688843, loss: 29.529911398887634 
Train [8/26] | Epoch [97/160] |	nca: 1.4741902314126492, flat: 1.3720738515257835, pod: 29.376486778259277, loss: 32.222750782966614 
Train [8/26] | Epoch [98/160] |	nca: 1.5679812915623188, flat: 1.3393305912613869, pod: 29.308646202087402, loss: 32.21595788002014 
Train [8/26] | Epoch [99/160] |	nca: 1.583542138338089, flat: 1.3834474682807922, pod: 29.42305612564087, loss: 32.39004588127136 
Train [8/26] | Epoch [100/160] |	nca: 1.339447308331728, flat: 1.262632042169571, pod: 28.030819416046143, loss: 30.632898926734924 
Train [8/26] | Epoch [101/160] |	nca: 1.4308603405952454, flat: 1.3594634383916855, pod: 28.783188462257385, loss: 31.573512315750122 
Train [8/26] | Epoch [102/160] |	nca: 1.423928290605545, flat: 1.2231110408902168, pod: 26.397159457206726, loss: 29.044198989868164 
Train [8/26] | Epoch [103/160] |	nca: 1.4975282698869705, flat: 1.1377937234938145, pod: 25.97115683555603, loss: 28.606478929519653 
Train [8/26] | Epoch [104/160] |	nca: 1.5034392848610878, flat: 1.2210704907774925, pod: 26.938305139541626, loss: 29.66281497478485 
Train [8/26] | Epoch [105/160] |	nca: 1.4005970619618893, flat: 1.2487586662173271, pod: 27.958977580070496, loss: 30.608333349227905 
Train [8/26] | Epoch [106/160] |	nca: 1.4128836952149868, flat: 1.130937360227108, pod: 26.26126456260681, loss: 28.80508542060852 
Train [8/26] | Epoch [107/160] |	nca: 1.502027165144682, flat: 1.1207778416574001, pod: 25.47537910938263, loss: 28.09818434715271 
Train [8/26] | Epoch [108/160] |	nca: 1.5478564612567425, flat: 1.0865202993154526, pod: 24.680163145065308, loss: 27.314539790153503 
Train [8/26] | Epoch [109/160] |	nca: 1.6709501259028912, flat: 1.1661383211612701, pod: 26.32689332962036, loss: 29.163981795310974 
Train [8/26] | Epoch [110/160] |	nca: 1.2611378394067287, flat: 1.0972789414227009, pod: 25.921096086502075, loss: 28.279512882232666 
Train [8/26] | Epoch [111/160] |	nca: 1.5231418833136559, flat: 1.1664390340447426, pod: 26.19953465461731, loss: 28.889115691184998 
Train [8/26] | Epoch [112/160] |	nca: 1.4775581285357475, flat: 1.1444213427603245, pod: 25.483993649482727, loss: 28.10597336292267 
Train [8/26] | Epoch [113/160] |	nca: 1.7177695631980896, flat: 1.1818453520536423, pod: 26.34562885761261, loss: 29.245244026184082 
Train [8/26] | Epoch [114/160] |	nca: 1.3632201813161373, flat: 1.0454963818192482, pod: 24.653802275657654, loss: 27.06251895427704 
Train [8/26] | Epoch [115/160] |	nca: 1.6092913150787354, flat: 1.0138569436967373, pod: 23.552477478981018, loss: 26.175625920295715 
Train [8/26] | Epoch [116/160] |	nca: 1.4703782238066196, flat: 1.0690990649163723, pod: 23.899224638938904, loss: 26.43870222568512 
Train [8/26] | Epoch [117/160] |	nca: 1.2777720391750336, flat: 1.0281929299235344, pod: 25.279754161834717, loss: 27.585718989372253 
Train [8/26] | Epoch [118/160] |	nca: 1.4932716563344002, flat: 0.9741755537688732, pod: 23.275519847869873, loss: 25.74296724796295 
Train [8/26] | Epoch [119/160] |	nca: 1.3519982658326626, flat: 0.9295828603208065, pod: 22.55448853969574, loss: 24.836069583892822 
Train [8/26] | Epoch [120/160] |	nca: 1.3399202711880207, flat: 0.9476218111813068, pod: 23.173575401306152, loss: 25.461117386817932 
Train [8/26] | Epoch [121/160] |	nca: 1.4613265693187714, flat: 0.9142566472291946, pod: 22.714062690734863, loss: 25.089645743370056 
Train [8/26] | Epoch [122/160] |	nca: 1.3630262836813927, flat: 0.9599377885460854, pod: 23.78897786140442, loss: 26.111942052841187 
Train [8/26] | Epoch [123/160] |	nca: 1.4444435127079487, flat: 0.9514538049697876, pod: 23.42228126525879, loss: 25.818178415298462 
Train [8/26] | Epoch [124/160] |	nca: 1.3753719590604305, flat: 0.8678143434226513, pod: 21.86799728870392, loss: 24.111183285713196 
Train [8/26] | Epoch [125/160] |	nca: 1.410165462642908, flat: 0.8682302534580231, pod: 22.019770979881287, loss: 24.298166871070862 
Train [8/26] | Epoch [126/160] |	nca: 1.6731025278568268, flat: 0.9244805350899696, pod: 21.736053943634033, loss: 24.33363699913025 
Train [8/26] | Epoch [127/160] |	nca: 1.2523501105606556, flat: 0.8711796589195728, pod: 21.385047435760498, loss: 23.508577346801758 
Train [8/26] | Epoch [128/160] |	nca: 1.4364543929696083, flat: 0.8861183151602745, pod: 21.56864732503891, loss: 23.891220092773438 
Train [8/26] | Epoch [129/160] |	nca: 1.42721102014184, flat: 0.866263285279274, pod: 21.971931993961334, loss: 24.265406012535095 
Train [8/26] | Epoch [130/160] |	nca: 1.3770748041570187, flat: 0.8635073788464069, pod: 21.72082006931305, loss: 23.96140217781067 
Train [8/26] | Epoch [131/160] |	nca: 1.3682428300380707, flat: 0.8778191395103931, pod: 21.744008898735046, loss: 23.990070819854736 
Train [8/26] | Epoch [132/160] |	nca: 1.394070390611887, flat: 0.7490284722298384, pod: 20.54138892889023, loss: 22.68448781967163 
Train [8/26] | Epoch [133/160] |	nca: 1.5006564185023308, flat: 0.8037870451807976, pod: 20.926103055477142, loss: 23.230546832084656 
Train [8/26] | Epoch [134/160] |	nca: 1.373068880289793, flat: 0.7794840410351753, pod: 20.386299788951874, loss: 22.53885269165039 
Train [8/26] | Epoch [135/160] |	nca: 1.475580956786871, flat: 0.7640597466379404, pod: 19.24016696214676, loss: 21.47980761528015 
Train [8/26] | Epoch [136/160] |	nca: 1.4771675057709217, flat: 0.791185762733221, pod: 19.709622144699097, loss: 21.9779754281044 
Train [8/26] | Epoch [137/160] |	nca: 1.334322601556778, flat: 0.8202890418469906, pod: 21.001549065113068, loss: 23.156160712242126 
Train [8/26] | Epoch [138/160] |	nca: 1.4218675829470158, flat: 0.7275230456143618, pod: 19.39749985933304, loss: 21.546890377998352 
Train [8/26] | Epoch [139/160] |	nca: 1.3864062167704105, flat: 0.7556022368371487, pod: 20.067430436611176, loss: 22.209438681602478 
Train [8/26] | Epoch [140/160] |	nca: 1.3166608288884163, flat: 0.7830802109092474, pod: 19.959360778331757, loss: 22.05910176038742 
Train [8/26] | Epoch [141/160] |	nca: 1.3942898362874985, flat: 0.701610554009676, pod: 18.887238681316376, loss: 20.983139038085938 
Train [8/26] | Epoch [142/160] |	nca: 1.3768278807401657, flat: 0.7776316236704588, pod: 20.852842807769775, loss: 23.007302045822144 
Train [8/26] | Epoch [143/160] |	nca: 1.3772590979933739, flat: 0.7188951577991247, pod: 19.002431869506836, loss: 21.098586201667786 
Train [8/26] | Epoch [144/160] |	nca: 1.3609099015593529, flat: 0.7198891695588827, pod: 18.395805716514587, loss: 20.476604878902435 
Train [8/26] | Epoch [145/160] |	nca: 1.272771243005991, flat: 0.6896196343004704, pod: 19.23078590631485, loss: 21.193176746368408 
Train [8/26] | Epoch [146/160] |	nca: 1.3982519283890724, flat: 0.7363039031624794, pod: 19.24398010969162, loss: 21.378536105155945 
Train [8/26] | Epoch [147/160] |	nca: 1.3001355566084385, flat: 0.6751057524234056, pod: 18.782670378684998, loss: 20.757911801338196 
Train [8/26] | Epoch [148/160] |	nca: 1.5137304216623306, flat: 0.7209985256195068, pod: 19.661558091640472, loss: 21.896286845207214 
Train [8/26] | Epoch [149/160] |	nca: 1.423386238515377, flat: 0.7007765583693981, pod: 19.32190978527069, loss: 21.44607263803482 
Train [8/26] | Epoch [150/160] |	nca: 1.3223658464848995, flat: 0.6896071713417768, pod: 18.15080237388611, loss: 20.16277539730072 
Train [8/26] | Epoch [151/160] |	nca: 1.3946397937834263, flat: 0.6722791250795126, pod: 17.703323364257812, loss: 19.770242273807526 
Train [8/26] | Epoch [152/160] |	nca: 1.436647653579712, flat: 0.626561913639307, pod: 17.530731737613678, loss: 19.59394121170044 
Train [8/26] | Epoch [153/160] |	nca: 1.3973113186657429, flat: 0.6803947649896145, pod: 17.59218841791153, loss: 19.669894456863403 
Train [8/26] | Epoch [154/160] |	nca: 1.2810633853077888, flat: 0.6335839182138443, pod: 17.175539016723633, loss: 19.09018647670746 
Train [8/26] | Epoch [155/160] |	nca: 1.3636607974767685, flat: 0.635190274566412, pod: 17.659644067287445, loss: 19.658495128154755 
Train [8/26] | Epoch [156/160] |	nca: 1.360346857458353, flat: 0.5764236282557249, pod: 16.71611189842224, loss: 18.65288245677948 
Train [8/26] | Epoch [157/160] |	nca: 1.4091175943613052, flat: 0.7011107578873634, pod: 18.459278404712677, loss: 20.569506883621216 
Train [8/26] | Epoch [158/160] |	nca: 1.3527125641703606, flat: 0.6302045192569494, pod: 17.13385361433029, loss: 19.116770565509796 
Train [8/26] | Epoch [159/160] |	nca: 1.424176998436451, flat: 0.6605554167181253, pod: 17.969409227371216, loss: 20.054141759872437 
Train [8/26] | Epoch [160/160] |	nca: 1.3684538267552853, flat: 0.62626101821661, pod: 17.098731577396393, loss: 19.093446254730225 
Fine-tuning
Building & updating memory.
Train [8/26] | Epoch [161/180] |	nca: 1.5841991677880287, flat: 1.1143295541405678, pod: 17.468917846679688, loss: 20.167446970939636 
Train [8/26] | Epoch [162/180] |	nca: 0.6257127709686756, flat: 1.1223127990961075, pod: 17.516155004501343, loss: 19.264180421829224 
Train [8/26] | Epoch [163/180] |	nca: 0.6192615628242493, flat: 1.1336678341031075, pod: 17.53189969062805, loss: 19.284829258918762 
Train [8/26] | Epoch [164/180] |	nca: 0.4822476767003536, flat: 1.13421630859375, pod: 17.597236275672913, loss: 19.21370041370392 
Train [8/26] | Epoch [165/180] |	nca: 0.4568320866674185, flat: 1.1764659583568573, pod: 17.59182357788086, loss: 19.22512173652649 
Train [8/26] | Epoch [166/180] |	nca: 0.4505793824791908, flat: 1.1134311854839325, pod: 17.379892230033875, loss: 18.943902611732483 
Train [8/26] | Epoch [167/180] |	nca: 0.40042486786842346, flat: 1.151243269443512, pod: 17.542845129966736, loss: 19.094513416290283 
Train [8/26] | Epoch [168/180] |	nca: 0.419389208778739, flat: 1.133139245212078, pod: 17.718233108520508, loss: 19.270761728286743 
Train [8/26] | Epoch [169/180] |	nca: 0.39446399360895157, flat: 1.1636303290724754, pod: 18.27374291419983, loss: 19.83183717727661 
Train [8/26] | Epoch [170/180] |	nca: 0.40173637494444847, flat: 1.1532988995313644, pod: 17.755728840827942, loss: 19.310763835906982 
Train [8/26] | Epoch [171/180] |	nca: 0.42031630128622055, flat: 1.101691909134388, pod: 17.445074677467346, loss: 18.967082858085632 
Train [8/26] | Epoch [172/180] |	nca: 0.40982868894934654, flat: 1.1477093547582626, pod: 17.727651476860046, loss: 19.285189390182495 
Train [8/26] | Epoch [173/180] |	nca: 0.36264681071043015, flat: 1.1163649931550026, pod: 17.487524271011353, loss: 18.966536164283752 
Train [8/26] | Epoch [174/180] |	nca: 0.3530623707920313, flat: 1.1885697320103645, pod: 18.007732629776, loss: 19.54936456680298 
Train [8/26] | Epoch [175/180] |	nca: 0.33154853247106075, flat: 1.1195619329810143, pod: 17.406627416610718, loss: 18.85773801803589 
Train [8/26] | Epoch [176/180] |	nca: 0.3444411586970091, flat: 1.175454005599022, pod: 17.88363552093506, loss: 19.403530597686768 
Train [8/26] | Epoch [177/180] |	nca: 0.3432519994676113, flat: 1.13461085408926, pod: 17.512585043907166, loss: 18.990447878837585 
Train [8/26] | Epoch [178/180] |	nca: 0.3821660354733467, flat: 1.1502850651741028, pod: 17.728264093399048, loss: 19.260715126991272 
Train [8/26] | Epoch [179/180] |	nca: 0.34128732420504093, flat: 1.1695749759674072, pod: 17.96540904045105, loss: 19.476271271705627 
Train [8/26] | Epoch [180/180] |	nca: 0.34648388996720314, flat: 1.1361393630504608, pod: 17.616132259368896, loss: 19.098755478858948 
after task
Building & updating memory.
after task
Eval on 0->64.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6972499999999999.
Current acc: {'total': 0.642, '00-09': 0.688, '10-19': 0.631, '20-29': 0.565, '30-39': 0.578, '40-49': 0.689, '50-59': 0.698, '60-69': 0.642}.
Avg inc acc top5: 0.9092499999999999.
Current acc top5: {'total': 0.882}.
Forgetting: 0.12825000000000003.
Cord metric: 0.70.
Old accuracy: 0.64, mean: 0.68.
New accuracy: 0.71, mean: 0.79.
================Task 8 Start!================
Testing on False unseen tasks (max class = 66).
Set memory of size: 1280.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 8 Training!================
The training samples number: 2280
Train on 64->66.
train task
nb 2280.
Train [9/26] | Epoch [1/160] |	nca: 8.546974390745163, flat: 3.5894940346479416, pod: 42.99540996551514, loss: 55.13187885284424 
Train [9/26] | Epoch [2/160] |	nca: 5.179396346211433, flat: 4.842170774936676, pod: 51.788774728775024, loss: 61.81034278869629 
Train [9/26] | Epoch [3/160] |	nca: 4.386612683534622, flat: 4.471131861209869, pod: 49.70996642112732, loss: 58.56771111488342 
Train [9/26] | Epoch [4/160] |	nca: 3.4370104372501373, flat: 3.8327590227127075, pod: 48.93662118911743, loss: 56.20639109611511 
Train [9/26] | Epoch [5/160] |	nca: 3.0084810480475426, flat: 3.3043372184038162, pod: 44.36241841316223, loss: 50.67523646354675 
Train [9/26] | Epoch [6/160] |	nca: 2.8695054948329926, flat: 3.1213313937187195, pod: 44.69286274909973, loss: 50.68369913101196 
Train [9/26] | Epoch [7/160] |	nca: 2.691395126283169, flat: 3.1841783821582794, pod: 44.66569471359253, loss: 50.54126858711243 
Train [9/26] | Epoch [8/160] |	nca: 2.5181232541799545, flat: 2.919134736061096, pod: 42.58911728858948, loss: 48.02637481689453 
Train [9/26] | Epoch [9/160] |	nca: 2.536767892539501, flat: 2.7912653535604477, pod: 40.39692234992981, loss: 45.724955797195435 
Train [9/26] | Epoch [10/160] |	nca: 2.3341188430786133, flat: 2.891755238175392, pod: 43.32613801956177, loss: 48.55201268196106 
Train [9/26] | Epoch [11/160] |	nca: 2.3877802677452564, flat: 2.9462197721004486, pod: 43.208322525024414, loss: 48.542322397232056 
Train [9/26] | Epoch [12/160] |	nca: 2.2847294062376022, flat: 2.813633158802986, pod: 42.24417805671692, loss: 47.34254050254822 
Train [9/26] | Epoch [13/160] |	nca: 2.255566291511059, flat: 2.7019805163145065, pod: 40.89672613143921, loss: 45.85427379608154 
Train [9/26] | Epoch [14/160] |	nca: 2.1996993720531464, flat: 2.7458217591047287, pod: 41.577688455581665, loss: 46.5232093334198 
Train [9/26] | Epoch [15/160] |	nca: 2.3999834805727005, flat: 2.670728027820587, pod: 41.48397254943848, loss: 46.55468416213989 
Train [9/26] | Epoch [16/160] |	nca: 2.2985243648290634, flat: 2.658238723874092, pod: 40.611939668655396, loss: 45.56870245933533 
Train [9/26] | Epoch [17/160] |	nca: 2.0192707255482674, flat: 2.5379992574453354, pod: 40.139716148376465, loss: 44.69698619842529 
Train [9/26] | Epoch [18/160] |	nca: 2.4919739365577698, flat: 2.931923598051071, pod: 44.42116022109985, loss: 49.845057249069214 
Train [9/26] | Epoch [19/160] |	nca: 2.2983665242791176, flat: 2.8363329470157623, pod: 42.716360569000244, loss: 47.85106015205383 
Train [9/26] | Epoch [20/160] |	nca: 2.168470621109009, flat: 2.7978392243385315, pod: 42.35667109489441, loss: 47.322980642318726 
Train [9/26] | Epoch [21/160] |	nca: 2.079570032656193, flat: 2.5200365036726, pod: 40.28288459777832, loss: 44.88249158859253 
Train [9/26] | Epoch [22/160] |	nca: 2.2627357989549637, flat: 2.8369759023189545, pod: 42.508768796920776, loss: 47.60848045349121 
Train [9/26] | Epoch [23/160] |	nca: 2.2058664187788963, flat: 2.704382002353668, pod: 40.98055362701416, loss: 45.89080214500427 
Train [9/26] | Epoch [24/160] |	nca: 1.8411236964166164, flat: 2.390954203903675, pod: 38.08263421058655, loss: 42.314712047576904 
Train [9/26] | Epoch [25/160] |	nca: 1.9778473675251007, flat: 2.271330066025257, pod: 37.84280455112457, loss: 42.09198212623596 
Train [9/26] | Epoch [26/160] |	nca: 2.216065589338541, flat: 2.6361332088708878, pod: 41.97325253486633, loss: 46.82545185089111 
Train [9/26] | Epoch [27/160] |	nca: 1.8520213067531586, flat: 2.6161860525608063, pod: 41.41250729560852, loss: 45.880714893341064 
Train [9/26] | Epoch [28/160] |	nca: 1.9948129951953888, flat: 2.2422829642891884, pod: 37.25953996181488, loss: 41.496636152267456 
Train [9/26] | Epoch [29/160] |	nca: 1.9561738185584545, flat: 2.209146238863468, pod: 36.779372215270996, loss: 40.94469165802002 
Train [9/26] | Epoch [30/160] |	nca: 2.105388715863228, flat: 2.642104648053646, pod: 40.8783757686615, loss: 45.62586951255798 
Train [9/26] | Epoch [31/160] |	nca: 1.957784079015255, flat: 2.6259117498993874, pod: 40.30041253566742, loss: 44.884108543395996 
Train [9/26] | Epoch [32/160] |	nca: 2.3021841794252396, flat: 2.582472860813141, pod: 39.49443864822388, loss: 44.379096031188965 
Train [9/26] | Epoch [33/160] |	nca: 1.865142360329628, flat: 2.4066748917102814, pod: 38.744176030159, loss: 43.01599335670471 
Train [9/26] | Epoch [34/160] |	nca: 1.862983115017414, flat: 2.310883328318596, pod: 37.57788276672363, loss: 41.75174927711487 
Train [9/26] | Epoch [35/160] |	nca: 1.9966902658343315, flat: 2.3203495740890503, pod: 38.37635159492493, loss: 42.6933913230896 
Train [9/26] | Epoch [36/160] |	nca: 1.7464685589075089, flat: 2.2161523774266243, pod: 37.06897783279419, loss: 41.031598806381226 
Train [9/26] | Epoch [37/160] |	nca: 1.9333580806851387, flat: 2.333392061293125, pod: 39.012452125549316, loss: 43.2792022228241 
Train [9/26] | Epoch [38/160] |	nca: 1.7391340509057045, flat: 2.120108500123024, pod: 36.637078642845154, loss: 40.496320962905884 
Train [9/26] | Epoch [39/160] |	nca: 1.8995736092329025, flat: 2.217884063720703, pod: 37.397804379463196, loss: 41.51526165008545 
Train [9/26] | Epoch [40/160] |	nca: 1.8393318057060242, flat: 2.2175847738981247, pod: 37.12314784526825, loss: 41.18006420135498 
Train [9/26] | Epoch [41/160] |	nca: 2.0122945606708527, flat: 2.208627238869667, pod: 37.751936078071594, loss: 41.97285747528076 
Train [9/26] | Epoch [42/160] |	nca: 1.8014526814222336, flat: 2.340069830417633, pod: 38.91400992870331, loss: 43.05553197860718 
Train [9/26] | Epoch [43/160] |	nca: 2.08451035246253, flat: 2.3232306987047195, pod: 38.27920973300934, loss: 42.68695068359375 
Train [9/26] | Epoch [44/160] |	nca: 1.8887170180678368, flat: 2.3340667337179184, pod: 38.077207922935486, loss: 42.29999136924744 
Train [9/26] | Epoch [45/160] |	nca: 1.907400269061327, flat: 2.214670702815056, pod: 36.7913533449173, loss: 40.913424253463745 
Train [9/26] | Epoch [46/160] |	nca: 1.8229838386178017, flat: 2.1625619381666183, pod: 36.576544404029846, loss: 40.562089920043945 
Train [9/26] | Epoch [47/160] |	nca: 1.8989477381110191, flat: 2.0456113666296005, pod: 35.66254901885986, loss: 39.60710787773132 
Train [9/26] | Epoch [48/160] |	nca: 1.9202351048588753, flat: 2.2509941309690475, pod: 37.614381074905396, loss: 41.78561019897461 
Train [9/26] | Epoch [49/160] |	nca: 2.1379110515117645, flat: 2.3877850025892258, pod: 38.209282994270325, loss: 42.734978675842285 
Train [9/26] | Epoch [50/160] |	nca: 1.8255503475666046, flat: 2.176875412464142, pod: 35.8007071018219, loss: 39.80313277244568 
Train [9/26] | Epoch [51/160] |	nca: 1.5024646408855915, flat: 1.9863726869225502, pod: 35.48171925544739, loss: 38.97055625915527 
Train [9/26] | Epoch [52/160] |	nca: 1.8903605714440346, flat: 1.9977440312504768, pod: 34.993849873542786, loss: 38.88195490837097 
Train [9/26] | Epoch [53/160] |	nca: 1.7383065670728683, flat: 2.0096181333065033, pod: 35.42428004741669, loss: 39.17220485210419 
Train [9/26] | Epoch [54/160] |	nca: 1.7720101699233055, flat: 1.9975525587797165, pod: 34.5597118139267, loss: 38.32927417755127 
Train [9/26] | Epoch [55/160] |	nca: 1.889978140592575, flat: 2.0276194661855698, pod: 34.95442175865173, loss: 38.87201917171478 
Train [9/26] | Epoch [56/160] |	nca: 1.7021249532699585, flat: 2.027211755514145, pod: 34.81838119029999, loss: 38.54771828651428 
Train [9/26] | Epoch [57/160] |	nca: 1.698050182312727, flat: 1.9286721870303154, pod: 35.032997727394104, loss: 38.65972030162811 
Train [9/26] | Epoch [58/160] |	nca: 1.6612499170005322, flat: 1.8841031417250633, pod: 34.43260931968689, loss: 37.97796273231506 
Train [9/26] | Epoch [59/160] |	nca: 1.750149480998516, flat: 1.8142606317996979, pod: 33.704439640045166, loss: 37.26884973049164 
Train [9/26] | Epoch [60/160] |	nca: 1.6031768396496773, flat: 1.8144274428486824, pod: 32.704431891441345, loss: 36.12203586101532 
Train [9/26] | Epoch [61/160] |	nca: 1.753507450222969, flat: 1.845310389995575, pod: 33.30672597885132, loss: 36.9055438041687 
Train [9/26] | Epoch [62/160] |	nca: 1.9110912829637527, flat: 1.9916809424757957, pod: 35.56939136981964, loss: 39.47216331958771 
Train [9/26] | Epoch [63/160] |	nca: 1.631921574473381, flat: 1.9799714386463165, pod: 35.85568368434906, loss: 39.46757686138153 
Train [9/26] | Epoch [64/160] |	nca: 1.7379314824938774, flat: 1.9657119438052177, pod: 35.509549260139465, loss: 39.21319270133972 
Train [9/26] | Epoch [65/160] |	nca: 1.700502723455429, flat: 1.9925573468208313, pod: 34.60363984107971, loss: 38.29670000076294 
Train [9/26] | Epoch [66/160] |	nca: 1.567584678530693, flat: 1.7723944708704948, pod: 33.05011796951294, loss: 36.39009726047516 
Train [9/26] | Epoch [67/160] |	nca: 1.6861349791288376, flat: 1.7025989294052124, pod: 32.91165518760681, loss: 36.30038940906525 
Train [9/26] | Epoch [68/160] |	nca: 1.7108556814491749, flat: 1.8106697648763657, pod: 32.97985351085663, loss: 36.501378536224365 
Train [9/26] | Epoch [69/160] |	nca: 1.668456919491291, flat: 1.8323894739151, pod: 33.29858160018921, loss: 36.79942810535431 
Train [9/26] | Epoch [70/160] |	nca: 1.629129447042942, flat: 1.700763151049614, pod: 32.047144532203674, loss: 35.377037525177 
Train [9/26] | Epoch [71/160] |	nca: 1.5729318000376225, flat: 1.8096164837479591, pod: 34.21364998817444, loss: 37.596197962760925 
Train [9/26] | Epoch [72/160] |	nca: 1.9766134470701218, flat: 1.757503479719162, pod: 33.04523253440857, loss: 36.77934956550598 
Train [9/26] | Epoch [73/160] |	nca: 1.6537616588175297, flat: 1.789718173444271, pod: 32.61483132839203, loss: 36.05831158161163 
Train [9/26] | Epoch [74/160] |	nca: 1.719702921807766, flat: 1.7237235233187675, pod: 32.22739052772522, loss: 35.670817136764526 
Train [9/26] | Epoch [75/160] |	nca: 1.6325477100908756, flat: 1.710661917924881, pod: 32.540751338005066, loss: 35.88396108150482 
Train [9/26] | Epoch [76/160] |	nca: 1.5410319566726685, flat: 1.6928236335515976, pod: 32.289710998535156, loss: 35.523566484451294 
Train [9/26] | Epoch [77/160] |	nca: 1.6109024472534657, flat: 1.5942691564559937, pod: 31.17826497554779, loss: 34.38343632221222 
Train [9/26] | Epoch [78/160] |	nca: 1.723827075213194, flat: 1.6554055511951447, pod: 31.57799196243286, loss: 34.95722460746765 
Train [9/26] | Epoch [79/160] |	nca: 1.5942267626523972, flat: 1.6866743564605713, pod: 31.224433660507202, loss: 34.50533473491669 
Train [9/26] | Epoch [80/160] |	nca: 1.5318515077233315, flat: 1.5257876440882683, pod: 29.985589385032654, loss: 33.04322874546051 
Train [9/26] | Epoch [81/160] |	nca: 1.433567475527525, flat: 1.4359331205487251, pod: 29.003785252571106, loss: 31.87328600883484 
Train [9/26] | Epoch [82/160] |	nca: 1.6159426234662533, flat: 1.4923975989222527, pod: 30.36235022544861, loss: 33.47069025039673 
Train [9/26] | Epoch [83/160] |	nca: 1.4809079132974148, flat: 1.4097341001033783, pod: 28.17214846611023, loss: 31.062790155410767 
Train [9/26] | Epoch [84/160] |	nca: 1.6008984073996544, flat: 1.3864622823894024, pod: 28.378833889961243, loss: 31.366194486618042 
Train [9/26] | Epoch [85/160] |	nca: 1.5894431583583355, flat: 1.55853733420372, pod: 31.077104926109314, loss: 34.225085377693176 
Train [9/26] | Epoch [86/160] |	nca: 1.458527572453022, flat: 1.4605749994516373, pod: 29.953790068626404, loss: 32.87289273738861 
Train [9/26] | Epoch [87/160] |	nca: 1.5455340705811977, flat: 1.3838611990213394, pod: 29.10505509376526, loss: 32.03445041179657 
Train [9/26] | Epoch [88/160] |	nca: 1.4580236673355103, flat: 1.42172110080719, pod: 30.086352109909058, loss: 32.96609711647034 
Train [9/26] | Epoch [89/160] |	nca: 1.4549408853054047, flat: 1.2753652781248093, pod: 27.122101545333862, loss: 29.852407574653625 
Train [9/26] | Epoch [90/160] |	nca: 1.5715246871113777, flat: 1.358982153236866, pod: 28.54333233833313, loss: 31.473839163780212 
Train [9/26] | Epoch [91/160] |	nca: 1.5520100817084312, flat: 1.40399219840765, pod: 29.129847288131714, loss: 32.08584952354431 
Train [9/26] | Epoch [92/160] |	nca: 1.602537613362074, flat: 1.319671142846346, pod: 27.68602192401886, loss: 30.608230471611023 
Train [9/26] | Epoch [93/160] |	nca: 1.463067427277565, flat: 1.2802012898027897, pod: 28.140776872634888, loss: 30.884045243263245 
Train [9/26] | Epoch [94/160] |	nca: 1.5226989760994911, flat: 1.314735434949398, pod: 28.271728515625, loss: 31.10916292667389 
Train [9/26] | Epoch [95/160] |	nca: 1.520764958113432, flat: 1.262366909533739, pod: 26.94454073905945, loss: 29.727672696113586 
Train [9/26] | Epoch [96/160] |	nca: 1.4957070127129555, flat: 1.3029638454318047, pod: 27.654389142990112, loss: 30.453060150146484 
Train [9/26] | Epoch [97/160] |	nca: 1.426253754645586, flat: 1.2202822230756283, pod: 26.258688926696777, loss: 28.905224919319153 
Train [9/26] | Epoch [98/160] |	nca: 1.5973791182041168, flat: 1.3012108579277992, pod: 27.795848727226257, loss: 30.694438457489014 
Train [9/26] | Epoch [99/160] |	nca: 1.5684603117406368, flat: 1.2785886600613594, pod: 27.36852729320526, loss: 30.215576171875 
Train [9/26] | Epoch [100/160] |	nca: 1.4810975641012192, flat: 1.1722183786332607, pod: 25.99503743648529, loss: 28.648353457450867 
Train [9/26] | Epoch [101/160] |	nca: 1.4619440957903862, flat: 1.1130187287926674, pod: 25.177852988243103, loss: 27.75281584262848 
Train [9/26] | Epoch [102/160] |	nca: 1.4900341890752316, flat: 1.1560882776975632, pod: 26.225219130516052, loss: 28.871341586112976 
Train [9/26] | Epoch [103/160] |	nca: 1.6026817634701729, flat: 1.2054920606315136, pod: 27.43340504169464, loss: 30.241578936576843 
Train [9/26] | Epoch [104/160] |	nca: 1.4197919629514217, flat: 1.0991152562201023, pod: 24.717586398124695, loss: 27.236493706703186 
Train [9/26] | Epoch [105/160] |	nca: 1.4730984382331371, flat: 1.2280143573880196, pod: 26.596464157104492, loss: 29.297577023506165 
Train [9/26] | Epoch [106/160] |	nca: 1.5591154545545578, flat: 1.0626217052340508, pod: 24.857137441635132, loss: 27.478874564170837 
Train [9/26] | Epoch [107/160] |	nca: 1.4955015070736408, flat: 1.1039363145828247, pod: 25.710381865501404, loss: 28.30981981754303 
Train [9/26] | Epoch [108/160] |	nca: 1.643435437232256, flat: 1.078471302986145, pod: 24.410974144935608, loss: 27.132880926132202 
Train [9/26] | Epoch [109/160] |	nca: 1.4604222886264324, flat: 1.0753542594611645, pod: 24.65398609638214, loss: 27.189762592315674 
Train [9/26] | Epoch [110/160] |	nca: 1.5465262234210968, flat: 1.0687004178762436, pod: 24.868876576423645, loss: 27.484103441238403 
Train [9/26] | Epoch [111/160] |	nca: 1.4793208166956902, flat: 1.0916576460003853, pod: 24.756725549697876, loss: 27.327704071998596 
Train [9/26] | Epoch [112/160] |	nca: 1.4728712663054466, flat: 0.9974532723426819, pod: 23.64774477481842, loss: 26.118069529533386 
Train [9/26] | Epoch [113/160] |	nca: 1.54350396245718, flat: 0.960590772330761, pod: 22.675094723701477, loss: 25.179189443588257 
Train [9/26] | Epoch [114/160] |	nca: 1.546905167400837, flat: 0.9912435933947563, pod: 23.83534574508667, loss: 26.373494625091553 
Train [9/26] | Epoch [115/160] |	nca: 1.4952781982719898, flat: 0.9818024523556232, pod: 22.74999225139618, loss: 25.227072954177856 
Train [9/26] | Epoch [116/160] |	nca: 1.4294848516583443, flat: 0.9048788547515869, pod: 21.632549285888672, loss: 23.966912984848022 
Train [9/26] | Epoch [117/160] |	nca: 1.3907021544873714, flat: 0.8940927758812904, pod: 21.645492911338806, loss: 23.930287957191467 
Train [9/26] | Epoch [118/160] |	nca: 1.3577044308185577, flat: 0.9400201849639416, pod: 23.3767249584198, loss: 25.674449682235718 
Train [9/26] | Epoch [119/160] |	nca: 1.437304463237524, flat: 0.9219746552407742, pod: 22.42007553577423, loss: 24.77935481071472 
Train [9/26] | Epoch [120/160] |	nca: 1.4011274352669716, flat: 0.8813271708786488, pod: 22.764400839805603, loss: 25.046855568885803 
Train [9/26] | Epoch [121/160] |	nca: 1.529902033507824, flat: 0.9005327671766281, pod: 22.10357904434204, loss: 24.534013509750366 
Train [9/26] | Epoch [122/160] |	nca: 1.5067360922694206, flat: 0.9418357126414776, pod: 22.253336548805237, loss: 24.701908349990845 
Train [9/26] | Epoch [123/160] |	nca: 1.4306605905294418, flat: 0.9130737856030464, pod: 22.406749963760376, loss: 24.750484108924866 
Train [9/26] | Epoch [124/160] |	nca: 1.4418416991829872, flat: 0.9216086976230145, pod: 22.245194792747498, loss: 24.60864508152008 
Train [9/26] | Epoch [125/160] |	nca: 1.4190494567155838, flat: 0.8708288781344891, pod: 21.829255282878876, loss: 24.119133591651917 
Train [9/26] | Epoch [126/160] |	nca: 1.4665737003087997, flat: 0.8883110657334328, pod: 22.064849019050598, loss: 24.4197336435318 
Train [9/26] | Epoch [127/160] |	nca: 1.4473876543343067, flat: 0.8450551889836788, pod: 20.786296665668488, loss: 23.078739047050476 
Train [9/26] | Epoch [128/160] |	nca: 1.475822325795889, flat: 0.8784327134490013, pod: 21.443143606185913, loss: 23.797398686408997 
Train [9/26] | Epoch [129/160] |	nca: 1.472646877169609, flat: 0.8556275069713593, pod: 20.813270390033722, loss: 23.14154452085495 
Train [9/26] | Epoch [130/160] |	nca: 1.517884399741888, flat: 0.8098386116325855, pod: 20.886789560317993, loss: 23.214512586593628 
Train [9/26] | Epoch [131/160] |	nca: 1.5316579788923264, flat: 0.7779373563826084, pod: 19.97397530078888, loss: 22.28357094526291 
Train [9/26] | Epoch [132/160] |	nca: 1.4982231073081493, flat: 0.7592018097639084, pod: 19.84235316514969, loss: 22.099778175354004 
Train [9/26] | Epoch [133/160] |	nca: 1.3741939924657345, flat: 0.748459842056036, pod: 19.24708741903305, loss: 21.369741201400757 
Train [9/26] | Epoch [134/160] |	nca: 1.4326028302311897, flat: 0.7556858249008656, pod: 19.66320914030075, loss: 21.851498007774353 
Train [9/26] | Epoch [135/160] |	nca: 1.5156741552054882, flat: 0.7662667278200388, pod: 19.37848609685898, loss: 21.66042709350586 
Train [9/26] | Epoch [136/160] |	nca: 1.4278492256999016, flat: 0.7189159989356995, pod: 18.964731872081757, loss: 21.111496925354004 
Train [9/26] | Epoch [137/160] |	nca: 1.5123343355953693, flat: 0.7796807624399662, pod: 19.731984853744507, loss: 22.0239999294281 
Train [9/26] | Epoch [138/160] |	nca: 1.372704416513443, flat: 0.6984990201890469, pod: 18.593445360660553, loss: 20.664648592472076 
Train [9/26] | Epoch [139/160] |	nca: 1.4385881908237934, flat: 0.7605861332267523, pod: 19.173334300518036, loss: 21.37250852584839 
Train [9/26] | Epoch [140/160] |	nca: 1.4238910004496574, flat: 0.7662671450525522, pod: 19.560845494270325, loss: 21.751003623008728 
Train [9/26] | Epoch [141/160] |	nca: 1.4178659915924072, flat: 0.7151148058474064, pod: 19.410058557987213, loss: 21.54303926229477 
Train [9/26] | Epoch [142/160] |	nca: 1.4177544079720974, flat: 0.7255615312606096, pod: 19.048684537410736, loss: 21.192000329494476 
Train [9/26] | Epoch [143/160] |	nca: 1.5584152564406395, flat: 0.725015826523304, pod: 18.535917103290558, loss: 20.81934827566147 
Train [9/26] | Epoch [144/160] |	nca: 1.4833193570375443, flat: 0.7273536529392004, pod: 18.73212993144989, loss: 20.942803144454956 
Train [9/26] | Epoch [145/160] |	nca: 1.4558094926178455, flat: 0.669935554265976, pod: 18.138157606124878, loss: 20.263902366161346 
Train [9/26] | Epoch [146/160] |	nca: 1.3971526324748993, flat: 0.6506430637091398, pod: 17.326121032238007, loss: 19.373916506767273 
Train [9/26] | Epoch [147/160] |	nca: 1.4160215891897678, flat: 0.6825975850224495, pod: 18.28884983062744, loss: 20.387468993663788 
Train [9/26] | Epoch [148/160] |	nca: 1.4048049375414848, flat: 0.7373980674892664, pod: 18.42529660463333, loss: 20.56749963760376 
Train [9/26] | Epoch [149/160] |	nca: 1.4221149235963821, flat: 0.646937794983387, pod: 17.885526061058044, loss: 19.954578638076782 
Train [9/26] | Epoch [150/160] |	nca: 1.3754280433058739, flat: 0.6483709439635277, pod: 16.810456216335297, loss: 18.834255158901215 
Train [9/26] | Epoch [151/160] |	nca: 1.3488053418695927, flat: 0.6360845379531384, pod: 16.615828275680542, loss: 18.600718200206757 
Train [9/26] | Epoch [152/160] |	nca: 1.5070185288786888, flat: 0.6553861331194639, pod: 17.136810541152954, loss: 19.299215078353882 
Train [9/26] | Epoch [153/160] |	nca: 1.4088442251086235, flat: 0.619858032092452, pod: 16.452747881412506, loss: 18.481450259685516 
Train [9/26] | Epoch [154/160] |	nca: 1.5193307548761368, flat: 0.6562014166265726, pod: 17.156599402427673, loss: 19.332131326198578 
Train [9/26] | Epoch [155/160] |	nca: 1.399509884417057, flat: 0.6690742429345846, pod: 17.411729633808136, loss: 19.480313658714294 
Train [9/26] | Epoch [156/160] |	nca: 1.329372763633728, flat: 0.6237091943621635, pod: 17.353480100631714, loss: 19.306561768054962 
Train [9/26] | Epoch [157/160] |	nca: 1.437609400600195, flat: 0.6191115882247686, pod: 16.648544490337372, loss: 18.705265402793884 
Train [9/26] | Epoch [158/160] |	nca: 1.3346972949802876, flat: 0.6663394719362259, pod: 17.42917513847351, loss: 19.4302117228508 
Train [9/26] | Epoch [159/160] |	nca: 1.4134883396327496, flat: 0.6294418554753065, pod: 17.33474051952362, loss: 19.37767082452774 
Train [9/26] | Epoch [160/160] |	nca: 1.3767597749829292, flat: 0.620247770100832, pod: 16.24843394756317, loss: 18.245441615581512 
Fine-tuning
Building & updating memory.
Train [9/26] | Epoch [161/180] |	nca: 1.13138697296381, flat: 0.7766485288739204, pod: 14.805052161216736, loss: 16.713087558746338 
Train [9/26] | Epoch [162/180] |	nca: 0.6667468175292015, flat: 0.9201883636415005, pod: 15.489263772964478, loss: 17.07619881629944 
Train [9/26] | Epoch [163/180] |	nca: 0.541462991386652, flat: 0.8635073639452457, pod: 15.609182238578796, loss: 17.01415264606476 
Train [9/26] | Epoch [164/180] |	nca: 0.4916892573237419, flat: 0.851695828139782, pod: 14.923736929893494, loss: 16.26712191104889 
Train [9/26] | Epoch [165/180] |	nca: 0.48819684982299805, flat: 0.7924840599298477, pod: 14.88347601890564, loss: 16.164157032966614 
Train [9/26] | Epoch [166/180] |	nca: 0.4585556108504534, flat: 0.8309082873165607, pod: 15.042000353336334, loss: 16.331464409828186 
Train [9/26] | Epoch [167/180] |	nca: 0.4919477216899395, flat: 0.8231302797794342, pod: 15.137395024299622, loss: 16.452473163604736 
Train [9/26] | Epoch [168/180] |	nca: 0.4821719639003277, flat: 0.8093645796179771, pod: 14.70435345172882, loss: 15.995890021324158 
Train [9/26] | Epoch [169/180] |	nca: 0.40601155161857605, flat: 0.8521462194621563, pod: 15.670138359069824, loss: 16.928296089172363 
Train [9/26] | Epoch [170/180] |	nca: 0.4377169292420149, flat: 0.8012170158326626, pod: 15.170067191123962, loss: 16.409001111984253 
Train [9/26] | Epoch [171/180] |	nca: 0.43603018298745155, flat: 0.8001472540199757, pod: 14.855544328689575, loss: 16.091721653938293 
Train [9/26] | Epoch [172/180] |	nca: 0.3935495223850012, flat: 0.8588919453322887, pod: 14.812035202980042, loss: 16.064476370811462 
Train [9/26] | Epoch [173/180] |	nca: 0.3540293835103512, flat: 0.8008021824061871, pod: 14.886579275131226, loss: 16.04141092300415 
Train [9/26] | Epoch [174/180] |	nca: 0.362620584666729, flat: 0.79883648827672, pod: 14.901471853256226, loss: 16.062929034233093 
Train [9/26] | Epoch [175/180] |	nca: 0.3922009076923132, flat: 0.8352015763521194, pod: 15.386973977088928, loss: 16.614376544952393 
Train [9/26] | Epoch [176/180] |	nca: 0.3836084958165884, flat: 0.8788169473409653, pod: 15.624783277511597, loss: 16.887208461761475 
Train [9/26] | Epoch [177/180] |	nca: 0.3832942694425583, flat: 0.876535028219223, pod: 15.277976155281067, loss: 16.537805557250977 
Train [9/26] | Epoch [178/180] |	nca: 0.34152891114354134, flat: 0.8122184090316296, pod: 14.520404696464539, loss: 15.674152255058289 
Train [9/26] | Epoch [179/180] |	nca: 0.3424103204160929, flat: 0.8687741011381149, pod: 15.067585229873657, loss: 16.278769731521606 
Train [9/26] | Epoch [180/180] |	nca: 0.3104435708373785, flat: 0.8585329838097095, pod: 15.261939883232117, loss: 16.43091654777527 
after task
Building & updating memory.
after task
Eval on 0->66.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6885555555555555.
Current acc: {'total': 0.619, '00-09': 0.649, '10-19': 0.614, '20-29': 0.542, '30-39': 0.574, '40-49': 0.676, '50-59': 0.657, '60-69': 0.625}.
Avg inc acc top5: 0.905222222222222.
Current acc top5: {'total': 0.873}.
Forgetting: 0.14750000000000002.
Cord metric: 0.69.
Old accuracy: 0.62, mean: 0.67.
New accuracy: 0.71, mean: 0.78.
================Task 9 Start!================
Testing on False unseen tasks (max class = 68).
Set memory of size: 1320.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 9 Training!================
The training samples number: 2320
Train on 66->68.
train task
nb 2320.
Train [10/26] | Epoch [1/160] |	nca: 7.461542159318924, flat: 3.1328133940696716, pod: 44.85328829288483, loss: 55.447643876075745 
Train [10/26] | Epoch [2/160] |	nca: 8.265236213803291, flat: 7.3758582174777985, pod: 67.41594624519348, loss: 83.05703973770142 
Train [10/26] | Epoch [3/160] |	nca: 7.084420621395111, flat: 6.6472607254981995, pod: 63.439547538757324, loss: 77.17122983932495 
Train [10/26] | Epoch [4/160] |	nca: 6.568335488438606, flat: 7.287920266389847, pod: 67.85323739051819, loss: 81.70949363708496 
Train [10/26] | Epoch [5/160] |	nca: 4.6578235775232315, flat: 5.635236233472824, pod: 61.45795750617981, loss: 71.75101637840271 
Train [10/26] | Epoch [6/160] |	nca: 4.236163958907127, flat: 4.878440082073212, pod: 55.84013223648071, loss: 64.95473623275757 
Train [10/26] | Epoch [7/160] |	nca: 2.973231054842472, flat: 3.962755098938942, pod: 51.391443490982056, loss: 58.32742953300476 
Train [10/26] | Epoch [8/160] |	nca: 3.224461056292057, flat: 3.8674047142267227, pod: 52.43569564819336, loss: 59.52756071090698 
Train [10/26] | Epoch [9/160] |	nca: 4.382626183331013, flat: 4.689978584647179, pod: 54.7344913482666, loss: 63.80709528923035 
Train [10/26] | Epoch [10/160] |	nca: 3.6715387254953384, flat: 4.845143958926201, pod: 56.5495810508728, loss: 65.0662636756897 
Train [10/26] | Epoch [11/160] |	nca: 3.0920813232660294, flat: 4.090839475393295, pod: 51.75397205352783, loss: 58.93689322471619 
Train [10/26] | Epoch [12/160] |	nca: 4.420615330338478, flat: 4.87056177854538, pod: 57.21151375770569, loss: 66.50269079208374 
Train [10/26] | Epoch [13/160] |	nca: 2.746382899582386, flat: 3.888627916574478, pod: 50.510857582092285, loss: 57.1458683013916 
Train [10/26] | Epoch [14/160] |	nca: 2.742618516087532, flat: 3.542490169405937, pod: 47.67401695251465, loss: 53.95912528038025 
Train [10/26] | Epoch [15/160] |	nca: 3.1616324335336685, flat: 3.906748130917549, pod: 51.69171953201294, loss: 58.7600998878479 
Train [10/26] | Epoch [16/160] |	nca: 2.3801041543483734, flat: 3.333584949374199, pod: 47.53043508529663, loss: 53.24412417411804 
Train [10/26] | Epoch [17/160] |	nca: 3.008723773062229, flat: 3.3467214554548264, pod: 47.13876914978027, loss: 53.49421405792236 
Train [10/26] | Epoch [18/160] |	nca: 2.728092648088932, flat: 3.8044620007276535, pod: 49.99188995361328, loss: 56.524444580078125 
Train [10/26] | Epoch [19/160] |	nca: 2.4071474596858025, flat: 3.193840503692627, pod: 47.56301212310791, loss: 53.164000272750854 
Train [10/26] | Epoch [20/160] |	nca: 3.5430456921458244, flat: 4.0742941200733185, pod: 50.11302661895752, loss: 57.730366230010986 
Train [10/26] | Epoch [21/160] |	nca: 2.9687083810567856, flat: 3.929743230342865, pod: 51.447261810302734, loss: 58.34571385383606 
Train [10/26] | Epoch [22/160] |	nca: 3.0989735648036003, flat: 3.505770891904831, pod: 48.08675932884216, loss: 54.69150376319885 
Train [10/26] | Epoch [23/160] |	nca: 4.650745138525963, flat: 5.548268988728523, pod: 57.34146451950073, loss: 67.54047846794128 
Train [10/26] | Epoch [24/160] |	nca: 3.9879968762397766, flat: 5.215117529034615, pod: 56.00240445137024, loss: 65.20551896095276 
Train [10/26] | Epoch [25/160] |	nca: 2.794936180114746, flat: 4.102857753634453, pod: 50.98666548728943, loss: 57.884458780288696 
Train [10/26] | Epoch [26/160] |	nca: 2.8838696777820587, flat: 4.004511579871178, pod: 50.592527866363525, loss: 57.48090839385986 
Train [10/26] | Epoch [27/160] |	nca: 3.149317316710949, flat: 3.560156151652336, pod: 49.06043744087219, loss: 55.76991081237793 
Train [10/26] | Epoch [28/160] |	nca: 2.574561908841133, flat: 3.9162429720163345, pod: 50.721020221710205, loss: 57.211825132369995 
Train [10/26] | Epoch [29/160] |	nca: 2.771312490105629, flat: 3.1804805546998978, pod: 48.21680164337158, loss: 54.16859436035156 
Train [10/26] | Epoch [30/160] |	nca: 3.202136181294918, flat: 4.353882074356079, pod: 52.471152782440186, loss: 60.02717065811157 
Train [10/26] | Epoch [31/160] |	nca: 2.84000663459301, flat: 4.010040640830994, pod: 51.43452739715576, loss: 58.284574031829834 
Train [10/26] | Epoch [32/160] |	nca: 2.5800340995192528, flat: 3.520879402756691, pod: 49.06511211395264, loss: 55.16602563858032 
Train [10/26] | Epoch [33/160] |	nca: 2.2225233018398285, flat: 2.8072430565953255, pod: 43.58505058288574, loss: 48.614816665649414 
Train [10/26] | Epoch [34/160] |	nca: 2.24336576461792, flat: 3.464163586497307, pod: 48.11705803871155, loss: 53.82458710670471 
Train [10/26] | Epoch [35/160] |	nca: 1.880300872027874, flat: 2.8245919421315193, pod: 44.60530614852905, loss: 49.31019902229309 
Train [10/26] | Epoch [36/160] |	nca: 1.840062938630581, flat: 2.6012216955423355, pod: 42.463698983192444, loss: 46.904983043670654 
Train [10/26] | Epoch [37/160] |	nca: 2.3963638022542, flat: 2.987116925418377, pod: 45.4088351726532, loss: 50.792316198349 
Train [10/26] | Epoch [38/160] |	nca: 2.415721744298935, flat: 2.9307817593216896, pod: 44.90362524986267, loss: 50.25012922286987 
Train [10/26] | Epoch [39/160] |	nca: 2.3660239204764366, flat: 3.196671485900879, pod: 45.718692779541016, loss: 51.28138780593872 
Train [10/26] | Epoch [40/160] |	nca: 2.0022652596235275, flat: 2.570663794875145, pod: 42.40462124347687, loss: 46.9775493144989 
Train [10/26] | Epoch [41/160] |	nca: 2.321649767458439, flat: 2.740293003618717, pod: 43.91456055641174, loss: 48.976502895355225 
Train [10/26] | Epoch [42/160] |	nca: 2.255001939833164, flat: 2.925780802965164, pod: 44.943440675735474, loss: 50.124223709106445 
Train [10/26] | Epoch [43/160] |	nca: 2.1552261114120483, flat: 2.7216478660702705, pod: 43.41118776798248, loss: 48.28806185722351 
Train [10/26] | Epoch [44/160] |	nca: 2.0980371721088886, flat: 2.4057587534189224, pod: 39.76607573032379, loss: 44.26987171173096 
Train [10/26] | Epoch [45/160] |	nca: 1.9017491042613983, flat: 2.770965628325939, pod: 42.221657514572144, loss: 46.89437246322632 
Train [10/26] | Epoch [46/160] |	nca: 2.1358564160764217, flat: 2.4437717497348785, pod: 41.20796191692352, loss: 45.78758931159973 
Train [10/26] | Epoch [47/160] |	nca: 2.2721377462148666, flat: 2.9049372747540474, pod: 43.575095891952515, loss: 48.75217080116272 
Train [10/26] | Epoch [48/160] |	nca: 1.7872189953923225, flat: 2.3413706719875336, pod: 42.01396834850311, loss: 46.142558336257935 
Train [10/26] | Epoch [49/160] |	nca: 1.791082687675953, flat: 2.3840300887823105, pod: 41.27616608142853, loss: 45.45127844810486 
Train [10/26] | Epoch [50/160] |	nca: 1.8102030344307423, flat: 2.346092067658901, pod: 41.31006360054016, loss: 45.46635818481445 
Train [10/26] | Epoch [51/160] |	nca: 1.9520146325230598, flat: 2.288719467818737, pod: 40.008769512176514, loss: 44.24950385093689 
Train [10/26] | Epoch [52/160] |	nca: 2.200378604233265, flat: 2.5615441277623177, pod: 42.25925302505493, loss: 47.021175384521484 
Train [10/26] | Epoch [53/160] |	nca: 2.093484915792942, flat: 2.4358266443014145, pod: 39.73483335971832, loss: 44.26414442062378 
Train [10/26] | Epoch [54/160] |	nca: 2.1844728365540504, flat: 2.414943404495716, pod: 39.623021841049194, loss: 44.22243809700012 
Train [10/26] | Epoch [55/160] |	nca: 2.3419971019029617, flat: 2.9522047266364098, pod: 43.20021080970764, loss: 48.494412660598755 
Train [10/26] | Epoch [56/160] |	nca: 2.4919081926345825, flat: 2.80233895778656, pod: 42.284741163253784, loss: 47.57898831367493 
Train [10/26] | Epoch [57/160] |	nca: 2.709176905453205, flat: 3.305159345269203, pod: 44.94285297393799, loss: 50.957189321517944 
Train [10/26] | Epoch [58/160] |	nca: 2.278158336877823, flat: 2.623274326324463, pod: 40.98466765880585, loss: 45.88610005378723 
Train [10/26] | Epoch [59/160] |	nca: 2.7487513720989227, flat: 2.7629873752593994, pod: 41.980857372283936, loss: 47.492595911026 
Train [10/26] | Epoch [60/160] |	nca: 2.1678526699543, flat: 2.6970972791314125, pod: 42.20056176185608, loss: 47.06551194190979 
Train [10/26] | Epoch [61/160] |	nca: 2.315696656703949, flat: 2.6500298008322716, pod: 40.98688209056854, loss: 45.952608585357666 
Train [10/26] | Epoch [62/160] |	nca: 2.197137765586376, flat: 3.0216355323791504, pod: 42.54688811302185, loss: 47.76566123962402 
Train [10/26] | Epoch [63/160] |	nca: 1.9568163193762302, flat: 2.4378798380494118, pod: 40.53271842002869, loss: 44.927414894104004 
Train [10/26] | Epoch [64/160] |	nca: 1.7906511016190052, flat: 2.219889536499977, pod: 37.54300081729889, loss: 41.5535409450531 
Train [10/26] | Epoch [65/160] |	nca: 1.8166999816894531, flat: 2.2419788911938667, pod: 37.833738803863525, loss: 41.892417669296265 
Train [10/26] | Epoch [66/160] |	nca: 1.699111070483923, flat: 2.151545003056526, pod: 38.146268367767334, loss: 41.99692440032959 
Train [10/26] | Epoch [67/160] |	nca: 1.7901083454489708, flat: 2.0797948464751244, pod: 36.58958172798157, loss: 40.459484696388245 
Train [10/26] | Epoch [68/160] |	nca: 2.231301926076412, flat: 2.413745380938053, pod: 40.98636269569397, loss: 45.631410121917725 
Train [10/26] | Epoch [69/160] |	nca: 2.024260960519314, flat: 2.6153853461146355, pod: 43.06875717639923, loss: 47.70840358734131 
Train [10/26] | Epoch [70/160] |	nca: 1.6630710884928703, flat: 2.026614621281624, pod: 37.52101969718933, loss: 41.2107058763504 
Train [10/26] | Epoch [71/160] |	nca: 1.8717368766665459, flat: 1.9761038348078728, pod: 37.18872511386871, loss: 41.036566495895386 
Train [10/26] | Epoch [72/160] |	nca: 1.5705832093954086, flat: 2.002480559051037, pod: 36.89083969593048, loss: 40.463902711868286 
Train [10/26] | Epoch [73/160] |	nca: 1.9542879164218903, flat: 1.9360900297760963, pod: 37.14038801193237, loss: 41.030766248703 
Train [10/26] | Epoch [74/160] |	nca: 1.9107179269194603, flat: 1.8728348165750504, pod: 34.6247798204422, loss: 38.40833258628845 
Train [10/26] | Epoch [75/160] |	nca: 1.837531328201294, flat: 1.9570967257022858, pod: 36.29420554637909, loss: 40.08883333206177 
Train [10/26] | Epoch [76/160] |	nca: 1.6584926806390285, flat: 1.7784535437822342, pod: 35.150872349739075, loss: 38.5878187417984 
Train [10/26] | Epoch [77/160] |	nca: 1.6489847674965858, flat: 1.7663796842098236, pod: 33.9830607175827, loss: 37.39842510223389 
Train [10/26] | Epoch [78/160] |	nca: 1.3939726240932941, flat: 1.7530580163002014, pod: 35.024256110191345, loss: 38.17128670215607 
Train [10/26] | Epoch [79/160] |	nca: 1.4283921159803867, flat: 1.5920656025409698, pod: 33.27512085437775, loss: 36.295578479766846 
Train [10/26] | Epoch [80/160] |	nca: 1.8702382892370224, flat: 1.622743234038353, pod: 33.79692578315735, loss: 37.289907455444336 
Train [10/26] | Epoch [81/160] |	nca: 1.9005002938210964, flat: 2.1605506613850594, pod: 37.15788459777832, loss: 41.21893537044525 
Train [10/26] | Epoch [82/160] |	nca: 1.912823598831892, flat: 1.9226603507995605, pod: 35.193156003952026, loss: 39.028640270233154 
Train [10/26] | Epoch [83/160] |	nca: 2.017008289694786, flat: 2.2640894800424576, pod: 37.644269585609436, loss: 41.9253671169281 
Train [10/26] | Epoch [84/160] |	nca: 1.6516669727861881, flat: 1.8870123103260994, pod: 35.18032371997833, loss: 38.719003200531006 
Train [10/26] | Epoch [85/160] |	nca: 1.7025295719504356, flat: 1.7214964032173157, pod: 33.364341735839844, loss: 36.78836786746979 
Train [10/26] | Epoch [86/160] |	nca: 1.6607347652316093, flat: 1.7131169810891151, pod: 32.16645562648773, loss: 35.54030764102936 
Train [10/26] | Epoch [87/160] |	nca: 2.241440422832966, flat: 2.063671238720417, pod: 34.65797579288483, loss: 38.96308708190918 
Train [10/26] | Epoch [88/160] |	nca: 1.9774415418505669, flat: 2.1279308274388313, pod: 35.12963581085205, loss: 39.235007882118225 
Train [10/26] | Epoch [89/160] |	nca: 1.9066747762262821, flat: 1.8237833455204964, pod: 33.48739171028137, loss: 37.2178498506546 
Train [10/26] | Epoch [90/160] |	nca: 1.6366374865174294, flat: 1.8300535380840302, pod: 33.10579717159271, loss: 36.57248818874359 
Train [10/26] | Epoch [91/160] |	nca: 1.8903201930224895, flat: 1.5680006220936775, pod: 30.83432912826538, loss: 34.29265010356903 
Train [10/26] | Epoch [92/160] |	nca: 1.6538265086710453, flat: 1.7602857574820518, pod: 31.742894768714905, loss: 35.15700721740723 
Train [10/26] | Epoch [93/160] |	nca: 1.4928974248468876, flat: 1.578976832330227, pod: 32.52420902252197, loss: 35.59608328342438 
Train [10/26] | Epoch [94/160] |	nca: 1.6421218998730183, flat: 1.5078572668135166, pod: 31.168442249298096, loss: 34.318421483039856 
Train [10/26] | Epoch [95/160] |	nca: 1.522742424160242, flat: 1.5488210693001747, pod: 31.795580506324768, loss: 34.867143869400024 
Train [10/26] | Epoch [96/160] |	nca: 1.5837054066359997, flat: 1.5224145837128162, pod: 31.96654176712036, loss: 35.07266187667847 
Train [10/26] | Epoch [97/160] |	nca: 2.1147087924182415, flat: 1.6928053945302963, pod: 32.82933270931244, loss: 36.636847138404846 
Train [10/26] | Epoch [98/160] |	nca: 1.7344573475420475, flat: 1.759864218533039, pod: 32.546541690826416, loss: 36.040863394737244 
Train [10/26] | Epoch [99/160] |	nca: 1.5244363322854042, flat: 1.5712319165468216, pod: 31.48911464214325, loss: 34.58478283882141 
Train [10/26] | Epoch [100/160] |	nca: 2.1171718277037144, flat: 1.5708639360964298, pod: 31.254158973693848, loss: 34.94219493865967 
Train [10/26] | Epoch [101/160] |	nca: 1.9341941624879837, flat: 1.7130064517259598, pod: 32.326455950737, loss: 35.97365665435791 
Train [10/26] | Epoch [102/160] |	nca: 1.5131753645837307, flat: 1.4621577747166157, pod: 30.024802446365356, loss: 33.0001357793808 
Train [10/26] | Epoch [103/160] |	nca: 1.3924369029700756, flat: 1.4377848505973816, pod: 28.642493963241577, loss: 31.472715854644775 
Train [10/26] | Epoch [104/160] |	nca: 1.6618057265877724, flat: 1.437240857630968, pod: 30.155609011650085, loss: 33.254655718803406 
Train [10/26] | Epoch [105/160] |	nca: 1.849782582372427, flat: 1.4412708468735218, pod: 29.99232053756714, loss: 33.283373951911926 
Train [10/26] | Epoch [106/160] |	nca: 1.6070484966039658, flat: 1.2793490774929523, pod: 27.085165143013, loss: 29.97156262397766 
Train [10/26] | Epoch [107/160] |	nca: 1.632857508957386, flat: 1.286121018230915, pod: 26.255205154418945, loss: 29.17418372631073 
Train [10/26] | Epoch [108/160] |	nca: 1.6513886824250221, flat: 1.3027498237788677, pod: 27.200548887252808, loss: 30.154687643051147 
Train [10/26] | Epoch [109/160] |	nca: 1.4598112143576145, flat: 1.2398812398314476, pod: 26.917577147483826, loss: 29.6172696352005 
Train [10/26] | Epoch [110/160] |	nca: 1.5432108789682388, flat: 1.1946804858744144, pod: 26.64753746986389, loss: 29.38542890548706 
Train [10/26] | Epoch [111/160] |	nca: 1.4967564940452576, flat: 1.195131603628397, pod: 26.329161524772644, loss: 29.021049737930298 
Train [10/26] | Epoch [112/160] |	nca: 1.763002436608076, flat: 1.1783162839710712, pod: 26.631790280342102, loss: 29.573108911514282 
Train [10/26] | Epoch [113/160] |	nca: 1.5924967378377914, flat: 1.3368520140647888, pod: 28.803470134735107, loss: 31.732819080352783 
Train [10/26] | Epoch [114/160] |	nca: 1.7533694542944431, flat: 1.198515985161066, pod: 26.418241500854492, loss: 29.370126962661743 
Train [10/26] | Epoch [115/160] |	nca: 1.6209473833441734, flat: 1.2415109053254128, pod: 27.362226366996765, loss: 30.224684715270996 
Train [10/26] | Epoch [116/160] |	nca: 1.4186821021139622, flat: 1.0533319041132927, pod: 26.023980498313904, loss: 28.495994448661804 
Train [10/26] | Epoch [117/160] |	nca: 1.3984097391366959, flat: 1.0342581234872341, pod: 24.69349503517151, loss: 27.12616276741028 
Train [10/26] | Epoch [118/160] |	nca: 1.4978684857487679, flat: 1.0528061464428902, pod: 24.64110791683197, loss: 27.191782236099243 
Train [10/26] | Epoch [119/160] |	nca: 1.4913800098001957, flat: 1.1361561566591263, pod: 26.408974170684814, loss: 29.036510467529297 
Train [10/26] | Epoch [120/160] |	nca: 1.5062262080609798, flat: 1.1243874169886112, pod: 25.13699507713318, loss: 27.767608761787415 
Train [10/26] | Epoch [121/160] |	nca: 1.4886809550225735, flat: 1.0798536092042923, pod: 24.17963469028473, loss: 26.748169541358948 
Train [10/26] | Epoch [122/160] |	nca: 1.5723892152309418, flat: 1.034440502524376, pod: 23.796435356140137, loss: 26.403265118598938 
Train [10/26] | Epoch [123/160] |	nca: 1.4493876956403255, flat: 1.0239196419715881, pod: 23.292237401008606, loss: 25.765544772148132 
Train [10/26] | Epoch [124/160] |	nca: 1.3160279989242554, flat: 0.992460735142231, pod: 22.492310881614685, loss: 24.80079960823059 
Train [10/26] | Epoch [125/160] |	nca: 1.5989347472786903, flat: 0.9530338179320097, pod: 23.305239737033844, loss: 25.857208132743835 
Train [10/26] | Epoch [126/160] |	nca: 1.3785872086882591, flat: 1.0684890560805798, pod: 24.73263943195343, loss: 27.179715752601624 
Train [10/26] | Epoch [127/160] |	nca: 1.4656487219035625, flat: 1.0666696019470692, pod: 23.471213221549988, loss: 26.003531455993652 
Train [10/26] | Epoch [128/160] |	nca: 1.513680286705494, flat: 1.0952954031527042, pod: 24.914623618125916, loss: 27.52359938621521 
Train [10/26] | Epoch [129/160] |	nca: 1.3261190187186003, flat: 0.9804034419357777, pod: 22.27898234128952, loss: 24.58550500869751 
Train [10/26] | Epoch [130/160] |	nca: 1.4763489291071892, flat: 0.9120027981698513, pod: 22.214341580867767, loss: 24.60269343852997 
Train [10/26] | Epoch [131/160] |	nca: 1.462898887693882, flat: 0.9789179861545563, pod: 22.62936681509018, loss: 25.071183800697327 
Train [10/26] | Epoch [132/160] |	nca: 1.509976677596569, flat: 0.9346201047301292, pod: 22.17841148376465, loss: 24.623008489608765 
Train [10/26] | Epoch [133/160] |	nca: 1.3308892734348774, flat: 0.9009307399392128, pod: 21.406229436397552, loss: 23.638049602508545 
Train [10/26] | Epoch [134/160] |	nca: 1.4283272847533226, flat: 0.9096486326307058, pod: 22.96017163991928, loss: 25.298147559165955 
Train [10/26] | Epoch [135/160] |	nca: 1.454406775534153, flat: 0.9578392468392849, pod: 22.422922670841217, loss: 24.835168778896332 
Train [10/26] | Epoch [136/160] |	nca: 1.5002995282411575, flat: 0.9247001223266125, pod: 22.341758012771606, loss: 24.766757488250732 
Train [10/26] | Epoch [137/160] |	nca: 1.766502108424902, flat: 0.935594879090786, pod: 20.891087353229523, loss: 23.59318435192108 
Train [10/26] | Epoch [138/160] |	nca: 1.4882134906947613, flat: 0.866098802536726, pod: 21.409719228744507, loss: 23.76403135061264 
Train [10/26] | Epoch [139/160] |	nca: 1.3495610356330872, flat: 0.8795947376638651, pod: 21.69307792186737, loss: 23.92223346233368 
Train [10/26] | Epoch [140/160] |	nca: 1.512039676308632, flat: 0.8218268435448408, pod: 20.640672266483307, loss: 22.97453874349594 
Train [10/26] | Epoch [141/160] |	nca: 1.7071934752166271, flat: 0.9876553062349558, pod: 21.19231826066971, loss: 23.887166917324066 
Train [10/26] | Epoch [142/160] |	nca: 1.4291983842849731, flat: 0.8512678388506174, pod: 20.9188329577446, loss: 23.19929927587509 
Train [10/26] | Epoch [143/160] |	nca: 1.3932808935642242, flat: 0.8900424316525459, pod: 20.33519220352173, loss: 22.61851567029953 
Train [10/26] | Epoch [144/160] |	nca: 1.5453532300889492, flat: 0.863514693453908, pod: 19.4605775475502, loss: 21.869445502758026 
Train [10/26] | Epoch [145/160] |	nca: 1.5347645170986652, flat: 0.8217745572328568, pod: 20.18382054567337, loss: 22.540359616279602 
Train [10/26] | Epoch [146/160] |	nca: 1.583968311548233, flat: 0.7736080083996058, pod: 20.229299426078796, loss: 22.586875796318054 
Train [10/26] | Epoch [147/160] |	nca: 1.4704404845833778, flat: 0.7379720062017441, pod: 19.073937952518463, loss: 21.282350599765778 
Train [10/26] | Epoch [148/160] |	nca: 1.3598195537924767, flat: 0.7900305464863777, pod: 19.156557977199554, loss: 21.306407868862152 
Train [10/26] | Epoch [149/160] |	nca: 1.3166625387966633, flat: 0.7737539261579514, pod: 19.184729039669037, loss: 21.275145411491394 
Train [10/26] | Epoch [150/160] |	nca: 1.9829140938818455, flat: 0.7483954597264528, pod: 18.751383244991302, loss: 21.482693076133728 
Train [10/26] | Epoch [151/160] |	nca: 1.345021866261959, flat: 0.7465379182249308, pod: 18.225990653038025, loss: 20.317550480365753 
Train [10/26] | Epoch [152/160] |	nca: 1.4753727354109287, flat: 0.8281152360141277, pod: 18.469692170619965, loss: 20.77318000793457 
Train [10/26] | Epoch [153/160] |	nca: 1.6194229647517204, flat: 0.8783215135335922, pod: 18.58244162797928, loss: 21.080186367034912 
Train [10/26] | Epoch [154/160] |	nca: 1.5403043553233147, flat: 0.8328698743134737, pod: 18.963872849941254, loss: 21.337047040462494 
Train [10/26] | Epoch [155/160] |	nca: 1.5045430064201355, flat: 0.8043341934680939, pod: 19.28234189748764, loss: 21.591219127178192 
Train [10/26] | Epoch [156/160] |	nca: 1.3689289838075638, flat: 0.7448013350367546, pod: 18.916861176490784, loss: 21.030591547489166 
Train [10/26] | Epoch [157/160] |	nca: 1.2922982200980186, flat: 0.7993809543550014, pod: 19.085647225379944, loss: 21.177326560020447 
Train [10/26] | Epoch [158/160] |	nca: 1.3071538545191288, flat: 0.7191039845347404, pod: 17.74776864051819, loss: 19.77402663230896 
Train [10/26] | Epoch [159/160] |	nca: 1.3233016580343246, flat: 0.7219511922448874, pod: 18.056596994400024, loss: 20.101849794387817 
Train [10/26] | Epoch [160/160] |	nca: 1.6736239045858383, flat: 0.8675338607281446, pod: 19.01845633983612, loss: 21.559614300727844 
Fine-tuning
Building & updating memory.
Train [10/26] | Epoch [161/180] |	nca: 1.4080994836986065, flat: 0.938945822417736, pod: 15.577224850654602, loss: 17.924270033836365 
Train [10/26] | Epoch [162/180] |	nca: 0.6638980470597744, flat: 0.9125259444117546, pod: 15.058893203735352, loss: 16.635317087173462 
Train [10/26] | Epoch [163/180] |	nca: 0.6049026809632778, flat: 0.9042820781469345, pod: 14.626610219478607, loss: 16.13579499721527 
Train [10/26] | Epoch [164/180] |	nca: 0.4663921594619751, flat: 0.8795551061630249, pod: 14.870248079299927, loss: 16.216195225715637 
Train [10/26] | Epoch [165/180] |	nca: 0.5152566563338041, flat: 0.9444245770573616, pod: 15.57513177394867, loss: 17.034813046455383 
Train [10/26] | Epoch [166/180] |	nca: 0.5007779076695442, flat: 0.9347677975893021, pod: 15.326831579208374, loss: 16.76237726211548 
Train [10/26] | Epoch [167/180] |	nca: 0.5126720052212477, flat: 0.9305792599916458, pod: 15.315348744392395, loss: 16.758599877357483 
Train [10/26] | Epoch [168/180] |	nca: 0.4485847018659115, flat: 0.9068593494594097, pod: 15.183269619941711, loss: 16.538713693618774 
Train [10/26] | Epoch [169/180] |	nca: 0.417743694037199, flat: 0.9343316033482552, pod: 15.236252546310425, loss: 16.588327884674072 
Train [10/26] | Epoch [170/180] |	nca: 0.44774269312620163, flat: 0.894452665001154, pod: 14.925725102424622, loss: 16.2679203748703 
Train [10/26] | Epoch [171/180] |	nca: 0.4529071059077978, flat: 0.9012791030108929, pod: 15.12245488166809, loss: 16.476640939712524 
Train [10/26] | Epoch [172/180] |	nca: 0.4505561552941799, flat: 0.8691013231873512, pod: 14.81941843032837, loss: 16.139075875282288 
Train [10/26] | Epoch [173/180] |	nca: 0.4036971777677536, flat: 0.8709543943405151, pod: 14.507651925086975, loss: 15.78230357170105 
Train [10/26] | Epoch [174/180] |	nca: 0.3954562433063984, flat: 0.9118457585573196, pod: 14.960992336273193, loss: 16.26829421520233 
Train [10/26] | Epoch [175/180] |	nca: 0.419261971488595, flat: 0.8934621512889862, pod: 15.08463442325592, loss: 16.397358417510986 
Train [10/26] | Epoch [176/180] |	nca: 0.43631352111697197, flat: 0.952800590544939, pod: 15.383349299430847, loss: 16.7724632024765 
Train [10/26] | Epoch [177/180] |	nca: 0.39760272204875946, flat: 0.9122287109494209, pod: 14.960744142532349, loss: 16.270575642585754 
Train [10/26] | Epoch [178/180] |	nca: 0.39215581119060516, flat: 0.9267074763774872, pod: 15.327392935752869, loss: 16.6462562084198 
Train [10/26] | Epoch [179/180] |	nca: 0.4238139111548662, flat: 0.911399457603693, pod: 14.925054430961609, loss: 16.260267853736877 
Train [10/26] | Epoch [180/180] |	nca: 0.421611987054348, flat: 0.8762793391942978, pod: 15.206077456474304, loss: 16.503968715667725 
after task
Building & updating memory.
after task
Eval on 0->68.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6804999999999999.
Current acc: {'total': 0.608, '00-09': 0.651, '10-19': 0.584, '20-29': 0.531, '30-39': 0.569, '40-49': 0.665, '50-59': 0.625, '60-69': 0.634}.
Avg inc acc top5: 0.9008999999999998.
Current acc top5: {'total': 0.862}.
Forgetting: 0.15725000000000003.
Cord metric: 0.68.
Old accuracy: 0.60, mean: 0.67.
New accuracy: 0.81, mean: 0.78.
================Task 10 Start!================
Testing on False unseen tasks (max class = 70).
Set memory of size: 1360.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 10 Training!================
The training samples number: 2360
Train on 68->70.
train task
nb 2360.
Train [11/26] | Epoch [1/160] |	nca: 6.790832072496414, flat: 2.896996460855007, pod: 42.10440731048584, loss: 51.79223620891571 
Train [11/26] | Epoch [2/160] |	nca: 3.903145745396614, flat: 3.301390439271927, pod: 49.63094186782837, loss: 56.83547878265381 
Train [11/26] | Epoch [3/160] |	nca: 3.2721368223428726, flat: 2.9389448910951614, pod: 46.02989983558655, loss: 52.240981101989746 
Train [11/26] | Epoch [4/160] |	nca: 2.757405586540699, flat: 2.5323377922177315, pod: 41.79520344734192, loss: 47.084946393966675 
Train [11/26] | Epoch [5/160] |	nca: 2.6392874345183372, flat: 2.522965408861637, pod: 44.151960372924805, loss: 49.314213275909424 
Train [11/26] | Epoch [6/160] |	nca: 2.3984678834676743, flat: 2.4666835367679596, pod: 44.42331671714783, loss: 49.2884681224823 
Train [11/26] | Epoch [7/160] |	nca: 2.4042998701334, flat: 2.342840254306793, pod: 42.0813045501709, loss: 46.828444957733154 
Train [11/26] | Epoch [8/160] |	nca: 2.442926123738289, flat: 2.5524530932307243, pod: 43.67225170135498, loss: 48.66763114929199 
Train [11/26] | Epoch [9/160] |	nca: 2.3787824735045433, flat: 2.422641471028328, pod: 42.848100900650024, loss: 47.6495246887207 
Train [11/26] | Epoch [10/160] |	nca: 2.4482779279351234, flat: 2.614647403359413, pod: 42.980506896972656, loss: 48.04343223571777 
Train [11/26] | Epoch [11/160] |	nca: 2.172783814370632, flat: 2.3203936517238617, pod: 40.93778085708618, loss: 45.43095827102661 
Train [11/26] | Epoch [12/160] |	nca: 2.1841211318969727, flat: 2.279210329055786, pod: 41.03497540950775, loss: 45.49830770492554 
Train [11/26] | Epoch [13/160] |	nca: 2.273019127547741, flat: 2.318802446126938, pod: 41.3752760887146, loss: 45.96709728240967 
Train [11/26] | Epoch [14/160] |	nca: 2.3511315882205963, flat: 2.4487526416778564, pod: 42.99671697616577, loss: 47.796600580215454 
Train [11/26] | Epoch [15/160] |	nca: 1.935024656355381, flat: 2.2317457124590874, pod: 40.406359910964966, loss: 44.5731303691864 
Train [11/26] | Epoch [16/160] |	nca: 2.3731991201639175, flat: 2.221033424139023, pod: 40.15428447723389, loss: 44.74851703643799 
Train [11/26] | Epoch [17/160] |	nca: 2.0046350061893463, flat: 2.1547258719801903, pod: 39.023030400276184, loss: 43.18239140510559 
Train [11/26] | Epoch [18/160] |	nca: 1.9656686782836914, flat: 2.1949887350201607, pod: 40.95195281505585, loss: 45.11261010169983 
Train [11/26] | Epoch [19/160] |	nca: 1.8477913364768028, flat: 2.0995314195752144, pod: 39.40383720397949, loss: 43.351160287857056 
Train [11/26] | Epoch [20/160] |	nca: 2.0284436494112015, flat: 2.2005761936306953, pod: 40.706034421920776, loss: 44.935054779052734 
Train [11/26] | Epoch [21/160] |	nca: 2.042676392942667, flat: 2.0494288727641106, pod: 38.89163565635681, loss: 42.98374128341675 
Train [11/26] | Epoch [22/160] |	nca: 2.0383776798844337, flat: 2.2177709490060806, pod: 40.76018953323364, loss: 45.01633834838867 
Train [11/26] | Epoch [23/160] |	nca: 2.215045180171728, flat: 2.4496568590402603, pod: 42.26009154319763, loss: 46.92479395866394 
Train [11/26] | Epoch [24/160] |	nca: 2.184483751654625, flat: 2.5243154242634773, pod: 41.72463095188141, loss: 46.433430194854736 
Train [11/26] | Epoch [25/160] |	nca: 2.045368976891041, flat: 2.137508310377598, pod: 39.34084212779999, loss: 43.5237193107605 
Train [11/26] | Epoch [26/160] |	nca: 1.8402977138757706, flat: 2.0885734781622887, pod: 39.45409846305847, loss: 43.38296961784363 
Train [11/26] | Epoch [27/160] |	nca: 1.9282383024692535, flat: 2.233229100704193, pod: 41.04036092758179, loss: 45.20182824134827 
Train [11/26] | Epoch [28/160] |	nca: 2.092951938509941, flat: 2.2046421840786934, pod: 41.07587790489197, loss: 45.37347197532654 
Train [11/26] | Epoch [29/160] |	nca: 1.8543439097702503, flat: 2.07482523471117, pod: 39.02788949012756, loss: 42.95705819129944 
Train [11/26] | Epoch [30/160] |	nca: 2.0506802573800087, flat: 2.067348062992096, pod: 39.449000120162964, loss: 43.567028284072876 
Train [11/26] | Epoch [31/160] |	nca: 1.9169331192970276, flat: 2.055694453418255, pod: 38.619584441185, loss: 42.592211961746216 
Train [11/26] | Epoch [32/160] |	nca: 1.879597268998623, flat: 2.0067022293806076, pod: 38.46581983566284, loss: 42.3521192073822 
Train [11/26] | Epoch [33/160] |	nca: 1.9118152037262917, flat: 1.9976719245314598, pod: 39.75674557685852, loss: 43.66623306274414 
Train [11/26] | Epoch [34/160] |	nca: 1.7866699919104576, flat: 2.1551339253783226, pod: 38.98048293590546, loss: 42.92228710651398 
Train [11/26] | Epoch [35/160] |	nca: 1.8929310031235218, flat: 1.9344169721007347, pod: 37.36533510684967, loss: 41.19268321990967 
Train [11/26] | Epoch [36/160] |	nca: 1.886481635272503, flat: 2.0457760766148567, pod: 39.19267392158508, loss: 43.12493181228638 
Train [11/26] | Epoch [37/160] |	nca: 2.009092517197132, flat: 2.2175661623477936, pod: 41.601726055145264, loss: 45.82838535308838 
Train [11/26] | Epoch [38/160] |	nca: 1.8293280899524689, flat: 2.1377449482679367, pod: 38.26341664791107, loss: 42.23048973083496 
Train [11/26] | Epoch [39/160] |	nca: 1.7554161325097084, flat: 2.080243431031704, pod: 38.1423020362854, loss: 41.97796165943146 
Train [11/26] | Epoch [40/160] |	nca: 1.8563908226788044, flat: 1.969337023794651, pod: 38.04431962966919, loss: 41.87004733085632 
Train [11/26] | Epoch [41/160] |	nca: 1.7311116084456444, flat: 1.9464868307113647, pod: 38.352999329566956, loss: 42.030597448349 
Train [11/26] | Epoch [42/160] |	nca: 2.0343015640974045, flat: 2.026157759130001, pod: 39.29633975028992, loss: 43.35679912567139 
Train [11/26] | Epoch [43/160] |	nca: 1.823483906686306, flat: 2.0337853357195854, pod: 39.005488872528076, loss: 42.86275839805603 
Train [11/26] | Epoch [44/160] |	nca: 1.9402238503098488, flat: 1.9346179515123367, pod: 37.40978956222534, loss: 41.28463172912598 
Train [11/26] | Epoch [45/160] |	nca: 1.7383920699357986, flat: 2.007916085422039, pod: 39.66947257518768, loss: 43.415780425071716 
Train [11/26] | Epoch [46/160] |	nca: 1.7353736832737923, flat: 2.0579152405261993, pod: 39.54279661178589, loss: 43.33608591556549 
Train [11/26] | Epoch [47/160] |	nca: 1.6665509343147278, flat: 1.8516875728964806, pod: 36.63017439842224, loss: 40.14841318130493 
Train [11/26] | Epoch [48/160] |	nca: 1.8606168776750565, flat: 1.8374236673116684, pod: 37.34503984451294, loss: 41.04308044910431 
Train [11/26] | Epoch [49/160] |	nca: 1.82078842446208, flat: 1.857857570052147, pod: 37.53076887130737, loss: 41.20941519737244 
Train [11/26] | Epoch [50/160] |	nca: 1.5807492919266224, flat: 1.7386044785380363, pod: 35.26010608673096, loss: 38.5794597864151 
Train [11/26] | Epoch [51/160] |	nca: 1.5455551072955132, flat: 1.777346208691597, pod: 35.30393826961517, loss: 38.62683975696564 
Train [11/26] | Epoch [52/160] |	nca: 1.8251331113278866, flat: 1.7042353078722954, pod: 35.084293246269226, loss: 38.613661885261536 
Train [11/26] | Epoch [53/160] |	nca: 1.777463924139738, flat: 1.7400972619652748, pod: 34.97994315624237, loss: 38.497503995895386 
Train [11/26] | Epoch [54/160] |	nca: 1.6111009530723095, flat: 1.7053405418992043, pod: 34.1361745595932, loss: 37.45261597633362 
Train [11/26] | Epoch [55/160] |	nca: 1.7547752149403095, flat: 1.698478952050209, pod: 34.592244148254395, loss: 38.04549777507782 
Train [11/26] | Epoch [56/160] |	nca: 1.6795135624706745, flat: 1.6557336747646332, pod: 34.30572843551636, loss: 37.64097535610199 
Train [11/26] | Epoch [57/160] |	nca: 1.7789228782057762, flat: 1.6574601978063583, pod: 35.23509085178375, loss: 38.67147386074066 
Train [11/26] | Epoch [58/160] |	nca: 1.7485397532582283, flat: 1.7209234312176704, pod: 36.15002083778381, loss: 39.619484066963196 
Train [11/26] | Epoch [59/160] |	nca: 1.7963125109672546, flat: 1.8330046907067299, pod: 37.06004524230957, loss: 40.68936204910278 
Train [11/26] | Epoch [60/160] |	nca: 1.710136853158474, flat: 1.7840951830148697, pod: 36.26005244255066, loss: 39.754284620285034 
Train [11/26] | Epoch [61/160] |	nca: 1.6992830745875835, flat: 1.735873594880104, pod: 36.26839554309845, loss: 39.70355188846588 
Train [11/26] | Epoch [62/160] |	nca: 1.7252593599259853, flat: 1.6008075177669525, pod: 34.044103384017944, loss: 37.37017071247101 
Train [11/26] | Epoch [63/160] |	nca: 1.688561573624611, flat: 1.5828574672341347, pod: 33.43527126312256, loss: 36.706690430641174 
Train [11/26] | Epoch [64/160] |	nca: 1.5749024897813797, flat: 1.7121874690055847, pod: 35.36033368110657, loss: 38.64742362499237 
Train [11/26] | Epoch [65/160] |	nca: 1.6514460034668446, flat: 1.5594976246356964, pod: 33.565672636032104, loss: 36.77661609649658 
Train [11/26] | Epoch [66/160] |	nca: 1.8643198050558567, flat: 1.6811505630612373, pod: 35.11029577255249, loss: 38.655766248703 
Train [11/26] | Epoch [67/160] |	nca: 1.622049417346716, flat: 1.5676480382680893, pod: 33.552973985672, loss: 36.742671489715576 
Train [11/26] | Epoch [68/160] |	nca: 1.6992693841457367, flat: 1.5401162654161453, pod: 32.850531816482544, loss: 36.08991718292236 
Train [11/26] | Epoch [69/160] |	nca: 1.632692277431488, flat: 1.6530621722340584, pod: 34.69189631938934, loss: 37.97765076160431 
Train [11/26] | Epoch [70/160] |	nca: 1.677413210272789, flat: 1.6578786820173264, pod: 35.28155243396759, loss: 38.61684477329254 
Train [11/26] | Epoch [71/160] |	nca: 1.7825693525373936, flat: 1.6809396892786026, pod: 35.0709832906723, loss: 38.5344922542572 
Train [11/26] | Epoch [72/160] |	nca: 1.6690027751028538, flat: 1.502208597958088, pod: 32.97105157375336, loss: 36.14226281642914 
Train [11/26] | Epoch [73/160] |	nca: 1.6800734400749207, flat: 1.6147488877177238, pod: 34.02754592895508, loss: 37.32236838340759 
Train [11/26] | Epoch [74/160] |	nca: 1.7132787853479385, flat: 1.5743161290884018, pod: 34.222018122673035, loss: 37.509613037109375 
Train [11/26] | Epoch [75/160] |	nca: 1.6319205537438393, flat: 1.4118556417524815, pod: 31.238049149513245, loss: 34.28182542324066 
Train [11/26] | Epoch [76/160] |	nca: 1.6213454082608223, flat: 1.5143891125917435, pod: 34.06224536895752, loss: 37.19797992706299 
Train [11/26] | Epoch [77/160] |	nca: 1.6624599359929562, flat: 1.4780437499284744, pod: 33.75902783870697, loss: 36.89953148365021 
Train [11/26] | Epoch [78/160] |	nca: 1.5948378145694733, flat: 1.449419654905796, pod: 31.63607108592987, loss: 34.680328726768494 
Train [11/26] | Epoch [79/160] |	nca: 1.6695621088147163, flat: 1.4619600474834442, pod: 31.957600712776184, loss: 35.089123249053955 
Train [11/26] | Epoch [80/160] |	nca: 1.5064111426472664, flat: 1.3599851801991463, pod: 31.480586767196655, loss: 34.34698295593262 
Train [11/26] | Epoch [81/160] |	nca: 1.66434096544981, flat: 1.4469413831830025, pod: 32.9577522277832, loss: 36.06903433799744 
Train [11/26] | Epoch [82/160] |	nca: 1.60891854763031, flat: 1.5398739501833916, pod: 34.289262533187866, loss: 37.43805527687073 
Train [11/26] | Epoch [83/160] |	nca: 1.4529176019132137, flat: 1.3744484595954418, pod: 30.15406370162964, loss: 32.98142969608307 
Train [11/26] | Epoch [84/160] |	nca: 1.6043305434286594, flat: 1.3281410969793797, pod: 30.78943693637848, loss: 33.72190880775452 
Train [11/26] | Epoch [85/160] |	nca: 1.4356255419552326, flat: 1.3205182440578938, pod: 31.202221751213074, loss: 33.95836555957794 
Train [11/26] | Epoch [86/160] |	nca: 1.6753108948469162, flat: 1.2641841657459736, pod: 30.169358611106873, loss: 33.10885393619537 
Train [11/26] | Epoch [87/160] |	nca: 1.57974311709404, flat: 1.3411706015467644, pod: 30.41765058040619, loss: 33.33856439590454 
Train [11/26] | Epoch [88/160] |	nca: 1.7829166762530804, flat: 1.3738657757639885, pod: 30.631868720054626, loss: 33.78865146636963 
Train [11/26] | Epoch [89/160] |	nca: 1.4794002771377563, flat: 1.2736935131251812, pod: 29.627323269844055, loss: 32.38041710853577 
Train [11/26] | Epoch [90/160] |	nca: 1.4476228915154934, flat: 1.2602806352078915, pod: 29.408228158950806, loss: 32.11613178253174 
Train [11/26] | Epoch [91/160] |	nca: 1.6582034267485142, flat: 1.2176706232130527, pod: 28.953182339668274, loss: 31.82905650138855 
Train [11/26] | Epoch [92/160] |	nca: 1.5747170448303223, flat: 1.2483078092336655, pod: 29.341899514198303, loss: 32.16492438316345 
Train [11/26] | Epoch [93/160] |	nca: 1.6154658943414688, flat: 1.1859412491321564, pod: 28.31561815738678, loss: 31.11702537536621 
Train [11/26] | Epoch [94/160] |	nca: 1.6261459775269032, flat: 1.1047446392476559, pod: 27.59893822669983, loss: 30.32982897758484 
Train [11/26] | Epoch [95/160] |	nca: 1.5361994095146656, flat: 1.195521768182516, pod: 28.615941524505615, loss: 31.347662568092346 
Train [11/26] | Epoch [96/160] |	nca: 1.5652266293764114, flat: 1.20093659684062, pod: 28.67929220199585, loss: 31.445455312728882 
Train [11/26] | Epoch [97/160] |	nca: 1.5723793618381023, flat: 1.1727867871522903, pod: 27.821751952171326, loss: 30.56691825389862 
Train [11/26] | Epoch [98/160] |	nca: 1.8273358903825283, flat: 1.321784496307373, pod: 29.86281955242157, loss: 33.011940002441406 
Train [11/26] | Epoch [99/160] |	nca: 1.5682890638709068, flat: 1.2989175617694855, pod: 30.87288475036621, loss: 33.74009168148041 
Train [11/26] | Epoch [100/160] |	nca: 1.4732407927513123, flat: 1.162723783403635, pod: 27.508360266685486, loss: 30.14432454109192 
Train [11/26] | Epoch [101/160] |	nca: 1.4554678536951542, flat: 1.1117643117904663, pod: 27.21723961830139, loss: 29.78447186946869 
Train [11/26] | Epoch [102/160] |	nca: 1.4011137895286083, flat: 1.0811843909323215, pod: 27.289939880371094, loss: 29.77223801612854 
Train [11/26] | Epoch [103/160] |	nca: 1.4156184941530228, flat: 1.1067369170486927, pod: 26.897790789604187, loss: 29.420146346092224 
Train [11/26] | Epoch [104/160] |	nca: 1.6173508539795876, flat: 1.0241719260811806, pod: 26.039057731628418, loss: 28.680580496788025 
Train [11/26] | Epoch [105/160] |	nca: 1.527813896536827, flat: 0.9856137558817863, pod: 25.663812518119812, loss: 28.177240133285522 
Train [11/26] | Epoch [106/160] |	nca: 1.5541448891162872, flat: 1.0797857977449894, pod: 25.705692768096924, loss: 28.33962368965149 
Train [11/26] | Epoch [107/160] |	nca: 1.5275960490107536, flat: 1.022008452564478, pod: 26.10180628299713, loss: 28.651410818099976 
Train [11/26] | Epoch [108/160] |	nca: 1.4056242778897285, flat: 1.0454331375658512, pod: 26.864579439163208, loss: 29.31563687324524 
Train [11/26] | Epoch [109/160] |	nca: 1.503075733780861, flat: 1.0243602655828, pod: 25.72824454307556, loss: 28.255680561065674 
Train [11/26] | Epoch [110/160] |	nca: 1.5362578071653843, flat: 0.9836130551993847, pod: 25.310011625289917, loss: 27.829882383346558 
Train [11/26] | Epoch [111/160] |	nca: 1.3253348171710968, flat: 0.9536092206835747, pod: 24.634342670440674, loss: 26.913286685943604 
Train [11/26] | Epoch [112/160] |	nca: 1.4128077365458012, flat: 0.8944897800683975, pod: 22.997895002365112, loss: 25.305192708969116 
Train [11/26] | Epoch [113/160] |	nca: 1.3936787880957127, flat: 0.8637834042310715, pod: 23.879276394844055, loss: 26.136738657951355 
Train [11/26] | Epoch [114/160] |	nca: 1.597651183605194, flat: 0.9089313521981239, pod: 23.596267104148865, loss: 26.1028493642807 
Train [11/26] | Epoch [115/160] |	nca: 1.5246923603117466, flat: 0.9073161296546459, pod: 23.70321238040924, loss: 26.135220885276794 
Train [11/26] | Epoch [116/160] |	nca: 1.4622593447566032, flat: 0.944842841476202, pod: 24.745378971099854, loss: 27.15248131752014 
Train [11/26] | Epoch [117/160] |	nca: 1.5213608071208, flat: 0.8975198790431023, pod: 24.57861030101776, loss: 26.997491002082825 
Train [11/26] | Epoch [118/160] |	nca: 1.4742352850735188, flat: 0.8670260570943356, pod: 24.249160766601562, loss: 26.59042203426361 
Train [11/26] | Epoch [119/160] |	nca: 1.5075198262929916, flat: 0.8626826070249081, pod: 23.436176896095276, loss: 25.806379318237305 
Train [11/26] | Epoch [120/160] |	nca: 1.4771715179085732, flat: 0.8514832109212875, pod: 22.83756995201111, loss: 25.16622495651245 
Train [11/26] | Epoch [121/160] |	nca: 1.4461317136883736, flat: 0.819346658885479, pod: 22.167760610580444, loss: 24.433239340782166 
Train [11/26] | Epoch [122/160] |	nca: 1.5178469121456146, flat: 0.8220920190215111, pod: 23.17580807209015, loss: 25.51574671268463 
Train [11/26] | Epoch [123/160] |	nca: 1.5649348087608814, flat: 0.7866568639874458, pod: 21.54533416032791, loss: 23.896925806999207 
Train [11/26] | Epoch [124/160] |	nca: 1.4196930043399334, flat: 0.8534324914216995, pod: 23.341873228549957, loss: 25.614999055862427 
Train [11/26] | Epoch [125/160] |	nca: 1.3798890337347984, flat: 0.7487215530127287, pod: 22.293861865997314, loss: 24.422472596168518 
Train [11/26] | Epoch [126/160] |	nca: 1.4189180731773376, flat: 0.7241861037909985, pod: 20.89022433757782, loss: 23.033328533172607 
Train [11/26] | Epoch [127/160] |	nca: 1.441332794725895, flat: 0.7439853698015213, pod: 21.52942395210266, loss: 23.714741945266724 
Train [11/26] | Epoch [128/160] |	nca: 1.4591731503605843, flat: 0.7124003320932388, pod: 20.759926974773407, loss: 22.931500554084778 
Train [11/26] | Epoch [129/160] |	nca: 1.4599809497594833, flat: 0.7111024856567383, pod: 20.93854683637619, loss: 23.109630346298218 
Train [11/26] | Epoch [130/160] |	nca: 1.5482907965779305, flat: 0.7885537873953581, pod: 22.187292277812958, loss: 24.524136543273926 
Train [11/26] | Epoch [131/160] |	nca: 1.452289842069149, flat: 0.758704723790288, pod: 21.252361118793488, loss: 23.463355660438538 
Train [11/26] | Epoch [132/160] |	nca: 1.5214867107570171, flat: 0.669442331418395, pod: 19.690311670303345, loss: 21.881240785121918 
Train [11/26] | Epoch [133/160] |	nca: 1.4240826517343521, flat: 0.6586599089205265, pod: 19.266867637634277, loss: 21.34961026906967 
Train [11/26] | Epoch [134/160] |	nca: 1.5046270415186882, flat: 0.678181728348136, pod: 19.029923617839813, loss: 21.212732434272766 
Train [11/26] | Epoch [135/160] |	nca: 1.4512824304401875, flat: 0.6580530926585197, pod: 19.190349221229553, loss: 21.299684464931488 
Train [11/26] | Epoch [136/160] |	nca: 1.4186532869935036, flat: 0.6482854727655649, pod: 18.471981167793274, loss: 20.538919925689697 
Train [11/26] | Epoch [137/160] |	nca: 1.4855373315513134, flat: 0.6429751757532358, pod: 18.752866685390472, loss: 20.88137912750244 
Train [11/26] | Epoch [138/160] |	nca: 1.5005600079894066, flat: 0.68053924664855, pod: 19.825498580932617, loss: 22.006597816944122 
Train [11/26] | Epoch [139/160] |	nca: 1.4810058884322643, flat: 0.6105639263987541, pod: 18.305370032787323, loss: 20.396940112113953 
Train [11/26] | Epoch [140/160] |	nca: 1.5254880040884018, flat: 0.6497346200048923, pod: 18.9485804438591, loss: 21.123802959918976 
Train [11/26] | Epoch [141/160] |	nca: 1.4412141367793083, flat: 0.6436418034136295, pod: 18.323681116104126, loss: 20.408537328243256 
Train [11/26] | Epoch [142/160] |	nca: 1.4825508520007133, flat: 0.6652923095971346, pod: 19.334125816822052, loss: 21.48196917772293 
Train [11/26] | Epoch [143/160] |	nca: 1.562843281775713, flat: 0.6160429790616035, pod: 18.5471892952919, loss: 20.726075530052185 
Train [11/26] | Epoch [144/160] |	nca: 1.4366496540606022, flat: 0.6393522303551435, pod: 18.73913687467575, loss: 20.81513875722885 
Train [11/26] | Epoch [145/160] |	nca: 1.510199848562479, flat: 0.6291854381561279, pod: 18.334254264831543, loss: 20.47363930940628 
Train [11/26] | Epoch [146/160] |	nca: 1.3926392681896687, flat: 0.6239919643849134, pod: 17.769704282283783, loss: 19.786335349082947 
Train [11/26] | Epoch [147/160] |	nca: 1.4677760004997253, flat: 0.5996029227972031, pod: 18.088972985744476, loss: 20.156352162361145 
Train [11/26] | Epoch [148/160] |	nca: 1.4851735942065716, flat: 0.5615899562835693, pod: 16.911251544952393, loss: 18.958015203475952 
Train [11/26] | Epoch [149/160] |	nca: 1.5005981139838696, flat: 0.5633775051683187, pod: 16.986504912376404, loss: 19.050480723381042 
Train [11/26] | Epoch [150/160] |	nca: 1.4036380723118782, flat: 0.5587901268154383, pod: 17.45179909467697, loss: 19.414227306842804 
Train [11/26] | Epoch [151/160] |	nca: 1.4162813797593117, flat: 0.5567565578967333, pod: 17.232555031776428, loss: 19.205592811107635 
Train [11/26] | Epoch [152/160] |	nca: 1.4187235124409199, flat: 0.525668554008007, pod: 16.41995006799698, loss: 18.364342212677002 
Train [11/26] | Epoch [153/160] |	nca: 1.3778319470584393, flat: 0.5487337429076433, pod: 16.441297471523285, loss: 18.367863178253174 
Train [11/26] | Epoch [154/160] |	nca: 1.406704094260931, flat: 0.567763265222311, pod: 16.638140499591827, loss: 18.612608015537262 
Train [11/26] | Epoch [155/160] |	nca: 1.3781525008380413, flat: 0.5462371986359358, pod: 16.62886893749237, loss: 18.553258657455444 
Train [11/26] | Epoch [156/160] |	nca: 1.4375046007335186, flat: 0.5374751146882772, pod: 16.246524274349213, loss: 18.221503913402557 
Train [11/26] | Epoch [157/160] |	nca: 1.4916057363152504, flat: 0.6027761604636908, pod: 17.353024125099182, loss: 19.447405755519867 
Train [11/26] | Epoch [158/160] |	nca: 1.4901097491383553, flat: 0.559954509139061, pod: 16.822807729244232, loss: 18.872872173786163 
Train [11/26] | Epoch [159/160] |	nca: 1.413293719291687, flat: 0.5496465153992176, pod: 16.654384195804596, loss: 18.617324352264404 
Train [11/26] | Epoch [160/160] |	nca: 1.4147963002324104, flat: 0.5787646323442459, pod: 17.06851214170456, loss: 19.062073230743408 
Fine-tuning
Building & updating memory.
Train [11/26] | Epoch [161/180] |	nca: 1.3065736405551434, flat: 0.7416981421411037, pod: 13.823951840400696, loss: 15.872223615646362 
Train [11/26] | Epoch [162/180] |	nca: 0.8511815816164017, flat: 0.7407797127962112, pod: 14.10755479335785, loss: 15.69951593875885 
Train [11/26] | Epoch [163/180] |	nca: 0.5944578573107719, flat: 0.7423360273241997, pod: 13.892560482025146, loss: 15.22935426235199 
Train [11/26] | Epoch [164/180] |	nca: 0.5383480228483677, flat: 0.7269523814320564, pod: 13.776769161224365, loss: 15.042069554328918 
Train [11/26] | Epoch [165/180] |	nca: 0.5382124744355679, flat: 0.7547782696783543, pod: 14.102998852729797, loss: 15.395989418029785 
Train [11/26] | Epoch [166/180] |	nca: 0.49938836693763733, flat: 0.7432280443608761, pod: 14.461857795715332, loss: 15.704474210739136 
Train [11/26] | Epoch [167/180] |	nca: 0.44301819428801537, flat: 0.7345976456999779, pod: 14.002585411071777, loss: 15.180201411247253 
Train [11/26] | Epoch [168/180] |	nca: 0.4621553998440504, flat: 0.7022014632821083, pod: 13.701740503311157, loss: 14.866097450256348 
Train [11/26] | Epoch [169/180] |	nca: 0.4565495792776346, flat: 0.7265896983444691, pod: 13.888821601867676, loss: 15.071960687637329 
Train [11/26] | Epoch [170/180] |	nca: 0.4458923451602459, flat: 0.7825928255915642, pod: 14.477179646492004, loss: 15.70566475391388 
Train [11/26] | Epoch [171/180] |	nca: 0.4523175209760666, flat: 0.7286180816590786, pod: 13.941256999969482, loss: 15.12219250202179 
Train [11/26] | Epoch [172/180] |	nca: 0.4328275304287672, flat: 0.7778342179954052, pod: 14.30900502204895, loss: 15.51966655254364 
Train [11/26] | Epoch [173/180] |	nca: 0.4136149473488331, flat: 0.7366684377193451, pod: 13.73314917087555, loss: 14.883432626724243 
Train [11/26] | Epoch [174/180] |	nca: 0.38946417160332203, flat: 0.7213457822799683, pod: 13.83424425125122, loss: 14.945054292678833 
Train [11/26] | Epoch [175/180] |	nca: 0.4648356009274721, flat: 0.7220811359584332, pod: 13.917264699935913, loss: 15.104181289672852 
Train [11/26] | Epoch [176/180] |	nca: 0.40382098592817783, flat: 0.7526948601007462, pod: 13.980539321899414, loss: 15.137055277824402 
Train [11/26] | Epoch [177/180] |	nca: 0.37912315130233765, flat: 0.7352065034210682, pod: 13.916372001171112, loss: 15.030701518058777 
Train [11/26] | Epoch [178/180] |	nca: 0.39804566837847233, flat: 0.7448618449270725, pod: 14.111658215522766, loss: 15.254565834999084 
Train [11/26] | Epoch [179/180] |	nca: 0.3965752348303795, flat: 0.7177059650421143, pod: 13.816813707351685, loss: 14.931094765663147 
Train [11/26] | Epoch [180/180] |	nca: 0.38775553554296494, flat: 0.7402538247406483, pod: 13.575920462608337, loss: 14.703929901123047 
after task
Building & updating memory.
after task
Eval on 0->70.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.673090909090909.
Current acc: {'total': 0.599, '00-09': 0.646, '10-19': 0.565, '20-29': 0.528, '30-39': 0.571, '40-49': 0.668, '50-59': 0.595, '60-69': 0.622}.
Avg inc acc top5: 0.8970909090909089.
Current acc top5: {'total': 0.859}.
Forgetting: 0.16525000000000004.
Cord metric: 0.67.
Old accuracy: 0.59, mean: 0.66.
New accuracy: 0.81, mean: 0.79.
================Task 11 Start!================
Testing on False unseen tasks (max class = 72).
Set memory of size: 1400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 11 Training!================
The training samples number: 2400
Train on 70->72.
train task
nb 2400.
Train [12/26] | Epoch [1/160] |	nca: 6.581291541457176, flat: 3.766458034515381, pod: 47.459425926208496, loss: 57.80717587471008 
Train [12/26] | Epoch [2/160] |	nca: 4.115900382399559, flat: 4.219755932688713, pod: 54.2265419960022, loss: 62.5621976852417 
Train [12/26] | Epoch [3/160] |	nca: 3.139258451759815, flat: 3.739577755331993, pod: 53.19860601425171, loss: 60.07744240760803 
Train [12/26] | Epoch [4/160] |	nca: 2.591230660676956, flat: 3.202401965856552, pod: 49.50344634056091, loss: 55.29707932472229 
Train [12/26] | Epoch [5/160] |	nca: 2.5406884849071503, flat: 3.0602285861968994, pod: 48.25436735153198, loss: 53.855284452438354 
Train [12/26] | Epoch [6/160] |	nca: 2.5042738541960716, flat: 2.888941675424576, pod: 47.62658476829529, loss: 53.01980018615723 
Train [12/26] | Epoch [7/160] |	nca: 2.2167679369449615, flat: 2.809426784515381, pod: 46.85092902183533, loss: 51.87712383270264 
Train [12/26] | Epoch [8/160] |	nca: 2.07378688454628, flat: 2.8379155844449997, pod: 46.94543099403381, loss: 51.857133865356445 
Train [12/26] | Epoch [9/160] |	nca: 2.086131401360035, flat: 2.826432853937149, pod: 45.46172881126404, loss: 50.374292850494385 
Train [12/26] | Epoch [10/160] |	nca: 2.023277699947357, flat: 2.7060476988554, pod: 45.91526007652283, loss: 50.644585371017456 
Train [12/26] | Epoch [11/160] |	nca: 2.0816792473196983, flat: 2.649295561015606, pod: 45.041407346725464, loss: 49.7723822593689 
Train [12/26] | Epoch [12/160] |	nca: 1.726884365081787, flat: 2.4627053141593933, pod: 44.86982178688049, loss: 49.05941152572632 
Train [12/26] | Epoch [13/160] |	nca: 1.7798415273427963, flat: 2.195589505136013, pod: 42.41112017631531, loss: 46.38655138015747 
Train [12/26] | Epoch [14/160] |	nca: 1.8624061569571495, flat: 2.2949483543634415, pod: 43.415831565856934, loss: 47.57318592071533 
Train [12/26] | Epoch [15/160] |	nca: 1.76610416918993, flat: 2.375818468630314, pod: 42.46414279937744, loss: 46.60606551170349 
Train [12/26] | Epoch [16/160] |	nca: 1.6603083610534668, flat: 2.3864086344838142, pod: 42.643489360809326, loss: 46.6902060508728 
Train [12/26] | Epoch [17/160] |	nca: 1.7288729175925255, flat: 2.3222341537475586, pod: 42.53054714202881, loss: 46.58165431022644 
Train [12/26] | Epoch [18/160] |	nca: 1.7537025474011898, flat: 2.398952640593052, pod: 43.80233955383301, loss: 47.954994440078735 
Train [12/26] | Epoch [19/160] |	nca: 1.5981954000890255, flat: 2.2435238733887672, pod: 42.17141270637512, loss: 46.013131856918335 
Train [12/26] | Epoch [20/160] |	nca: 1.949932087212801, flat: 2.5190431252121925, pod: 45.53301692008972, loss: 50.00199222564697 
Train [12/26] | Epoch [21/160] |	nca: 1.7113021276891232, flat: 2.426584340631962, pod: 44.93703627586365, loss: 49.07492256164551 
Train [12/26] | Epoch [22/160] |	nca: 1.5730434246361256, flat: 2.23436039686203, pod: 41.425065755844116, loss: 45.2324697971344 
Train [12/26] | Epoch [23/160] |	nca: 1.509285118430853, flat: 1.9190300703048706, pod: 37.760095834732056, loss: 41.18841052055359 
Train [12/26] | Epoch [24/160] |	nca: 1.6181510351598263, flat: 2.002055026590824, pod: 39.655896067619324, loss: 43.27610182762146 
Train [12/26] | Epoch [25/160] |	nca: 1.6600325889885426, flat: 2.2175173610448837, pod: 42.03088879585266, loss: 45.90843915939331 
Train [12/26] | Epoch [26/160] |	nca: 1.749921042472124, flat: 2.2569177597761154, pod: 42.37361240386963, loss: 46.380451679229736 
Train [12/26] | Epoch [27/160] |	nca: 1.72700085490942, flat: 2.172587588429451, pod: 40.547000765800476, loss: 44.44658899307251 
Train [12/26] | Epoch [28/160] |	nca: 1.625798437744379, flat: 2.1771130189299583, pod: 41.060293555259705, loss: 44.86320495605469 
Train [12/26] | Epoch [29/160] |	nca: 1.7269943542778492, flat: 2.43315027654171, pod: 43.32160699367523, loss: 47.48175120353699 
Train [12/26] | Epoch [30/160] |	nca: 1.5893049947917461, flat: 2.1566098406910896, pod: 40.94777309894562, loss: 44.69368767738342 
Train [12/26] | Epoch [31/160] |	nca: 1.6476018503308296, flat: 2.1044281274080276, pod: 40.61709988117218, loss: 44.36912941932678 
Train [12/26] | Epoch [32/160] |	nca: 1.629014477133751, flat: 2.2892458215355873, pod: 42.64030194282532, loss: 46.55856227874756 
Train [12/26] | Epoch [33/160] |	nca: 1.6606560684740543, flat: 2.089845448732376, pod: 39.36414909362793, loss: 43.11465048789978 
Train [12/26] | Epoch [34/160] |	nca: 1.658832173794508, flat: 1.9956633895635605, pod: 38.650799036026, loss: 42.30529475212097 
Train [12/26] | Epoch [35/160] |	nca: 1.6972593441605568, flat: 1.9875067919492722, pod: 38.04102182388306, loss: 41.72578811645508 
Train [12/26] | Epoch [36/160] |	nca: 1.5132752321660519, flat: 2.002456374466419, pod: 38.51184320449829, loss: 42.02757501602173 
Train [12/26] | Epoch [37/160] |	nca: 1.5980808660387993, flat: 2.055282860994339, pod: 40.70735836029053, loss: 44.36072254180908 
Train [12/26] | Epoch [38/160] |	nca: 1.415983360260725, flat: 1.9283113926649094, pod: 38.49338901042938, loss: 41.83768367767334 
Train [12/26] | Epoch [39/160] |	nca: 1.5641170218586922, flat: 1.9770039319992065, pod: 38.727388978004456, loss: 42.26851034164429 
Train [12/26] | Epoch [40/160] |	nca: 1.5725622810423374, flat: 1.9991349205374718, pod: 39.201576828956604, loss: 42.773274183273315 
Train [12/26] | Epoch [41/160] |	nca: 1.5043111108243465, flat: 1.9159998893737793, pod: 37.23346030712128, loss: 40.65377140045166 
Train [12/26] | Epoch [42/160] |	nca: 1.5202318541705608, flat: 1.8513518646359444, pod: 38.030245661735535, loss: 41.40182912349701 
Train [12/26] | Epoch [43/160] |	nca: 1.6083850897848606, flat: 1.8780620321631432, pod: 36.89814496040344, loss: 40.384591698646545 
Train [12/26] | Epoch [44/160] |	nca: 1.6952864155173302, flat: 2.1613645404577255, pod: 40.549108266830444, loss: 44.40575909614563 
Train [12/26] | Epoch [45/160] |	nca: 1.678169347345829, flat: 2.1189443543553352, pod: 40.602110743522644, loss: 44.399224519729614 
Train [12/26] | Epoch [46/160] |	nca: 1.3951342217624187, flat: 1.7891171425580978, pod: 37.41632628440857, loss: 40.60057735443115 
Train [12/26] | Epoch [47/160] |	nca: 1.5020519644021988, flat: 1.6931675150990486, pod: 37.39779019355774, loss: 40.59300994873047 
Train [12/26] | Epoch [48/160] |	nca: 1.4562056846916676, flat: 1.9153604060411453, pod: 40.01583385467529, loss: 43.387399673461914 
Train [12/26] | Epoch [49/160] |	nca: 1.5305569469928741, flat: 1.9083783403038979, pod: 39.23752522468567, loss: 42.67646026611328 
Train [12/26] | Epoch [50/160] |	nca: 1.5099473111331463, flat: 1.947558008134365, pod: 38.142497181892395, loss: 41.60000264644623 
Train [12/26] | Epoch [51/160] |	nca: 1.54083301872015, flat: 1.9679636135697365, pod: 39.317134737968445, loss: 42.82593131065369 
Train [12/26] | Epoch [52/160] |	nca: 1.5445510409772396, flat: 1.9655318185687065, pod: 38.47786486148834, loss: 41.98794770240784 
Train [12/26] | Epoch [53/160] |	nca: 1.423403974622488, flat: 1.8688834458589554, pod: 37.33084499835968, loss: 40.6231324672699 
Train [12/26] | Epoch [54/160] |	nca: 1.4635664448142052, flat: 1.7654303014278412, pod: 37.23591732978821, loss: 40.464914202690125 
Train [12/26] | Epoch [55/160] |	nca: 1.5879956968128681, flat: 1.8895389661192894, pod: 37.574448108673096, loss: 41.0519825220108 
Train [12/26] | Epoch [56/160] |	nca: 1.4436205141246319, flat: 1.9476113617420197, pod: 39.285114884376526, loss: 42.67634725570679 
Train [12/26] | Epoch [57/160] |	nca: 1.4826261550188065, flat: 1.903629295527935, pod: 38.15402925014496, loss: 41.54028511047363 
Train [12/26] | Epoch [58/160] |	nca: 1.4147794470191002, flat: 1.7481372654438019, pod: 36.69697713851929, loss: 39.859894037246704 
Train [12/26] | Epoch [59/160] |	nca: 1.532233577221632, flat: 1.6230950132012367, pod: 35.015724539756775, loss: 38.171053409576416 
Train [12/26] | Epoch [60/160] |	nca: 1.4680466130375862, flat: 1.6684964001178741, pod: 35.19018912315369, loss: 38.32673239707947 
Train [12/26] | Epoch [61/160] |	nca: 1.384116180241108, flat: 1.6065377816557884, pod: 34.190704703330994, loss: 37.18135857582092 
Train [12/26] | Epoch [62/160] |	nca: 1.35997374355793, flat: 1.6676575541496277, pod: 35.542357325553894, loss: 38.56998860836029 
Train [12/26] | Epoch [63/160] |	nca: 1.5013478063046932, flat: 1.8310387954115868, pod: 38.84516882896423, loss: 42.177555561065674 
Train [12/26] | Epoch [64/160] |	nca: 1.6056652441620827, flat: 1.8731811717152596, pod: 38.66720747947693, loss: 42.14605355262756 
Train [12/26] | Epoch [65/160] |	nca: 1.6429454907774925, flat: 1.8215939179062843, pod: 37.081786036491394, loss: 40.54632556438446 
Train [12/26] | Epoch [66/160] |	nca: 1.334614846855402, flat: 1.668479785323143, pod: 35.58278691768646, loss: 38.58588182926178 
Train [12/26] | Epoch [67/160] |	nca: 1.5808623060584068, flat: 1.8219567984342575, pod: 39.109689593315125, loss: 42.512508153915405 
Train [12/26] | Epoch [68/160] |	nca: 1.4197142645716667, flat: 1.6064058244228363, pod: 35.75339603424072, loss: 38.779516100883484 
Train [12/26] | Epoch [69/160] |	nca: 1.439106434583664, flat: 1.5029916688799858, pod: 33.495479702949524, loss: 36.43757784366608 
Train [12/26] | Epoch [70/160] |	nca: 1.463670875877142, flat: 1.5828825011849403, pod: 33.71421778202057, loss: 36.76077091693878 
Train [12/26] | Epoch [71/160] |	nca: 1.3554547168314457, flat: 1.4950013756752014, pod: 32.958341002464294, loss: 35.808797001838684 
Train [12/26] | Epoch [72/160] |	nca: 1.2819327265024185, flat: 1.5486821085214615, pod: 35.348774433135986, loss: 38.179389238357544 
Train [12/26] | Epoch [73/160] |	nca: 1.4571205638349056, flat: 1.5298945903778076, pod: 33.50968086719513, loss: 36.49669623374939 
Train [12/26] | Epoch [74/160] |	nca: 1.3485532328486443, flat: 1.556174248456955, pod: 34.45395612716675, loss: 37.358683943748474 
Train [12/26] | Epoch [75/160] |	nca: 1.3661919087171555, flat: 1.5642275959253311, pod: 34.16545104980469, loss: 37.09587073326111 
Train [12/26] | Epoch [76/160] |	nca: 1.3234897702932358, flat: 1.393291436135769, pod: 32.30171060562134, loss: 35.01849150657654 
Train [12/26] | Epoch [77/160] |	nca: 1.3308773264288902, flat: 1.4758466631174088, pod: 33.98152577877045, loss: 36.788250207901 
Train [12/26] | Epoch [78/160] |	nca: 1.4686278067529202, flat: 1.5475318059325218, pod: 34.480257749557495, loss: 37.49641752243042 
Train [12/26] | Epoch [79/160] |	nca: 1.3527611941099167, flat: 1.289867389947176, pod: 31.133041620254517, loss: 33.775670289993286 
Train [12/26] | Epoch [80/160] |	nca: 1.4140867069363594, flat: 1.476855095475912, pod: 34.30561685562134, loss: 37.196558356285095 
Train [12/26] | Epoch [81/160] |	nca: 1.3757497854530811, flat: 1.3846195228397846, pod: 31.473300099372864, loss: 34.23366940021515 
Train [12/26] | Epoch [82/160] |	nca: 1.6092489585280418, flat: 1.51787743344903, pod: 33.55155396461487, loss: 36.678680062294006 
Train [12/26] | Epoch [83/160] |	nca: 1.3321596048772335, flat: 1.4961216375231743, pod: 33.46149432659149, loss: 36.289775371551514 
Train [12/26] | Epoch [84/160] |	nca: 1.4652510471642017, flat: 1.4183374717831612, pod: 32.05741202831268, loss: 34.94100093841553 
Train [12/26] | Epoch [85/160] |	nca: 1.3950059190392494, flat: 1.4257131926715374, pod: 32.5381293296814, loss: 35.358848214149475 
Train [12/26] | Epoch [86/160] |	nca: 1.4655332900583744, flat: 1.441227588802576, pod: 33.496705055236816, loss: 36.40346586704254 
Train [12/26] | Epoch [87/160] |	nca: 1.5220905542373657, flat: 1.2944745235145092, pod: 31.150511622428894, loss: 33.967076778411865 
Train [12/26] | Epoch [88/160] |	nca: 1.2830567918717861, flat: 1.2709656655788422, pod: 30.20447087287903, loss: 32.758492946624756 
Train [12/26] | Epoch [89/160] |	nca: 1.2662432193756104, flat: 1.1874206624925137, pod: 28.880993366241455, loss: 31.334657073020935 
Train [12/26] | Epoch [90/160] |	nca: 1.2643625885248184, flat: 1.193441417068243, pod: 30.15350341796875, loss: 32.61130714416504 
Train [12/26] | Epoch [91/160] |	nca: 1.2628388591110706, flat: 1.3497805520892143, pod: 32.239893317222595, loss: 34.85251307487488 
Train [12/26] | Epoch [92/160] |	nca: 1.2760117501020432, flat: 1.0528392307460308, pod: 27.275004029273987, loss: 29.60385501384735 
Train [12/26] | Epoch [93/160] |	nca: 1.2865784205496311, flat: 1.1063686721026897, pod: 27.697753429412842, loss: 30.090700268745422 
Train [12/26] | Epoch [94/160] |	nca: 1.2292478419840336, flat: 1.1644315756857395, pod: 28.541189551353455, loss: 30.934869170188904 
Train [12/26] | Epoch [95/160] |	nca: 1.2980340532958508, flat: 1.105270341038704, pod: 28.412575006484985, loss: 30.815879583358765 
Train [12/26] | Epoch [96/160] |	nca: 1.400191269814968, flat: 1.1487167999148369, pod: 29.268898963928223, loss: 31.817806839942932 
Train [12/26] | Epoch [97/160] |	nca: 1.3881502449512482, flat: 1.212384857237339, pod: 30.6088365316391, loss: 33.20937156677246 
Train [12/26] | Epoch [98/160] |	nca: 1.3495073802769184, flat: 1.2185643017292023, pod: 30.028749346733093, loss: 32.59682095050812 
Train [12/26] | Epoch [99/160] |	nca: 1.2111314311623573, flat: 1.144508734345436, pod: 28.860929250717163, loss: 31.216569185256958 
Train [12/26] | Epoch [100/160] |	nca: 1.3604567795991898, flat: 1.1706652380526066, pod: 28.63600766658783, loss: 31.16712975502014 
Train [12/26] | Epoch [101/160] |	nca: 1.3025758564472198, flat: 1.1035021468997002, pod: 28.60346245765686, loss: 31.009540557861328 
Train [12/26] | Epoch [102/160] |	nca: 1.1186029016971588, flat: 0.9970886148512363, pod: 26.597707271575928, loss: 28.713398694992065 
Train [12/26] | Epoch [103/160] |	nca: 1.3601128682494164, flat: 1.0807291269302368, pod: 28.446536779403687, loss: 30.887378692626953 
Train [12/26] | Epoch [104/160] |	nca: 1.1577012203633785, flat: 1.072004433721304, pod: 27.99407410621643, loss: 30.223779678344727 
Train [12/26] | Epoch [105/160] |	nca: 1.3023713380098343, flat: 1.1268778145313263, pod: 27.926211714744568, loss: 30.35546088218689 
Train [12/26] | Epoch [106/160] |	nca: 1.3125386461615562, flat: 1.1145181879401207, pod: 29.210977911949158, loss: 31.63803482055664 
Train [12/26] | Epoch [107/160] |	nca: 1.24548863992095, flat: 1.0865187235176563, pod: 28.000678062438965, loss: 30.332685470581055 
Train [12/26] | Epoch [108/160] |	nca: 1.2006413638591766, flat: 1.0067766718566418, pod: 27.759432673454285, loss: 29.966850757598877 
Train [12/26] | Epoch [109/160] |	nca: 1.2889822907745838, flat: 0.9483869485557079, pod: 25.76577925682068, loss: 28.003148674964905 
Train [12/26] | Epoch [110/160] |	nca: 1.315648090094328, flat: 0.9841235652565956, pod: 25.881444454193115, loss: 28.18121600151062 
Train [12/26] | Epoch [111/160] |	nca: 1.2079332545399666, flat: 0.898351676762104, pod: 24.73531222343445, loss: 26.841597318649292 
Train [12/26] | Epoch [112/160] |	nca: 1.2819403372704983, flat: 0.9041938111186028, pod: 24.445610642433167, loss: 26.631744742393494 
Train [12/26] | Epoch [113/160] |	nca: 1.2887179180979729, flat: 0.9603681676089764, pod: 25.795486450195312, loss: 28.044572591781616 
Train [12/26] | Epoch [114/160] |	nca: 1.2637902274727821, flat: 0.8741670623421669, pod: 24.96339511871338, loss: 27.10135245323181 
Train [12/26] | Epoch [115/160] |	nca: 1.1342368461191654, flat: 0.8543663360178471, pod: 24.748525142669678, loss: 26.737128496170044 
Train [12/26] | Epoch [116/160] |	nca: 1.2556891329586506, flat: 0.8063383996486664, pod: 22.56728184223175, loss: 24.62930929660797 
Train [12/26] | Epoch [117/160] |	nca: 1.3524055518209934, flat: 0.888624083250761, pod: 24.216761469841003, loss: 26.457790970802307 
Train [12/26] | Epoch [118/160] |	nca: 1.188128687441349, flat: 0.8723545521497726, pod: 24.386226773262024, loss: 26.446709990501404 
Train [12/26] | Epoch [119/160] |	nca: 1.2106893695890903, flat: 0.780914893373847, pod: 22.383603930473328, loss: 24.375208139419556 
Train [12/26] | Epoch [120/160] |	nca: 1.2525519393384457, flat: 0.7819121554493904, pod: 22.891181230545044, loss: 24.92564558982849 
Train [12/26] | Epoch [121/160] |	nca: 1.2691532298922539, flat: 0.8266250677406788, pod: 24.26809823513031, loss: 26.363876461982727 
Train [12/26] | Epoch [122/160] |	nca: 1.2247076705098152, flat: 0.7688678987324238, pod: 22.490755438804626, loss: 24.484330773353577 
Train [12/26] | Epoch [123/160] |	nca: 1.1765881106257439, flat: 0.7910449355840683, pod: 22.24716579914093, loss: 24.21479880809784 
Train [12/26] | Epoch [124/160] |	nca: 1.2711435221135616, flat: 0.7634270824491978, pod: 22.423802375793457, loss: 24.458372950553894 
Train [12/26] | Epoch [125/160] |	nca: 1.2133735567331314, flat: 0.7635354027152061, pod: 22.630951046943665, loss: 24.60785984992981 
Train [12/26] | Epoch [126/160] |	nca: 1.2446746714413166, flat: 0.8158453404903412, pod: 24.055113315582275, loss: 26.115633487701416 
Train [12/26] | Epoch [127/160] |	nca: 1.2055185474455357, flat: 0.7236944399774075, pod: 22.08113133907318, loss: 24.01034438610077 
Train [12/26] | Epoch [128/160] |	nca: 1.185330145061016, flat: 0.7269171550869942, pod: 21.857675552368164, loss: 23.769922852516174 
Train [12/26] | Epoch [129/160] |	nca: 1.1798771508038044, flat: 0.7354792542755604, pod: 21.7382835149765, loss: 23.653639793395996 
Train [12/26] | Epoch [130/160] |	nca: 1.2370239570736885, flat: 0.7267860975116491, pod: 21.45806521177292, loss: 23.421875476837158 
Train [12/26] | Epoch [131/160] |	nca: 1.1730910614132881, flat: 0.7156291957944632, pod: 22.16120308637619, loss: 24.049923062324524 
Train [12/26] | Epoch [132/160] |	nca: 1.228649266064167, flat: 0.6399956941604614, pod: 19.590710043907166, loss: 21.459355115890503 
Train [12/26] | Epoch [133/160] |	nca: 1.3086043372750282, flat: 0.6537757385522127, pod: 20.48134332895279, loss: 22.443723320961 
Train [12/26] | Epoch [134/160] |	nca: 1.1225287057459354, flat: 0.6126232482492924, pod: 19.32485717535019, loss: 21.060008704662323 
Train [12/26] | Epoch [135/160] |	nca: 1.1642447374761105, flat: 0.595272159203887, pod: 19.27735996246338, loss: 21.036876618862152 
Train [12/26] | Epoch [136/160] |	nca: 1.2708489075303078, flat: 0.6576685719192028, pod: 19.997693240642548, loss: 21.926210820674896 
Train [12/26] | Epoch [137/160] |	nca: 1.2392705753445625, flat: 0.648296982049942, pod: 19.89619928598404, loss: 21.78376680612564 
Train [12/26] | Epoch [138/160] |	nca: 1.2794843465089798, flat: 0.7164908293634653, pod: 20.687521159648895, loss: 22.683496296405792 
Train [12/26] | Epoch [139/160] |	nca: 1.2956927008926868, flat: 0.6444362457841635, pod: 19.717383861541748, loss: 21.657512962818146 
Train [12/26] | Epoch [140/160] |	nca: 1.1548882871866226, flat: 0.6174082588404417, pod: 19.419629514217377, loss: 21.19192600250244 
Train [12/26] | Epoch [141/160] |	nca: 1.1547116376459599, flat: 0.5523524973541498, pod: 18.37555867433548, loss: 20.08262264728546 
Train [12/26] | Epoch [142/160] |	nca: 1.235437486320734, flat: 0.6068786103278399, pod: 19.356578052043915, loss: 21.198894262313843 
Train [12/26] | Epoch [143/160] |	nca: 1.1944423094391823, flat: 0.6456628441810608, pod: 19.487773537635803, loss: 21.327878773212433 
Train [12/26] | Epoch [144/160] |	nca: 1.1575135253369808, flat: 0.5682301186025143, pod: 18.239992558956146, loss: 19.965736210346222 
Train [12/26] | Epoch [145/160] |	nca: 1.17743606492877, flat: 0.6366580910980701, pod: 19.21743768453598, loss: 21.031531929969788 
Train [12/26] | Epoch [146/160] |	nca: 1.1522516645491123, flat: 0.5169930532574654, pod: 17.218496322631836, loss: 18.887740910053253 
Train [12/26] | Epoch [147/160] |	nca: 1.192819844931364, flat: 0.5724978968501091, pod: 18.192307472229004, loss: 19.957625150680542 
Train [12/26] | Epoch [148/160] |	nca: 1.1556729823350906, flat: 0.6215324755758047, pod: 18.331606447696686, loss: 20.108811914920807 
Train [12/26] | Epoch [149/160] |	nca: 1.236530240625143, flat: 0.5433772038668394, pod: 17.903456330299377, loss: 19.68336373567581 
Train [12/26] | Epoch [150/160] |	nca: 1.2218147739768028, flat: 0.5640910379588604, pod: 17.852975368499756, loss: 19.638881027698517 
Train [12/26] | Epoch [151/160] |	nca: 1.2018530778586864, flat: 0.5629838015884161, pod: 17.45284342765808, loss: 19.217680275440216 
Train [12/26] | Epoch [152/160] |	nca: 1.1582273729145527, flat: 0.5656975470483303, pod: 18.02081048488617, loss: 19.74473536014557 
Train [12/26] | Epoch [153/160] |	nca: 1.1576433889567852, flat: 0.5473499409854412, pod: 17.140629291534424, loss: 18.84562259912491 
Train [12/26] | Epoch [154/160] |	nca: 1.250984337180853, flat: 0.528341019526124, pod: 17.0104877948761, loss: 18.78981304168701 
Train [12/26] | Epoch [155/160] |	nca: 1.2299718894064426, flat: 0.5662117172032595, pod: 17.702559769153595, loss: 19.498743176460266 
Train [12/26] | Epoch [156/160] |	nca: 1.221178736537695, flat: 0.5440826490521431, pod: 16.826340436935425, loss: 18.591601848602295 
Train [12/26] | Epoch [157/160] |	nca: 1.235408280044794, flat: 0.5591130834072828, pod: 16.66992563009262, loss: 18.464447140693665 
Train [12/26] | Epoch [158/160] |	nca: 1.1531807631254196, flat: 0.5157665573060513, pod: 16.060044586658478, loss: 17.728991985321045 
Train [12/26] | Epoch [159/160] |	nca: 1.2306094206869602, flat: 0.5426421444863081, pod: 16.936267256736755, loss: 18.709518909454346 
Train [12/26] | Epoch [160/160] |	nca: 1.167484998703003, flat: 0.5467926878482103, pod: 16.875929832458496, loss: 18.590207397937775 
Fine-tuning
Building & updating memory.
Train [12/26] | Epoch [161/180] |	nca: 1.2238690555095673, flat: 1.1385945044457912, pod: 18.91477608680725, loss: 21.277239680290222 
Train [12/26] | Epoch [162/180] |	nca: 0.8005560860037804, flat: 1.1276769526302814, pod: 18.40613877773285, loss: 20.33437204360962 
Train [12/26] | Epoch [163/180] |	nca: 0.6412069164216518, flat: 1.1260063275694847, pod: 18.293313026428223, loss: 20.060526251792908 
Train [12/26] | Epoch [164/180] |	nca: 0.5495827347040176, flat: 1.1763462983071804, pod: 18.90065085887909, loss: 20.626580238342285 
Train [12/26] | Epoch [165/180] |	nca: 0.5477398354560137, flat: 1.1181836761534214, pod: 18.148088574409485, loss: 19.814012050628662 
Train [12/26] | Epoch [166/180] |	nca: 0.5365856103599072, flat: 1.1181368827819824, pod: 18.569525241851807, loss: 20.224247574806213 
Train [12/26] | Epoch [167/180] |	nca: 0.6183681935071945, flat: 1.1856057941913605, pod: 18.6460177898407, loss: 20.449991822242737 
Train [12/26] | Epoch [168/180] |	nca: 0.6140551418066025, flat: 1.1768852099776268, pod: 18.84932780265808, loss: 20.640268206596375 
Train [12/26] | Epoch [169/180] |	nca: 0.5036376267671585, flat: 1.0681529939174652, pod: 17.802574515342712, loss: 19.374365091323853 
Train [12/26] | Epoch [170/180] |	nca: 0.6202421523630619, flat: 1.1404234766960144, pod: 18.512757778167725, loss: 20.273423314094543 
Train [12/26] | Epoch [171/180] |	nca: 0.5695601031184196, flat: 1.167834609746933, pod: 18.586037278175354, loss: 20.323432087898254 
Train [12/26] | Epoch [172/180] |	nca: 0.5184481497853994, flat: 1.1433698385953903, pod: 18.5980167388916, loss: 20.25983452796936 
Train [12/26] | Epoch [173/180] |	nca: 0.5156811214983463, flat: 1.1128053069114685, pod: 18.300216913223267, loss: 19.92870342731476 
Train [12/26] | Epoch [174/180] |	nca: 0.5972031652927399, flat: 1.212058573961258, pod: 18.79473853111267, loss: 20.604000329971313 
Train [12/26] | Epoch [175/180] |	nca: 0.5479424074292183, flat: 1.152286410331726, pod: 18.36407506465912, loss: 20.064303874969482 
Train [12/26] | Epoch [176/180] |	nca: 0.5592167805880308, flat: 1.133437879383564, pod: 18.610254406929016, loss: 20.302909016609192 
Train [12/26] | Epoch [177/180] |	nca: 0.5398538392037153, flat: 1.1091600880026817, pod: 18.35531783103943, loss: 20.004331827163696 
Train [12/26] | Epoch [178/180] |	nca: 0.4831947013735771, flat: 1.1069464087486267, pod: 18.63300371170044, loss: 20.22314465045929 
Train [12/26] | Epoch [179/180] |	nca: 0.4843767173588276, flat: 1.1580806449055672, pod: 18.814115285873413, loss: 20.456572890281677 
Train [12/26] | Epoch [180/180] |	nca: 0.4529877323657274, flat: 1.1536518447101116, pod: 18.325576543807983, loss: 19.93221616744995 
after task
Building & updating memory.
after task
Eval on 0->72.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6666666666666666.
Current acc: {'total': 0.596, '00-09': 0.639, '10-19': 0.578, '20-29': 0.525, '30-39': 0.557, '40-49': 0.664, '50-59': 0.583, '60-69': 0.59, '70-79': 0.76}.
Avg inc acc top5: 0.8937499999999998.
Current acc top5: {'total': 0.857}.
Forgetting: 0.069.
Cord metric: 0.66.
Old accuracy: 0.59, mean: 0.65.
New accuracy: 0.76, mean: 0.79.
================Task 12 Start!================
Testing on False unseen tasks (max class = 74).
Set memory of size: 1440.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 12 Training!================
The training samples number: 2440
Train on 72->74.
train task
nb 2440.
Train [13/26] | Epoch [1/160] |	nca: 7.140806540846825, flat: 4.209853462874889, pod: 49.379465222358704, loss: 60.730125188827515 
Train [13/26] | Epoch [2/160] |	nca: 8.730058908462524, flat: 7.713387876749039, pod: 70.46446228027344, loss: 86.90790939331055 
Train [13/26] | Epoch [3/160] |	nca: 15.29494959115982, flat: 12.17032876610756, pod: 87.48267865180969, loss: 114.9479570388794 
Train [13/26] | Epoch [4/160] |	nca: 16.792448818683624, flat: 13.01038932800293, pod: 92.37313890457153, loss: 122.17597818374634 
Train [13/26] | Epoch [5/160] |	nca: 20.86138027906418, flat: 15.96258020401001, pod: 101.59323692321777, loss: 138.41719722747803 
Train [13/26] | Epoch [6/160] |	nca: 10.68973508477211, flat: 11.417647421360016, pod: 87.10141444206238, loss: 109.20879745483398 
Train [13/26] | Epoch [7/160] |	nca: 6.365454614162445, flat: 8.858811169862747, pod: 79.35265064239502, loss: 94.57691669464111 
Train [13/26] | Epoch [8/160] |	nca: 4.654340833425522, flat: 7.179497987031937, pod: 72.73351740837097, loss: 84.56735563278198 
Train [13/26] | Epoch [9/160] |	nca: 4.395758330821991, flat: 6.115358531475067, pod: 65.6064703464508, loss: 76.11758780479431 
Train [13/26] | Epoch [10/160] |	nca: 5.931520119309425, flat: 7.443354845046997, pod: 71.1821722984314, loss: 84.5570478439331 
Train [13/26] | Epoch [11/160] |	nca: 5.553988292813301, flat: 7.458437830209732, pod: 72.18504476547241, loss: 85.19747114181519 
Train [13/26] | Epoch [12/160] |	nca: 3.827802501618862, flat: 6.170531794428825, pod: 65.7855474948883, loss: 75.78388142585754 
Train [13/26] | Epoch [13/160] |	nca: 4.208032011985779, flat: 5.687551751732826, pod: 63.735172510147095, loss: 73.63075613975525 
Train [13/26] | Epoch [14/160] |	nca: 5.031124971807003, flat: 6.881393253803253, pod: 67.42086052894592, loss: 79.33337831497192 
Train [13/26] | Epoch [15/160] |	nca: 5.672034904360771, flat: 6.621727257966995, pod: 67.16210174560547, loss: 79.45586395263672 
Train [13/26] | Epoch [16/160] |	nca: 6.050430670380592, flat: 7.582910269498825, pod: 70.03622150421143, loss: 83.66956233978271 
Train [13/26] | Epoch [17/160] |	nca: 3.73469390720129, flat: 5.462681785225868, pod: 61.849000692367554, loss: 71.04637694358826 
Train [13/26] | Epoch [18/160] |	nca: 4.433865904808044, flat: 5.930849581956863, pod: 63.63160943984985, loss: 73.99632573127747 
Train [13/26] | Epoch [19/160] |	nca: 3.8660871908068657, flat: 5.282088443636894, pod: 61.019917249679565, loss: 70.16809296607971 
Train [13/26] | Epoch [20/160] |	nca: 4.9576544016599655, flat: 6.491507813334465, pod: 64.17746877670288, loss: 75.62663102149963 
Train [13/26] | Epoch [21/160] |	nca: 3.8647698760032654, flat: 6.05239836871624, pod: 62.93850493431091, loss: 72.85567259788513 
Train [13/26] | Epoch [22/160] |	nca: 2.7650533989071846, flat: 4.607528641819954, pod: 56.64063572883606, loss: 64.01321792602539 
Train [13/26] | Epoch [23/160] |	nca: 2.637925811111927, flat: 4.571175277233124, pod: 56.80952429771423, loss: 64.01862502098083 
Train [13/26] | Epoch [24/160] |	nca: 3.340279422700405, flat: 4.7407035529613495, pod: 57.922730684280396, loss: 66.00371408462524 
Train [13/26] | Epoch [25/160] |	nca: 3.190204083919525, flat: 4.486499458551407, pod: 56.914894342422485, loss: 64.59159827232361 
Train [13/26] | Epoch [26/160] |	nca: 4.063396953046322, flat: 5.294035419821739, pod: 60.540611267089844, loss: 69.8980438709259 
Train [13/26] | Epoch [27/160] |	nca: 4.761114552617073, flat: 5.670332700014114, pod: 61.78474545478821, loss: 72.2161922454834 
Train [13/26] | Epoch [28/160] |	nca: 3.3665001541376114, flat: 4.97286818921566, pod: 57.33772325515747, loss: 65.67709112167358 
Train [13/26] | Epoch [29/160] |	nca: 3.3600558564066887, flat: 4.812325477600098, pod: 57.59964561462402, loss: 65.77202701568604 
Train [13/26] | Epoch [30/160] |	nca: 3.1082068383693695, flat: 4.153508931398392, pod: 53.689767837524414, loss: 60.951483726501465 
Train [13/26] | Epoch [31/160] |	nca: 5.997377723455429, flat: 6.851489037275314, pod: 66.09941077232361, loss: 78.9482774734497 
Train [13/26] | Epoch [32/160] |	nca: 4.4720843732357025, flat: 6.324123054742813, pod: 66.23977565765381, loss: 77.03598380088806 
Train [13/26] | Epoch [33/160] |	nca: 2.9108235836029053, flat: 4.332680717110634, pod: 55.270973682403564, loss: 62.51447820663452 
Train [13/26] | Epoch [34/160] |	nca: 3.2571036890149117, flat: 4.392639234662056, pod: 54.66005539894104, loss: 62.30979824066162 
Train [13/26] | Epoch [35/160] |	nca: 2.708700455725193, flat: 4.032967045903206, pod: 51.702529191970825, loss: 58.444196701049805 
Train [13/26] | Epoch [36/160] |	nca: 2.788373440504074, flat: 4.43530635535717, pod: 56.0041720867157, loss: 63.22785210609436 
Train [13/26] | Epoch [37/160] |	nca: 1.9183497801423073, flat: 3.4181265830993652, pod: 48.60965609550476, loss: 53.94613242149353 
Train [13/26] | Epoch [38/160] |	nca: 2.1621131598949432, flat: 3.3621113896369934, pod: 50.95295286178589, loss: 56.4771773815155 
Train [13/26] | Epoch [39/160] |	nca: 1.8976635709404945, flat: 3.0755574479699135, pod: 46.96856164932251, loss: 51.9417827129364 
Train [13/26] | Epoch [40/160] |	nca: 2.4423806481063366, flat: 3.5214161574840546, pod: 48.737977027893066, loss: 54.70177340507507 
Train [13/26] | Epoch [41/160] |	nca: 3.358940474689007, flat: 3.863722175359726, pod: 50.32594060897827, loss: 57.54860305786133 
Train [13/26] | Epoch [42/160] |	nca: 4.227221116423607, flat: 5.478119120001793, pod: 59.98103332519531, loss: 69.68637347221375 
Train [13/26] | Epoch [43/160] |	nca: 2.9761711582541466, flat: 3.7258803099393845, pod: 49.402973890304565, loss: 56.10502576828003 
Train [13/26] | Epoch [44/160] |	nca: 3.8014421686530113, flat: 5.2787612825632095, pod: 57.03535985946655, loss: 66.11556339263916 
Train [13/26] | Epoch [45/160] |	nca: 4.205570802092552, flat: 5.301220282912254, pod: 57.497907638549805, loss: 67.00469851493835 
Train [13/26] | Epoch [46/160] |	nca: 6.940539591014385, flat: 7.4997295290231705, pod: 70.69285869598389, loss: 85.13312816619873 
Train [13/26] | Epoch [47/160] |	nca: 7.312284991145134, flat: 7.884872734546661, pod: 70.72561502456665, loss: 85.92277336120605 
Train [13/26] | Epoch [48/160] |	nca: 3.6274470537900925, flat: 5.620808392763138, pod: 60.96569538116455, loss: 70.21395087242126 
Train [13/26] | Epoch [49/160] |	nca: 4.316327437758446, flat: 5.504224240779877, pod: 57.97967457771301, loss: 67.80022668838501 
Train [13/26] | Epoch [50/160] |	nca: 3.116032652556896, flat: 5.1532008945941925, pod: 56.94503569602966, loss: 65.21426892280579 
Train [13/26] | Epoch [51/160] |	nca: 2.141788676381111, flat: 3.725376322865486, pod: 49.61195755004883, loss: 55.47912263870239 
Train [13/26] | Epoch [52/160] |	nca: 1.9281029477715492, flat: 3.2637637853622437, pod: 46.5259063243866, loss: 51.7177734375 
Train [13/26] | Epoch [53/160] |	nca: 2.4752232208848, flat: 3.4399462789297104, pod: 47.963324785232544, loss: 53.87849473953247 
Train [13/26] | Epoch [54/160] |	nca: 3.3526710495352745, flat: 3.9558694064617157, pod: 51.43982791900635, loss: 58.74836850166321 
Train [13/26] | Epoch [55/160] |	nca: 3.66443595290184, flat: 5.017442971467972, pod: 58.45579814910889, loss: 67.13767719268799 
Train [13/26] | Epoch [56/160] |	nca: 3.422228030860424, flat: 4.400017976760864, pod: 54.82641553878784, loss: 62.648662090301514 
Train [13/26] | Epoch [57/160] |	nca: 3.4283809885382652, flat: 4.5665653347969055, pod: 55.96433210372925, loss: 63.95927834510803 
Train [13/26] | Epoch [58/160] |	nca: 1.9452984891831875, flat: 3.490030139684677, pod: 49.06635904312134, loss: 54.50168800354004 
Train [13/26] | Epoch [59/160] |	nca: 1.896057978272438, flat: 2.691700331866741, pod: 43.258442640304565, loss: 47.84620130062103 
Train [13/26] | Epoch [60/160] |	nca: 2.288622371852398, flat: 3.243626296520233, pod: 46.543988943099976, loss: 52.07623744010925 
Train [13/26] | Epoch [61/160] |	nca: 1.734334472566843, flat: 2.543999992311001, pod: 42.93910896778107, loss: 47.21744346618652 
Train [13/26] | Epoch [62/160] |	nca: 2.5927684754133224, flat: 3.1776712089776993, pod: 45.64895796775818, loss: 51.419398069381714 
Train [13/26] | Epoch [63/160] |	nca: 2.2368809171020985, flat: 2.8949997052550316, pod: 43.681596994400024, loss: 48.813477516174316 
Train [13/26] | Epoch [64/160] |	nca: 2.0506082363426685, flat: 3.2407790571451187, pod: 45.09648156166077, loss: 50.38786864280701 
Train [13/26] | Epoch [65/160] |	nca: 1.7843735255300999, flat: 2.541734106838703, pod: 40.598161816596985, loss: 44.924269795417786 
Train [13/26] | Epoch [66/160] |	nca: 2.3157418072223663, flat: 3.3701077923178673, pod: 46.362701177597046, loss: 52.048551082611084 
Train [13/26] | Epoch [67/160] |	nca: 1.7121367864310741, flat: 2.5487913712859154, pod: 42.453081011772156, loss: 46.714009523391724 
Train [13/26] | Epoch [68/160] |	nca: 1.6262564100325108, flat: 2.4368892535567284, pod: 41.63020098209381, loss: 45.6933468580246 
Train [13/26] | Epoch [69/160] |	nca: 1.9844723045825958, flat: 2.35121838003397, pod: 40.783668756484985, loss: 45.11935913562775 
Train [13/26] | Epoch [70/160] |	nca: 2.339704304933548, flat: 2.858028180897236, pod: 42.782490849494934, loss: 47.98022389411926 
Train [13/26] | Epoch [71/160] |	nca: 2.7126092314720154, flat: 3.615464136004448, pod: 47.45137619972229, loss: 53.779449701309204 
Train [13/26] | Epoch [72/160] |	nca: 2.686321407556534, flat: 3.7482666447758675, pod: 47.68286144733429, loss: 54.11744928359985 
Train [13/26] | Epoch [73/160] |	nca: 2.240888386964798, flat: 3.019117295742035, pod: 44.388699531555176, loss: 49.64870476722717 
Train [13/26] | Epoch [74/160] |	nca: 2.8164458572864532, flat: 3.1647461131215096, pod: 46.3152961730957, loss: 52.29648804664612 
Train [13/26] | Epoch [75/160] |	nca: 1.940123688429594, flat: 2.717865452170372, pod: 42.684608697891235, loss: 47.34259843826294 
Train [13/26] | Epoch [76/160] |	nca: 2.8012460619211197, flat: 2.6437575817108154, pod: 41.20891523361206, loss: 46.653918862342834 
Train [13/26] | Epoch [77/160] |	nca: 3.17299447953701, flat: 3.59809797257185, pod: 44.80897653102875, loss: 51.580069065093994 
Train [13/26] | Epoch [78/160] |	nca: 3.1833858713507652, flat: 3.435969814658165, pod: 45.03241240978241, loss: 51.65176796913147 
Train [13/26] | Epoch [79/160] |	nca: 3.0290710106492043, flat: 4.437325417995453, pod: 51.39454984664917, loss: 58.86094641685486 
Train [13/26] | Epoch [80/160] |	nca: 2.4810345619916916, flat: 3.15575297921896, pod: 43.776612401008606, loss: 49.41339993476868 
Train [13/26] | Epoch [81/160] |	nca: 3.1967105492949486, flat: 4.314695507287979, pod: 50.858267307281494, loss: 58.36967325210571 
Train [13/26] | Epoch [82/160] |	nca: 1.926937572658062, flat: 2.75641967356205, pod: 43.64469122886658, loss: 48.32804822921753 
Train [13/26] | Epoch [83/160] |	nca: 2.038791060447693, flat: 2.6376592367887497, pod: 40.63701331615448, loss: 45.31346368789673 
Train [13/26] | Epoch [84/160] |	nca: 2.3017032332718372, flat: 2.53543059527874, pod: 40.325892090797424, loss: 45.163026332855225 
Train [13/26] | Epoch [85/160] |	nca: 2.7727644741535187, flat: 2.9144747257232666, pod: 42.84233331680298, loss: 48.52957236766815 
Train [13/26] | Epoch [86/160] |	nca: 2.198105074465275, flat: 3.048666127026081, pod: 44.88624835014343, loss: 50.1330189704895 
Train [13/26] | Epoch [87/160] |	nca: 2.36663156747818, flat: 3.239410124719143, pod: 43.719884395599365, loss: 49.325926065444946 
Train [13/26] | Epoch [88/160] |	nca: 2.1323065124452114, flat: 2.7790150716900826, pod: 40.781012535095215, loss: 45.692333698272705 
Train [13/26] | Epoch [89/160] |	nca: 1.896398887038231, flat: 2.9495540112257004, pod: 41.38042688369751, loss: 46.22637987136841 
Train [13/26] | Epoch [90/160] |	nca: 1.9683434925973415, flat: 2.325084313750267, pod: 38.74353754520416, loss: 43.036965012550354 
Train [13/26] | Epoch [91/160] |	nca: 2.3129629008471966, flat: 2.9495933055877686, pod: 41.29065752029419, loss: 46.55321383476257 
Train [13/26] | Epoch [92/160] |	nca: 1.6597610004246235, flat: 2.160339333117008, pod: 37.103429436683655, loss: 40.923529744148254 
Train [13/26] | Epoch [93/160] |	nca: 2.1610336489975452, flat: 2.3394018337130547, pod: 38.29217994213104, loss: 42.79261541366577 
Train [13/26] | Epoch [94/160] |	nca: 2.656314443796873, flat: 2.447163365781307, pod: 37.9658340215683, loss: 43.06931221485138 
Train [13/26] | Epoch [95/160] |	nca: 2.196964044123888, flat: 2.881556585431099, pod: 41.32603919506073, loss: 46.40455961227417 
Train [13/26] | Epoch [96/160] |	nca: 1.539039671421051, flat: 2.084640249609947, pod: 37.485543727874756, loss: 41.10922372341156 
Train [13/26] | Epoch [97/160] |	nca: 1.8474415838718414, flat: 1.7986869663000107, pod: 33.82607054710388, loss: 37.472198724746704 
Train [13/26] | Epoch [98/160] |	nca: 1.7147773206233978, flat: 1.9786086305975914, pod: 34.49896705150604, loss: 38.1923531293869 
Train [13/26] | Epoch [99/160] |	nca: 1.6687532849609852, flat: 1.8726424872875214, pod: 34.36964166164398, loss: 37.91103732585907 
Train [13/26] | Epoch [100/160] |	nca: 1.6212299801409245, flat: 2.215559184551239, pod: 38.90074634552002, loss: 42.73753571510315 
Train [13/26] | Epoch [101/160] |	nca: 2.5735597386956215, flat: 1.743618592619896, pod: 33.34384214878082, loss: 37.661020398139954 
Train [13/26] | Epoch [102/160] |	nca: 1.9917382411658764, flat: 2.3859157040715218, pod: 36.7470988035202, loss: 41.12475264072418 
Train [13/26] | Epoch [103/160] |	nca: 1.5234106741845608, flat: 1.8006399124860764, pod: 33.55505096912384, loss: 36.879101395606995 
Train [13/26] | Epoch [104/160] |	nca: 1.6412119828164577, flat: 1.7271104492247105, pod: 30.9949072599411, loss: 34.363229513168335 
Train [13/26] | Epoch [105/160] |	nca: 2.1515516489744186, flat: 2.058116927742958, pod: 33.221588134765625, loss: 37.431257009506226 
Train [13/26] | Epoch [106/160] |	nca: 2.097985751926899, flat: 2.4272392615675926, pod: 37.516950249671936, loss: 42.04217541217804 
Train [13/26] | Epoch [107/160] |	nca: 2.01718956977129, flat: 1.7593813389539719, pod: 33.04225051403046, loss: 36.81882131099701 
Train [13/26] | Epoch [108/160] |	nca: 2.172206047922373, flat: 2.0369935631752014, pod: 32.60805559158325, loss: 36.81725537776947 
Train [13/26] | Epoch [109/160] |	nca: 1.8988590463995934, flat: 1.9908484108746052, pod: 33.12974953651428, loss: 37.01945662498474 
Train [13/26] | Epoch [110/160] |	nca: 1.9540666602551937, flat: 1.8432482555508614, pod: 32.164536118507385, loss: 35.96185064315796 
Train [13/26] | Epoch [111/160] |	nca: 1.7636310495436192, flat: 1.756970290094614, pod: 31.824153184890747, loss: 35.34475481510162 
Train [13/26] | Epoch [112/160] |	nca: 1.9231784865260124, flat: 2.0039270408451557, pod: 32.25204873085022, loss: 36.17915451526642 
Train [13/26] | Epoch [113/160] |	nca: 1.7651824355125427, flat: 1.8168350532650948, pod: 32.47038197517395, loss: 36.05239951610565 
Train [13/26] | Epoch [114/160] |	nca: 1.6286729201674461, flat: 1.5386616736650467, pod: 29.147639870643616, loss: 32.31497418880463 
Train [13/26] | Epoch [115/160] |	nca: 1.3059351034462452, flat: 1.524239681661129, pod: 29.988418102264404, loss: 32.81859302520752 
Train [13/26] | Epoch [116/160] |	nca: 1.5181693360209465, flat: 1.379829365760088, pod: 29.20562982559204, loss: 32.103628516197205 
Train [13/26] | Epoch [117/160] |	nca: 1.8601835146546364, flat: 1.4798609279096127, pod: 28.298741221427917, loss: 31.63878571987152 
Train [13/26] | Epoch [118/160] |	nca: 1.7648984380066395, flat: 1.6408105418086052, pod: 29.903724312782288, loss: 33.309433460235596 
Train [13/26] | Epoch [119/160] |	nca: 1.3634130582213402, flat: 1.736657876521349, pod: 32.07834088802338, loss: 35.17841196060181 
Train [13/26] | Epoch [120/160] |	nca: 1.830212201923132, flat: 1.4492320083081722, pod: 29.694581866264343, loss: 32.97402596473694 
Train [13/26] | Epoch [121/160] |	nca: 1.7250319682061672, flat: 1.6297749876976013, pod: 30.42205262184143, loss: 33.776859283447266 
Train [13/26] | Epoch [122/160] |	nca: 1.4546028040349483, flat: 1.3387389704585075, pod: 27.147964358329773, loss: 29.941305994987488 
Train [13/26] | Epoch [123/160] |	nca: 2.1943334490060806, flat: 1.2857175767421722, pod: 26.731062650680542, loss: 30.211113691329956 
Train [13/26] | Epoch [124/160] |	nca: 3.3345295041799545, flat: 1.7083518393337727, pod: 29.3387508392334, loss: 34.38163220882416 
Train [13/26] | Epoch [125/160] |	nca: 1.6351476237177849, flat: 1.6764070242643356, pod: 30.014652848243713, loss: 33.326207518577576 
Train [13/26] | Epoch [126/160] |	nca: 1.4437299072742462, flat: 1.422469675540924, pod: 26.950888872146606, loss: 29.8170884847641 
Train [13/26] | Epoch [127/160] |	nca: 1.9364494532346725, flat: 1.3756730929017067, pod: 27.767643213272095, loss: 31.079765796661377 
Train [13/26] | Epoch [128/160] |	nca: 1.666180793195963, flat: 1.393288690596819, pod: 26.524041891098022, loss: 29.583511352539062 
Train [13/26] | Epoch [129/160] |	nca: 1.6750267185270786, flat: 1.4328798092901707, pod: 27.243314146995544, loss: 30.35122060775757 
Train [13/26] | Epoch [130/160] |	nca: 1.8084289021790028, flat: 1.4076090529561043, pod: 27.249277234077454, loss: 30.465315222740173 
Train [13/26] | Epoch [131/160] |	nca: 1.7405154034495354, flat: 1.4134799391031265, pod: 26.21278667449951, loss: 29.36678194999695 
Train [13/26] | Epoch [132/160] |	nca: 1.4342455193400383, flat: 1.303052056580782, pod: 25.810637593269348, loss: 28.547935128211975 
Train [13/26] | Epoch [133/160] |	nca: 1.490009881556034, flat: 1.2478390149772167, pod: 26.268998980522156, loss: 29.006847977638245 
Train [13/26] | Epoch [134/160] |	nca: 1.3658294044435024, flat: 1.3866535425186157, pod: 26.761777758598328, loss: 29.5142605304718 
Train [13/26] | Epoch [135/160] |	nca: 1.3269432969391346, flat: 1.1706163138151169, pod: 24.375304758548737, loss: 26.872864365577698 
Train [13/26] | Epoch [136/160] |	nca: 1.4173090308904648, flat: 1.1416619792580605, pod: 23.64557057619095, loss: 26.20454168319702 
Train [13/26] | Epoch [137/160] |	nca: 1.4138313457369804, flat: 1.3387958593666553, pod: 24.65876191854477, loss: 27.41138917207718 
Train [13/26] | Epoch [138/160] |	nca: 1.4650847651064396, flat: 1.1625008769333363, pod: 24.099912583827972, loss: 26.727497935295105 
Train [13/26] | Epoch [139/160] |	nca: 1.386208288371563, flat: 1.2059342749416828, pod: 23.798569917678833, loss: 26.39071238040924 
Train [13/26] | Epoch [140/160] |	nca: 1.8272804506123066, flat: 1.4269719943404198, pod: 25.528500616550446, loss: 28.782753467559814 
Train [13/26] | Epoch [141/160] |	nca: 1.8288573995232582, flat: 1.2749028950929642, pod: 25.54035848379135, loss: 28.644118905067444 
Train [13/26] | Epoch [142/160] |	nca: 1.8217098824679852, flat: 1.2691086754202843, pod: 24.21553659439087, loss: 27.306355118751526 
Train [13/26] | Epoch [143/160] |	nca: 1.9831737242639065, flat: 1.1293816156685352, pod: 22.65264266729355, loss: 25.76519799232483 
Train [13/26] | Epoch [144/160] |	nca: 1.6430883817374706, flat: 1.1778426319360733, pod: 23.497992396354675, loss: 26.31892365217209 
Train [13/26] | Epoch [145/160] |	nca: 1.2568202689290047, flat: 1.1686476357281208, pod: 23.944221198558807, loss: 26.36968892812729 
Train [13/26] | Epoch [146/160] |	nca: 1.4201015420258045, flat: 1.0083336979150772, pod: 21.86039710044861, loss: 24.288832306861877 
Train [13/26] | Epoch [147/160] |	nca: 1.4303024411201477, flat: 1.0321482680737972, pod: 22.60100883245468, loss: 25.06345957517624 
Train [13/26] | Epoch [148/160] |	nca: 1.8963300362229347, flat: 1.4035215843468904, pod: 23.404726088047028, loss: 26.7045778632164 
Train [13/26] | Epoch [149/160] |	nca: 1.3208576254546642, flat: 1.1280923765152693, pod: 22.57483696937561, loss: 25.023787021636963 
Train [13/26] | Epoch [150/160] |	nca: 1.5300493985414505, flat: 1.0508059449493885, pod: 22.141176402568817, loss: 24.72203153371811 
Train [13/26] | Epoch [151/160] |	nca: 1.4283055029809475, flat: 1.06680709682405, pod: 21.928077280521393, loss: 24.423189878463745 
Train [13/26] | Epoch [152/160] |	nca: 1.588314138352871, flat: 1.0867332369089127, pod: 21.5682652592659, loss: 24.243312776088715 
Train [13/26] | Epoch [153/160] |	nca: 1.332547839730978, flat: 0.9662276096642017, pod: 21.53819227218628, loss: 23.83696800470352 
Train [13/26] | Epoch [154/160] |	nca: 1.3204019665718079, flat: 1.109711665660143, pod: 22.1791011095047, loss: 24.60921448469162 
Train [13/26] | Epoch [155/160] |	nca: 1.2620154023170471, flat: 1.1426478531211615, pod: 22.807707965373993, loss: 25.212371230125427 
Train [13/26] | Epoch [156/160] |	nca: 1.3841758146882057, flat: 1.1232577934861183, pod: 22.139407455921173, loss: 24.646840929985046 
Train [13/26] | Epoch [157/160] |	nca: 1.6334780380129814, flat: 1.1258034370839596, pod: 22.19133895635605, loss: 24.950620710849762 
Train [13/26] | Epoch [158/160] |	nca: 1.4858939424157143, flat: 1.022347953170538, pod: 20.880828082561493, loss: 23.38906991481781 
Train [13/26] | Epoch [159/160] |	nca: 1.5324921198189259, flat: 1.1119730696082115, pod: 21.89204752445221, loss: 24.5365127325058 
Train [13/26] | Epoch [160/160] |	nca: 1.6142828278243542, flat: 1.1022616811096668, pod: 21.56883078813553, loss: 24.285375356674194 
Fine-tuning
Building & updating memory.
Train [13/26] | Epoch [161/180] |	nca: 1.1585049405694008, flat: 1.0391983091831207, pod: 19.818723797798157, loss: 22.01642680168152 
Train [13/26] | Epoch [162/180] |	nca: 0.6280278898775578, flat: 1.0130677036941051, pod: 19.63211727142334, loss: 21.273212790489197 
Train [13/26] | Epoch [163/180] |	nca: 0.5783623903989792, flat: 1.024112518876791, pod: 19.77181589603424, loss: 21.374290704727173 
Train [13/26] | Epoch [164/180] |	nca: 0.5055403094738722, flat: 1.051781453192234, pod: 20.069823384284973, loss: 21.627145171165466 
Train [13/26] | Epoch [165/180] |	nca: 0.4389333724975586, flat: 1.0371864140033722, pod: 19.779983520507812, loss: 21.25610327720642 
Train [13/26] | Epoch [166/180] |	nca: 0.4882415197789669, flat: 1.0094992108643055, pod: 19.749127507209778, loss: 21.2468683719635 
Train [13/26] | Epoch [167/180] |	nca: 0.46422920748591423, flat: 1.0604008585214615, pod: 20.07500123977661, loss: 21.599631428718567 
Train [13/26] | Epoch [168/180] |	nca: 0.44592885486781597, flat: 1.0255528092384338, pod: 19.870558261871338, loss: 21.342039942741394 
Train [13/26] | Epoch [169/180] |	nca: 0.468350188806653, flat: 1.0436714515089989, pod: 19.838971853256226, loss: 21.350993633270264 
Train [13/26] | Epoch [170/180] |	nca: 0.4435787461698055, flat: 1.024699255824089, pod: 19.863620042800903, loss: 21.331897974014282 
Train [13/26] | Epoch [171/180] |	nca: 0.4178887065500021, flat: 1.0366478934884071, pod: 19.7261084318161, loss: 21.18064510822296 
Train [13/26] | Epoch [172/180] |	nca: 0.468567194417119, flat: 1.0548712760210037, pod: 20.11556112766266, loss: 21.638999581336975 
Train [13/26] | Epoch [173/180] |	nca: 0.3974666614085436, flat: 1.059114284813404, pod: 20.170704126358032, loss: 21.62728524208069 
Train [13/26] | Epoch [174/180] |	nca: 0.42154210805892944, flat: 1.0187319442629814, pod: 19.594099640846252, loss: 21.03437376022339 
Train [13/26] | Epoch [175/180] |	nca: 0.4060458783060312, flat: 1.0201851725578308, pod: 19.82190215587616, loss: 21.248133063316345 
Train [13/26] | Epoch [176/180] |	nca: 0.4057685062289238, flat: 1.0189070887863636, pod: 20.013280868530273, loss: 21.43795680999756 
Train [13/26] | Epoch [177/180] |	nca: 0.40851229429244995, flat: 1.0663417130708694, pod: 20.059839963912964, loss: 21.534693837165833 
Train [13/26] | Epoch [178/180] |	nca: 0.40160778537392616, flat: 1.061354286968708, pod: 20.188069820404053, loss: 21.651031851768494 
Train [13/26] | Epoch [179/180] |	nca: 0.36563299410045147, flat: 1.0183174647390842, pod: 19.886698365211487, loss: 21.270649075508118 
Train [13/26] | Epoch [180/180] |	nca: 0.3900120686739683, flat: 1.0127526447176933, pod: 19.892163157463074, loss: 21.294927716255188 
after task
Building & updating memory.
after task
Eval on 0->74.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6608461538461537.
Current acc: {'total': 0.591, '00-09': 0.624, '10-19': 0.568, '20-29': 0.528, '30-39': 0.561, '40-49': 0.619, '50-59': 0.575, '60-69': 0.581, '70-79': 0.802}.
Avg inc acc top5: 0.8907692307692306.
Current acc top5: {'total': 0.855}.
Forgetting: 0.1576666666666667.
Cord metric: 0.66.
Old accuracy: 0.58, mean: 0.65.
New accuracy: 0.86, mean: 0.79.
================Task 13 Start!================
Testing on False unseen tasks (max class = 76).
Set memory of size: 1480.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 13 Training!================
The training samples number: 2480
Train on 74->76.
train task
nb 2480.
Train [14/26] | Epoch [1/160] |	nca: 5.927059397101402, flat: 2.1888757683336735, pod: 38.27845048904419, loss: 46.39438593387604 
Train [14/26] | Epoch [2/160] |	nca: 3.528872564435005, flat: 2.5814513564109802, pod: 46.0409893989563, loss: 52.15131330490112 
Train [14/26] | Epoch [3/160] |	nca: 2.706675745546818, flat: 2.3241468518972397, pod: 43.221845388412476, loss: 48.252668619155884 
Train [14/26] | Epoch [4/160] |	nca: 2.21048004925251, flat: 2.0584397986531258, pod: 40.858604073524475, loss: 45.12752413749695 
Train [14/26] | Epoch [5/160] |	nca: 1.9959651306271553, flat: 1.8088577166199684, pod: 37.768340706825256, loss: 41.5731635093689 
Train [14/26] | Epoch [6/160] |	nca: 1.9324990883469582, flat: 1.9428078904747963, pod: 40.692405700683594, loss: 44.56771278381348 
Train [14/26] | Epoch [7/160] |	nca: 1.9798769541084766, flat: 1.798558421432972, pod: 38.941508293151855, loss: 42.71994376182556 
Train [14/26] | Epoch [8/160] |	nca: 1.7995361909270287, flat: 1.9195556938648224, pod: 39.704031586647034, loss: 43.423123836517334 
Train [14/26] | Epoch [9/160] |	nca: 2.1404408663511276, flat: 2.0255802795290947, pod: 40.06752800941467, loss: 44.23354887962341 
Train [14/26] | Epoch [10/160] |	nca: 1.9079507626593113, flat: 2.047379843890667, pod: 40.93474888801575, loss: 44.890079498291016 
Train [14/26] | Epoch [11/160] |	nca: 1.8646131232380867, flat: 1.9799614325165749, pod: 40.49511909484863, loss: 44.3396931886673 
Train [14/26] | Epoch [12/160] |	nca: 1.950565904378891, flat: 2.2419666945934296, pod: 44.773563861846924, loss: 48.96609663963318 
Train [14/26] | Epoch [13/160] |	nca: 1.8966387063264847, flat: 1.8917932137846947, pod: 38.9557044506073, loss: 42.744136691093445 
Train [14/26] | Epoch [14/160] |	nca: 2.038274336606264, flat: 2.0966745913028717, pod: 41.6051139831543, loss: 45.74006223678589 
Train [14/26] | Epoch [15/160] |	nca: 1.7159751206636429, flat: 1.877426639199257, pod: 38.947319746017456, loss: 42.5407212972641 
Train [14/26] | Epoch [16/160] |	nca: 2.1592666655778885, flat: 1.9693217054009438, pod: 39.29890584945679, loss: 43.427493929862976 
Train [14/26] | Epoch [17/160] |	nca: 1.702333439141512, flat: 1.8922304138541222, pod: 37.98425579071045, loss: 41.57881999015808 
Train [14/26] | Epoch [18/160] |	nca: 1.99250877648592, flat: 2.0001663863658905, pod: 40.58426773548126, loss: 44.576942801475525 
Train [14/26] | Epoch [19/160] |	nca: 1.6637244373559952, flat: 1.8972134813666344, pod: 39.38641309738159, loss: 42.94735074043274 
Train [14/26] | Epoch [20/160] |	nca: 1.713039830327034, flat: 1.885842740535736, pod: 40.10356783866882, loss: 43.7024507522583 
Train [14/26] | Epoch [21/160] |	nca: 1.9095329716801643, flat: 1.9371925815939903, pod: 38.5320200920105, loss: 42.378745675086975 
Train [14/26] | Epoch [22/160] |	nca: 1.8151860237121582, flat: 2.033832721412182, pod: 39.29825186729431, loss: 43.14727032184601 
Train [14/26] | Epoch [23/160] |	nca: 1.7170344777405262, flat: 2.0084268897771835, pod: 40.629069328308105, loss: 44.354530334472656 
Train [14/26] | Epoch [24/160] |	nca: 1.7831174582242966, flat: 1.9139419496059418, pod: 38.71269249916077, loss: 42.40975248813629 
Train [14/26] | Epoch [25/160] |	nca: 1.7678701542317867, flat: 2.0616008266806602, pod: 41.35004997253418, loss: 45.17952120304108 
Train [14/26] | Epoch [26/160] |	nca: 1.8177148140966892, flat: 2.016321823000908, pod: 40.114218950271606, loss: 43.9482558965683 
Train [14/26] | Epoch [27/160] |	nca: 1.7711263336241245, flat: 2.014874540269375, pod: 39.99287807941437, loss: 43.778878569602966 
Train [14/26] | Epoch [28/160] |	nca: 1.9417556189000607, flat: 2.114622540771961, pod: 41.63063955307007, loss: 45.6870174407959 
Train [14/26] | Epoch [29/160] |	nca: 1.8361571542918682, flat: 1.9669550955295563, pod: 40.08021020889282, loss: 43.88332223892212 
Train [14/26] | Epoch [30/160] |	nca: 1.6483690738677979, flat: 1.9303613975644112, pod: 38.55727422237396, loss: 42.13600420951843 
Train [14/26] | Epoch [31/160] |	nca: 1.706657312810421, flat: 1.9771552830934525, pod: 41.099933385849, loss: 44.783745765686035 
Train [14/26] | Epoch [32/160] |	nca: 1.6509741321206093, flat: 1.9619752392172813, pod: 39.54178977012634, loss: 43.154738783836365 
Train [14/26] | Epoch [33/160] |	nca: 1.7464217990636826, flat: 1.8842273205518723, pod: 39.49975848197937, loss: 43.13040792942047 
Train [14/26] | Epoch [34/160] |	nca: 1.5954916924238205, flat: 1.8901787400245667, pod: 38.26703405380249, loss: 41.75270462036133 
Train [14/26] | Epoch [35/160] |	nca: 1.6047427542507648, flat: 1.8005315959453583, pod: 38.26230239868164, loss: 41.66757678985596 
Train [14/26] | Epoch [36/160] |	nca: 1.9879159703850746, flat: 1.9388723522424698, pod: 39.066683530807495, loss: 42.99347221851349 
Train [14/26] | Epoch [37/160] |	nca: 1.585819598287344, flat: 1.8309707045555115, pod: 36.71164894104004, loss: 40.12843906879425 
Train [14/26] | Epoch [38/160] |	nca: 1.5809789225459099, flat: 1.8807114288210869, pod: 40.235965847969055, loss: 43.69765603542328 
Train [14/26] | Epoch [39/160] |	nca: 1.6386407129466534, flat: 1.8733061850070953, pod: 40.490792632102966, loss: 44.0027391910553 
Train [14/26] | Epoch [40/160] |	nca: 1.6595501936972141, flat: 1.7948013097047806, pod: 38.26865315437317, loss: 41.72300457954407 
Train [14/26] | Epoch [41/160] |	nca: 1.6091558262705803, flat: 1.8002626299858093, pod: 37.697253942489624, loss: 41.106672167778015 
Train [14/26] | Epoch [42/160] |	nca: 1.6806260906159878, flat: 1.8316547572612762, pod: 37.049111008644104, loss: 40.561391830444336 
Train [14/26] | Epoch [43/160] |	nca: 1.8268780447542667, flat: 1.9764737486839294, pod: 39.770989179611206, loss: 43.57434105873108 
Train [14/26] | Epoch [44/160] |	nca: 1.7067142352461815, flat: 2.1169159039855003, pod: 43.51238167285919, loss: 47.33601152896881 
Train [14/26] | Epoch [45/160] |	nca: 1.516392469406128, flat: 1.733521744608879, pod: 35.65493369102478, loss: 38.90484821796417 
Train [14/26] | Epoch [46/160] |	nca: 1.6236881576478481, flat: 1.8350326791405678, pod: 38.51118624210358, loss: 41.9699068069458 
Train [14/26] | Epoch [47/160] |	nca: 1.6865232028067112, flat: 1.6541544422507286, pod: 36.12293767929077, loss: 39.46361529827118 
Train [14/26] | Epoch [48/160] |	nca: 1.5627688467502594, flat: 1.682242676615715, pod: 36.141072392463684, loss: 39.38608396053314 
Train [14/26] | Epoch [49/160] |	nca: 1.6310929991304874, flat: 1.8073680326342583, pod: 37.54064238071442, loss: 40.979103803634644 
Train [14/26] | Epoch [50/160] |	nca: 1.7956511750817299, flat: 1.7455401793122292, pod: 35.39101779460907, loss: 38.93220901489258 
Train [14/26] | Epoch [51/160] |	nca: 1.5854920074343681, flat: 1.9040708020329475, pod: 38.28896462917328, loss: 41.77852761745453 
Train [14/26] | Epoch [52/160] |	nca: 1.447133880108595, flat: 1.6910342127084732, pod: 35.89787948131561, loss: 39.03604733943939 
Train [14/26] | Epoch [53/160] |	nca: 1.388654287904501, flat: 1.611049696803093, pod: 34.052446603775024, loss: 37.05215036869049 
Train [14/26] | Epoch [54/160] |	nca: 1.705653376877308, flat: 1.657837100327015, pod: 36.322155475616455, loss: 39.68564581871033 
Train [14/26] | Epoch [55/160] |	nca: 1.5115806013345718, flat: 1.7006089761853218, pod: 36.59019422531128, loss: 39.80238366127014 
Train [14/26] | Epoch [56/160] |	nca: 1.5848442167043686, flat: 1.7438418939709663, pod: 37.519810795784, loss: 40.8484970331192 
Train [14/26] | Epoch [57/160] |	nca: 1.7227353639900684, flat: 1.6863595768809319, pod: 35.060033440589905, loss: 38.469128370285034 
Train [14/26] | Epoch [58/160] |	nca: 1.6261201314628124, flat: 1.6388197615742683, pod: 34.44702911376953, loss: 37.71196937561035 
Train [14/26] | Epoch [59/160] |	nca: 1.5227711535990238, flat: 1.700244389474392, pod: 35.21759760379791, loss: 38.44061303138733 
Train [14/26] | Epoch [60/160] |	nca: 1.584373775869608, flat: 1.6059686988592148, pod: 35.84114980697632, loss: 39.03149211406708 
Train [14/26] | Epoch [61/160] |	nca: 1.5484228730201721, flat: 1.7277679294347763, pod: 35.77319657802582, loss: 39.04938721656799 
Train [14/26] | Epoch [62/160] |	nca: 1.5066591389477253, flat: 1.617069348692894, pod: 35.50781810283661, loss: 38.63154637813568 
Train [14/26] | Epoch [63/160] |	nca: 1.474771000444889, flat: 1.4560906514525414, pod: 33.03776288032532, loss: 35.96862471103668 
Train [14/26] | Epoch [64/160] |	nca: 1.620209887623787, flat: 1.4760145843029022, pod: 33.830867886543274, loss: 36.92709243297577 
Train [14/26] | Epoch [65/160] |	nca: 1.5089435391128063, flat: 1.5257425159215927, pod: 33.5094496011734, loss: 36.54413557052612 
Train [14/26] | Epoch [66/160] |	nca: 1.3979385234415531, flat: 1.4767869003117085, pod: 33.7696373462677, loss: 36.644362807273865 
Train [14/26] | Epoch [67/160] |	nca: 1.5249669179320335, flat: 1.4320510663092136, pod: 33.04704487323761, loss: 36.00406277179718 
Train [14/26] | Epoch [68/160] |	nca: 1.6663708798587322, flat: 1.5372969657182693, pod: 33.92093467712402, loss: 37.12460279464722 
Train [14/26] | Epoch [69/160] |	nca: 1.4645699448883533, flat: 1.4938569702208042, pod: 34.53467774391174, loss: 37.49310481548309 
Train [14/26] | Epoch [70/160] |	nca: 1.6867258101701736, flat: 1.4427022822201252, pod: 33.000502824783325, loss: 36.12993121147156 
Train [14/26] | Epoch [71/160] |	nca: 1.6170621290802956, flat: 1.578543744981289, pod: 35.85072374343872, loss: 39.046329379081726 
Train [14/26] | Epoch [72/160] |	nca: 1.598841730505228, flat: 1.6273461282253265, pod: 36.049142837524414, loss: 39.275331258773804 
Train [14/26] | Epoch [73/160] |	nca: 1.4781229048967361, flat: 1.538893736898899, pod: 32.80106258392334, loss: 35.818079352378845 
Train [14/26] | Epoch [74/160] |	nca: 1.5460882633924484, flat: 1.5223506428301334, pod: 33.97520565986633, loss: 37.04364454746246 
Train [14/26] | Epoch [75/160] |	nca: 1.366970058530569, flat: 1.3399395383894444, pod: 31.733028292655945, loss: 34.43993818759918 
Train [14/26] | Epoch [76/160] |	nca: 1.3657540418207645, flat: 1.3436178304255009, pod: 32.43281400203705, loss: 35.14218592643738 
Train [14/26] | Epoch [77/160] |	nca: 1.3904922269284725, flat: 1.294924907386303, pod: 31.20640194416046, loss: 33.89181911945343 
Train [14/26] | Epoch [78/160] |	nca: 1.5306649655103683, flat: 1.3250669315457344, pod: 31.15708601474762, loss: 34.01281785964966 
Train [14/26] | Epoch [79/160] |	nca: 1.4457113817334175, flat: 1.3903678953647614, pod: 31.74371361732483, loss: 34.579792976379395 
Train [14/26] | Epoch [80/160] |	nca: 1.4180490635335445, flat: 1.2661891169846058, pod: 29.776718378067017, loss: 32.46095645427704 
Train [14/26] | Epoch [81/160] |	nca: 1.3825131841003895, flat: 1.2333846725523472, pod: 29.82708489894867, loss: 32.44298267364502 
Train [14/26] | Epoch [82/160] |	nca: 1.475914355367422, flat: 1.207378312945366, pod: 28.767811059951782, loss: 31.451103806495667 
Train [14/26] | Epoch [83/160] |	nca: 1.532072864472866, flat: 1.3346933908760548, pod: 31.567391753196716, loss: 34.4341584444046 
Train [14/26] | Epoch [84/160] |	nca: 1.3594029508531094, flat: 1.260808378458023, pod: 30.379088759422302, loss: 32.99930000305176 
Train [14/26] | Epoch [85/160] |	nca: 1.4928719475865364, flat: 1.2842636704444885, pod: 32.02685856819153, loss: 34.80399429798126 
Train [14/26] | Epoch [86/160] |	nca: 1.327770683914423, flat: 1.303507536649704, pod: 31.69372546672821, loss: 34.32500398159027 
Train [14/26] | Epoch [87/160] |	nca: 1.4559256844222546, flat: 1.216432474553585, pod: 31.31401789188385, loss: 33.98637616634369 
Train [14/26] | Epoch [88/160] |	nca: 1.4968582019209862, flat: 1.194965161383152, pod: 29.394063472747803, loss: 32.08588695526123 
Train [14/26] | Epoch [89/160] |	nca: 1.3703916035592556, flat: 1.1134602017700672, pod: 28.758984565734863, loss: 31.242836236953735 
Train [14/26] | Epoch [90/160] |	nca: 1.453079104423523, flat: 1.3416510038077831, pod: 33.79702043533325, loss: 36.59175086021423 
Train [14/26] | Epoch [91/160] |	nca: 1.3707626312971115, flat: 1.3170680180191994, pod: 32.227514028549194, loss: 34.91534471511841 
Train [14/26] | Epoch [92/160] |	nca: 1.4077988155186176, flat: 1.220864836126566, pod: 31.063296794891357, loss: 33.69196057319641 
Train [14/26] | Epoch [93/160] |	nca: 1.24657816067338, flat: 1.0501903295516968, pod: 27.542418122291565, loss: 29.839186668395996 
Train [14/26] | Epoch [94/160] |	nca: 1.4923339933156967, flat: 1.1445646025240421, pod: 29.16563081741333, loss: 31.802529215812683 
Train [14/26] | Epoch [95/160] |	nca: 1.3772890269756317, flat: 1.1069605574011803, pod: 27.44507145881653, loss: 29.92932093143463 
Train [14/26] | Epoch [96/160] |	nca: 1.2578970566391945, flat: 1.1063815727829933, pod: 29.635820269584656, loss: 32.00009882450104 
Train [14/26] | Epoch [97/160] |	nca: 1.2719611376523972, flat: 1.061249639838934, pod: 28.569884657859802, loss: 30.903095245361328 
Train [14/26] | Epoch [98/160] |	nca: 1.4049476832151413, flat: 1.112893559038639, pod: 28.810052275657654, loss: 31.327893614768982 
Train [14/26] | Epoch [99/160] |	nca: 1.266574639827013, flat: 1.0234840586781502, pod: 27.844242453575134, loss: 30.13430106639862 
Train [14/26] | Epoch [100/160] |	nca: 1.2664832845330238, flat: 0.9763230942189693, pod: 27.172324895858765, loss: 29.415131092071533 
Train [14/26] | Epoch [101/160] |	nca: 1.365301962941885, flat: 1.0273003540933132, pod: 27.27026665210724, loss: 29.662869095802307 
Train [14/26] | Epoch [102/160] |	nca: 1.4156344160437584, flat: 1.0146962814033031, pod: 28.442601919174194, loss: 30.87293255329132 
Train [14/26] | Epoch [103/160] |	nca: 1.3238264843821526, flat: 0.9868955835700035, pod: 26.1727637052536, loss: 28.48348557949066 
Train [14/26] | Epoch [104/160] |	nca: 1.3320292942225933, flat: 0.9676398932933807, pod: 26.271013855934143, loss: 28.570683240890503 
Train [14/26] | Epoch [105/160] |	nca: 1.2835876569151878, flat: 0.879082877188921, pod: 24.691556215286255, loss: 26.85422694683075 
Train [14/26] | Epoch [106/160] |	nca: 1.333750408142805, flat: 0.9384831190109253, pod: 26.397209763526917, loss: 28.669443488121033 
Train [14/26] | Epoch [107/160] |	nca: 1.2467146813869476, flat: 0.9354547448456287, pod: 26.294249653816223, loss: 28.47641897201538 
Train [14/26] | Epoch [108/160] |	nca: 1.233880765736103, flat: 0.8256267141550779, pod: 24.346957981586456, loss: 26.40646541118622 
Train [14/26] | Epoch [109/160] |	nca: 1.2591106332838535, flat: 0.8384159840643406, pod: 24.28251624107361, loss: 26.380043148994446 
Train [14/26] | Epoch [110/160] |	nca: 1.360115122050047, flat: 0.9568613991141319, pod: 26.045857667922974, loss: 28.362834334373474 
Train [14/26] | Epoch [111/160] |	nca: 1.452839333564043, flat: 1.0335945561528206, pod: 26.7048419713974, loss: 29.19127583503723 
Train [14/26] | Epoch [112/160] |	nca: 1.3311844393610954, flat: 0.8578062951564789, pod: 25.06675350666046, loss: 27.255744457244873 
Train [14/26] | Epoch [113/160] |	nca: 1.2072584629058838, flat: 0.8129551205784082, pod: 23.23360377550125, loss: 25.253817677497864 
Train [14/26] | Epoch [114/160] |	nca: 1.3587344028055668, flat: 0.8594915419816971, pod: 24.99561834335327, loss: 27.213844537734985 
Train [14/26] | Epoch [115/160] |	nca: 1.3517136126756668, flat: 0.8524946086108685, pod: 23.826743364334106, loss: 26.030951619148254 
Train [14/26] | Epoch [116/160] |	nca: 1.2940519712865353, flat: 0.8157226126641035, pod: 23.018849968910217, loss: 25.128624320030212 
Train [14/26] | Epoch [117/160] |	nca: 1.395725816488266, flat: 0.8145465441048145, pod: 24.00401145219803, loss: 26.21428394317627 
Train [14/26] | Epoch [118/160] |	nca: 1.3142446987330914, flat: 0.8371479324996471, pod: 24.06853413581848, loss: 26.219926834106445 
Train [14/26] | Epoch [119/160] |	nca: 1.3163110874593258, flat: 0.730158606544137, pod: 21.602976143360138, loss: 23.64944589138031 
Train [14/26] | Epoch [120/160] |	nca: 1.2929369024932384, flat: 0.7844900488853455, pod: 22.353757739067078, loss: 24.431184887886047 
Train [14/26] | Epoch [121/160] |	nca: 1.2269951365888119, flat: 0.7613206952810287, pod: 21.62837666273117, loss: 23.616692781448364 
Train [14/26] | Epoch [122/160] |	nca: 1.2206413187086582, flat: 0.6734353750944138, pod: 20.290823221206665, loss: 22.184899747371674 
Train [14/26] | Epoch [123/160] |	nca: 1.3744939900934696, flat: 0.7786813136190176, pod: 23.101892471313477, loss: 25.255067706108093 
Train [14/26] | Epoch [124/160] |	nca: 1.2346120737493038, flat: 0.7672402951866388, pod: 21.71377146244049, loss: 23.71562385559082 
Train [14/26] | Epoch [125/160] |	nca: 1.2752485536038876, flat: 0.7428458482027054, pod: 22.236071586608887, loss: 24.25416588783264 
Train [14/26] | Epoch [126/160] |	nca: 1.2780417799949646, flat: 0.7385432403534651, pod: 21.621641874313354, loss: 23.638226866722107 
Train [14/26] | Epoch [127/160] |	nca: 1.2370764650404453, flat: 0.6735489312559366, pod: 20.500291645526886, loss: 22.410916924476624 
Train [14/26] | Epoch [128/160] |	nca: 1.214784525334835, flat: 0.7303138636052608, pod: 21.538967967033386, loss: 23.484066247940063 
Train [14/26] | Epoch [129/160] |	nca: 1.3087625466287136, flat: 0.7124315872788429, pod: 21.482488095760345, loss: 23.503682255744934 
Train [14/26] | Epoch [130/160] |	nca: 1.3596490435302258, flat: 0.7031693235039711, pod: 20.803077518939972, loss: 22.865895688533783 
Train [14/26] | Epoch [131/160] |	nca: 1.2365535832941532, flat: 0.6808507535606623, pod: 20.567336082458496, loss: 22.484740734100342 
Train [14/26] | Epoch [132/160] |	nca: 1.3786592409014702, flat: 0.6666412279009819, pod: 21.098184406757355, loss: 23.143484830856323 
Train [14/26] | Epoch [133/160] |	nca: 1.2486683279275894, flat: 0.6872095223516226, pod: 21.001717507839203, loss: 22.93759536743164 
Train [14/26] | Epoch [134/160] |	nca: 1.285281978547573, flat: 0.668976403772831, pod: 20.269917488098145, loss: 22.224175989627838 
Train [14/26] | Epoch [135/160] |	nca: 1.2687084004282951, flat: 0.6881309021264315, pod: 20.719072937965393, loss: 22.67591220140457 
Train [14/26] | Epoch [136/160] |	nca: 1.4070617593824863, flat: 0.6523668151348829, pod: 20.007902145385742, loss: 22.067330598831177 
Train [14/26] | Epoch [137/160] |	nca: 1.2650241293013096, flat: 0.6651384513825178, pod: 19.95108687877655, loss: 21.88124930858612 
Train [14/26] | Epoch [138/160] |	nca: 1.2509717009961605, flat: 0.6022530011832714, pod: 18.112341582775116, loss: 19.965566337108612 
Train [14/26] | Epoch [139/160] |	nca: 1.2494615577161312, flat: 0.6085186321288347, pod: 18.319761276245117, loss: 20.177741587162018 
Train [14/26] | Epoch [140/160] |	nca: 1.2432878650724888, flat: 0.5610880441963673, pod: 18.336977422237396, loss: 20.14135366678238 
Train [14/26] | Epoch [141/160] |	nca: 1.1983413100242615, flat: 0.5739493723958731, pod: 17.718305706977844, loss: 19.490596413612366 
Train [14/26] | Epoch [142/160] |	nca: 1.3064402118325233, flat: 0.6061189565807581, pod: 18.464637577533722, loss: 20.377196550369263 
Train [14/26] | Epoch [143/160] |	nca: 1.2745281383395195, flat: 0.5579388309270144, pod: 17.452802777290344, loss: 19.285269677639008 
Train [14/26] | Epoch [144/160] |	nca: 1.351295005530119, flat: 0.5851184483617544, pod: 18.036176443099976, loss: 19.97258996963501 
Train [14/26] | Epoch [145/160] |	nca: 1.2313406392931938, flat: 0.5716084688901901, pod: 17.639790415763855, loss: 19.44273942708969 
Train [14/26] | Epoch [146/160] |	nca: 1.272807750850916, flat: 0.5573452971875668, pod: 16.86222219467163, loss: 18.692375242710114 
Train [14/26] | Epoch [147/160] |	nca: 1.2649834603071213, flat: 0.6191902812570333, pod: 17.961041390895844, loss: 19.84521496295929 
Train [14/26] | Epoch [148/160] |	nca: 1.2469497509300709, flat: 0.5592498015612364, pod: 16.981702744960785, loss: 18.787902235984802 
Train [14/26] | Epoch [149/160] |	nca: 1.2145015466958284, flat: 0.5588290113955736, pod: 16.959950268268585, loss: 18.733280897140503 
Train [14/26] | Epoch [150/160] |	nca: 1.2235861606895924, flat: 0.5559296682476997, pod: 16.446512937545776, loss: 18.226028621196747 
Train [14/26] | Epoch [151/160] |	nca: 1.204489391297102, flat: 0.5348327774554491, pod: 16.959309577941895, loss: 18.698631763458252 
Train [14/26] | Epoch [152/160] |	nca: 1.3003826588392258, flat: 0.5643843002617359, pod: 17.131391286849976, loss: 18.996158361434937 
Train [14/26] | Epoch [153/160] |	nca: 1.2298247143626213, flat: 0.5851675709709525, pod: 16.800775229930878, loss: 18.615767538547516 
Train [14/26] | Epoch [154/160] |	nca: 1.1832563132047653, flat: 0.5007818080484867, pod: 16.35199213027954, loss: 18.036030292510986 
Train [14/26] | Epoch [155/160] |	nca: 1.1917086578905582, flat: 0.5009514968842268, pod: 15.850549399852753, loss: 17.543209493160248 
Train [14/26] | Epoch [156/160] |	nca: 1.3288288712501526, flat: 0.5378983318805695, pod: 16.027887046337128, loss: 17.894614458084106 
Train [14/26] | Epoch [157/160] |	nca: 1.3219975531101227, flat: 0.537638271227479, pod: 16.573228359222412, loss: 18.432864010334015 
Train [14/26] | Epoch [158/160] |	nca: 1.2977108880877495, flat: 0.5115178488194942, pod: 16.237457036972046, loss: 18.04668563604355 
Train [14/26] | Epoch [159/160] |	nca: 1.155091479420662, flat: 0.4964735768735409, pod: 16.04073202610016, loss: 17.692297041416168 
Train [14/26] | Epoch [160/160] |	nca: 1.1758115869015455, flat: 0.5545741189271212, pod: 17.110733032226562, loss: 18.84111851453781 
Fine-tuning
Building & updating memory.
Train [14/26] | Epoch [161/180] |	nca: 1.0443180575966835, flat: 0.6282541789114475, pod: 14.662848114967346, loss: 16.33542025089264 
Train [14/26] | Epoch [162/180] |	nca: 0.7486835792660713, flat: 0.6176929622888565, pod: 14.887256562709808, loss: 16.25363314151764 
Train [14/26] | Epoch [163/180] |	nca: 0.6929072253406048, flat: 0.6182340271770954, pod: 14.643622994422913, loss: 15.954764246940613 
Train [14/26] | Epoch [164/180] |	nca: 0.5939734987914562, flat: 0.6383761949837208, pod: 15.180871605873108, loss: 16.41322135925293 
Train [14/26] | Epoch [165/180] |	nca: 0.526966530829668, flat: 0.6380697153508663, pod: 15.270785629749298, loss: 16.435821890830994 
Train [14/26] | Epoch [166/180] |	nca: 0.5056103728711605, flat: 0.6108971908688545, pod: 14.776278138160706, loss: 15.892785906791687 
Train [14/26] | Epoch [167/180] |	nca: 0.5176238901913166, flat: 0.6224128939211369, pod: 14.906580924987793, loss: 16.04661786556244 
Train [14/26] | Epoch [168/180] |	nca: 0.541292242705822, flat: 0.6410811394453049, pod: 15.220216035842896, loss: 16.402589321136475 
Train [14/26] | Epoch [169/180] |	nca: 0.4869212731719017, flat: 0.6273059546947479, pod: 15.268102765083313, loss: 16.382330060005188 
Train [14/26] | Epoch [170/180] |	nca: 0.510247640311718, flat: 0.619584895670414, pod: 14.84003895521164, loss: 15.969871520996094 
Train [14/26] | Epoch [171/180] |	nca: 0.47521185129880905, flat: 0.6169602535665035, pod: 14.980248391628265, loss: 16.072420597076416 
Train [14/26] | Epoch [172/180] |	nca: 0.48563471622765064, flat: 0.6143675688654184, pod: 15.11228883266449, loss: 16.212291300296783 
Train [14/26] | Epoch [173/180] |	nca: 0.47558210976421833, flat: 0.6516166478395462, pod: 15.353493928909302, loss: 16.480692505836487 
Train [14/26] | Epoch [174/180] |	nca: 0.4697736091911793, flat: 0.6121761836111546, pod: 14.653712630271912, loss: 15.735662460327148 
Train [14/26] | Epoch [175/180] |	nca: 0.4616786316037178, flat: 0.6153715923428535, pod: 15.393126845359802, loss: 16.470177054405212 
Train [14/26] | Epoch [176/180] |	nca: 0.4501975141465664, flat: 0.6032841727137566, pod: 14.604923903942108, loss: 15.658405601978302 
Train [14/26] | Epoch [177/180] |	nca: 0.4423287957906723, flat: 0.6133825853466988, pod: 14.859479188919067, loss: 15.915190577507019 
Train [14/26] | Epoch [178/180] |	nca: 0.4733875896781683, flat: 0.6502403169870377, pod: 15.142226994037628, loss: 16.265854716300964 
Train [14/26] | Epoch [179/180] |	nca: 0.4607657864689827, flat: 0.6238819770514965, pod: 15.426414132118225, loss: 16.511061668395996 
Train [14/26] | Epoch [180/180] |	nca: 0.44627867452800274, flat: 0.6274303011596203, pod: 15.188132882118225, loss: 16.261841773986816 
after task
Building & updating memory.
after task
Eval on 0->76.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6552857142857142.
Current acc: {'total': 0.583, '00-09': 0.634, '10-19': 0.569, '20-29': 0.519, '30-39': 0.55, '40-49': 0.605, '50-59': 0.552, '60-69': 0.552, '70-79': 0.755}.
Avg inc acc top5: 0.8879285714285713.
Current acc top5: {'total': 0.851}.
Forgetting: 0.1758888888888889.
Cord metric: 0.66.
Old accuracy: 0.58, mean: 0.64.
New accuracy: 0.80, mean: 0.79.
================Task 14 Start!================
Testing on False unseen tasks (max class = 78).
Set memory of size: 1520.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 14 Training!================
The training samples number: 2520
Train on 76->78.
train task
nb 2520.
Train [15/26] | Epoch [1/160] |	nca: 8.601094856858253, flat: 3.53431586176157, pod: 44.688037514686584, loss: 56.82344853878021 
Train [15/26] | Epoch [2/160] |	nca: 4.973568007349968, flat: 4.176548480987549, pod: 53.34715390205383, loss: 62.49727010726929 
Train [15/26] | Epoch [3/160] |	nca: 4.075460240244865, flat: 3.9168288856744766, pod: 53.588886737823486, loss: 61.58117604255676 
Train [15/26] | Epoch [4/160] |	nca: 3.2360768541693687, flat: 3.2500373870134354, pod: 49.338380336761475, loss: 55.82449460029602 
Train [15/26] | Epoch [5/160] |	nca: 2.857201762497425, flat: 2.764756627380848, pod: 46.715595722198486, loss: 52.33755373954773 
Train [15/26] | Epoch [6/160] |	nca: 2.5403169095516205, flat: 2.548529401421547, pod: 45.16579604148865, loss: 50.254642486572266 
Train [15/26] | Epoch [7/160] |	nca: 2.684151664376259, flat: 2.5558446422219276, pod: 46.73542261123657, loss: 51.97541904449463 
Train [15/26] | Epoch [8/160] |	nca: 2.4286774396896362, flat: 2.424782417714596, pod: 44.47940754890442, loss: 49.33286738395691 
Train [15/26] | Epoch [9/160] |	nca: 2.2035017013549805, flat: 2.249991796910763, pod: 42.027533769607544, loss: 46.48102784156799 
Train [15/26] | Epoch [10/160] |	nca: 2.3401302620768547, flat: 2.377695530653, pod: 43.70155394077301, loss: 48.41938042640686 
Train [15/26] | Epoch [11/160] |	nca: 2.2613287195563316, flat: 2.391924872994423, pod: 43.4965238571167, loss: 48.14977717399597 
Train [15/26] | Epoch [12/160] |	nca: 2.5513291135430336, flat: 2.4453651681542397, pod: 44.66316103935242, loss: 49.65985560417175 
Train [15/26] | Epoch [13/160] |	nca: 2.3458375707268715, flat: 2.344247467815876, pod: 42.405121088027954, loss: 47.09520649909973 
Train [15/26] | Epoch [14/160] |	nca: 2.50199918448925, flat: 2.3440834134817123, pod: 41.8918741941452, loss: 46.73795700073242 
Train [15/26] | Epoch [15/160] |	nca: 2.154456742107868, flat: 2.376743368804455, pod: 42.313071489334106, loss: 46.844271183013916 
Train [15/26] | Epoch [16/160] |	nca: 2.1334873512387276, flat: 2.328617826104164, pod: 43.095709681510925, loss: 47.557814598083496 
Train [15/26] | Epoch [17/160] |	nca: 2.043091595172882, flat: 2.0444565787911415, pod: 40.58769714832306, loss: 44.67524576187134 
Train [15/26] | Epoch [18/160] |	nca: 2.1757718548178673, flat: 2.09491515904665, pod: 39.8231862783432, loss: 44.093873023986816 
Train [15/26] | Epoch [19/160] |	nca: 2.132583174854517, flat: 2.224982276558876, pod: 41.48401761054993, loss: 45.84158253669739 
Train [15/26] | Epoch [20/160] |	nca: 2.0734320506453514, flat: 2.2489482015371323, pod: 41.980663895606995, loss: 46.30304455757141 
Train [15/26] | Epoch [21/160] |	nca: 2.1204565912485123, flat: 2.2685860618948936, pod: 43.34315836429596, loss: 47.73220086097717 
Train [15/26] | Epoch [22/160] |	nca: 2.1154654175043106, flat: 2.201171427965164, pod: 40.44118571281433, loss: 44.75782299041748 
Train [15/26] | Epoch [23/160] |	nca: 2.027771271765232, flat: 2.2050370201468468, pod: 41.967294096946716, loss: 46.20010280609131 
Train [15/26] | Epoch [24/160] |	nca: 2.0448326990008354, flat: 2.260873608291149, pod: 42.950167775154114, loss: 47.255873918533325 
Train [15/26] | Epoch [25/160] |	nca: 2.5649087131023407, flat: 2.346204712986946, pod: 44.39808702468872, loss: 49.30920076370239 
Train [15/26] | Epoch [26/160] |	nca: 1.9139541983604431, flat: 2.202035553753376, pod: 42.42190742492676, loss: 46.53789687156677 
Train [15/26] | Epoch [27/160] |	nca: 2.115073785185814, flat: 2.1896574795246124, pod: 43.26989984512329, loss: 47.574631214141846 
Train [15/26] | Epoch [28/160] |	nca: 1.8883323147892952, flat: 2.1950047090649605, pod: 41.132476806640625, loss: 45.215813636779785 
Train [15/26] | Epoch [29/160] |	nca: 2.0441858544945717, flat: 2.1058646515011787, pod: 41.91942250728607, loss: 46.06947350502014 
Train [15/26] | Epoch [30/160] |	nca: 1.9397179186344147, flat: 2.1397387385368347, pod: 41.248029470443726, loss: 45.32748627662659 
Train [15/26] | Epoch [31/160] |	nca: 1.948292300105095, flat: 2.213818021118641, pod: 43.123414635658264, loss: 47.28552508354187 
Train [15/26] | Epoch [32/160] |	nca: 1.9617643915116787, flat: 2.1660681068897247, pod: 41.41738760471344, loss: 45.54521989822388 
Train [15/26] | Epoch [33/160] |	nca: 1.9741066917777061, flat: 1.9832486733794212, pod: 39.42924737930298, loss: 43.386603116989136 
Train [15/26] | Epoch [34/160] |	nca: 2.072331190109253, flat: 2.151082418859005, pod: 41.679449915885925, loss: 45.9028639793396 
Train [15/26] | Epoch [35/160] |	nca: 2.2329605743288994, flat: 2.2564818412065506, pod: 42.442296504974365, loss: 46.9317387342453 
Train [15/26] | Epoch [36/160] |	nca: 2.0960712023079395, flat: 2.2943502590060234, pod: 41.957197070121765, loss: 46.3476185798645 
Train [15/26] | Epoch [37/160] |	nca: 1.8771540522575378, flat: 2.0201308578252792, pod: 40.40601325035095, loss: 44.303298234939575 
Train [15/26] | Epoch [38/160] |	nca: 2.05930682271719, flat: 1.9967646151781082, pod: 38.886956453323364, loss: 42.94302797317505 
Train [15/26] | Epoch [39/160] |	nca: 1.8524080887436867, flat: 1.9341342225670815, pod: 39.24406445026398, loss: 43.030606746673584 
Train [15/26] | Epoch [40/160] |	nca: 1.903100237250328, flat: 2.000516787171364, pod: 39.83114778995514, loss: 43.73476457595825 
Train [15/26] | Epoch [41/160] |	nca: 1.888811081647873, flat: 1.8715314716100693, pod: 39.147687911987305, loss: 42.90803062915802 
Train [15/26] | Epoch [42/160] |	nca: 1.8913194350898266, flat: 1.9022006168961525, pod: 38.337143540382385, loss: 42.13066327571869 
Train [15/26] | Epoch [43/160] |	nca: 1.8168628588318825, flat: 1.8769228905439377, pod: 38.28564727306366, loss: 41.97943329811096 
Train [15/26] | Epoch [44/160] |	nca: 1.8255122862756252, flat: 1.805903747677803, pod: 38.43463325500488, loss: 42.06604874134064 
Train [15/26] | Epoch [45/160] |	nca: 1.900346428155899, flat: 1.812559500336647, pod: 38.56576144695282, loss: 42.27866733074188 
Train [15/26] | Epoch [46/160] |	nca: 1.9669975563883781, flat: 1.9109633043408394, pod: 38.67797529697418, loss: 42.555936336517334 
Train [15/26] | Epoch [47/160] |	nca: 1.9781028926372528, flat: 2.006646804511547, pod: 39.327662229537964, loss: 43.31241178512573 
Train [15/26] | Epoch [48/160] |	nca: 2.006477240473032, flat: 1.8478270769119263, pod: 38.093546748161316, loss: 41.947850465774536 
Train [15/26] | Epoch [49/160] |	nca: 1.7032687738537788, flat: 1.848435178399086, pod: 38.20299994945526, loss: 41.754703998565674 
Train [15/26] | Epoch [50/160] |	nca: 1.718885399401188, flat: 1.7345529794692993, pod: 36.893794894218445, loss: 40.34723377227783 
Train [15/26] | Epoch [51/160] |	nca: 1.6552591174840927, flat: 1.5669946074485779, pod: 35.731364250183105, loss: 38.95361793041229 
Train [15/26] | Epoch [52/160] |	nca: 1.8093336150050163, flat: 1.64112688601017, pod: 35.63794541358948, loss: 39.08840572834015 
Train [15/26] | Epoch [53/160] |	nca: 1.7264714390039444, flat: 1.7255580350756645, pod: 37.16204559803009, loss: 40.61407494544983 
Train [15/26] | Epoch [54/160] |	nca: 1.8275025114417076, flat: 1.7478691786527634, pod: 36.998011112213135, loss: 40.57338297367096 
Train [15/26] | Epoch [55/160] |	nca: 1.7522812485694885, flat: 1.702490508556366, pod: 37.999256014823914, loss: 41.45402801036835 
Train [15/26] | Epoch [56/160] |	nca: 1.8464283049106598, flat: 1.5843199416995049, pod: 34.6556510925293, loss: 38.08639919757843 
Train [15/26] | Epoch [57/160] |	nca: 1.8323678188025951, flat: 1.6965900883078575, pod: 36.37793684005737, loss: 39.90689480304718 
Train [15/26] | Epoch [58/160] |	nca: 1.6938864514231682, flat: 1.6810325533151627, pod: 36.72407948970795, loss: 40.09899890422821 
Train [15/26] | Epoch [59/160] |	nca: 1.7237983345985413, flat: 1.7016681358218193, pod: 36.714213371276855, loss: 40.13967978954315 
Train [15/26] | Epoch [60/160] |	nca: 1.8201860263943672, flat: 1.644717589020729, pod: 35.46669626235962, loss: 38.931599855422974 
Train [15/26] | Epoch [61/160] |	nca: 1.623785838484764, flat: 1.6072884537279606, pod: 35.66450357437134, loss: 38.895578026771545 
Train [15/26] | Epoch [62/160] |	nca: 1.7076420560479164, flat: 1.4867958091199398, pod: 33.931628465652466, loss: 37.12606644630432 
Train [15/26] | Epoch [63/160] |	nca: 1.7935896292328835, flat: 1.521899476647377, pod: 34.179399609565735, loss: 37.49488890171051 
Train [15/26] | Epoch [64/160] |	nca: 1.7116754353046417, flat: 1.6921266987919807, pod: 36.69315266609192, loss: 40.096954703330994 
Train [15/26] | Epoch [65/160] |	nca: 1.725096169859171, flat: 1.590803824365139, pod: 34.89281725883484, loss: 38.20871686935425 
Train [15/26] | Epoch [66/160] |	nca: 1.8012952357530594, flat: 1.6703607216477394, pod: 36.26225829124451, loss: 39.7339141368866 
Train [15/26] | Epoch [67/160] |	nca: 1.6005419977009296, flat: 1.4271265976130962, pod: 33.94256067276001, loss: 36.970229387283325 
Train [15/26] | Epoch [68/160] |	nca: 1.6372331604361534, flat: 1.3539480939507484, pod: 32.362887024879456, loss: 35.35406827926636 
Train [15/26] | Epoch [69/160] |	nca: 1.762217540293932, flat: 1.3651430197060108, pod: 31.735105752944946, loss: 34.86246657371521 
Train [15/26] | Epoch [70/160] |	nca: 1.8255475014448166, flat: 1.626368410885334, pod: 36.485729932785034, loss: 39.93764567375183 
Train [15/26] | Epoch [71/160] |	nca: 1.7890404090285301, flat: 1.4661063812673092, pod: 33.87213444709778, loss: 37.127280712127686 
Train [15/26] | Epoch [72/160] |	nca: 1.785593070089817, flat: 1.5693046152591705, pod: 34.79919993877411, loss: 38.15409779548645 
Train [15/26] | Epoch [73/160] |	nca: 1.5984582863748074, flat: 1.4373095482587814, pod: 33.61498522758484, loss: 36.650753021240234 
Train [15/26] | Epoch [74/160] |	nca: 1.5766283459961414, flat: 1.3785632401704788, pod: 33.2544424533844, loss: 36.20963418483734 
Train [15/26] | Epoch [75/160] |	nca: 1.5747808665037155, flat: 1.353384017944336, pod: 31.93571102619171, loss: 34.86387574672699 
Train [15/26] | Epoch [76/160] |	nca: 1.6323187164962292, flat: 1.4443901292979717, pod: 34.00281596183777, loss: 37.079525113105774 
Train [15/26] | Epoch [77/160] |	nca: 1.7074874304234982, flat: 1.4998984336853027, pod: 33.54369533061981, loss: 36.751081109046936 
Train [15/26] | Epoch [78/160] |	nca: 1.6577429957687855, flat: 1.4489642158150673, pod: 32.678783774375916, loss: 35.78549098968506 
Train [15/26] | Epoch [79/160] |	nca: 1.5396838746964931, flat: 1.4285768941044807, pod: 33.249401688575745, loss: 36.21766245365143 
Train [15/26] | Epoch [80/160] |	nca: 1.5919469110667706, flat: 1.4411019645631313, pod: 33.37403917312622, loss: 36.40708816051483 
Train [15/26] | Epoch [81/160] |	nca: 1.5710204765200615, flat: 1.4011639542877674, pod: 32.33363199234009, loss: 35.305816411972046 
Train [15/26] | Epoch [82/160] |	nca: 1.6725342385470867, flat: 1.3786309622228146, pod: 31.760111212730408, loss: 34.81127667427063 
Train [15/26] | Epoch [83/160] |	nca: 1.509415552020073, flat: 1.1560334749519825, pod: 30.234238743782043, loss: 32.89968752861023 
Train [15/26] | Epoch [84/160] |	nca: 1.5863989628851414, flat: 1.2923657670617104, pod: 32.38634812831879, loss: 35.26511311531067 
Train [15/26] | Epoch [85/160] |	nca: 1.5614463053643703, flat: 1.322427362203598, pod: 31.07040536403656, loss: 33.95427894592285 
Train [15/26] | Epoch [86/160] |	nca: 1.6956063956022263, flat: 1.262199953198433, pod: 30.43868911266327, loss: 33.39649522304535 
Train [15/26] | Epoch [87/160] |	nca: 1.6448997259140015, flat: 1.3278533071279526, pod: 32.408740878105164, loss: 35.38149416446686 
Train [15/26] | Epoch [88/160] |	nca: 1.5017580278217793, flat: 1.262524027377367, pod: 31.278507113456726, loss: 34.04278898239136 
Train [15/26] | Epoch [89/160] |	nca: 1.537431262433529, flat: 1.1450424268841743, pod: 29.099111676216125, loss: 31.781585216522217 
Train [15/26] | Epoch [90/160] |	nca: 1.535278644412756, flat: 1.276977851986885, pod: 30.609437584877014, loss: 33.42169451713562 
Train [15/26] | Epoch [91/160] |	nca: 1.5820030272006989, flat: 1.1659379191696644, pod: 29.46955406665802, loss: 32.21749484539032 
Train [15/26] | Epoch [92/160] |	nca: 1.5587315522134304, flat: 1.1352924555540085, pod: 29.73949444293976, loss: 32.43351864814758 
Train [15/26] | Epoch [93/160] |	nca: 1.705347515642643, flat: 1.1228764094412327, pod: 27.960309982299805, loss: 30.788533687591553 
Train [15/26] | Epoch [94/160] |	nca: 1.4884294904768467, flat: 1.0447604320943356, pod: 27.802769422531128, loss: 30.335959315299988 
Train [15/26] | Epoch [95/160] |	nca: 1.4965489841997623, flat: 1.112999476492405, pod: 28.49468445777893, loss: 31.104232907295227 
Train [15/26] | Epoch [96/160] |	nca: 1.462800182402134, flat: 1.0301107689738274, pod: 26.813140153884888, loss: 29.30605113506317 
Train [15/26] | Epoch [97/160] |	nca: 1.712071780115366, flat: 1.1380251497030258, pod: 29.34176528453827, loss: 32.19186234474182 
Train [15/26] | Epoch [98/160] |	nca: 1.5431217066943645, flat: 1.0624838136136532, pod: 28.46120047569275, loss: 31.066806197166443 
Train [15/26] | Epoch [99/160] |	nca: 1.5278539843857288, flat: 1.044198915362358, pod: 27.51772153377533, loss: 30.08977448940277 
Train [15/26] | Epoch [100/160] |	nca: 1.5943801142275333, flat: 1.0824630595743656, pod: 29.09305489063263, loss: 31.769898295402527 
Train [15/26] | Epoch [101/160] |	nca: 1.4922754168510437, flat: 0.9948054924607277, pod: 26.59430468082428, loss: 29.081385731697083 
Train [15/26] | Epoch [102/160] |	nca: 1.5045917592942715, flat: 1.0497860088944435, pod: 27.653191208839417, loss: 30.207568764686584 
Train [15/26] | Epoch [103/160] |	nca: 1.6144928373396397, flat: 1.1151293963193893, pod: 29.509122490882874, loss: 32.238744616508484 
Train [15/26] | Epoch [104/160] |	nca: 1.4551110789179802, flat: 0.9815214835107327, pod: 26.88610529899597, loss: 29.32273781299591 
Train [15/26] | Epoch [105/160] |	nca: 1.6580108031630516, flat: 1.0819524675607681, pod: 27.776707530021667, loss: 30.51667070388794 
Train [15/26] | Epoch [106/160] |	nca: 1.4195546470582485, flat: 0.98026317730546, pod: 26.728976249694824, loss: 29.128794193267822 
Train [15/26] | Epoch [107/160] |	nca: 1.4898263476788998, flat: 0.9302089251577854, pod: 26.379925847053528, loss: 28.7999609708786 
Train [15/26] | Epoch [108/160] |	nca: 1.5524024963378906, flat: 0.9960520751774311, pod: 26.391666054725647, loss: 28.940120458602905 
Train [15/26] | Epoch [109/160] |	nca: 1.5330070555210114, flat: 1.0364524312317371, pod: 27.408799648284912, loss: 29.978259086608887 
Train [15/26] | Epoch [110/160] |	nca: 1.4105576016008854, flat: 0.9694588631391525, pod: 25.9926974773407, loss: 28.372713923454285 
Train [15/26] | Epoch [111/160] |	nca: 1.476189412176609, flat: 0.8858505859971046, pod: 25.563949584960938, loss: 27.925989627838135 
Train [15/26] | Epoch [112/160] |	nca: 1.479205809533596, flat: 0.8427577465772629, pod: 23.73661971092224, loss: 26.05858314037323 
Train [15/26] | Epoch [113/160] |	nca: 1.5081112161278725, flat: 0.837543822824955, pod: 24.084063470363617, loss: 26.429718375205994 
Train [15/26] | Epoch [114/160] |	nca: 1.5821969509124756, flat: 0.8900298662483692, pod: 24.44051170349121, loss: 26.91273844242096 
Train [15/26] | Epoch [115/160] |	nca: 1.4877980686724186, flat: 0.7682687025517225, pod: 22.89219743013382, loss: 25.148264169692993 
Train [15/26] | Epoch [116/160] |	nca: 1.4786962941288948, flat: 0.892319243401289, pod: 24.05590796470642, loss: 26.426923394203186 
Train [15/26] | Epoch [117/160] |	nca: 1.5457034073770046, flat: 0.846871092915535, pod: 23.87204647064209, loss: 26.264620900154114 
Train [15/26] | Epoch [118/160] |	nca: 1.4018410332500935, flat: 0.8090370297431946, pod: 23.7287734746933, loss: 25.939651489257812 
Train [15/26] | Epoch [119/160] |	nca: 1.4753004424273968, flat: 0.7760248221457005, pod: 23.37002396583557, loss: 25.621349096298218 
Train [15/26] | Epoch [120/160] |	nca: 1.4387452192604542, flat: 0.8375208582729101, pod: 24.52461063861847, loss: 26.80087685585022 
Train [15/26] | Epoch [121/160] |	nca: 1.5799542963504791, flat: 0.806875329464674, pod: 23.75786781311035, loss: 26.144697546958923 
Train [15/26] | Epoch [122/160] |	nca: 1.4586244374513626, flat: 0.8718306310474873, pod: 24.804165363311768, loss: 27.134620547294617 
Train [15/26] | Epoch [123/160] |	nca: 1.4243572615087032, flat: 0.8228161279112101, pod: 24.532577395439148, loss: 26.77975082397461 
Train [15/26] | Epoch [124/160] |	nca: 1.4617397226393223, flat: 0.7561457492411137, pod: 21.603407859802246, loss: 23.821293473243713 
Train [15/26] | Epoch [125/160] |	nca: 1.426906280219555, flat: 0.7282382473349571, pod: 21.59995526075363, loss: 23.755099952220917 
Train [15/26] | Epoch [126/160] |	nca: 1.4298838749527931, flat: 0.7767523285001516, pod: 22.28513342142105, loss: 24.49176961183548 
Train [15/26] | Epoch [127/160] |	nca: 1.3653823472559452, flat: 0.6988232564181089, pod: 21.36097526550293, loss: 23.425180912017822 
Train [15/26] | Epoch [128/160] |	nca: 1.4223118908703327, flat: 0.6556248068809509, pod: 20.423112392425537, loss: 22.501048803329468 
Train [15/26] | Epoch [129/160] |	nca: 1.5180543884634972, flat: 0.690863648429513, pod: 20.575552821159363, loss: 22.784470856189728 
Train [15/26] | Epoch [130/160] |	nca: 1.4717833027243614, flat: 0.6288888268172741, pod: 19.60689550638199, loss: 21.707567751407623 
Train [15/26] | Epoch [131/160] |	nca: 1.4050734303891659, flat: 0.674502782523632, pod: 21.663102328777313, loss: 23.74267852306366 
Train [15/26] | Epoch [132/160] |	nca: 1.4106834195554256, flat: 0.7100350968539715, pod: 21.4807226061821, loss: 23.601441204547882 
Train [15/26] | Epoch [133/160] |	nca: 1.5355657041072845, flat: 0.6882287133485079, pod: 20.854529082775116, loss: 23.07832306623459 
Train [15/26] | Epoch [134/160] |	nca: 1.361408058553934, flat: 0.6281062718480825, pod: 19.865479469299316, loss: 21.85499382019043 
Train [15/26] | Epoch [135/160] |	nca: 1.5109418332576752, flat: 0.6441780477762222, pod: 20.050202012062073, loss: 22.205321967601776 
Train [15/26] | Epoch [136/160] |	nca: 1.4514703191816807, flat: 0.6575442776083946, pod: 21.206782937049866, loss: 23.315797209739685 
Train [15/26] | Epoch [137/160] |	nca: 1.3687658607959747, flat: 0.6344912014901638, pod: 20.03946876525879, loss: 22.04272598028183 
Train [15/26] | Epoch [138/160] |	nca: 1.5450595617294312, flat: 0.6600568797439337, pod: 19.984240233898163, loss: 22.189356744289398 
Train [15/26] | Epoch [139/160] |	nca: 1.4072864465415478, flat: 0.6242164429277182, pod: 19.1550030708313, loss: 21.186505794525146 
Train [15/26] | Epoch [140/160] |	nca: 1.3295334354043007, flat: 0.6219822019338608, pod: 19.57186096906662, loss: 21.523376643657684 
Train [15/26] | Epoch [141/160] |	nca: 1.4670005552470684, flat: 0.6135395709425211, pod: 18.974703431129456, loss: 21.0552436709404 
Train [15/26] | Epoch [142/160] |	nca: 1.469724539667368, flat: 0.560869699344039, pod: 17.840842604637146, loss: 19.871436536312103 
Train [15/26] | Epoch [143/160] |	nca: 1.3560057394206524, flat: 0.6047483030706644, pod: 19.31302374601364, loss: 21.273777723312378 
Train [15/26] | Epoch [144/160] |	nca: 1.4652006700634956, flat: 0.6188709177076817, pod: 18.709213078022003, loss: 20.793284714221954 
Train [15/26] | Epoch [145/160] |	nca: 1.3886857144534588, flat: 0.5520267877727747, pod: 18.280913054943085, loss: 20.221625566482544 
Train [15/26] | Epoch [146/160] |	nca: 1.396447729319334, flat: 0.5390884298831224, pod: 17.386745929718018, loss: 19.322282016277313 
Train [15/26] | Epoch [147/160] |	nca: 1.381332203745842, flat: 0.5511053279042244, pod: 18.017544627189636, loss: 19.949982404708862 
Train [15/26] | Epoch [148/160] |	nca: 1.4140022210776806, flat: 0.5299648828804493, pod: 17.81986826658249, loss: 19.76383537054062 
Train [15/26] | Epoch [149/160] |	nca: 1.3883882947266102, flat: 0.5537957735359669, pod: 17.450980603694916, loss: 19.393164575099945 
Train [15/26] | Epoch [150/160] |	nca: 1.3118966333568096, flat: 0.5352712608873844, pod: 17.99439960718155, loss: 19.84156745672226 
Train [15/26] | Epoch [151/160] |	nca: 1.3889954909682274, flat: 0.5290846843272448, pod: 17.159649670124054, loss: 19.07772982120514 
Train [15/26] | Epoch [152/160] |	nca: 1.4657367318868637, flat: 0.5742996875196695, pod: 17.49789184331894, loss: 19.537928223609924 
Train [15/26] | Epoch [153/160] |	nca: 1.3843822441995144, flat: 0.5235918164253235, pod: 16.96010249853134, loss: 18.86807632446289 
Train [15/26] | Epoch [154/160] |	nca: 1.3081685826182365, flat: 0.5142106078565121, pod: 16.451339423656464, loss: 18.273718655109406 
Train [15/26] | Epoch [155/160] |	nca: 1.3817066960036755, flat: 0.5176490135490894, pod: 17.075886130332947, loss: 18.97524183988571 
Train [15/26] | Epoch [156/160] |	nca: 1.3180982284247875, flat: 0.4771387614309788, pod: 15.651234984397888, loss: 17.446471989154816 
Train [15/26] | Epoch [157/160] |	nca: 1.454007837921381, flat: 0.4786458220332861, pod: 16.167752265930176, loss: 18.10040593147278 
Train [15/26] | Epoch [158/160] |	nca: 1.3903278782963753, flat: 0.5023542977869511, pod: 16.458978712558746, loss: 18.35166108608246 
Train [15/26] | Epoch [159/160] |	nca: 1.3415033407509327, flat: 0.4901570249348879, pod: 16.492840945720673, loss: 18.324501276016235 
Train [15/26] | Epoch [160/160] |	nca: 1.4812052212655544, flat: 0.5689243488013744, pod: 17.554548501968384, loss: 19.604677975177765 
Fine-tuning
Building & updating memory.
Train [15/26] | Epoch [161/180] |	nca: 1.0853925198316574, flat: 0.8452971912920475, pod: 18.26255691051483, loss: 20.193246603012085 
Train [15/26] | Epoch [162/180] |	nca: 0.8152284659445286, flat: 0.8544958792626858, pod: 18.89480769634247, loss: 20.564532160758972 
Train [15/26] | Epoch [163/180] |	nca: 0.6858072392642498, flat: 0.8346523754298687, pod: 18.560881853103638, loss: 20.08134162425995 
Train [15/26] | Epoch [164/180] |	nca: 0.6585629805922508, flat: 0.9046060964465141, pod: 18.876822113990784, loss: 20.439990997314453 
Train [15/26] | Epoch [165/180] |	nca: 0.6644832640886307, flat: 0.8366120345890522, pod: 18.052917063236237, loss: 19.554012298583984 
Train [15/26] | Epoch [166/180] |	nca: 0.8010991513729095, flat: 0.8641513288021088, pod: 18.437437295913696, loss: 20.10268771648407 
Train [15/26] | Epoch [167/180] |	nca: 0.926238514482975, flat: 0.7819382138550282, pod: 18.16773545742035, loss: 19.875912070274353 
Train [15/26] | Epoch [168/180] |	nca: 0.7209727354347706, flat: 0.8177735395729542, pod: 18.169657230377197, loss: 19.708403706550598 
Train [15/26] | Epoch [169/180] |	nca: 0.6419603265821934, flat: 0.8092852234840393, pod: 17.975597143173218, loss: 19.42684257030487 
Train [15/26] | Epoch [170/180] |	nca: 0.5745213255286217, flat: 0.8005537688732147, pod: 17.782170057296753, loss: 19.15724527835846 
Train [15/26] | Epoch [171/180] |	nca: 0.4977566506713629, flat: 0.7616610527038574, pod: 18.050878286361694, loss: 19.310296058654785 
Train [15/26] | Epoch [172/180] |	nca: 0.5879139453172684, flat: 0.8415157906711102, pod: 17.937201499938965, loss: 19.366631150245667 
Train [15/26] | Epoch [173/180] |	nca: 0.5144281573593616, flat: 0.7848590537905693, pod: 17.843965470790863, loss: 19.14325249195099 
Train [15/26] | Epoch [174/180] |	nca: 0.6478493995964527, flat: 0.8082921914756298, pod: 18.14614236354828, loss: 19.60228407382965 
Train [15/26] | Epoch [175/180] |	nca: 0.8089932799339294, flat: 0.8114336133003235, pod: 17.924221634864807, loss: 19.54464840888977 
Train [15/26] | Epoch [176/180] |	nca: 0.6131047829985619, flat: 0.8345747850835323, pod: 18.261338114738464, loss: 19.709017634391785 
Train [15/26] | Epoch [177/180] |	nca: 0.5988907013088465, flat: 0.8163939788937569, pod: 18.004360795021057, loss: 19.41964554786682 
Train [15/26] | Epoch [178/180] |	nca: 0.5273912120610476, flat: 0.9099675714969635, pod: 18.81884229183197, loss: 20.256201028823853 
Train [15/26] | Epoch [179/180] |	nca: 0.539747342467308, flat: 0.8142606653273106, pod: 18.003586888313293, loss: 19.357595205307007 
Train [15/26] | Epoch [180/180] |	nca: 0.527905061841011, flat: 0.8089278694242239, pod: 17.663342356681824, loss: 19.00017535686493 
after task
Building & updating memory.
after task
Eval on 0->78.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6498666666666666.
Current acc: {'total': 0.574, '00-09': 0.637, '10-19': 0.552, '20-29': 0.487, '30-39': 0.546, '40-49': 0.582, '50-59': 0.552, '60-69': 0.526, '70-79': 0.743}.
Avg inc acc top5: 0.8849999999999998.
Current acc top5: {'total': 0.844}.
Forgetting: 0.1882222222222222.
Cord metric: 0.65.
Old accuracy: 0.57, mean: 0.64.
New accuracy: 0.77, mean: 0.79.
================Task 15 Start!================
Testing on False unseen tasks (max class = 80).
Set memory of size: 1560.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 15 Training!================
The training samples number: 2560
Train on 78->80.
train task
nb 2560.
Train [16/26] | Epoch [1/160] |	nca: 9.650978773832321, flat: 4.346792697906494, pod: 52.62497580051422, loss: 66.6227478981018 
Train [16/26] | Epoch [2/160] |	nca: 6.700126066803932, flat: 5.145969375967979, pod: 59.74545502662659, loss: 71.59155011177063 
Train [16/26] | Epoch [3/160] |	nca: 4.969820663332939, flat: 4.553821533918381, pod: 57.46765160560608, loss: 66.99129319190979 
Train [16/26] | Epoch [4/160] |	nca: 4.099314734339714, flat: 3.7833304405212402, pod: 53.537521839141846, loss: 61.420166969299316 
Train [16/26] | Epoch [5/160] |	nca: 2.9741858690977097, flat: 3.218799278140068, pod: 50.72913908958435, loss: 56.92212390899658 
Train [16/26] | Epoch [6/160] |	nca: 3.1038004234433174, flat: 2.9102911055088043, pod: 48.507485151290894, loss: 54.52157664299011 
Train [16/26] | Epoch [7/160] |	nca: 2.940863512456417, flat: 2.903536409139633, pod: 48.26901292800903, loss: 54.113412618637085 
Train [16/26] | Epoch [8/160] |	nca: 2.5812546461820602, flat: 2.618776746094227, pod: 46.356640100479126, loss: 51.556670904159546 
Train [16/26] | Epoch [9/160] |	nca: 2.312855452299118, flat: 2.4838662296533585, pod: 46.200236320495605, loss: 50.99695825576782 
Train [16/26] | Epoch [10/160] |	nca: 2.74935120344162, flat: 2.50152737647295, pod: 44.27658724784851, loss: 49.52746534347534 
Train [16/26] | Epoch [11/160] |	nca: 2.316643837839365, flat: 2.487071417272091, pod: 44.971110343933105, loss: 49.77482557296753 
Train [16/26] | Epoch [12/160] |	nca: 2.3629428818821907, flat: 2.4824058562517166, pod: 45.01536440849304, loss: 49.86071300506592 
Train [16/26] | Epoch [13/160] |	nca: 2.4186543077230453, flat: 2.3758970499038696, pod: 43.10374093055725, loss: 47.89829230308533 
Train [16/26] | Epoch [14/160] |	nca: 2.5312263444066048, flat: 2.4298830926418304, pod: 44.35631990432739, loss: 49.31742882728577 
Train [16/26] | Epoch [15/160] |	nca: 2.2465063259005547, flat: 2.278302937746048, pod: 42.81280493736267, loss: 47.3376145362854 
Train [16/26] | Epoch [16/160] |	nca: 2.3661485500633717, flat: 2.2358557507395744, pod: 42.05770564079285, loss: 46.659709453582764 
Train [16/26] | Epoch [17/160] |	nca: 2.2598189935088158, flat: 2.391491785645485, pod: 44.44336128234863, loss: 49.094672203063965 
Train [16/26] | Epoch [18/160] |	nca: 2.3116004019975662, flat: 2.400759994983673, pod: 44.85636365413666, loss: 49.568723917007446 
Train [16/26] | Epoch [19/160] |	nca: 2.256361536681652, flat: 2.4036451876163483, pod: 45.043434143066406, loss: 49.70344114303589 
Train [16/26] | Epoch [20/160] |	nca: 2.1974563486874104, flat: 2.2953667864203453, pod: 43.19626438617706, loss: 47.68908715248108 
Train [16/26] | Epoch [21/160] |	nca: 2.3977119624614716, flat: 2.367383122444153, pod: 43.00271391868591, loss: 47.76780891418457 
Train [16/26] | Epoch [22/160] |	nca: 2.527768388390541, flat: 2.521241009235382, pod: 45.98376488685608, loss: 51.032774686813354 
Train [16/26] | Epoch [23/160] |	nca: 2.2856126576662064, flat: 2.4680556803941727, pod: 44.60576891899109, loss: 49.359437465667725 
Train [16/26] | Epoch [24/160] |	nca: 2.3862789422273636, flat: 2.396386429667473, pod: 45.11217164993286, loss: 49.89483666419983 
Train [16/26] | Epoch [25/160] |	nca: 2.3590734004974365, flat: 2.3119287714362144, pod: 43.165876150131226, loss: 47.836878299713135 
Train [16/26] | Epoch [26/160] |	nca: 2.289995677769184, flat: 2.2939894050359726, pod: 43.11547338962555, loss: 47.69945812225342 
Train [16/26] | Epoch [27/160] |	nca: 2.030394569039345, flat: 2.1953180879354477, pod: 42.04703676700592, loss: 46.27274990081787 
Train [16/26] | Epoch [28/160] |	nca: 2.1143548861145973, flat: 2.11368715018034, pod: 41.0244916677475, loss: 45.25253415107727 
Train [16/26] | Epoch [29/160] |	nca: 2.13440665602684, flat: 2.0589834824204445, pod: 41.930354833602905, loss: 46.12374472618103 
Train [16/26] | Epoch [30/160] |	nca: 2.274437729269266, flat: 2.3217289969325066, pod: 43.56322526931763, loss: 48.15939235687256 
Train [16/26] | Epoch [31/160] |	nca: 1.905726246535778, flat: 2.1400036588311195, pod: 41.644495606422424, loss: 45.69022583961487 
Train [16/26] | Epoch [32/160] |	nca: 1.966127760708332, flat: 1.9821549504995346, pod: 39.81626605987549, loss: 43.764548540115356 
Train [16/26] | Epoch [33/160] |	nca: 2.1315263137221336, flat: 2.0611342564225197, pod: 39.95472276210785, loss: 44.14738345146179 
Train [16/26] | Epoch [34/160] |	nca: 2.25115417689085, flat: 2.1745503693819046, pod: 41.958319425582886, loss: 46.384024262428284 
Train [16/26] | Epoch [35/160] |	nca: 2.142128922045231, flat: 2.0987209752202034, pod: 40.82670724391937, loss: 45.06755709648132 
Train [16/26] | Epoch [36/160] |	nca: 2.024829722940922, flat: 1.9817437008023262, pod: 39.76112699508667, loss: 43.7677001953125 
Train [16/26] | Epoch [37/160] |	nca: 1.974762238562107, flat: 1.9527814537286758, pod: 39.359591603279114, loss: 43.28713500499725 
Train [16/26] | Epoch [38/160] |	nca: 2.1366430297493935, flat: 2.252580389380455, pod: 43.48248863220215, loss: 47.87171196937561 
Train [16/26] | Epoch [39/160] |	nca: 2.0135963037610054, flat: 2.0765819400548935, pod: 40.56197786331177, loss: 44.652156591415405 
Train [16/26] | Epoch [40/160] |	nca: 2.003581900149584, flat: 1.9392280355095863, pod: 39.80315959453583, loss: 43.74596953392029 
Train [16/26] | Epoch [41/160] |	nca: 2.009782187640667, flat: 1.9497978389263153, pod: 40.12100577354431, loss: 44.08058559894562 
Train [16/26] | Epoch [42/160] |	nca: 1.9292561709880829, flat: 1.9649416357278824, pod: 41.00853431224823, loss: 44.902732729911804 
Train [16/26] | Epoch [43/160] |	nca: 1.864217959344387, flat: 1.8946366012096405, pod: 40.177361369132996, loss: 43.93621575832367 
Train [16/26] | Epoch [44/160] |	nca: 1.9405974075198174, flat: 1.76912322640419, pod: 37.59191286563873, loss: 41.30163323879242 
Train [16/26] | Epoch [45/160] |	nca: 2.012996181845665, flat: 1.8795562162995338, pod: 38.93353033065796, loss: 42.82608246803284 
Train [16/26] | Epoch [46/160] |	nca: 2.1980258896946907, flat: 1.924034520983696, pod: 39.203893065452576, loss: 43.32595360279083 
Train [16/26] | Epoch [47/160] |	nca: 1.9728237614035606, flat: 1.9861890450119972, pod: 39.990623474121094, loss: 43.949636340141296 
Train [16/26] | Epoch [48/160] |	nca: 2.0633841454982758, flat: 1.942776843905449, pod: 39.343989610672, loss: 43.35015058517456 
Train [16/26] | Epoch [49/160] |	nca: 1.8889099955558777, flat: 1.892375148832798, pod: 39.20937943458557, loss: 42.9906644821167 
Train [16/26] | Epoch [50/160] |	nca: 1.7674768045544624, flat: 1.6969581097364426, pod: 37.780540347099304, loss: 41.244975209236145 
Train [16/26] | Epoch [51/160] |	nca: 1.8259236961603165, flat: 1.8324545994400978, pod: 38.14405405521393, loss: 41.80243253707886 
Train [16/26] | Epoch [52/160] |	nca: 1.9612664505839348, flat: 1.787393145263195, pod: 36.86645305156708, loss: 40.61511266231537 
Train [16/26] | Epoch [53/160] |	nca: 1.9802575334906578, flat: 2.0103138387203217, pod: 41.282601952552795, loss: 45.273173093795776 
Train [16/26] | Epoch [54/160] |	nca: 1.835554089397192, flat: 1.9364598765969276, pod: 40.26169192790985, loss: 44.03370523452759 
Train [16/26] | Epoch [55/160] |	nca: 1.776367723941803, flat: 1.8113840147852898, pod: 38.069050431251526, loss: 41.65680205821991 
Train [16/26] | Epoch [56/160] |	nca: 1.868803784251213, flat: 1.862366832792759, pod: 39.14267325401306, loss: 42.873844146728516 
Train [16/26] | Epoch [57/160] |	nca: 1.8070339038968086, flat: 1.7273365333676338, pod: 37.52895367145538, loss: 41.063323974609375 
Train [16/26] | Epoch [58/160] |	nca: 1.8658217154443264, flat: 1.6727871969342232, pod: 37.874579310417175, loss: 41.413188219070435 
Train [16/26] | Epoch [59/160] |	nca: 2.116552896797657, flat: 1.8490789830684662, pod: 37.792322635650635, loss: 41.757954359054565 
Train [16/26] | Epoch [60/160] |	nca: 1.852142609655857, flat: 1.764781914651394, pod: 36.57218611240387, loss: 40.18911027908325 
Train [16/26] | Epoch [61/160] |	nca: 1.8752925544977188, flat: 1.7262412086129189, pod: 35.479854226112366, loss: 39.081387877464294 
Train [16/26] | Epoch [62/160] |	nca: 1.7204878777265549, flat: 1.6167506724596024, pod: 35.351908564567566, loss: 38.689146995544434 
Train [16/26] | Epoch [63/160] |	nca: 1.7883942797780037, flat: 1.6870588809251785, pod: 37.02435779571533, loss: 40.49981093406677 
Train [16/26] | Epoch [64/160] |	nca: 1.6600823998451233, flat: 1.5486758798360825, pod: 35.51245987415314, loss: 38.72121775150299 
Train [16/26] | Epoch [65/160] |	nca: 1.7210360541939735, flat: 1.5782388299703598, pod: 35.45751440525055, loss: 38.75678896903992 
Train [16/26] | Epoch [66/160] |	nca: 1.724982675164938, flat: 1.5933870375156403, pod: 36.316165924072266, loss: 39.634535908699036 
Train [16/26] | Epoch [67/160] |	nca: 1.6879529058933258, flat: 1.6051173731684685, pod: 36.97581875324249, loss: 40.26888906955719 
Train [16/26] | Epoch [68/160] |	nca: 1.790165737271309, flat: 1.4850763157010078, pod: 33.93128824234009, loss: 37.20652997493744 
Train [16/26] | Epoch [69/160] |	nca: 1.6381117887794971, flat: 1.542991254478693, pod: 35.4857622385025, loss: 38.6668655872345 
Train [16/26] | Epoch [70/160] |	nca: 1.6838896423578262, flat: 1.4049679227173328, pod: 33.775431394577026, loss: 36.86428916454315 
Train [16/26] | Epoch [71/160] |	nca: 1.7673339806497097, flat: 1.552785612642765, pod: 35.894081354141235, loss: 39.21420109272003 
Train [16/26] | Epoch [72/160] |	nca: 1.7794587947428226, flat: 1.5643329061567783, pod: 35.6176894903183, loss: 38.96148097515106 
Train [16/26] | Epoch [73/160] |	nca: 1.7698432952165604, flat: 1.479071743786335, pod: 34.527422189712524, loss: 37.7763375043869 
Train [16/26] | Epoch [74/160] |	nca: 1.6107657887041569, flat: 1.346132393926382, pod: 31.307753920555115, loss: 34.2646518945694 
Train [16/26] | Epoch [75/160] |	nca: 1.7356057539582253, flat: 1.4166246727108955, pod: 33.65610897541046, loss: 36.80833959579468 
Train [16/26] | Epoch [76/160] |	nca: 1.70744251832366, flat: 1.5403982400894165, pod: 34.34837770462036, loss: 37.59621834754944 
Train [16/26] | Epoch [77/160] |	nca: 1.6892432197928429, flat: 1.5761634185910225, pod: 35.792160987854004, loss: 39.057567834854126 
Train [16/26] | Epoch [78/160] |	nca: 1.5257683619856834, flat: 1.3640893027186394, pod: 33.24701750278473, loss: 36.13687539100647 
Train [16/26] | Epoch [79/160] |	nca: 1.8033406808972359, flat: 1.3852436281740665, pod: 32.203176856040955, loss: 35.39176118373871 
Train [16/26] | Epoch [80/160] |	nca: 1.7016159370541573, flat: 1.3799776621162891, pod: 32.6440407037735, loss: 35.72563445568085 
Train [16/26] | Epoch [81/160] |	nca: 1.7246194332838058, flat: 1.4050314389169216, pod: 33.97488582134247, loss: 37.10453641414642 
Train [16/26] | Epoch [82/160] |	nca: 1.596980445086956, flat: 1.363406702876091, pod: 34.08981943130493, loss: 37.05020618438721 
Train [16/26] | Epoch [83/160] |	nca: 1.6073943562805653, flat: 1.3743210434913635, pod: 33.04488253593445, loss: 36.02659773826599 
Train [16/26] | Epoch [84/160] |	nca: 1.7267039865255356, flat: 1.4091427847743034, pod: 34.465418338775635, loss: 37.60126519203186 
Train [16/26] | Epoch [85/160] |	nca: 1.5566272214055061, flat: 1.2474237605929375, pod: 31.620080947875977, loss: 34.424131989479065 
Train [16/26] | Epoch [86/160] |	nca: 1.5961338505148888, flat: 1.1821250766515732, pod: 30.295812487602234, loss: 33.074071407318115 
Train [16/26] | Epoch [87/160] |	nca: 1.597411870956421, flat: 1.2084852829575539, pod: 30.000043511390686, loss: 32.80594074726105 
Train [16/26] | Epoch [88/160] |	nca: 1.6880708895623684, flat: 1.1910830587148666, pod: 30.07389223575592, loss: 32.95304596424103 
Train [16/26] | Epoch [89/160] |	nca: 1.6050730980932713, flat: 1.234292145818472, pod: 30.833616256713867, loss: 33.67298102378845 
Train [16/26] | Epoch [90/160] |	nca: 1.7012295238673687, flat: 1.177435863763094, pod: 30.519716382026672, loss: 33.39838182926178 
Train [16/26] | Epoch [91/160] |	nca: 1.5815398283302784, flat: 1.3055398538708687, pod: 32.293352484703064, loss: 35.18043231964111 
Train [16/26] | Epoch [92/160] |	nca: 1.5265946984291077, flat: 1.1655493192374706, pod: 30.491045236587524, loss: 33.183189272880554 
Train [16/26] | Epoch [93/160] |	nca: 1.7738324627280235, flat: 1.2068182155489922, pod: 29.661640167236328, loss: 32.64229094982147 
Train [16/26] | Epoch [94/160] |	nca: 1.5130657888948917, flat: 1.1042162030935287, pod: 29.131160497665405, loss: 31.74844253063202 
Train [16/26] | Epoch [95/160] |	nca: 1.4642276242375374, flat: 1.0971423387527466, pod: 28.02956461906433, loss: 30.59093451499939 
Train [16/26] | Epoch [96/160] |	nca: 1.7131020985543728, flat: 1.0014826767146587, pod: 26.563344478607178, loss: 29.277929067611694 
Train [16/26] | Epoch [97/160] |	nca: 1.7133850194513798, flat: 1.047567430883646, pod: 27.987461805343628, loss: 30.748414397239685 
Train [16/26] | Epoch [98/160] |	nca: 1.5301727205514908, flat: 1.0493088103830814, pod: 27.930683135986328, loss: 30.510164737701416 
Train [16/26] | Epoch [99/160] |	nca: 1.4761161617934704, flat: 1.1762352883815765, pod: 29.588887929916382, loss: 32.24123930931091 
Train [16/26] | Epoch [100/160] |	nca: 1.4541780389845371, flat: 1.0737958550453186, pod: 28.25244128704071, loss: 30.780415415763855 
Train [16/26] | Epoch [101/160] |	nca: 1.6594263799488544, flat: 1.0557273775339127, pod: 28.262187480926514, loss: 30.977341175079346 
Train [16/26] | Epoch [102/160] |	nca: 1.4993630722165108, flat: 1.0580711476504803, pod: 28.450880885124207, loss: 31.008315324783325 
Train [16/26] | Epoch [103/160] |	nca: 1.7210847362875938, flat: 1.1205940581858158, pod: 29.777812600135803, loss: 32.61949133872986 
Train [16/26] | Epoch [104/160] |	nca: 1.637347236275673, flat: 1.080804731696844, pod: 29.358177304267883, loss: 32.07632911205292 
Train [16/26] | Epoch [105/160] |	nca: 1.4707525074481964, flat: 1.0973180271685123, pod: 29.158541321754456, loss: 31.726611971855164 
Train [16/26] | Epoch [106/160] |	nca: 1.4716199599206448, flat: 0.9985554553568363, pod: 27.105870246887207, loss: 29.576045632362366 
Train [16/26] | Epoch [107/160] |	nca: 1.3818131685256958, flat: 0.9501094967126846, pod: 26.671234846115112, loss: 29.003157258033752 
Train [16/26] | Epoch [108/160] |	nca: 1.5728573985397816, flat: 0.9101037941873074, pod: 25.48599946498871, loss: 27.968960881233215 
Train [16/26] | Epoch [109/160] |	nca: 1.5083025097846985, flat: 0.9389761164784431, pod: 26.16863739490509, loss: 28.615915775299072 
Train [16/26] | Epoch [110/160] |	nca: 1.4560391530394554, flat: 0.8995623290538788, pod: 26.000224828720093, loss: 28.355826139450073 
Train [16/26] | Epoch [111/160] |	nca: 1.577908270061016, flat: 0.8713764287531376, pod: 24.51012897491455, loss: 26.959413528442383 
Train [16/26] | Epoch [112/160] |	nca: 1.5409373380243778, flat: 0.89943578094244, pod: 24.670794010162354, loss: 27.111167430877686 
Train [16/26] | Epoch [113/160] |	nca: 1.636457271873951, flat: 0.9776015989482403, pod: 27.083794713020325, loss: 29.697853446006775 
Train [16/26] | Epoch [114/160] |	nca: 1.4994634613394737, flat: 0.8868999481201172, pod: 25.700566172599792, loss: 28.08692967891693 
Train [16/26] | Epoch [115/160] |	nca: 1.5820943601429462, flat: 0.9369211792945862, pod: 26.742388010025024, loss: 29.261403560638428 
Train [16/26] | Epoch [116/160] |	nca: 1.5555140636861324, flat: 0.8805932328104973, pod: 25.14095950126648, loss: 27.577066779136658 
Train [16/26] | Epoch [117/160] |	nca: 1.6819630041718483, flat: 0.8770851232111454, pod: 24.832915425300598, loss: 27.391963720321655 
Train [16/26] | Epoch [118/160] |	nca: 1.4734350591897964, flat: 0.812381798401475, pod: 24.27525222301483, loss: 26.561069130897522 
Train [16/26] | Epoch [119/160] |	nca: 1.4966812543570995, flat: 0.8070269133895636, pod: 23.410001516342163, loss: 25.713709950447083 
Train [16/26] | Epoch [120/160] |	nca: 1.5574562884867191, flat: 0.8016432672739029, pod: 23.425846874713898, loss: 25.78494644165039 
Train [16/26] | Epoch [121/160] |	nca: 1.5424818098545074, flat: 0.791936419904232, pod: 23.71975839138031, loss: 26.054176330566406 
Train [16/26] | Epoch [122/160] |	nca: 1.5927473567426205, flat: 0.7444131821393967, pod: 22.372747838497162, loss: 24.709908366203308 
Train [16/26] | Epoch [123/160] |	nca: 1.5435341075062752, flat: 0.8215566668659449, pod: 23.79809820652008, loss: 26.16318905353546 
Train [16/26] | Epoch [124/160] |	nca: 1.6015968658030033, flat: 0.7816265318542719, pod: 23.028592467308044, loss: 25.411815762519836 
Train [16/26] | Epoch [125/160] |	nca: 1.495222482830286, flat: 0.785567183047533, pod: 22.891218662261963, loss: 25.172008633613586 
Train [16/26] | Epoch [126/160] |	nca: 1.479318905621767, flat: 0.7522604800760746, pod: 22.40672928094864, loss: 24.63830852508545 
Train [16/26] | Epoch [127/160] |	nca: 1.413899376988411, flat: 0.7382412943989038, pod: 22.14094215631485, loss: 24.29308247566223 
Train [16/26] | Epoch [128/160] |	nca: 1.474668938666582, flat: 0.6709270365536213, pod: 20.425974667072296, loss: 22.571570575237274 
Train [16/26] | Epoch [129/160] |	nca: 1.546253241598606, flat: 0.7143008224666119, pod: 21.57402193546295, loss: 23.83457589149475 
Train [16/26] | Epoch [130/160] |	nca: 1.6246038153767586, flat: 0.7366083897650242, pod: 21.918712377548218, loss: 24.279924631118774 
Train [16/26] | Epoch [131/160] |	nca: 1.4664959982037544, flat: 0.6987010706216097, pod: 21.314885139465332, loss: 23.48008221387863 
Train [16/26] | Epoch [132/160] |	nca: 1.4478943385183811, flat: 0.6969401221722364, pod: 20.771606028079987, loss: 22.91644060611725 
Train [16/26] | Epoch [133/160] |	nca: 1.514810960739851, flat: 0.7121629696339369, pod: 21.815929114818573, loss: 24.04290270805359 
Train [16/26] | Epoch [134/160] |	nca: 1.595811616629362, flat: 0.6575819496065378, pod: 20.59355592727661, loss: 22.84694939851761 
Train [16/26] | Epoch [135/160] |	nca: 1.5631388686597347, flat: 0.7173486389219761, pod: 21.42892473936081, loss: 23.709412276744843 
Train [16/26] | Epoch [136/160] |	nca: 1.4461972378194332, flat: 0.6725584492087364, pod: 20.439756631851196, loss: 22.558512330055237 
Train [16/26] | Epoch [137/160] |	nca: 1.4568463414907455, flat: 0.636915635317564, pod: 19.354310512542725, loss: 21.44807255268097 
Train [16/26] | Epoch [138/160] |	nca: 1.514464233070612, flat: 0.6311412192881107, pod: 19.652032494544983, loss: 21.797637939453125 
Train [16/26] | Epoch [139/160] |	nca: 1.5269156880676746, flat: 0.6555389650166035, pod: 20.387308955192566, loss: 22.56976342201233 
Train [16/26] | Epoch [140/160] |	nca: 1.408718854188919, flat: 0.5768925230950117, pod: 19.418163418769836, loss: 21.403774797916412 
Train [16/26] | Epoch [141/160] |	nca: 1.466061718761921, flat: 0.6128382217139006, pod: 19.562434196472168, loss: 21.64133459329605 
Train [16/26] | Epoch [142/160] |	nca: 1.3327181451022625, flat: 0.5751312002539635, pod: 18.90130925178528, loss: 20.80915868282318 
Train [16/26] | Epoch [143/160] |	nca: 1.4540101327002048, flat: 0.6004893910139799, pod: 18.397899270057678, loss: 20.452398777008057 
Train [16/26] | Epoch [144/160] |	nca: 1.4703479148447514, flat: 0.632419042289257, pod: 19.553394496440887, loss: 21.65616124868393 
Train [16/26] | Epoch [145/160] |	nca: 1.5597692765295506, flat: 0.5560329798609018, pod: 18.056115329265594, loss: 20.17191755771637 
Train [16/26] | Epoch [146/160] |	nca: 1.4737950563430786, flat: 0.578774293884635, pod: 17.88564258813858, loss: 19.93821209669113 
Train [16/26] | Epoch [147/160] |	nca: 1.4881798028945923, flat: 0.5605891440063715, pod: 18.297878801822662, loss: 20.346647679805756 
Train [16/26] | Epoch [148/160] |	nca: 1.5195403285324574, flat: 0.5376065392047167, pod: 17.90879660844803, loss: 19.96594351530075 
Train [16/26] | Epoch [149/160] |	nca: 1.4289272800087929, flat: 0.5860504526644945, pod: 18.32500046491623, loss: 20.339978098869324 
Train [16/26] | Epoch [150/160] |	nca: 1.4425490088760853, flat: 0.5507407784461975, pod: 17.455323219299316, loss: 19.448613047599792 
Train [16/26] | Epoch [151/160] |	nca: 1.536121640354395, flat: 0.5512243416160345, pod: 17.937466144561768, loss: 20.0248122215271 
Train [16/26] | Epoch [152/160] |	nca: 1.3983881957828999, flat: 0.5672248881310225, pod: 17.98971402645111, loss: 19.955327033996582 
Train [16/26] | Epoch [153/160] |	nca: 1.4304222352802753, flat: 0.5432363487780094, pod: 17.570615708827972, loss: 19.54427421092987 
Train [16/26] | Epoch [154/160] |	nca: 1.4071026481688023, flat: 0.5232323687523603, pod: 17.309449553489685, loss: 19.23978465795517 
Train [16/26] | Epoch [155/160] |	nca: 1.367894984781742, flat: 0.5493337456136942, pod: 16.890568137168884, loss: 18.80779665708542 
Train [16/26] | Epoch [156/160] |	nca: 1.399895865470171, flat: 0.502692611888051, pod: 17.197395026683807, loss: 19.099983394145966 
Train [16/26] | Epoch [157/160] |	nca: 1.448146391659975, flat: 0.5073544159531593, pod: 16.977015256881714, loss: 18.93251597881317 
Train [16/26] | Epoch [158/160] |	nca: 1.4365929625928402, flat: 0.5380147770047188, pod: 16.96785455942154, loss: 18.942462384700775 
Train [16/26] | Epoch [159/160] |	nca: 1.4404468834400177, flat: 0.5476472191512585, pod: 17.75390714406967, loss: 19.742001175880432 
Train [16/26] | Epoch [160/160] |	nca: 1.4190720692276955, flat: 0.49915220215916634, pod: 16.642733097076416, loss: 18.560957491397858 
Fine-tuning
Building & updating memory.
Train [16/26] | Epoch [161/180] |	nca: 0.9179139919579029, flat: 0.6644537895917892, pod: 15.598698616027832, loss: 17.181066393852234 
Train [16/26] | Epoch [162/180] |	nca: 0.6294160559773445, flat: 0.6588253676891327, pod: 15.869301199913025, loss: 17.1575425863266 
Train [16/26] | Epoch [163/180] |	nca: 0.6210130602121353, flat: 0.6989747099578381, pod: 16.12743365764618, loss: 17.447421550750732 
Train [16/26] | Epoch [164/180] |	nca: 0.5858123563230038, flat: 0.654500076547265, pod: 15.635839819908142, loss: 16.87615257501602 
Train [16/26] | Epoch [165/180] |	nca: 0.5345356166362762, flat: 0.6687897741794586, pod: 15.561361491680145, loss: 16.764687061309814 
Train [16/26] | Epoch [166/180] |	nca: 0.5334765408188105, flat: 0.6775347590446472, pod: 16.020670533180237, loss: 17.23168182373047 
Train [16/26] | Epoch [167/180] |	nca: 0.540692362934351, flat: 0.6830081567168236, pod: 16.05351608991623, loss: 17.27721655368805 
Train [16/26] | Epoch [168/180] |	nca: 0.49683420546352863, flat: 0.6841958090662956, pod: 16.24435806274414, loss: 17.425387978553772 
Train [16/26] | Epoch [169/180] |	nca: 0.5454678237438202, flat: 0.6540740914642811, pod: 15.611251950263977, loss: 16.81079375743866 
Train [16/26] | Epoch [170/180] |	nca: 0.506609970703721, flat: 0.6726214215159416, pod: 15.356686174869537, loss: 16.53591752052307 
Train [16/26] | Epoch [171/180] |	nca: 0.48598718643188477, flat: 0.6294288784265518, pod: 15.194464802742004, loss: 16.30988085269928 
Train [16/26] | Epoch [172/180] |	nca: 0.45235431380569935, flat: 0.677406657487154, pod: 15.900409579277039, loss: 17.030170440673828 
Train [16/26] | Epoch [173/180] |	nca: 0.457876767963171, flat: 0.7196086123585701, pod: 16.28268039226532, loss: 17.460165977478027 
Train [16/26] | Epoch [174/180] |	nca: 0.4487891364842653, flat: 0.6372999548912048, pod: 15.279394447803497, loss: 16.365483283996582 
Train [16/26] | Epoch [175/180] |	nca: 0.42055227793753147, flat: 0.6938631795346737, pod: 16.311046481132507, loss: 17.425461888313293 
Train [16/26] | Epoch [176/180] |	nca: 0.4883806388825178, flat: 0.6697266064584255, pod: 15.864471316337585, loss: 17.022578477859497 
Train [16/26] | Epoch [177/180] |	nca: 0.4594178572297096, flat: 0.6987699009478092, pod: 15.88643616437912, loss: 17.044623732566833 
Train [16/26] | Epoch [178/180] |	nca: 0.44673640839755535, flat: 0.6753472499549389, pod: 15.69008481502533, loss: 16.81216859817505 
Train [16/26] | Epoch [179/180] |	nca: 0.432695584371686, flat: 0.6345407664775848, pod: 15.34772539138794, loss: 16.41496193408966 
Train [16/26] | Epoch [180/180] |	nca: 0.47358304262161255, flat: 0.6970160566270351, pod: 15.961098968982697, loss: 17.13169801235199 
after task
Building & updating memory.
after task
Eval on 0->80.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6450625.
Current acc: {'total': 0.573, '00-09': 0.617, '10-19': 0.563, '20-29': 0.508, '30-39': 0.538, '40-49': 0.589, '50-59': 0.553, '60-69': 0.495, '70-79': 0.721}.
Avg inc acc top5: 0.8820624999999997.
Current acc top5: {'total': 0.838}.
Forgetting: 0.19277777777777783.
Cord metric: 0.65.
Old accuracy: 0.57, mean: 0.63.
New accuracy: 0.77, mean: 0.79.
================Task 16 Start!================
Testing on False unseen tasks (max class = 82).
Set memory of size: 1600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 16 Training!================
The training samples number: 2600
Train on 80->82.
train task
nb 2600.
Train [17/26] | Epoch [1/160] |	nca: 9.852011159062386, flat: 4.7473152950406075, pod: 56.5818692445755, loss: 71.18119597434998 
Train [17/26] | Epoch [2/160] |	nca: 7.634981453418732, flat: 5.890090048313141, pod: 66.82265210151672, loss: 80.34772396087646 
Train [17/26] | Epoch [3/160] |	nca: 5.7502956092357635, flat: 5.468728482723236, pod: 64.80618238449097, loss: 76.02520608901978 
Train [17/26] | Epoch [4/160] |	nca: 5.054361671209335, flat: 4.6445132791996, pod: 60.108423471450806, loss: 69.80729818344116 
Train [17/26] | Epoch [5/160] |	nca: 4.076007634401321, flat: 4.090191259980202, pod: 56.78290367126465, loss: 64.94910264015198 
Train [17/26] | Epoch [6/160] |	nca: 3.4497574493288994, flat: 3.6366770416498184, pod: 54.36630344390869, loss: 61.45273733139038 
Train [17/26] | Epoch [7/160] |	nca: 3.1275750920176506, flat: 3.2422285825014114, pod: 51.536815881729126, loss: 57.906620025634766 
Train [17/26] | Epoch [8/160] |	nca: 3.1582141369581223, flat: 3.3936666697263718, pod: 53.88664221763611, loss: 60.438523054122925 
Train [17/26] | Epoch [9/160] |	nca: 2.953816443681717, flat: 2.8959929049015045, pod: 48.4250431060791, loss: 54.27485179901123 
Train [17/26] | Epoch [10/160] |	nca: 2.527502253651619, flat: 2.7544291242957115, pod: 46.91883444786072, loss: 52.20076608657837 
Train [17/26] | Epoch [11/160] |	nca: 2.6908665001392365, flat: 2.6174521520733833, pod: 46.74161767959595, loss: 52.04993653297424 
Train [17/26] | Epoch [12/160] |	nca: 3.3100931122899055, flat: 2.967572957277298, pod: 48.61073279380798, loss: 54.88839840888977 
Train [17/26] | Epoch [13/160] |	nca: 3.4472248032689095, flat: 3.4296278059482574, pod: 54.23337483406067, loss: 61.11022734642029 
Train [17/26] | Epoch [14/160] |	nca: 3.086393564939499, flat: 3.40526857227087, pod: 54.12466788291931, loss: 60.61633014678955 
Train [17/26] | Epoch [15/160] |	nca: 2.741754859685898, flat: 2.923898361623287, pod: 49.17715525627136, loss: 54.842809200286865 
Train [17/26] | Epoch [16/160] |	nca: 2.750702291727066, flat: 2.6604373902082443, pod: 47.401442527770996, loss: 52.81258225440979 
Train [17/26] | Epoch [17/160] |	nca: 2.311078190803528, flat: 2.679022140800953, pod: 47.27986943721771, loss: 52.269970417022705 
Train [17/26] | Epoch [18/160] |	nca: 2.549803987145424, flat: 2.4138676151633263, pod: 45.47517704963684, loss: 50.43884873390198 
Train [17/26] | Epoch [19/160] |	nca: 2.72996274381876, flat: 2.636198103427887, pod: 44.77528619766235, loss: 50.14144730567932 
Train [17/26] | Epoch [20/160] |	nca: 2.683558627963066, flat: 2.704348437488079, pod: 47.51333212852478, loss: 52.90123891830444 
Train [17/26] | Epoch [21/160] |	nca: 2.3402894847095013, flat: 2.6014392748475075, pod: 47.17534518241882, loss: 52.11707425117493 
Train [17/26] | Epoch [22/160] |	nca: 2.2864300906658173, flat: 2.6023039743304253, pod: 48.08002209663391, loss: 52.96875596046448 
Train [17/26] | Epoch [23/160] |	nca: 2.3968561813235283, flat: 2.528770923614502, pod: 45.92646825313568, loss: 50.85209512710571 
Train [17/26] | Epoch [24/160] |	nca: 2.418312907218933, flat: 2.5942872390151024, pod: 46.93790519237518, loss: 51.95050501823425 
Train [17/26] | Epoch [25/160] |	nca: 2.232464425265789, flat: 2.2843136191368103, pod: 43.97850215435028, loss: 48.495280265808105 
Train [17/26] | Epoch [26/160] |	nca: 2.2912421077489853, flat: 2.569444917142391, pod: 48.08134353160858, loss: 52.942030906677246 
Train [17/26] | Epoch [27/160] |	nca: 2.50310967117548, flat: 2.531296983361244, pod: 46.47608923912048, loss: 51.51049590110779 
Train [17/26] | Epoch [28/160] |	nca: 2.3392408937215805, flat: 2.494435727596283, pod: 45.8564692735672, loss: 50.69014549255371 
Train [17/26] | Epoch [29/160] |	nca: 2.228327065706253, flat: 2.418366976082325, pod: 44.918094992637634, loss: 49.56478834152222 
Train [17/26] | Epoch [30/160] |	nca: 2.6491063609719276, flat: 2.3792032077908516, pod: 44.94164764881134, loss: 49.96995711326599 
Train [17/26] | Epoch [31/160] |	nca: 2.3826276659965515, flat: 2.404718264937401, pod: 46.22123169898987, loss: 51.00857734680176 
Train [17/26] | Epoch [32/160] |	nca: 2.500540755689144, flat: 2.719622418284416, pod: 48.046321392059326, loss: 53.26648473739624 
Train [17/26] | Epoch [33/160] |	nca: 2.2421659976243973, flat: 2.636469252407551, pod: 48.5263135433197, loss: 53.404949426651 
Train [17/26] | Epoch [34/160] |	nca: 2.234045073390007, flat: 2.4391931667923927, pod: 44.875707387924194, loss: 49.54894495010376 
Train [17/26] | Epoch [35/160] |	nca: 2.2927421033382416, flat: 2.364512450993061, pod: 44.4038245677948, loss: 49.061078786849976 
Train [17/26] | Epoch [36/160] |	nca: 2.109800323843956, flat: 2.385819800198078, pod: 44.80402338504791, loss: 49.299643754959106 
Train [17/26] | Epoch [37/160] |	nca: 2.310804232954979, flat: 2.4195748195052147, pod: 45.343026518821716, loss: 50.073405265808105 
Train [17/26] | Epoch [38/160] |	nca: 2.6795153953135014, flat: 2.645914353430271, pod: 49.58276081085205, loss: 54.90819048881531 
Train [17/26] | Epoch [39/160] |	nca: 2.4334161654114723, flat: 2.477961763739586, pod: 44.504056215286255, loss: 49.41543388366699 
Train [17/26] | Epoch [40/160] |	nca: 2.2565914690494537, flat: 2.308552399277687, pod: 43.72524166107178, loss: 48.290385723114014 
Train [17/26] | Epoch [41/160] |	nca: 1.9645545929670334, flat: 2.3604489490389824, pod: 45.30126929283142, loss: 49.626272678375244 
Train [17/26] | Epoch [42/160] |	nca: 2.028991177678108, flat: 2.3127306774258614, pod: 44.96058201789856, loss: 49.30230402946472 
Train [17/26] | Epoch [43/160] |	nca: 2.3861167803406715, flat: 2.382425382733345, pod: 45.99534809589386, loss: 50.763890504837036 
Train [17/26] | Epoch [44/160] |	nca: 2.2340211421251297, flat: 2.4264217168092728, pod: 45.63356804847717, loss: 50.29401135444641 
Train [17/26] | Epoch [45/160] |	nca: 2.1122028529644012, flat: 2.373710945248604, pod: 44.894299030303955, loss: 49.38021278381348 
Train [17/26] | Epoch [46/160] |	nca: 2.306819621473551, flat: 2.3624948486685753, pod: 44.858686447143555, loss: 49.52800107002258 
Train [17/26] | Epoch [47/160] |	nca: 2.3429204374551773, flat: 2.4059891551733017, pod: 44.616331338882446, loss: 49.365241050720215 
Train [17/26] | Epoch [48/160] |	nca: 2.1489942893385887, flat: 2.5431660562753677, pod: 47.91236627101898, loss: 52.60452651977539 
Train [17/26] | Epoch [49/160] |	nca: 1.9963804371654987, flat: 2.0283917486667633, pod: 41.121395230293274, loss: 45.146167159080505 
Train [17/26] | Epoch [50/160] |	nca: 2.1019116900861263, flat: 2.039450690150261, pod: 41.027461886405945, loss: 45.16882407665253 
Train [17/26] | Epoch [51/160] |	nca: 2.1421073526144028, flat: 1.9856285527348518, pod: 40.624791741371155, loss: 44.752527832984924 
Train [17/26] | Epoch [52/160] |	nca: 1.8815382830798626, flat: 2.050100177526474, pod: 42.37905943393707, loss: 46.31069755554199 
Train [17/26] | Epoch [53/160] |	nca: 2.0708200931549072, flat: 2.0086623951792717, pod: 40.82353723049164, loss: 44.90301990509033 
Train [17/26] | Epoch [54/160] |	nca: 2.4245937392115593, flat: 2.4739474207162857, pod: 44.269418716430664, loss: 49.16796016693115 
Train [17/26] | Epoch [55/160] |	nca: 2.009491343051195, flat: 2.104398660361767, pod: 42.10982894897461, loss: 46.223718881607056 
Train [17/26] | Epoch [56/160] |	nca: 1.9801155626773834, flat: 2.056298680603504, pod: 40.38429522514343, loss: 44.42070972919464 
Train [17/26] | Epoch [57/160] |	nca: 2.287584386765957, flat: 2.1408790051937103, pod: 43.02686047554016, loss: 47.455323576927185 
Train [17/26] | Epoch [58/160] |	nca: 2.1482030153274536, flat: 2.111741453409195, pod: 41.483303904533386, loss: 45.74324810504913 
Train [17/26] | Epoch [59/160] |	nca: 2.0606847181916237, flat: 2.055546849966049, pod: 39.8704092502594, loss: 43.98664116859436 
Train [17/26] | Epoch [60/160] |	nca: 1.834625743329525, flat: 1.839624434709549, pod: 39.14599347114563, loss: 42.82024419307709 
Train [17/26] | Epoch [61/160] |	nca: 2.1511340290308, flat: 1.9695544689893723, pod: 41.00449848175049, loss: 45.125186920166016 
Train [17/26] | Epoch [62/160] |	nca: 1.9320137351751328, flat: 1.8917036578059196, pod: 39.30740761756897, loss: 43.13112461566925 
Train [17/26] | Epoch [63/160] |	nca: 1.872234158217907, flat: 1.7360484451055527, pod: 38.37871539592743, loss: 41.986998081207275 
Train [17/26] | Epoch [64/160] |	nca: 1.8205227889120579, flat: 1.7807442471385002, pod: 37.271323442459106, loss: 40.87259006500244 
Train [17/26] | Epoch [65/160] |	nca: 1.9486255757510662, flat: 1.9257532432675362, pod: 40.676982402801514, loss: 44.551361441612244 
Train [17/26] | Epoch [66/160] |	nca: 1.8997461386024952, flat: 1.8618997856974602, pod: 39.63207924365997, loss: 43.39372479915619 
Train [17/26] | Epoch [67/160] |	nca: 1.9633639864623547, flat: 1.7963015362620354, pod: 38.78428053855896, loss: 42.54394555091858 
Train [17/26] | Epoch [68/160] |	nca: 1.9930201582610607, flat: 1.9124979600310326, pod: 39.023720145225525, loss: 42.92923831939697 
Train [17/26] | Epoch [69/160] |	nca: 2.1531811133027077, flat: 1.78047364205122, pod: 37.94775366783142, loss: 41.88140845298767 
Train [17/26] | Epoch [70/160] |	nca: 1.732769463211298, flat: 1.6985875889658928, pod: 36.45284104347229, loss: 39.88419830799103 
Train [17/26] | Epoch [71/160] |	nca: 1.7424395345151424, flat: 1.5892600417137146, pod: 36.78100287914276, loss: 40.11270236968994 
Train [17/26] | Epoch [72/160] |	nca: 1.7819813080132008, flat: 1.5185121931135654, pod: 34.73731184005737, loss: 38.03780543804169 
Train [17/26] | Epoch [73/160] |	nca: 1.8489342778921127, flat: 1.6523654274642467, pod: 38.231433153152466, loss: 41.73273277282715 
Train [17/26] | Epoch [74/160] |	nca: 1.9031489342451096, flat: 1.7625988349318504, pod: 37.84732699394226, loss: 41.51307475566864 
Train [17/26] | Epoch [75/160] |	nca: 1.966218613088131, flat: 1.718438409268856, pod: 37.34225308895111, loss: 41.026910185813904 
Train [17/26] | Epoch [76/160] |	nca: 1.8813855350017548, flat: 1.651025265455246, pod: 37.031317591667175, loss: 40.56372833251953 
Train [17/26] | Epoch [77/160] |	nca: 2.016146555542946, flat: 1.7366972342133522, pod: 37.70931613445282, loss: 41.46216011047363 
Train [17/26] | Epoch [78/160] |	nca: 2.1256401389837265, flat: 1.9317437931895256, pod: 39.37322747707367, loss: 43.43061125278473 
Train [17/26] | Epoch [79/160] |	nca: 1.8688627406954765, flat: 1.633994147181511, pod: 36.31275534629822, loss: 39.81561231613159 
Train [17/26] | Epoch [80/160] |	nca: 1.8713207691907883, flat: 1.6036907769739628, pod: 36.55761253833771, loss: 40.03262424468994 
Train [17/26] | Epoch [81/160] |	nca: 1.7161547057330608, flat: 1.5558286234736443, pod: 35.021127104759216, loss: 38.29311013221741 
Train [17/26] | Epoch [82/160] |	nca: 1.929150216281414, flat: 1.5030183270573616, pod: 34.27875852584839, loss: 37.71092677116394 
Train [17/26] | Epoch [83/160] |	nca: 1.8789961226284504, flat: 1.6410246640443802, pod: 36.37186110019684, loss: 39.89188194274902 
Train [17/26] | Epoch [84/160] |	nca: 1.7618914507329464, flat: 1.5076116286218166, pod: 35.111045122146606, loss: 38.380547881126404 
Train [17/26] | Epoch [85/160] |	nca: 1.873928040266037, flat: 1.6558362059295177, pod: 36.936503171920776, loss: 40.466267824172974 
Train [17/26] | Epoch [86/160] |	nca: 1.805121410638094, flat: 1.413316510617733, pod: 33.56203079223633, loss: 36.780468702316284 
Train [17/26] | Epoch [87/160] |	nca: 1.9656212106347084, flat: 1.5286297462880611, pod: 34.35725939273834, loss: 37.85151028633118 
Train [17/26] | Epoch [88/160] |	nca: 1.7866192609071732, flat: 1.5207029059529305, pod: 33.92950475215912, loss: 37.23682689666748 
Train [17/26] | Epoch [89/160] |	nca: 1.7746172994375229, flat: 1.4614530503749847, pod: 34.326764941215515, loss: 37.56283509731293 
Train [17/26] | Epoch [90/160] |	nca: 1.6509183906018734, flat: 1.4002081416547298, pod: 32.69013428688049, loss: 35.74126076698303 
Train [17/26] | Epoch [91/160] |	nca: 1.753444042056799, flat: 1.3943754322826862, pod: 33.67269682884216, loss: 36.82051646709442 
Train [17/26] | Epoch [92/160] |	nca: 1.806193482130766, flat: 1.3532140739262104, pod: 32.483808159828186, loss: 35.64321565628052 
Train [17/26] | Epoch [93/160] |	nca: 1.7999269291758537, flat: 1.4491481855511665, pod: 34.63289988040924, loss: 37.881974935531616 
Train [17/26] | Epoch [94/160] |	nca: 1.9613754823803902, flat: 1.3673120252788067, pod: 33.31989562511444, loss: 36.64858341217041 
Train [17/26] | Epoch [95/160] |	nca: 1.7741368375718594, flat: 1.3913155533373356, pod: 33.38353359699249, loss: 36.548985958099365 
Train [17/26] | Epoch [96/160] |	nca: 1.7371089272201061, flat: 1.3427132815122604, pod: 32.85227298736572, loss: 35.93209528923035 
Train [17/26] | Epoch [97/160] |	nca: 1.729680448770523, flat: 1.3907044641673565, pod: 32.57486128807068, loss: 35.69524621963501 
Train [17/26] | Epoch [98/160] |	nca: 1.7920348085463047, flat: 1.3575587086379528, pod: 33.14466631412506, loss: 36.294260025024414 
Train [17/26] | Epoch [99/160] |	nca: 1.8164964765310287, flat: 1.3627215139567852, pod: 33.47522985935211, loss: 36.65444767475128 
Train [17/26] | Epoch [100/160] |	nca: 1.651047918945551, flat: 1.275252029299736, pod: 30.750352382659912, loss: 33.67665195465088 
Train [17/26] | Epoch [101/160] |	nca: 1.7380576133728027, flat: 1.236023437231779, pod: 31.32256805896759, loss: 34.29664945602417 
Train [17/26] | Epoch [102/160] |	nca: 1.6545735709369183, flat: 1.1803793348371983, pod: 29.644603610038757, loss: 32.47955656051636 
Train [17/26] | Epoch [103/160] |	nca: 1.7862307503819466, flat: 1.1603142730891705, pod: 30.046453952789307, loss: 32.99299931526184 
Train [17/26] | Epoch [104/160] |	nca: 1.8230551108717918, flat: 1.3517244197428226, pod: 31.643305778503418, loss: 34.81808531284332 
Train [17/26] | Epoch [105/160] |	nca: 1.8699503280222416, flat: 1.3490358144044876, pod: 32.08419978618622, loss: 35.30318582057953 
Train [17/26] | Epoch [106/160] |	nca: 1.58087857067585, flat: 1.1677795350551605, pod: 29.927324652671814, loss: 32.67598259449005 
Train [17/26] | Epoch [107/160] |	nca: 1.9008126221597195, flat: 1.232096366584301, pod: 31.430471062660217, loss: 34.56338012218475 
Train [17/26] | Epoch [108/160] |	nca: 1.6085945814847946, flat: 1.2091381959617138, pod: 31.25744640827179, loss: 34.0751793384552 
Train [17/26] | Epoch [109/160] |	nca: 1.7813298851251602, flat: 1.1023852191865444, pod: 28.31054699420929, loss: 31.194262266159058 
Train [17/26] | Epoch [110/160] |	nca: 1.7050892002880573, flat: 1.0586565174162388, pod: 28.251254439353943, loss: 31.015000104904175 
Train [17/26] | Epoch [111/160] |	nca: 1.489930909126997, flat: 1.033385954797268, pod: 28.507497310638428, loss: 31.030814051628113 
Train [17/26] | Epoch [112/160] |	nca: 1.712684191763401, flat: 1.0933362543582916, pod: 28.71976399421692, loss: 31.525784254074097 
Train [17/26] | Epoch [113/160] |	nca: 1.6253114938735962, flat: 1.0622261129319668, pod: 28.86015546321869, loss: 31.547693252563477 
Train [17/26] | Epoch [114/160] |	nca: 1.6376522965729237, flat: 1.045411590486765, pod: 28.557266235351562, loss: 31.2403302192688 
Train [17/26] | Epoch [115/160] |	nca: 1.5547035373747349, flat: 1.0387143269181252, pod: 28.068960905075073, loss: 30.662378907203674 
Train [17/26] | Epoch [116/160] |	nca: 1.7030348852276802, flat: 0.942893385887146, pod: 26.244664430618286, loss: 28.89059269428253 
Train [17/26] | Epoch [117/160] |	nca: 1.6938243880867958, flat: 1.0031160488724709, pod: 27.00144398212433, loss: 29.698384642601013 
Train [17/26] | Epoch [118/160] |	nca: 1.5736293345689774, flat: 0.9741666316986084, pod: 26.543388962745667, loss: 29.091185212135315 
Train [17/26] | Epoch [119/160] |	nca: 1.4623219780623913, flat: 0.920173317193985, pod: 25.771697640419006, loss: 28.15419292449951 
Train [17/26] | Epoch [120/160] |	nca: 1.7583557292819023, flat: 0.9201115593314171, pod: 25.940308570861816, loss: 28.618776202201843 
Train [17/26] | Epoch [121/160] |	nca: 1.6388459876179695, flat: 0.9889813102781773, pod: 26.54698133468628, loss: 29.174808621406555 
Train [17/26] | Epoch [122/160] |	nca: 1.4954079687595367, flat: 0.9169846810400486, pod: 25.398898899555206, loss: 27.811291456222534 
Train [17/26] | Epoch [123/160] |	nca: 1.7019550241529942, flat: 0.8560981433838606, pod: 24.717581033706665, loss: 27.275633931159973 
Train [17/26] | Epoch [124/160] |	nca: 1.6690287552773952, flat: 0.8301073908805847, pod: 24.58021855354309, loss: 27.079354405403137 
Train [17/26] | Epoch [125/160] |	nca: 1.673165239393711, flat: 0.8658114913851023, pod: 23.605460941791534, loss: 26.144437432289124 
Train [17/26] | Epoch [126/160] |	nca: 1.588924091309309, flat: 0.8285419270396233, pod: 24.720661222934723, loss: 27.138127088546753 
Train [17/26] | Epoch [127/160] |	nca: 1.7015013881027699, flat: 0.8234841506928205, pod: 24.487651348114014, loss: 27.01263689994812 
Train [17/26] | Epoch [128/160] |	nca: 1.5950346067547798, flat: 0.8724929410964251, pod: 23.88331240415573, loss: 26.350839972496033 
Train [17/26] | Epoch [129/160] |	nca: 1.7739218957722187, flat: 0.8429239001125097, pod: 23.469038605690002, loss: 26.08588433265686 
Train [17/26] | Epoch [130/160] |	nca: 1.5575427301228046, flat: 0.7445170730352402, pod: 22.207663357257843, loss: 24.50972306728363 
Train [17/26] | Epoch [131/160] |	nca: 1.573053628206253, flat: 0.7711605578660965, pod: 23.1633278131485, loss: 25.50754225254059 
Train [17/26] | Epoch [132/160] |	nca: 1.6119736284017563, flat: 0.74589460529387, pod: 22.52762907743454, loss: 24.885497391223907 
Train [17/26] | Epoch [133/160] |	nca: 1.508869208395481, flat: 0.7525767050683498, pod: 22.715018332004547, loss: 24.976464211940765 
Train [17/26] | Epoch [134/160] |	nca: 1.6912205256521702, flat: 0.716019544750452, pod: 21.995724856853485, loss: 24.40296506881714 
Train [17/26] | Epoch [135/160] |	nca: 1.6155012473464012, flat: 0.7088899910449982, pod: 21.932418167591095, loss: 24.25680947303772 
Train [17/26] | Epoch [136/160] |	nca: 1.718328282237053, flat: 0.712814848870039, pod: 21.714823007583618, loss: 24.145966053009033 
Train [17/26] | Epoch [137/160] |	nca: 1.5853515639901161, flat: 0.7388150822371244, pod: 22.361270546913147, loss: 24.685437202453613 
Train [17/26] | Epoch [138/160] |	nca: 1.6423272304236889, flat: 0.7758670784533024, pod: 22.51928424835205, loss: 24.93747866153717 
Train [17/26] | Epoch [139/160] |	nca: 1.6278824284672737, flat: 0.7923609111458063, pod: 22.930647790431976, loss: 25.35089111328125 
Train [17/26] | Epoch [140/160] |	nca: 1.6441891305148602, flat: 0.8007322158664465, pod: 22.835084855556488, loss: 25.280006051063538 
Train [17/26] | Epoch [141/160] |	nca: 1.6206256709992886, flat: 0.7729838192462921, pod: 22.199001252651215, loss: 24.59261053800583 
Train [17/26] | Epoch [142/160] |	nca: 1.6664130799472332, flat: 0.6927166674286127, pod: 21.091908276081085, loss: 23.45103818178177 
Train [17/26] | Epoch [143/160] |	nca: 1.4999771006405354, flat: 0.7171517442911863, pod: 21.289229214191437, loss: 23.506357848644257 
Train [17/26] | Epoch [144/160] |	nca: 1.564618680626154, flat: 0.7143309023231268, pod: 20.92674833536148, loss: 23.20569795370102 
Train [17/26] | Epoch [145/160] |	nca: 1.6665618419647217, flat: 0.6973120961338282, pod: 20.928852379322052, loss: 23.292726278305054 
Train [17/26] | Epoch [146/160] |	nca: 1.6456563211977482, flat: 0.6741582937538624, pod: 20.063682734966278, loss: 22.38349735736847 
Train [17/26] | Epoch [147/160] |	nca: 1.6609530076384544, flat: 0.6291311923414469, pod: 19.15485906600952, loss: 21.444943487644196 
Train [17/26] | Epoch [148/160] |	nca: 1.542408149689436, flat: 0.6190989669412374, pod: 19.63761067390442, loss: 21.79911768436432 
Train [17/26] | Epoch [149/160] |	nca: 1.5250121355056763, flat: 0.6328119561076164, pod: 19.804720520973206, loss: 21.962544918060303 
Train [17/26] | Epoch [150/160] |	nca: 1.5607110857963562, flat: 0.6531563717871904, pod: 20.04175901412964, loss: 22.255626440048218 
Train [17/26] | Epoch [151/160] |	nca: 1.6578878350555897, flat: 0.6374856494367123, pod: 19.157877206802368, loss: 21.453250646591187 
Train [17/26] | Epoch [152/160] |	nca: 1.5959111899137497, flat: 0.6333508621901274, pod: 19.416117548942566, loss: 21.64537936449051 
Train [17/26] | Epoch [153/160] |	nca: 1.5528899803757668, flat: 0.6619414500892162, pod: 20.839530050754547, loss: 23.05436146259308 
Train [17/26] | Epoch [154/160] |	nca: 1.5317945592105389, flat: 0.6799790114164352, pod: 19.184107542037964, loss: 21.39588099718094 
Train [17/26] | Epoch [155/160] |	nca: 1.604593101888895, flat: 0.6246072761714458, pod: 19.392530500888824, loss: 21.62173104286194 
Train [17/26] | Epoch [156/160] |	nca: 1.5952905528247356, flat: 0.5809483658522367, pod: 18.519948542118073, loss: 20.696187436580658 
Train [17/26] | Epoch [157/160] |	nca: 1.4442447647452354, flat: 0.6105024144053459, pod: 18.677053093910217, loss: 20.731800436973572 
Train [17/26] | Epoch [158/160] |	nca: 1.5724692568182945, flat: 0.5987994577735662, pod: 18.2031489610672, loss: 20.374417662620544 
Train [17/26] | Epoch [159/160] |	nca: 1.5402124114334583, flat: 0.6592188142240047, pod: 20.22088724374771, loss: 22.420318603515625 
Train [17/26] | Epoch [160/160] |	nca: 1.581394501030445, flat: 0.6588822267949581, pod: 19.742604911327362, loss: 21.982881724834442 
Fine-tuning
Building & updating memory.
Train [17/26] | Epoch [161/180] |	nca: 1.0352484993636608, flat: 0.8080317378044128, pod: 18.43230450153351, loss: 20.27558469772339 
Train [17/26] | Epoch [162/180] |	nca: 0.674717802554369, flat: 0.8287635669112206, pod: 18.343247056007385, loss: 19.846728444099426 
Train [17/26] | Epoch [163/180] |	nca: 0.5736956112086773, flat: 0.8453716821968555, pod: 18.65922701358795, loss: 20.078294157981873 
Train [17/26] | Epoch [164/180] |	nca: 0.5355209466069937, flat: 0.8478678800165653, pod: 18.679675936698914, loss: 20.063064694404602 
Train [17/26] | Epoch [165/180] |	nca: 0.5094263069331646, flat: 0.8185394331812859, pod: 18.65407633781433, loss: 19.98204207420349 
Train [17/26] | Epoch [166/180] |	nca: 0.5323966071009636, flat: 0.7954009398818016, pod: 18.264278531074524, loss: 19.592076063156128 
Train [17/26] | Epoch [167/180] |	nca: 0.5137879271060228, flat: 0.7904138974845409, pod: 18.398874878883362, loss: 19.703076601028442 
Train [17/26] | Epoch [168/180] |	nca: 0.46272058226168156, flat: 0.8098965398967266, pod: 18.282799005508423, loss: 19.555416107177734 
Train [17/26] | Epoch [169/180] |	nca: 0.4468260835856199, flat: 0.8238811306655407, pod: 18.54209268093109, loss: 19.81279993057251 
Train [17/26] | Epoch [170/180] |	nca: 0.4653882868587971, flat: 0.7994309812784195, pod: 18.307909607887268, loss: 19.572728872299194 
Train [17/26] | Epoch [171/180] |	nca: 0.4365926440805197, flat: 0.78757419064641, pod: 18.286327600479126, loss: 19.510494232177734 
Train [17/26] | Epoch [172/180] |	nca: 0.4166821092367172, flat: 0.7841277346014977, pod: 18.189221024513245, loss: 19.39003074169159 
Train [17/26] | Epoch [173/180] |	nca: 0.42111557722091675, flat: 0.7870065346360207, pod: 18.068938374519348, loss: 19.277060508728027 
Train [17/26] | Epoch [174/180] |	nca: 0.43134816735982895, flat: 0.7729045934975147, pod: 17.853416919708252, loss: 19.057669520378113 
Train [17/26] | Epoch [175/180] |	nca: 0.41686083003878593, flat: 0.7900079116225243, pod: 18.270861625671387, loss: 19.47773051261902 
Train [17/26] | Epoch [176/180] |	nca: 0.41475233994424343, flat: 0.8320735767483711, pod: 18.623530626296997, loss: 19.870356678962708 
Train [17/26] | Epoch [177/180] |	nca: 0.4295170921832323, flat: 0.8240902312099934, pod: 19.117287755012512, loss: 20.37089514732361 
Train [17/26] | Epoch [178/180] |	nca: 0.39765286818146706, flat: 0.8174145929515362, pod: 18.59758687019348, loss: 19.81265437602997 
Train [17/26] | Epoch [179/180] |	nca: 0.39120478741824627, flat: 0.7785973958671093, pod: 18.03698706626892, loss: 19.206789255142212 
Train [17/26] | Epoch [180/180] |	nca: 0.39807545207440853, flat: 0.7756008505821228, pod: 17.954318642616272, loss: 19.127995014190674 
after task
Building & updating memory.
after task
Eval on 0->82.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6405294117647058.
Current acc: {'total': 0.568, '00-09': 0.622, '10-19': 0.553, '20-29': 0.494, '30-39': 0.527, '40-49': 0.572, '50-59': 0.542, '60-69': 0.484, '70-79': 0.706, '80-89': 0.795}.
Avg inc acc top5: 0.8794117647058821.
Current acc top5: {'total': 0.837}.
Forgetting: 0.1024.
Cord metric: 0.64.
Old accuracy: 0.56, mean: 0.63.
New accuracy: 0.80, mean: 0.79.
================Task 17 Start!================
Testing on False unseen tasks (max class = 84).
Set memory of size: 1640.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 17 Training!================
The training samples number: 2640
Train on 82->84.
train task
nb 2640.
Train [18/26] | Epoch [1/160] |	nca: 7.297632589936256, flat: 3.8670674189925194, pod: 51.65065109729767, loss: 62.815351247787476 
Train [18/26] | Epoch [2/160] |	nca: 3.8167619556188583, flat: 3.9546575248241425, pod: 56.24529314041138, loss: 64.01671266555786 
Train [18/26] | Epoch [3/160] |	nca: 2.9514831230044365, flat: 3.4415953308343887, pod: 52.55427575111389, loss: 58.94735360145569 
Train [18/26] | Epoch [4/160] |	nca: 2.3954891860485077, flat: 2.804580844938755, pod: 49.2593297958374, loss: 54.459399461746216 
Train [18/26] | Epoch [5/160] |	nca: 2.4362339302897453, flat: 2.7969133108854294, pod: 49.407575607299805, loss: 54.64072275161743 
Train [18/26] | Epoch [6/160] |	nca: 2.2592966966331005, flat: 2.6978313997387886, pod: 49.98469567298889, loss: 54.941823959350586 
Train [18/26] | Epoch [7/160] |	nca: 2.1308721601963043, flat: 2.5062948018312454, pod: 47.004334807395935, loss: 51.641501903533936 
Train [18/26] | Epoch [8/160] |	nca: 2.131754569709301, flat: 2.484814003109932, pod: 46.57524585723877, loss: 51.19181418418884 
Train [18/26] | Epoch [9/160] |	nca: 2.3455473855137825, flat: 2.485955186188221, pod: 46.01628351211548, loss: 50.84778618812561 
Train [18/26] | Epoch [10/160] |	nca: 2.1469167321920395, flat: 2.5734739303588867, pod: 48.17301106452942, loss: 52.89340138435364 
Train [18/26] | Epoch [11/160] |	nca: 1.9169106483459473, flat: 2.487048014998436, pod: 46.29509258270264, loss: 50.69905138015747 
Train [18/26] | Epoch [12/160] |	nca: 1.9284076243638992, flat: 2.5312397330999374, pod: 47.81951975822449, loss: 52.27916717529297 
Train [18/26] | Epoch [13/160] |	nca: 2.077798444777727, flat: 2.4818226620554924, pod: 47.916863441467285, loss: 52.476484298706055 
Train [18/26] | Epoch [14/160] |	nca: 2.2139191552996635, flat: 2.447783388197422, pod: 46.660447120666504, loss: 51.32214975357056 
Train [18/26] | Epoch [15/160] |	nca: 1.9820599965751171, flat: 2.4702110663056374, pod: 46.44488763809204, loss: 50.89715886116028 
Train [18/26] | Epoch [16/160] |	nca: 1.9953938536345959, flat: 2.4143197908997536, pod: 46.541860818862915, loss: 50.9515745639801 
Train [18/26] | Epoch [17/160] |	nca: 2.3069797940552235, flat: 2.586742676794529, pod: 47.648706912994385, loss: 52.54242968559265 
Train [18/26] | Epoch [18/160] |	nca: 1.844451617449522, flat: 2.448553539812565, pod: 47.01991868019104, loss: 51.31292366981506 
Train [18/26] | Epoch [19/160] |	nca: 1.6509843915700912, flat: 2.154844470322132, pod: 43.57721543312073, loss: 47.38304400444031 
Train [18/26] | Epoch [20/160] |	nca: 1.7038739547133446, flat: 2.1691441759467125, pod: 42.7968168258667, loss: 46.66983509063721 
Train [18/26] | Epoch [21/160] |	nca: 1.818583320826292, flat: 2.38363116979599, pod: 47.75770711898804, loss: 51.95992159843445 
Train [18/26] | Epoch [22/160] |	nca: 1.9268444515764713, flat: 2.5416665598750114, pod: 47.42954134941101, loss: 51.89805245399475 
Train [18/26] | Epoch [23/160] |	nca: 1.9141052663326263, flat: 2.546309858560562, pod: 47.59575164318085, loss: 52.05616641044617 
Train [18/26] | Epoch [24/160] |	nca: 1.7838661707937717, flat: 2.1560274735093117, pod: 44.2644305229187, loss: 48.20432424545288 
Train [18/26] | Epoch [25/160] |	nca: 1.9273928068578243, flat: 2.3640126660466194, pod: 44.4296737909317, loss: 48.721078872680664 
Train [18/26] | Epoch [26/160] |	nca: 1.7686935849487782, flat: 2.388494297862053, pod: 45.49469995498657, loss: 49.6518874168396 
Train [18/26] | Epoch [27/160] |	nca: 1.7071479558944702, flat: 2.18216223269701, pod: 43.84058487415314, loss: 47.7298948764801 
Train [18/26] | Epoch [28/160] |	nca: 1.7609283849596977, flat: 2.001076817512512, pod: 41.56116700172424, loss: 45.323171734809875 
Train [18/26] | Epoch [29/160] |	nca: 1.8143450990319252, flat: 2.1733612194657326, pod: 43.32089960575104, loss: 47.30860638618469 
Train [18/26] | Epoch [30/160] |	nca: 1.836526870727539, flat: 2.1518199294805527, pod: 42.7105438709259, loss: 46.698890686035156 
Train [18/26] | Epoch [31/160] |	nca: 1.8761660046875477, flat: 2.3860701099038124, pod: 45.42400884628296, loss: 49.68624544143677 
Train [18/26] | Epoch [32/160] |	nca: 1.6695685870945454, flat: 2.164252981543541, pod: 43.963268995285034, loss: 47.79709005355835 
Train [18/26] | Epoch [33/160] |	nca: 1.613570462912321, flat: 2.22773015499115, pod: 45.65443396568298, loss: 49.49573493003845 
Train [18/26] | Epoch [34/160] |	nca: 1.7084439918398857, flat: 1.9732768386602402, pod: 41.89818298816681, loss: 45.57990384101868 
Train [18/26] | Epoch [35/160] |	nca: 1.8440866209566593, flat: 2.1370109766721725, pod: 43.33724391460419, loss: 47.318342208862305 
Train [18/26] | Epoch [36/160] |	nca: 1.6820293292403221, flat: 2.0880553871393204, pod: 42.392226696014404, loss: 46.16231167316437 
Train [18/26] | Epoch [37/160] |	nca: 1.5006186068058014, flat: 1.9365066438913345, pod: 39.17004930973053, loss: 42.60717499256134 
Train [18/26] | Epoch [38/160] |	nca: 1.7227663472294807, flat: 2.0833990201354027, pod: 43.301737666130066, loss: 47.10790312290192 
Train [18/26] | Epoch [39/160] |	nca: 1.7036096043884754, flat: 2.042942389845848, pod: 42.766592383384705, loss: 46.51314389705658 
Train [18/26] | Epoch [40/160] |	nca: 1.591206457465887, flat: 1.9234222546219826, pod: 41.01468575000763, loss: 44.52931475639343 
Train [18/26] | Epoch [41/160] |	nca: 1.498786997050047, flat: 1.8216253221035004, pod: 41.148863077163696, loss: 44.46927523612976 
Train [18/26] | Epoch [42/160] |	nca: 1.567308634519577, flat: 1.7951070815324783, pod: 39.774298310279846, loss: 43.13671386241913 
Train [18/26] | Epoch [43/160] |	nca: 1.8435270749032497, flat: 2.0508749336004257, pod: 41.06164908409119, loss: 44.95605111122131 
Train [18/26] | Epoch [44/160] |	nca: 1.6260734163224697, flat: 1.9389626756310463, pod: 41.02238953113556, loss: 44.58742547035217 
Train [18/26] | Epoch [45/160] |	nca: 1.8252912983298302, flat: 2.2001767307519913, pod: 43.50255060195923, loss: 47.52801823616028 
Train [18/26] | Epoch [46/160] |	nca: 1.610633660107851, flat: 2.0374558195471764, pod: 41.25733292102814, loss: 44.90542221069336 
Train [18/26] | Epoch [47/160] |	nca: 1.5593217350542545, flat: 1.962285466492176, pod: 40.647964119911194, loss: 44.16957116127014 
Train [18/26] | Epoch [48/160] |	nca: 1.723490446805954, flat: 1.9283829852938652, pod: 40.360193729400635, loss: 44.01206696033478 
Train [18/26] | Epoch [49/160] |	nca: 1.6454163044691086, flat: 2.0409017205238342, pod: 42.22181177139282, loss: 45.90812957286835 
Train [18/26] | Epoch [50/160] |	nca: 1.56719583645463, flat: 1.7768351510167122, pod: 39.56485724449158, loss: 42.90888833999634 
Train [18/26] | Epoch [51/160] |	nca: 1.4463898986577988, flat: 1.7236526757478714, pod: 38.921511054039, loss: 42.09155344963074 
Train [18/26] | Epoch [52/160] |	nca: 1.5553176067769527, flat: 1.7314166352152824, pod: 38.81540548801422, loss: 42.102139949798584 
Train [18/26] | Epoch [53/160] |	nca: 1.8481015302240849, flat: 1.8498526588082314, pod: 39.4641090631485, loss: 43.162063241004944 
Train [18/26] | Epoch [54/160] |	nca: 1.440054975450039, flat: 1.6953329592943192, pod: 37.01961708068848, loss: 40.15500509738922 
Train [18/26] | Epoch [55/160] |	nca: 1.7286481820046902, flat: 1.771304003894329, pod: 38.827168107032776, loss: 42.3271210193634 
Train [18/26] | Epoch [56/160] |	nca: 1.5674072280526161, flat: 1.760124795138836, pod: 39.5049649477005, loss: 42.832497000694275 
Train [18/26] | Epoch [57/160] |	nca: 1.5208993814885616, flat: 1.7937089279294014, pod: 40.237375259399414, loss: 43.55198383331299 
Train [18/26] | Epoch [58/160] |	nca: 1.6241600662469864, flat: 1.7298194989562035, pod: 38.591811299324036, loss: 41.94579088687897 
Train [18/26] | Epoch [59/160] |	nca: 1.513372227549553, flat: 1.7232506349682808, pod: 38.06723415851593, loss: 41.3038569688797 
Train [18/26] | Epoch [60/160] |	nca: 1.54789437353611, flat: 1.6832301691174507, pod: 38.17365336418152, loss: 41.40477800369263 
Train [18/26] | Epoch [61/160] |	nca: 1.5984453856945038, flat: 1.7473003789782524, pod: 39.68951618671417, loss: 43.03526210784912 
Train [18/26] | Epoch [62/160] |	nca: 1.5452127568423748, flat: 1.6798844039440155, pod: 38.1859495639801, loss: 41.411046862602234 
Train [18/26] | Epoch [63/160] |	nca: 1.523452267050743, flat: 1.5889555178582668, pod: 36.35507822036743, loss: 39.467485547065735 
Train [18/26] | Epoch [64/160] |	nca: 1.4892713092267513, flat: 1.779341384768486, pod: 38.68919575214386, loss: 41.95780825614929 
Train [18/26] | Epoch [65/160] |	nca: 1.593156635761261, flat: 1.6696530692279339, pod: 38.18514537811279, loss: 41.44795501232147 
Train [18/26] | Epoch [66/160] |	nca: 1.7113737873733044, flat: 1.7365656644105911, pod: 38.61766600608826, loss: 42.06560564041138 
Train [18/26] | Epoch [67/160] |	nca: 1.6862113401293755, flat: 1.707260388880968, pod: 38.37101233005524, loss: 41.76448428630829 
Train [18/26] | Epoch [68/160] |	nca: 1.3659099116921425, flat: 1.6664347052574158, pod: 36.902429819107056, loss: 39.93477463722229 
Train [18/26] | Epoch [69/160] |	nca: 1.3972401358187199, flat: 1.6547404006123543, pod: 37.40261697769165, loss: 40.45459723472595 
Train [18/26] | Epoch [70/160] |	nca: 1.336256880313158, flat: 1.5019351169466972, pod: 35.744840145111084, loss: 38.58303225040436 
Train [18/26] | Epoch [71/160] |	nca: 1.6763186268508434, flat: 1.5920035876333714, pod: 35.37696170806885, loss: 38.645283818244934 
Train [18/26] | Epoch [72/160] |	nca: 1.4116056449711323, flat: 1.6496194750070572, pod: 37.79541289806366, loss: 40.856637716293335 
Train [18/26] | Epoch [73/160] |	nca: 1.3599343486130238, flat: 1.4988731741905212, pod: 35.64839553833008, loss: 38.50720298290253 
Train [18/26] | Epoch [74/160] |	nca: 1.613085888326168, flat: 1.6750459745526314, pod: 38.3169766664505, loss: 41.60510849952698 
Train [18/26] | Epoch [75/160] |	nca: 1.4205493479967117, flat: 1.5153923854231834, pod: 36.28807592391968, loss: 39.22401750087738 
Train [18/26] | Epoch [76/160] |	nca: 1.5805353075265884, flat: 1.5671944580972195, pod: 37.421521067619324, loss: 40.56925070285797 
Train [18/26] | Epoch [77/160] |	nca: 1.3953649960458279, flat: 1.3759375251829624, pod: 34.49897003173828, loss: 37.270272612571716 
Train [18/26] | Epoch [78/160] |	nca: 1.5258152857422829, flat: 1.470916759222746, pod: 35.8088835477829, loss: 38.80561554431915 
Train [18/26] | Epoch [79/160] |	nca: 1.4495912678539753, flat: 1.3861053921282291, pod: 33.95598781108856, loss: 36.79168438911438 
Train [18/26] | Epoch [80/160] |	nca: 1.489441454410553, flat: 1.518955945968628, pod: 35.67011547088623, loss: 38.67851281166077 
Train [18/26] | Epoch [81/160] |	nca: 1.3837319277226925, flat: 1.3527614958584309, pod: 33.61766862869263, loss: 36.354162096977234 
Train [18/26] | Epoch [82/160] |	nca: 1.3663130290806293, flat: 1.211333867162466, pod: 31.859541416168213, loss: 34.437188386917114 
Train [18/26] | Epoch [83/160] |	nca: 1.4885025508701801, flat: 1.4063584096729755, pod: 34.38574421405792, loss: 37.28060495853424 
Train [18/26] | Epoch [84/160] |	nca: 1.293181411921978, flat: 1.4552102200686932, pod: 33.938613057136536, loss: 36.68700468540192 
Train [18/26] | Epoch [85/160] |	nca: 1.4247521460056305, flat: 1.2886322773993015, pod: 32.49834132194519, loss: 35.21172571182251 
Train [18/26] | Epoch [86/160] |	nca: 1.4837245345115662, flat: 1.316251516342163, pod: 32.64148128032684, loss: 35.44145715236664 
Train [18/26] | Epoch [87/160] |	nca: 1.3956953845918179, flat: 1.197113685309887, pod: 31.50309443473816, loss: 34.095903396606445 
Train [18/26] | Epoch [88/160] |	nca: 1.4380874894559383, flat: 1.3977453634142876, pod: 35.063671588897705, loss: 37.89950442314148 
Train [18/26] | Epoch [89/160] |	nca: 1.442270901054144, flat: 1.297609243541956, pod: 32.89356553554535, loss: 35.63344585895538 
Train [18/26] | Epoch [90/160] |	nca: 1.4427009336650372, flat: 1.2308134697377682, pod: 32.85650014877319, loss: 35.530014514923096 
Train [18/26] | Epoch [91/160] |	nca: 1.3334191851317883, flat: 1.1915437914431095, pod: 31.722209930419922, loss: 34.247172832489014 
Train [18/26] | Epoch [92/160] |	nca: 1.3830953761935234, flat: 1.3230604194104671, pod: 32.80110943317413, loss: 35.50726509094238 
Train [18/26] | Epoch [93/160] |	nca: 1.3560627065598965, flat: 1.2687362097203732, pod: 32.711647391319275, loss: 35.3364462852478 
Train [18/26] | Epoch [94/160] |	nca: 1.2970803584903479, flat: 1.1831951849162579, pod: 30.73494577407837, loss: 33.21522116661072 
Train [18/26] | Epoch [95/160] |	nca: 1.3356734067201614, flat: 1.103305459022522, pod: 30.44827961921692, loss: 32.887258529663086 
Train [18/26] | Epoch [96/160] |	nca: 1.3236671760678291, flat: 1.0991382002830505, pod: 29.676241993904114, loss: 32.09904754161835 
Train [18/26] | Epoch [97/160] |	nca: 1.3579095788300037, flat: 1.175526101142168, pod: 31.6473491191864, loss: 34.180784702301025 
Train [18/26] | Epoch [98/160] |	nca: 1.3720766752958298, flat: 1.103200688958168, pod: 29.961026906967163, loss: 32.436304330825806 
Train [18/26] | Epoch [99/160] |	nca: 1.4018899761140347, flat: 1.168939296156168, pod: 30.284018635749817, loss: 32.85484778881073 
Train [18/26] | Epoch [100/160] |	nca: 1.3693292737007141, flat: 1.0738965645432472, pod: 30.64424729347229, loss: 33.08747315406799 
Train [18/26] | Epoch [101/160] |	nca: 1.309882991015911, flat: 1.254100326448679, pod: 31.712262511253357, loss: 34.27624571323395 
Train [18/26] | Epoch [102/160] |	nca: 1.4743181467056274, flat: 1.1273096352815628, pod: 29.845731139183044, loss: 32.44735860824585 
Train [18/26] | Epoch [103/160] |	nca: 1.40921426191926, flat: 1.206276811659336, pod: 31.696354627609253, loss: 34.311845779418945 
Train [18/26] | Epoch [104/160] |	nca: 1.2955400981009007, flat: 1.0960665121674538, pod: 29.95950710773468, loss: 32.35111379623413 
Train [18/26] | Epoch [105/160] |	nca: 1.269637731835246, flat: 0.9773053526878357, pod: 27.662304997444153, loss: 29.909247994422913 
Train [18/26] | Epoch [106/160] |	nca: 1.176796518266201, flat: 0.9094256982207298, pod: 26.198157906532288, loss: 28.284380316734314 
Train [18/26] | Epoch [107/160] |	nca: 1.3330261707305908, flat: 1.0208320505917072, pod: 27.638283371925354, loss: 29.992141485214233 
Train [18/26] | Epoch [108/160] |	nca: 1.3525338247418404, flat: 1.0015191473066807, pod: 28.338257312774658, loss: 30.692310094833374 
Train [18/26] | Epoch [109/160] |	nca: 1.2773660235106945, flat: 0.9147711992263794, pod: 26.766160368919373, loss: 28.958297610282898 
Train [18/26] | Epoch [110/160] |	nca: 1.3075187802314758, flat: 1.0040622651576996, pod: 27.514883756637573, loss: 29.826464414596558 
Train [18/26] | Epoch [111/160] |	nca: 1.3616297394037247, flat: 1.0915119163691998, pod: 29.2486230134964, loss: 31.701764941215515 
Train [18/26] | Epoch [112/160] |	nca: 1.2199296467006207, flat: 0.9226522333920002, pod: 27.090662837028503, loss: 29.23324453830719 
Train [18/26] | Epoch [113/160] |	nca: 1.3131362423300743, flat: 0.9631768763065338, pod: 27.62596321105957, loss: 29.902276396751404 
Train [18/26] | Epoch [114/160] |	nca: 1.3449936546385288, flat: 0.9468332529067993, pod: 26.977717757225037, loss: 29.26954460144043 
Train [18/26] | Epoch [115/160] |	nca: 1.4537614732980728, flat: 0.9187076222151518, pod: 26.629915237426758, loss: 29.002384305000305 
Train [18/26] | Epoch [116/160] |	nca: 1.3408555947244167, flat: 0.9602792225778103, pod: 27.250589609146118, loss: 29.551724433898926 
Train [18/26] | Epoch [117/160] |	nca: 1.2566064335405827, flat: 0.8486938867717981, pod: 25.7732275724411, loss: 27.878528118133545 
Train [18/26] | Epoch [118/160] |	nca: 1.280223522335291, flat: 0.9377014487981796, pod: 27.50812828540802, loss: 29.72605323791504 
Train [18/26] | Epoch [119/160] |	nca: 1.2994260340929031, flat: 0.8908755704760551, pod: 26.03109884262085, loss: 28.221400380134583 
Train [18/26] | Epoch [120/160] |	nca: 1.322603676468134, flat: 0.877165213227272, pod: 25.889811277389526, loss: 28.089580059051514 
Train [18/26] | Epoch [121/160] |	nca: 1.3371086157858372, flat: 0.8103619255125523, pod: 23.901171922683716, loss: 26.04864251613617 
Train [18/26] | Epoch [122/160] |	nca: 1.3158345110714436, flat: 0.8557573948055506, pod: 24.429576575756073, loss: 26.601168394088745 
Train [18/26] | Epoch [123/160] |	nca: 1.2730998285114765, flat: 0.8595996648073196, pod: 24.472571849822998, loss: 26.605271577835083 
Train [18/26] | Epoch [124/160] |	nca: 1.2474237494170666, flat: 0.8310188502073288, pod: 25.56247854232788, loss: 27.640921354293823 
Train [18/26] | Epoch [125/160] |	nca: 1.3725942336022854, flat: 0.880044549703598, pod: 25.361653327941895, loss: 27.6142920255661 
Train [18/26] | Epoch [126/160] |	nca: 1.267877098172903, flat: 0.7697923667728901, pod: 23.649238765239716, loss: 25.68690812587738 
Train [18/26] | Epoch [127/160] |	nca: 1.2142565362155437, flat: 0.8153529558330774, pod: 23.453234553337097, loss: 25.4828439950943 
Train [18/26] | Epoch [128/160] |	nca: 1.3144507706165314, flat: 0.7881876472383738, pod: 24.647103428840637, loss: 26.7497421503067 
Train [18/26] | Epoch [129/160] |	nca: 1.2481400333344936, flat: 0.7000393476337194, pod: 22.688281178474426, loss: 24.63646024465561 
Train [18/26] | Epoch [130/160] |	nca: 1.332711398601532, flat: 0.707020714879036, pod: 22.4528386592865, loss: 24.49257057905197 
Train [18/26] | Epoch [131/160] |	nca: 1.3280870616436005, flat: 0.7493888642638922, pod: 22.719907879829407, loss: 24.797383904457092 
Train [18/26] | Epoch [132/160] |	nca: 1.3304538652300835, flat: 0.7100567519664764, pod: 22.44914972782135, loss: 24.489660322666168 
Train [18/26] | Epoch [133/160] |	nca: 1.3541651852428913, flat: 0.7128390464931726, pod: 21.973351776599884, loss: 24.04035586118698 
Train [18/26] | Epoch [134/160] |	nca: 1.351713901385665, flat: 0.7480573672801256, pod: 22.68639898300171, loss: 24.786170303821564 
Train [18/26] | Epoch [135/160] |	nca: 1.3010426722466946, flat: 0.6721517313271761, pod: 21.186246275901794, loss: 23.159440517425537 
Train [18/26] | Epoch [136/160] |	nca: 1.2363545596599579, flat: 0.7403304018080235, pod: 22.69539326429367, loss: 24.67207807302475 
Train [18/26] | Epoch [137/160] |	nca: 1.2440811470150948, flat: 0.6137922052294016, pod: 20.21396827697754, loss: 22.071841716766357 
Train [18/26] | Epoch [138/160] |	nca: 1.2713244259357452, flat: 0.6571230422705412, pod: 20.940146923065186, loss: 22.86859440803528 
Train [18/26] | Epoch [139/160] |	nca: 1.2477054856717587, flat: 0.6221576351672411, pod: 20.44312608242035, loss: 22.312989115715027 
Train [18/26] | Epoch [140/160] |	nca: 1.345603071153164, flat: 0.63717857375741, pod: 20.1061789393425, loss: 22.088960826396942 
Train [18/26] | Epoch [141/160] |	nca: 1.3847173005342484, flat: 0.6328802276402712, pod: 20.43602478504181, loss: 22.453622460365295 
Train [18/26] | Epoch [142/160] |	nca: 1.1876084618270397, flat: 0.6737333778291941, pod: 21.24098938703537, loss: 23.102331459522247 
Train [18/26] | Epoch [143/160] |	nca: 1.2560584023594856, flat: 0.5857614129781723, pod: 19.962984144687653, loss: 21.804803788661957 
Train [18/26] | Epoch [144/160] |	nca: 1.230696901679039, flat: 0.6200378462672234, pod: 20.24136883020401, loss: 22.09210330247879 
Train [18/26] | Epoch [145/160] |	nca: 1.2573046833276749, flat: 0.6317413188517094, pod: 20.325939118862152, loss: 22.214984953403473 
Train [18/26] | Epoch [146/160] |	nca: 1.2640385441482067, flat: 0.602623550221324, pod: 19.65448886156082, loss: 21.52115100622177 
Train [18/26] | Epoch [147/160] |	nca: 1.2598032541573048, flat: 0.5787052977830172, pod: 19.03969371318817, loss: 20.878202259540558 
Train [18/26] | Epoch [148/160] |	nca: 1.2630157098174095, flat: 0.5831416845321655, pod: 19.135014712810516, loss: 20.981171786785126 
Train [18/26] | Epoch [149/160] |	nca: 1.2556579634547234, flat: 0.5879504047334194, pod: 18.92354255914688, loss: 20.767150938510895 
Train [18/26] | Epoch [150/160] |	nca: 1.2322946339845657, flat: 0.5881915874779224, pod: 19.339995443820953, loss: 21.16048163175583 
Train [18/26] | Epoch [151/160] |	nca: 1.2238197810947895, flat: 0.5524537339806557, pod: 18.668613255023956, loss: 20.444886803627014 
Train [18/26] | Epoch [152/160] |	nca: 1.2782119549810886, flat: 0.5310891643166542, pod: 17.86751037836075, loss: 19.676811456680298 
Train [18/26] | Epoch [153/160] |	nca: 1.2723652683198452, flat: 0.5203049667179585, pod: 17.805802166461945, loss: 19.59847241640091 
Train [18/26] | Epoch [154/160] |	nca: 1.2411863282322884, flat: 0.5623747333884239, pod: 18.92138934135437, loss: 20.724950551986694 
Train [18/26] | Epoch [155/160] |	nca: 1.1608774848282337, flat: 0.5199928693473339, pod: 17.916271150112152, loss: 19.597141563892365 
Train [18/26] | Epoch [156/160] |	nca: 1.3036053068935871, flat: 0.6018977575004101, pod: 18.493836045265198, loss: 20.399339199066162 
Train [18/26] | Epoch [157/160] |	nca: 1.1919912919402122, flat: 0.5797686763107777, pod: 19.233495473861694, loss: 21.005255341529846 
Train [18/26] | Epoch [158/160] |	nca: 1.255131982266903, flat: 0.557594271376729, pod: 18.285462617874146, loss: 20.098188817501068 
Train [18/26] | Epoch [159/160] |	nca: 1.1827029213309288, flat: 0.5161662008613348, pod: 17.7487753033638, loss: 19.447644472122192 
Train [18/26] | Epoch [160/160] |	nca: 1.2467592507600784, flat: 0.5141126215457916, pod: 17.608186304569244, loss: 19.369058191776276 
Fine-tuning
Building & updating memory.
Train [18/26] | Epoch [161/180] |	nca: 1.3551161512732506, flat: 1.0635528303682804, pod: 20.479551434516907, loss: 22.898220419883728 
Train [18/26] | Epoch [162/180] |	nca: 0.8227956555783749, flat: 1.1104661151766777, pod: 20.52222204208374, loss: 22.45548391342163 
Train [18/26] | Epoch [163/180] |	nca: 0.8036978952586651, flat: 1.113761629909277, pod: 20.26129424571991, loss: 22.178753972053528 
Train [18/26] | Epoch [164/180] |	nca: 0.887293316423893, flat: 1.086613953113556, pod: 20.460063099861145, loss: 22.43397045135498 
Train [18/26] | Epoch [165/180] |	nca: 0.8441309221088886, flat: 1.148033894598484, pod: 20.816858768463135, loss: 22.80902373790741 
Train [18/26] | Epoch [166/180] |	nca: 0.8220849186182022, flat: 1.0928610302507877, pod: 20.74678647518158, loss: 22.66173243522644 
Train [18/26] | Epoch [167/180] |	nca: 0.8593765869736671, flat: 1.1464983969926834, pod: 21.06872284412384, loss: 23.07459783554077 
Train [18/26] | Epoch [168/180] |	nca: 0.9218960255384445, flat: 1.0286383219063282, pod: 20.18662166595459, loss: 22.137156009674072 
Train [18/26] | Epoch [169/180] |	nca: 0.7391993701457977, flat: 1.1015310361981392, pod: 20.12600803375244, loss: 21.96673834323883 
Train [18/26] | Epoch [170/180] |	nca: 0.7357670553028584, flat: 1.1187332421541214, pod: 20.951407313346863, loss: 22.805907487869263 
Train [18/26] | Epoch [171/180] |	nca: 0.7041427381336689, flat: 1.073903039097786, pod: 20.68097758293152, loss: 22.459023594856262 
Train [18/26] | Epoch [172/180] |	nca: 0.7551995106041431, flat: 1.1187773384153843, pod: 20.433509826660156, loss: 22.30748677253723 
Train [18/26] | Epoch [173/180] |	nca: 1.0660114586353302, flat: 1.1193300671875477, pod: 20.948572635650635, loss: 23.13391411304474 
Train [18/26] | Epoch [174/180] |	nca: 0.8537135645747185, flat: 1.1158784665167332, pod: 20.932319402694702, loss: 22.90191149711609 
Train [18/26] | Epoch [175/180] |	nca: 0.7178608998656273, flat: 1.1279640533030033, pod: 20.3718980550766, loss: 22.21772313117981 
Train [18/26] | Epoch [176/180] |	nca: 0.8008730039000511, flat: 1.1758222542703152, pod: 20.64421510696411, loss: 22.62091028690338 
Train [18/26] | Epoch [177/180] |	nca: 0.8153432607650757, flat: 1.0965021811425686, pod: 20.49065375328064, loss: 22.402499079704285 
Train [18/26] | Epoch [178/180] |	nca: 0.7094430178403854, flat: 1.2071173377335072, pod: 21.27501094341278, loss: 23.19157111644745 
Train [18/26] | Epoch [179/180] |	nca: 0.8485736586153507, flat: 1.0783990062773228, pod: 20.550962448120117, loss: 22.477935194969177 
Train [18/26] | Epoch [180/180] |	nca: 0.7219431269913912, flat: 1.1379183791577816, pod: 20.925751090049744, loss: 22.78561246395111 
after task
Building & updating memory.
after task
Eval on 0->84.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6363333333333333.
Current acc: {'total': 0.565, '00-09': 0.615, '10-19': 0.549, '20-29': 0.492, '30-39': 0.503, '40-49': 0.565, '50-59': 0.562, '60-69': 0.494, '70-79': 0.644, '80-89': 0.802}.
Avg inc acc top5: 0.8770555555555553.
Current acc top5: {'total': 0.837}.
Forgetting: 0.1888.
Cord metric: 0.64.
Old accuracy: 0.56, mean: 0.62.
New accuracy: 0.90, mean: 0.80.
================Task 18 Start!================
Testing on False unseen tasks (max class = 86).
Set memory of size: 1680.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 18 Training!================
The training samples number: 2680
Train on 84->86.
train task
nb 2680.
Train [19/26] | Epoch [1/160] |	nca: 9.763908058404922, flat: 4.817785762250423, pod: 54.7466596364975, loss: 69.32835388183594 
Train [19/26] | Epoch [2/160] |	nca: 5.9904914647340775, flat: 4.387609109282494, pod: 56.81508278846741, loss: 67.19318318367004 
Train [19/26] | Epoch [3/160] |	nca: 5.010896906256676, flat: 3.9001656472682953, pod: 55.43219494819641, loss: 64.34325742721558 
Train [19/26] | Epoch [4/160] |	nca: 4.058859184384346, flat: 3.460505396127701, pod: 53.97715759277344, loss: 61.496522188186646 
Train [19/26] | Epoch [5/160] |	nca: 3.534890115261078, flat: 3.221267983317375, pod: 52.45265746116638, loss: 59.208815813064575 
Train [19/26] | Epoch [6/160] |	nca: 3.1624108999967575, flat: 2.7746004685759544, pod: 47.80666923522949, loss: 53.743680238723755 
Train [19/26] | Epoch [7/160] |	nca: 2.802790306508541, flat: 2.601232998073101, pod: 47.09533643722534, loss: 52.49935984611511 
Train [19/26] | Epoch [8/160] |	nca: 3.017427645623684, flat: 2.5388801991939545, pod: 47.75957691669464, loss: 53.315884828567505 
Train [19/26] | Epoch [9/160] |	nca: 2.6853318735957146, flat: 2.661359414458275, pod: 49.03538465499878, loss: 54.38207530975342 
Train [19/26] | Epoch [10/160] |	nca: 2.959586165845394, flat: 2.732142813503742, pod: 50.01406002044678, loss: 55.7057888507843 
Train [19/26] | Epoch [11/160] |	nca: 2.844015024602413, flat: 2.7121578082442284, pod: 50.347512006759644, loss: 55.90368461608887 
Train [19/26] | Epoch [12/160] |	nca: 2.495597690343857, flat: 2.406522713601589, pod: 46.751526951789856, loss: 51.653647661209106 
Train [19/26] | Epoch [13/160] |	nca: 2.7769112288951874, flat: 2.4580583572387695, pod: 45.73499798774719, loss: 50.96996784210205 
Train [19/26] | Epoch [14/160] |	nca: 2.2584055960178375, flat: 2.3771019652485847, pod: 44.96062350273132, loss: 49.59613108634949 
Train [19/26] | Epoch [15/160] |	nca: 2.488804802298546, flat: 2.518767736852169, pod: 49.6517653465271, loss: 54.659337759017944 
Train [19/26] | Epoch [16/160] |	nca: 2.5390973538160324, flat: 2.585380405187607, pod: 49.01298189163208, loss: 54.13745951652527 
Train [19/26] | Epoch [17/160] |	nca: 2.734396278858185, flat: 2.8931180834770203, pod: 52.037726640701294, loss: 57.66524076461792 
Train [19/26] | Epoch [18/160] |	nca: 2.788658820092678, flat: 2.527352623641491, pod: 46.371556878089905, loss: 51.68756866455078 
Train [19/26] | Epoch [19/160] |	nca: 2.5919413566589355, flat: 2.425391159951687, pod: 45.369701862335205, loss: 50.38703441619873 
Train [19/26] | Epoch [20/160] |	nca: 2.107715766876936, flat: 2.211514003574848, pod: 44.54990589618683, loss: 48.86913585662842 
Train [19/26] | Epoch [21/160] |	nca: 2.320777103304863, flat: 2.125960662961006, pod: 44.51199960708618, loss: 48.95873785018921 
Train [19/26] | Epoch [22/160] |	nca: 2.3568208143115044, flat: 2.173407271504402, pod: 43.035773515701294, loss: 47.56600213050842 
Train [19/26] | Epoch [23/160] |	nca: 2.3159088641405106, flat: 2.193508006632328, pod: 43.69794964790344, loss: 48.207366943359375 
Train [19/26] | Epoch [24/160] |	nca: 2.2912911623716354, flat: 2.236416317522526, pod: 45.431583523750305, loss: 49.959290981292725 
Train [19/26] | Epoch [25/160] |	nca: 2.2063928991556168, flat: 2.199188753962517, pod: 45.00783085823059, loss: 49.41341209411621 
Train [19/26] | Epoch [26/160] |	nca: 2.24875545501709, flat: 2.2106933146715164, pod: 45.02914500236511, loss: 49.48859405517578 
Train [19/26] | Epoch [27/160] |	nca: 2.2014517784118652, flat: 2.2363113090395927, pod: 44.866312742233276, loss: 49.304075717926025 
Train [19/26] | Epoch [28/160] |	nca: 2.3780503273010254, flat: 2.3097889721393585, pod: 44.735919713974, loss: 49.42375898361206 
Train [19/26] | Epoch [29/160] |	nca: 2.0667162090539932, flat: 1.960442878305912, pod: 40.21044683456421, loss: 44.237605810165405 
Train [19/26] | Epoch [30/160] |	nca: 2.060459189116955, flat: 1.9672110378742218, pod: 41.97413349151611, loss: 46.001803517341614 
Train [19/26] | Epoch [31/160] |	nca: 2.3061945140361786, flat: 1.9907878711819649, pod: 42.540440797805786, loss: 46.8374228477478 
Train [19/26] | Epoch [32/160] |	nca: 2.166015215218067, flat: 2.123246967792511, pod: 44.225090861320496, loss: 48.51435303688049 
Train [19/26] | Epoch [33/160] |	nca: 2.030638813972473, flat: 1.9785280004143715, pod: 42.6918830871582, loss: 46.70104968547821 
Train [19/26] | Epoch [34/160] |	nca: 2.0116923302412033, flat: 2.0512928664684296, pod: 42.73037552833557, loss: 46.79336106777191 
Train [19/26] | Epoch [35/160] |	nca: 2.1847730353474617, flat: 2.1923655048012733, pod: 44.4544438123703, loss: 48.83158254623413 
Train [19/26] | Epoch [36/160] |	nca: 1.9821418523788452, flat: 1.98616673797369, pod: 42.21581768989563, loss: 46.184126138687134 
Train [19/26] | Epoch [37/160] |	nca: 2.0509298518300056, flat: 1.8881716802716255, pod: 40.782034397125244, loss: 44.72113609313965 
Train [19/26] | Epoch [38/160] |	nca: 2.28214443475008, flat: 2.138498730957508, pod: 43.86208367347717, loss: 48.28272724151611 
Train [19/26] | Epoch [39/160] |	nca: 2.2144121155142784, flat: 2.142282173037529, pod: 43.25204873085022, loss: 47.60874319076538 
Train [19/26] | Epoch [40/160] |	nca: 2.053785055875778, flat: 1.9488135650753975, pod: 40.66812205314636, loss: 44.67072057723999 
Train [19/26] | Epoch [41/160] |	nca: 1.9507519006729126, flat: 1.9416334107518196, pod: 43.70892035961151, loss: 47.6013058423996 
Train [19/26] | Epoch [42/160] |	nca: 2.0607319995760918, flat: 2.003416635096073, pod: 42.223397731781006, loss: 46.28754651546478 
Train [19/26] | Epoch [43/160] |	nca: 2.1200560107827187, flat: 2.1919474080204964, pod: 44.86520218849182, loss: 49.177205324172974 
Train [19/26] | Epoch [44/160] |	nca: 1.745450682938099, flat: 1.870737947523594, pod: 41.78432214260101, loss: 45.40051054954529 
Train [19/26] | Epoch [45/160] |	nca: 2.00185963511467, flat: 1.7601607590913773, pod: 39.89872765541077, loss: 43.66074788570404 
Train [19/26] | Epoch [46/160] |	nca: 2.127416580915451, flat: 1.775337502360344, pod: 39.39501702785492, loss: 43.297770977020264 
Train [19/26] | Epoch [47/160] |	nca: 2.1447219103574753, flat: 1.88111562281847, pod: 40.108357667922974, loss: 44.13419508934021 
Train [19/26] | Epoch [48/160] |	nca: 2.109946981072426, flat: 1.8709552958607674, pod: 39.7664235830307, loss: 43.747326016426086 
Train [19/26] | Epoch [49/160] |	nca: 2.0465888865292072, flat: 1.8257010504603386, pod: 39.01113212108612, loss: 42.883421778678894 
Train [19/26] | Epoch [50/160] |	nca: 1.940842967480421, flat: 1.8045545518398285, pod: 39.167813777923584, loss: 42.91321134567261 
Train [19/26] | Epoch [51/160] |	nca: 1.9578221216797829, flat: 1.7453678771853447, pod: 39.08399701118469, loss: 42.7871869802475 
Train [19/26] | Epoch [52/160] |	nca: 2.0412100329995155, flat: 1.7318129017949104, pod: 39.15610432624817, loss: 42.9291273355484 
Train [19/26] | Epoch [53/160] |	nca: 1.8995123505592346, flat: 1.6788484752178192, pod: 38.106973528862, loss: 41.68533432483673 
Train [19/26] | Epoch [54/160] |	nca: 2.0123784467577934, flat: 1.739242598414421, pod: 38.9429315328598, loss: 42.694552302360535 
Train [19/26] | Epoch [55/160] |	nca: 1.9267163127660751, flat: 1.7712587416172028, pod: 40.136961698532104, loss: 43.83493685722351 
Train [19/26] | Epoch [56/160] |	nca: 1.8045250661671162, flat: 1.6642301231622696, pod: 37.364479184150696, loss: 40.833234429359436 
Train [19/26] | Epoch [57/160] |	nca: 2.1126861795783043, flat: 1.6973878964781761, pod: 38.49306273460388, loss: 42.303136706352234 
Train [19/26] | Epoch [58/160] |	nca: 1.9750313498079777, flat: 1.7367290556430817, pod: 38.56378734111786, loss: 42.275548458099365 
Train [19/26] | Epoch [59/160] |	nca: 2.1185985803604126, flat: 1.6378643363714218, pod: 37.313955426216125, loss: 41.07041811943054 
Train [19/26] | Epoch [60/160] |	nca: 2.0586302280426025, flat: 1.794932134449482, pod: 39.83330416679382, loss: 43.68686664104462 
Train [19/26] | Epoch [61/160] |	nca: 1.6674720980226994, flat: 1.6299108564853668, pod: 37.54546523094177, loss: 40.84284782409668 
Train [19/26] | Epoch [62/160] |	nca: 1.8050001338124275, flat: 1.5687377080321312, pod: 37.03756785392761, loss: 40.41130578517914 
Train [19/26] | Epoch [63/160] |	nca: 1.672389518469572, flat: 1.5289447978138924, pod: 36.81165158748627, loss: 40.012985944747925 
Train [19/26] | Epoch [64/160] |	nca: 1.9636055678129196, flat: 1.5824058167636395, pod: 37.21139204502106, loss: 40.75740349292755 
Train [19/26] | Epoch [65/160] |	nca: 1.7109706737101078, flat: 1.5220564901828766, pod: 36.18322205543518, loss: 39.41624915599823 
Train [19/26] | Epoch [66/160] |	nca: 2.005078434944153, flat: 1.6113164387643337, pod: 38.22285544872284, loss: 41.839250326156616 
Train [19/26] | Epoch [67/160] |	nca: 1.9013120755553246, flat: 1.5889661461114883, pod: 36.6717689037323, loss: 40.162046909332275 
Train [19/26] | Epoch [68/160] |	nca: 1.8529177643358707, flat: 1.5289011113345623, pod: 36.99977695941925, loss: 40.381596088409424 
Train [19/26] | Epoch [69/160] |	nca: 1.8372797705233097, flat: 1.6071466878056526, pod: 39.20681047439575, loss: 42.65123665332794 
Train [19/26] | Epoch [70/160] |	nca: 1.9138559512794018, flat: 1.533013455569744, pod: 36.906436920166016, loss: 40.35330617427826 
Train [19/26] | Epoch [71/160] |	nca: 1.8764280416071415, flat: 1.54111822322011, pod: 36.976300954818726, loss: 40.39384686946869 
Train [19/26] | Epoch [72/160] |	nca: 1.8961114026606083, flat: 1.487254787236452, pod: 35.66462552547455, loss: 39.0479918718338 
Train [19/26] | Epoch [73/160] |	nca: 1.888782098889351, flat: 1.5190514922142029, pod: 35.924784779548645, loss: 39.33261847496033 
Train [19/26] | Epoch [74/160] |	nca: 1.792083002626896, flat: 1.3938786759972572, pod: 34.14410638809204, loss: 37.33006775379181 
Train [19/26] | Epoch [75/160] |	nca: 1.822679728269577, flat: 1.498143557459116, pod: 35.35871374607086, loss: 38.679537415504456 
Train [19/26] | Epoch [76/160] |	nca: 1.677579503506422, flat: 1.2416606657207012, pod: 32.8975830078125, loss: 35.81682300567627 
Train [19/26] | Epoch [77/160] |	nca: 1.901009388267994, flat: 1.4557176642119884, pod: 35.04853177070618, loss: 38.405258774757385 
Train [19/26] | Epoch [78/160] |	nca: 1.7984891794621944, flat: 1.3765862695872784, pod: 35.25415110588074, loss: 38.42922651767731 
Train [19/26] | Epoch [79/160] |	nca: 1.8024573922157288, flat: 1.411243200302124, pod: 34.582438230514526, loss: 37.796138882637024 
Train [19/26] | Epoch [80/160] |	nca: 1.8212270140647888, flat: 1.3790939263999462, pod: 33.43961751461029, loss: 36.63993847370148 
Train [19/26] | Epoch [81/160] |	nca: 1.643600881099701, flat: 1.4731627255678177, pod: 34.65269076824188, loss: 37.76945459842682 
Train [19/26] | Epoch [82/160] |	nca: 1.7457934357225895, flat: 1.4026160165667534, pod: 34.71955466270447, loss: 37.867964029312134 
Train [19/26] | Epoch [83/160] |	nca: 1.8475575149059296, flat: 1.3904133290052414, pod: 35.32830345630646, loss: 38.56627440452576 
Train [19/26] | Epoch [84/160] |	nca: 1.6067561469972134, flat: 1.244990285485983, pod: 32.80492973327637, loss: 35.65667641162872 
Train [19/26] | Epoch [85/160] |	nca: 1.7509518042206764, flat: 1.266939114779234, pod: 32.63965940475464, loss: 35.65755021572113 
Train [19/26] | Epoch [86/160] |	nca: 1.6655295938253403, flat: 1.3829910643398762, pod: 35.25141227245331, loss: 38.29993271827698 
Train [19/26] | Epoch [87/160] |	nca: 1.8104428313672543, flat: 1.3198054395616055, pod: 34.37518656253815, loss: 37.50543475151062 
Train [19/26] | Epoch [88/160] |	nca: 1.6375996619462967, flat: 1.1588239073753357, pod: 31.380684852600098, loss: 34.17710876464844 
Train [19/26] | Epoch [89/160] |	nca: 1.7084104530513287, flat: 1.229490727186203, pod: 32.613741993904114, loss: 35.55164337158203 
Train [19/26] | Epoch [90/160] |	nca: 1.8514489904046059, flat: 1.1591367237269878, pod: 31.56190848350525, loss: 34.57249402999878 
Train [19/26] | Epoch [91/160] |	nca: 1.5631890557706356, flat: 1.0902056023478508, pod: 30.52995467185974, loss: 33.18334913253784 
Train [19/26] | Epoch [92/160] |	nca: 1.6259127259254456, flat: 1.0945403724908829, pod: 29.055909514427185, loss: 31.776362538337708 
Train [19/26] | Epoch [93/160] |	nca: 1.6315911002457142, flat: 1.3159504123032093, pod: 32.881677865982056, loss: 35.829219460487366 
Train [19/26] | Epoch [94/160] |	nca: 1.618388507515192, flat: 1.1159067042171955, pod: 30.68061339855194, loss: 33.41490852832794 
Train [19/26] | Epoch [95/160] |	nca: 1.7815796807408333, flat: 1.1171679235994816, pod: 29.96705186367035, loss: 32.86579954624176 
Train [19/26] | Epoch [96/160] |	nca: 1.547286745160818, flat: 1.1408365406095982, pod: 30.76570701599121, loss: 33.45383012294769 
Train [19/26] | Epoch [97/160] |	nca: 1.7202096171677113, flat: 1.0750473104417324, pod: 30.128151297569275, loss: 32.92340815067291 
Train [19/26] | Epoch [98/160] |	nca: 1.6286164931952953, flat: 1.0218533352017403, pod: 28.411623239517212, loss: 31.062093138694763 
Train [19/26] | Epoch [99/160] |	nca: 1.6560692936182022, flat: 1.1192440837621689, pod: 30.84864354133606, loss: 33.62395691871643 
Train [19/26] | Epoch [100/160] |	nca: 1.6168011836707592, flat: 1.060045976191759, pod: 30.23635959625244, loss: 32.913206815719604 
Train [19/26] | Epoch [101/160] |	nca: 1.7632731795310974, flat: 1.0905717052519321, pod: 29.394906282424927, loss: 32.248751282691956 
Train [19/26] | Epoch [102/160] |	nca: 1.6581420078873634, flat: 1.043368361890316, pod: 28.990674257278442, loss: 31.692184448242188 
Train [19/26] | Epoch [103/160] |	nca: 1.731009341776371, flat: 1.096478920429945, pod: 29.57639765739441, loss: 32.40388607978821 
Train [19/26] | Epoch [104/160] |	nca: 1.7026281505823135, flat: 0.979839451611042, pod: 28.805951952934265, loss: 31.48841941356659 
Train [19/26] | Epoch [105/160] |	nca: 1.6660971269011497, flat: 1.0481694899499416, pod: 28.366669416427612, loss: 31.080935955047607 
Train [19/26] | Epoch [106/160] |	nca: 1.598255217075348, flat: 0.9591716155409813, pod: 27.63090741634369, loss: 30.188334107398987 
Train [19/26] | Epoch [107/160] |	nca: 1.7466893270611763, flat: 1.0808748453855515, pod: 29.923346281051636, loss: 32.75091028213501 
Train [19/26] | Epoch [108/160] |	nca: 1.5616255216300488, flat: 0.9224296398460865, pod: 27.622978687286377, loss: 30.107033729553223 
Train [19/26] | Epoch [109/160] |	nca: 1.6955538354814053, flat: 0.9903310872614384, pod: 28.330650687217712, loss: 31.01653552055359 
Train [19/26] | Epoch [110/160] |	nca: 1.5552320145070553, flat: 0.9130949564278126, pod: 26.722215056419373, loss: 29.190542221069336 
Train [19/26] | Epoch [111/160] |	nca: 1.6388858743011951, flat: 0.9351631365716457, pod: 27.456212639808655, loss: 30.030261516571045 
Train [19/26] | Epoch [112/160] |	nca: 1.5350093021988869, flat: 0.8888728357851505, pod: 26.175675868988037, loss: 28.599558234214783 
Train [19/26] | Epoch [113/160] |	nca: 1.6681212186813354, flat: 0.8354562371969223, pod: 25.652851343154907, loss: 28.156428575515747 
Train [19/26] | Epoch [114/160] |	nca: 1.516166727989912, flat: 0.8782919384539127, pod: 25.3901709318161, loss: 27.784629583358765 
Train [19/26] | Epoch [115/160] |	nca: 1.5292933844029903, flat: 0.8145448658615351, pod: 24.89155125617981, loss: 27.235389351844788 
Train [19/26] | Epoch [116/160] |	nca: 1.5494111143052578, flat: 0.8518478721380234, pod: 25.751626133918762, loss: 28.15288507938385 
Train [19/26] | Epoch [117/160] |	nca: 1.5305857695639133, flat: 0.8707087691873312, pod: 26.395671367645264, loss: 28.796965837478638 
Train [19/26] | Epoch [118/160] |	nca: 1.5432833693921566, flat: 0.8551818318665028, pod: 25.431848287582397, loss: 27.830313563346863 
Train [19/26] | Epoch [119/160] |	nca: 1.6216989681124687, flat: 0.7871890924870968, pod: 24.517653465270996, loss: 26.926541447639465 
Train [19/26] | Epoch [120/160] |	nca: 1.5637698397040367, flat: 0.7498259916901588, pod: 24.187108159065247, loss: 26.500704169273376 
Train [19/26] | Epoch [121/160] |	nca: 1.6366662047803402, flat: 0.8017716575413942, pod: 24.03888463973999, loss: 26.477322578430176 
Train [19/26] | Epoch [122/160] |	nca: 1.5111063905060291, flat: 0.808860432356596, pod: 24.448950707912445, loss: 26.768917083740234 
Train [19/26] | Epoch [123/160] |	nca: 1.6251804791390896, flat: 0.7506166882812977, pod: 24.199264526367188, loss: 26.575061798095703 
Train [19/26] | Epoch [124/160] |	nca: 1.659231435507536, flat: 0.766863502562046, pod: 24.11773991584778, loss: 26.543834686279297 
Train [19/26] | Epoch [125/160] |	nca: 1.6033578291535378, flat: 0.8050961922854185, pod: 23.40118896961212, loss: 25.809643030166626 
Train [19/26] | Epoch [126/160] |	nca: 1.5871071852743626, flat: 0.7480593789368868, pod: 23.738281667232513, loss: 26.073448300361633 
Train [19/26] | Epoch [127/160] |	nca: 1.681777410209179, flat: 0.7056451756507158, pod: 23.052439987659454, loss: 25.439862370491028 
Train [19/26] | Epoch [128/160] |	nca: 1.5417091213166714, flat: 0.6786239556968212, pod: 20.80758947134018, loss: 23.027922570705414 
Train [19/26] | Epoch [129/160] |	nca: 1.542187750339508, flat: 0.7584110498428345, pod: 23.66202813386917, loss: 25.962626934051514 
Train [19/26] | Epoch [130/160] |	nca: 1.4832295514643192, flat: 0.6810906231403351, pod: 22.039504826068878, loss: 24.203825056552887 
Train [19/26] | Epoch [131/160] |	nca: 1.5096090771257877, flat: 0.7003179956227541, pod: 21.91740334033966, loss: 24.12733030319214 
Train [19/26] | Epoch [132/160] |	nca: 1.7154260538518429, flat: 0.7059910651296377, pod: 22.472550988197327, loss: 24.893967866897583 
Train [19/26] | Epoch [133/160] |	nca: 1.5030600875616074, flat: 0.65341473557055, pod: 21.23979824781418, loss: 23.396272778511047 
Train [19/26] | Epoch [134/160] |	nca: 1.4564977288246155, flat: 0.6756007894873619, pod: 21.883628606796265, loss: 24.01572722196579 
Train [19/26] | Epoch [135/160] |	nca: 1.5116101205348969, flat: 0.6241756901144981, pod: 20.750116407871246, loss: 22.88590234518051 
Train [19/26] | Epoch [136/160] |	nca: 1.5502904653549194, flat: 0.6437513288110495, pod: 20.798865377902985, loss: 22.992907166481018 
Train [19/26] | Epoch [137/160] |	nca: 1.55859350040555, flat: 0.6733983363956213, pod: 21.409000992774963, loss: 23.64099270105362 
Train [19/26] | Epoch [138/160] |	nca: 1.5316676497459412, flat: 0.6087188329547644, pod: 20.465921700000763, loss: 22.606308102607727 
Train [19/26] | Epoch [139/160] |	nca: 1.6204166002571583, flat: 0.6347804740071297, pod: 21.04878795146942, loss: 23.303985059261322 
Train [19/26] | Epoch [140/160] |	nca: 1.5233228132128716, flat: 0.602585481479764, pod: 19.853713870048523, loss: 21.97962236404419 
Train [19/26] | Epoch [141/160] |	nca: 1.4886486195027828, flat: 0.5802768841385841, pod: 20.025109112262726, loss: 22.09403485059738 
Train [19/26] | Epoch [142/160] |	nca: 1.5694386512041092, flat: 0.594802975654602, pod: 19.74844855070114, loss: 21.912690341472626 
Train [19/26] | Epoch [143/160] |	nca: 1.5771703943610191, flat: 0.5598331950604916, pod: 19.405288994312286, loss: 21.542292416095734 
Train [19/26] | Epoch [144/160] |	nca: 1.6048432812094688, flat: 0.5676940251141787, pod: 18.425389289855957, loss: 20.59792649745941 
Train [19/26] | Epoch [145/160] |	nca: 1.4454132430255413, flat: 0.5386858023703098, pod: 18.6207395195961, loss: 20.604838728904724 
Train [19/26] | Epoch [146/160] |	nca: 1.5059620328247547, flat: 0.5522423088550568, pod: 19.05068403482437, loss: 21.10888832807541 
Train [19/26] | Epoch [147/160] |	nca: 1.5194466672837734, flat: 0.5474247112870216, pod: 18.153558433055878, loss: 20.22042977809906 
Train [19/26] | Epoch [148/160] |	nca: 1.5533330738544464, flat: 0.5419465824961662, pod: 18.19925683736801, loss: 20.294536471366882 
Train [19/26] | Epoch [149/160] |	nca: 1.4712339341640472, flat: 0.5530182830989361, pod: 18.97732174396515, loss: 21.001574099063873 
Train [19/26] | Epoch [150/160] |	nca: 1.4990191049873829, flat: 0.5428092926740646, pod: 18.48359966278076, loss: 20.525428116321564 
Train [19/26] | Epoch [151/160] |	nca: 1.5599191971123219, flat: 0.5513448100537062, pod: 18.876455903053284, loss: 20.98771995306015 
Train [19/26] | Epoch [152/160] |	nca: 1.5082264579832554, flat: 0.5482632126659155, pod: 18.695110857486725, loss: 20.7516006231308 
Train [19/26] | Epoch [153/160] |	nca: 1.4587095156311989, flat: 0.5082739759236574, pod: 17.756600320339203, loss: 19.723583936691284 
Train [19/26] | Epoch [154/160] |	nca: 1.5337220914661884, flat: 0.5476906131953001, pod: 18.32538253068924, loss: 20.406795382499695 
Train [19/26] | Epoch [155/160] |	nca: 1.4603214748203754, flat: 0.5204783044755459, pod: 17.38756036758423, loss: 19.3683602809906 
Train [19/26] | Epoch [156/160] |	nca: 1.496350347995758, flat: 0.504888255149126, pod: 17.484285354614258, loss: 19.48552393913269 
Train [19/26] | Epoch [157/160] |	nca: 1.4987273178994656, flat: 0.4804372685030103, pod: 16.693370699882507, loss: 18.672535240650177 
Train [19/26] | Epoch [158/160] |	nca: 1.5103397443890572, flat: 0.5170458871871233, pod: 17.511939108371735, loss: 19.5393248796463 
Train [19/26] | Epoch [159/160] |	nca: 1.5708254501223564, flat: 0.4882825221866369, pod: 16.86473947763443, loss: 18.923847436904907 
Train [19/26] | Epoch [160/160] |	nca: 1.5332816652953625, flat: 0.5105314999818802, pod: 16.84085088968277, loss: 18.884664058685303 
Fine-tuning
Building & updating memory.
Train [19/26] | Epoch [161/180] |	nca: 1.3094512857496738, flat: 0.8925589546561241, pod: 19.541365802288055, loss: 21.74337601661682 
Train [19/26] | Epoch [162/180] |	nca: 0.6818288154900074, flat: 0.850808646529913, pod: 19.188343107700348, loss: 20.720980644226074 
Train [19/26] | Epoch [163/180] |	nca: 0.6874905377626419, flat: 0.8726954273879528, pod: 19.43686866760254, loss: 20.99705469608307 
Train [19/26] | Epoch [164/180] |	nca: 0.6508381403982639, flat: 0.8063727170228958, pod: 18.650282502174377, loss: 20.10749340057373 
Train [19/26] | Epoch [165/180] |	nca: 0.7035597618669271, flat: 0.877888236194849, pod: 19.381145119667053, loss: 20.96259319782257 
Train [19/26] | Epoch [166/180] |	nca: 0.6248042024672031, flat: 0.8426598273217678, pod: 19.076984405517578, loss: 20.544448614120483 
Train [19/26] | Epoch [167/180] |	nca: 0.6211120635271072, flat: 0.8450960330665112, pod: 18.95425307750702, loss: 20.420461177825928 
Train [19/26] | Epoch [168/180] |	nca: 0.6314770504832268, flat: 0.8476930595934391, pod: 18.942452549934387, loss: 20.42162263393402 
Train [19/26] | Epoch [169/180] |	nca: 0.5800799950957298, flat: 0.84767210111022, pod: 19.533010482788086, loss: 20.96076250076294 
Train [19/26] | Epoch [170/180] |	nca: 0.5815693847835064, flat: 0.8756306320428848, pod: 19.495610535144806, loss: 20.95281058549881 
Train [19/26] | Epoch [171/180] |	nca: 0.5175513569265604, flat: 0.8927936740219593, pod: 19.3526349067688, loss: 20.762979984283447 
Train [19/26] | Epoch [172/180] |	nca: 0.5446946676820517, flat: 0.8690776042640209, pod: 18.83700168132782, loss: 20.250773787498474 
Train [19/26] | Epoch [173/180] |	nca: 0.5174934845417738, flat: 0.9114632904529572, pod: 19.602285981178284, loss: 21.031242728233337 
Train [19/26] | Epoch [174/180] |	nca: 0.5756695345044136, flat: 0.8167403005063534, pod: 18.433347642421722, loss: 19.825757443904877 
Train [19/26] | Epoch [175/180] |	nca: 0.556705916300416, flat: 0.8374197743833065, pod: 18.966749012470245, loss: 20.36087477207184 
Train [19/26] | Epoch [176/180] |	nca: 0.5646888092160225, flat: 0.8715540915727615, pod: 19.80385410785675, loss: 21.240096926689148 
Train [19/26] | Epoch [177/180] |	nca: 0.5397537127137184, flat: 0.9174321368336678, pod: 19.93224787712097, loss: 21.38943362236023 
Train [19/26] | Epoch [178/180] |	nca: 0.5026440992951393, flat: 0.8329210765659809, pod: 18.91966986656189, loss: 20.255235195159912 
Train [19/26] | Epoch [179/180] |	nca: 0.48401280865073204, flat: 0.8141391538083553, pod: 19.026999950408936, loss: 20.325151801109314 
Train [19/26] | Epoch [180/180] |	nca: 0.5322875007987022, flat: 0.8717163875699043, pod: 19.257989466190338, loss: 20.661993265151978 
after task
Building & updating memory.
after task
Eval on 0->86.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6321052631578946.
Current acc: {'total': 0.556, '00-09': 0.617, '10-19': 0.541, '20-29': 0.445, '30-39': 0.528, '40-49': 0.566, '50-59': 0.541, '60-69': 0.48, '70-79': 0.637, '80-89': 0.708}.
Avg inc acc top5: 0.8747894736842102.
Current acc top5: {'total': 0.834}.
Forgetting: 0.20580000000000007.
Cord metric: 0.64.
Old accuracy: 0.55, mean: 0.62.
New accuracy: 0.81, mean: 0.80.
================Task 19 Start!================
Testing on False unseen tasks (max class = 88).
Set memory of size: 1720.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 19 Training!================
The training samples number: 2720
Train on 86->88.
train task
nb 2720.
Train [20/26] | Epoch [1/160] |	nca: 8.427062183618546, flat: 5.21422603726387, pod: 53.70447564125061, loss: 67.34576416015625 
Train [20/26] | Epoch [2/160] |	nca: 6.487333610653877, flat: 5.9107774049043655, pod: 63.51779627799988, loss: 75.91590714454651 
Train [20/26] | Epoch [3/160] |	nca: 5.320885807275772, flat: 6.035272642970085, pod: 65.97078204154968, loss: 77.32694029808044 
Train [20/26] | Epoch [4/160] |	nca: 3.6895821020007133, flat: 4.935993030667305, pod: 62.01781368255615, loss: 70.64338898658752 
Train [20/26] | Epoch [5/160] |	nca: 2.67456728965044, flat: 3.6274859458208084, pod: 54.579262256622314, loss: 60.88131618499756 
Train [20/26] | Epoch [6/160] |	nca: 2.2712523862719536, flat: 3.201662190258503, pod: 52.664671659469604, loss: 58.13758635520935 
Train [20/26] | Epoch [7/160] |	nca: 2.0219233855605125, flat: 2.9424993470311165, pod: 50.46097946166992, loss: 55.42540192604065 
Train [20/26] | Epoch [8/160] |	nca: 1.9344102516770363, flat: 2.8463306576013565, pod: 50.57724380493164, loss: 55.35798501968384 
Train [20/26] | Epoch [9/160] |	nca: 2.027027193456888, flat: 2.903910368680954, pod: 52.66078972816467, loss: 57.5917272567749 
Train [20/26] | Epoch [10/160] |	nca: 1.9413563795387745, flat: 2.7057273983955383, pod: 50.01324391365051, loss: 54.660327434539795 
Train [20/26] | Epoch [11/160] |	nca: 1.7845705263316631, flat: 2.5783007591962814, pod: 48.71040415763855, loss: 53.073275089263916 
Train [20/26] | Epoch [12/160] |	nca: 1.951800912618637, flat: 2.4261186569929123, pod: 46.55444145202637, loss: 50.9323616027832 
Train [20/26] | Epoch [13/160] |	nca: 2.026979684829712, flat: 2.8195565342903137, pod: 50.30963087081909, loss: 55.156166791915894 
Train [20/26] | Epoch [14/160] |	nca: 1.8943386599421501, flat: 2.4118785560131073, pod: 45.53561508655548, loss: 49.841832280159 
Train [20/26] | Epoch [15/160] |	nca: 1.7643501423299313, flat: 2.443383611738682, pod: 47.05577325820923, loss: 51.26350748538971 
Train [20/26] | Epoch [16/160] |	nca: 1.7747301198542118, flat: 2.3053939267992973, pod: 44.98664045333862, loss: 49.06676411628723 
Train [20/26] | Epoch [17/160] |	nca: 1.8622329719364643, flat: 2.795768164098263, pod: 49.41475808620453, loss: 54.07275938987732 
Train [20/26] | Epoch [18/160] |	nca: 2.149838026612997, flat: 2.6775994524359703, pod: 47.75135338306427, loss: 52.57879114151001 
Train [20/26] | Epoch [19/160] |	nca: 1.8259995467960835, flat: 2.605270676314831, pod: 46.92738127708435, loss: 51.35865139961243 
Train [20/26] | Epoch [20/160] |	nca: 1.8413709327578545, flat: 2.4416868835687637, pod: 47.30629575252533, loss: 51.58935332298279 
Train [20/26] | Epoch [21/160] |	nca: 1.9897246733307838, flat: 2.8755484372377396, pod: 51.720139384269714, loss: 56.5854127407074 
Train [20/26] | Epoch [22/160] |	nca: 1.6153525561094284, flat: 2.233631268143654, pod: 43.123035073280334, loss: 46.97201871871948 
Train [20/26] | Epoch [23/160] |	nca: 1.7469644211232662, flat: 2.3350833281874657, pod: 44.37874746322632, loss: 48.4607949256897 
Train [20/26] | Epoch [24/160] |	nca: 1.7889163866639137, flat: 2.2845227047801018, pod: 44.087671399116516, loss: 48.161110639572144 
Train [20/26] | Epoch [25/160] |	nca: 1.7678670808672905, flat: 2.4183939546346664, pod: 47.57977509498596, loss: 51.76603603363037 
Train [20/26] | Epoch [26/160] |	nca: 1.9048722796142101, flat: 2.443058021366596, pod: 48.681087374687195, loss: 53.02901744842529 
Train [20/26] | Epoch [27/160] |	nca: 1.914288580417633, flat: 2.6081488057971, pod: 46.579508543014526, loss: 51.101946115493774 
Train [20/26] | Epoch [28/160] |	nca: 1.8444826267659664, flat: 2.524390898644924, pod: 47.48073494434357, loss: 51.849608182907104 
Train [20/26] | Epoch [29/160] |	nca: 1.9128844924271107, flat: 2.316479481756687, pod: 45.14149296283722, loss: 49.37085723876953 
Train [20/26] | Epoch [30/160] |	nca: 1.8064895644783974, flat: 2.6257510855793953, pod: 47.06219959259033, loss: 51.49444079399109 
Train [20/26] | Epoch [31/160] |	nca: 1.620568048208952, flat: 2.244277745485306, pod: 44.33308827877045, loss: 48.19793438911438 
Train [20/26] | Epoch [32/160] |	nca: 1.6000783927738667, flat: 2.2921767607331276, pod: 43.92918360233307, loss: 47.821438789367676 
Train [20/26] | Epoch [33/160] |	nca: 1.59888182207942, flat: 2.3359803184866905, pod: 44.685471415519714, loss: 48.62033414840698 
Train [20/26] | Epoch [34/160] |	nca: 1.955777209252119, flat: 2.491345204412937, pod: 45.316335558891296, loss: 49.76345753669739 
Train [20/26] | Epoch [35/160] |	nca: 1.6949871964752674, flat: 2.2681757360696793, pod: 45.420425057411194, loss: 49.38358783721924 
Train [20/26] | Epoch [36/160] |	nca: 1.5908309780061245, flat: 2.114728659391403, pod: 43.198086977005005, loss: 46.90364694595337 
Train [20/26] | Epoch [37/160] |	nca: 1.7715649902820587, flat: 2.041683480143547, pod: 40.40182316303253, loss: 44.21507179737091 
Train [20/26] | Epoch [38/160] |	nca: 1.6213305816054344, flat: 2.281081609427929, pod: 44.17585480213165, loss: 48.078267097473145 
Train [20/26] | Epoch [39/160] |	nca: 1.625276643782854, flat: 2.209496334195137, pod: 45.18446910381317, loss: 49.01924204826355 
Train [20/26] | Epoch [40/160] |	nca: 1.9148428700864315, flat: 2.200765810906887, pod: 43.16766059398651, loss: 47.28326952457428 
Train [20/26] | Epoch [41/160] |	nca: 2.006907422095537, flat: 2.4976136088371277, pod: 46.826393246650696, loss: 51.33091402053833 
Train [20/26] | Epoch [42/160] |	nca: 2.053165841847658, flat: 2.5896668508648872, pod: 44.7987802028656, loss: 49.44161295890808 
Train [20/26] | Epoch [43/160] |	nca: 1.806543443351984, flat: 2.4028806164860725, pod: 45.1471506357193, loss: 49.35657477378845 
Train [20/26] | Epoch [44/160] |	nca: 1.7021919265389442, flat: 2.1755837872624397, pod: 43.738357186317444, loss: 47.6161322593689 
Train [20/26] | Epoch [45/160] |	nca: 1.5774735882878304, flat: 2.036261223256588, pod: 41.902567863464355, loss: 45.516302943229675 
Train [20/26] | Epoch [46/160] |	nca: 1.5300138108432293, flat: 2.1033990383148193, pod: 45.36447048187256, loss: 48.997883796691895 
Train [20/26] | Epoch [47/160] |	nca: 1.6187627725303173, flat: 2.133121632039547, pod: 42.008227467536926, loss: 45.760111927986145 
Train [20/26] | Epoch [48/160] |	nca: 1.4823275581002235, flat: 1.9159437492489815, pod: 40.35953366756439, loss: 43.75780475139618 
Train [20/26] | Epoch [49/160] |	nca: 1.6908309198915958, flat: 2.0387801229953766, pod: 42.75824427604675, loss: 46.487855195999146 
Train [20/26] | Epoch [50/160] |	nca: 1.5560721680521965, flat: 1.993580810725689, pod: 43.12749397754669, loss: 46.67714762687683 
Train [20/26] | Epoch [51/160] |	nca: 1.5120841227471828, flat: 1.994329184293747, pod: 41.783525466918945, loss: 45.28993892669678 
Train [20/26] | Epoch [52/160] |	nca: 1.566257283091545, flat: 2.043109819293022, pod: 42.22644603252411, loss: 45.83581280708313 
Train [20/26] | Epoch [53/160] |	nca: 1.485905036330223, flat: 1.879367783665657, pod: 39.99589467048645, loss: 43.36116814613342 
Train [20/26] | Epoch [54/160] |	nca: 1.4173471592366695, flat: 1.9726975932717323, pod: 42.560108065605164, loss: 45.95015251636505 
Train [20/26] | Epoch [55/160] |	nca: 1.4990684427320957, flat: 1.9357851967215538, pod: 42.21803879737854, loss: 45.65289294719696 
Train [20/26] | Epoch [56/160] |	nca: 1.6245580799877644, flat: 1.8331243470311165, pod: 40.74531102180481, loss: 44.202993512153625 
Train [20/26] | Epoch [57/160] |	nca: 1.7915715128183365, flat: 2.088241294026375, pod: 41.75480842590332, loss: 45.634621381759644 
Train [20/26] | Epoch [58/160] |	nca: 1.5368489883840084, flat: 1.8851097151637077, pod: 39.87972390651703, loss: 43.30168259143829 
Train [20/26] | Epoch [59/160] |	nca: 1.4571458622813225, flat: 2.102955937385559, pod: 43.41478884220123, loss: 46.97489082813263 
Train [20/26] | Epoch [60/160] |	nca: 1.5274278186261654, flat: 1.728695534169674, pod: 38.69120121002197, loss: 41.94732427597046 
Train [20/26] | Epoch [61/160] |	nca: 1.4684421345591545, flat: 1.71195263043046, pod: 37.68813860416412, loss: 40.86853313446045 
Train [20/26] | Epoch [62/160] |	nca: 1.4595631137490273, flat: 1.6890672519803047, pod: 38.35470521450043, loss: 41.50333559513092 
Train [20/26] | Epoch [63/160] |	nca: 1.6558208614587784, flat: 1.9016658142209053, pod: 40.854909777641296, loss: 44.41239655017853 
Train [20/26] | Epoch [64/160] |	nca: 1.4537541344761848, flat: 1.8825919479131699, pod: 40.518038868904114, loss: 43.854384779930115 
Train [20/26] | Epoch [65/160] |	nca: 1.5536557249724865, flat: 1.8023009151220322, pod: 39.35607087612152, loss: 42.71202731132507 
Train [20/26] | Epoch [66/160] |	nca: 1.3570047207176685, flat: 1.842473953962326, pod: 40.11442828178406, loss: 43.31390678882599 
Train [20/26] | Epoch [67/160] |	nca: 1.6454770788550377, flat: 1.73822071403265, pod: 38.677528858184814, loss: 42.06122660636902 
Train [20/26] | Epoch [68/160] |	nca: 1.5108972303569317, flat: 1.7220954559743404, pod: 38.79100465774536, loss: 42.02399706840515 
Train [20/26] | Epoch [69/160] |	nca: 1.6829429492354393, flat: 1.6387298367917538, pod: 36.68934118747711, loss: 40.011013865470886 
Train [20/26] | Epoch [70/160] |	nca: 1.5207718946039677, flat: 1.7468597032129765, pod: 38.502157330513, loss: 41.76978886127472 
Train [20/26] | Epoch [71/160] |	nca: 1.415701825171709, flat: 1.7443045377731323, pod: 39.56238496303558, loss: 42.7223916053772 
Train [20/26] | Epoch [72/160] |	nca: 1.3433684222400188, flat: 1.5078106857836246, pod: 35.81227993965149, loss: 38.66345930099487 
Train [20/26] | Epoch [73/160] |	nca: 1.4227873533964157, flat: 1.4967789873480797, pod: 36.25242495536804, loss: 39.17199146747589 
Train [20/26] | Epoch [74/160] |	nca: 1.3539595305919647, flat: 1.4268338084220886, pod: 35.20746898651123, loss: 37.98826265335083 
Train [20/26] | Epoch [75/160] |	nca: 1.3784349113702774, flat: 1.4588906280696392, pod: 34.64418137073517, loss: 37.48150658607483 
Train [20/26] | Epoch [76/160] |	nca: 1.5747555866837502, flat: 1.6542355045676231, pod: 37.90270781517029, loss: 41.13169884681702 
Train [20/26] | Epoch [77/160] |	nca: 1.4446369968354702, flat: 1.491798296570778, pod: 34.88221633434296, loss: 37.81865119934082 
Train [20/26] | Epoch [78/160] |	nca: 1.5137919448316097, flat: 1.513231337070465, pod: 35.992528438568115, loss: 39.01955163478851 
Train [20/26] | Epoch [79/160] |	nca: 1.4491830170154572, flat: 1.5778137780725956, pod: 35.42684078216553, loss: 38.453837633132935 
Train [20/26] | Epoch [80/160] |	nca: 1.6144028529524803, flat: 1.4876312613487244, pod: 34.8199577331543, loss: 37.92199194431305 
Train [20/26] | Epoch [81/160] |	nca: 1.5349980033934116, flat: 1.603424146771431, pod: 36.24335527420044, loss: 39.38177716732025 
Train [20/26] | Epoch [82/160] |	nca: 1.3260120376944542, flat: 1.4787794910371304, pod: 35.44600462913513, loss: 38.25079596042633 
Train [20/26] | Epoch [83/160] |	nca: 1.4116386957466602, flat: 1.5380901955068111, pod: 35.96856939792633, loss: 38.91829824447632 
Train [20/26] | Epoch [84/160] |	nca: 1.4784137979149818, flat: 1.5336034037172794, pod: 35.35134708881378, loss: 38.36336433887482 
Train [20/26] | Epoch [85/160] |	nca: 1.7920008040964603, flat: 1.6925552859902382, pod: 37.5041686296463, loss: 40.98872435092926 
Train [20/26] | Epoch [86/160] |	nca: 1.6784995682537556, flat: 1.8847488313913345, pod: 40.13664710521698, loss: 43.69989573955536 
Train [20/26] | Epoch [87/160] |	nca: 1.3998779244720936, flat: 1.4925314038991928, pod: 34.68112123012543, loss: 37.57353067398071 
Train [20/26] | Epoch [88/160] |	nca: 1.3414146527647972, flat: 1.3815587610006332, pod: 33.47950053215027, loss: 36.20247423648834 
Train [20/26] | Epoch [89/160] |	nca: 1.5714018307626247, flat: 1.5721470192074776, pod: 35.68641459941864, loss: 38.82996332645416 
Train [20/26] | Epoch [90/160] |	nca: 1.3907523788511753, flat: 1.4230766706168652, pod: 33.669113755226135, loss: 36.48294270038605 
Train [20/26] | Epoch [91/160] |	nca: 1.3996686786413193, flat: 1.3925187550485134, pod: 33.861449241638184, loss: 36.65363669395447 
Train [20/26] | Epoch [92/160] |	nca: 1.3568670824170113, flat: 1.278424222022295, pod: 33.18729031085968, loss: 35.82258152961731 
Train [20/26] | Epoch [93/160] |	nca: 1.3028502874076366, flat: 1.2159281373023987, pod: 31.76752805709839, loss: 34.286306738853455 
Train [20/26] | Epoch [94/160] |	nca: 1.4367040283977985, flat: 1.2811274975538254, pod: 31.80019772052765, loss: 34.51802945137024 
Train [20/26] | Epoch [95/160] |	nca: 1.3349959254264832, flat: 1.2507539466023445, pod: 31.080107927322388, loss: 33.665858030319214 
Train [20/26] | Epoch [96/160] |	nca: 1.3186745084822178, flat: 1.1651913300156593, pod: 30.26171886920929, loss: 32.74558472633362 
Train [20/26] | Epoch [97/160] |	nca: 1.2762223184108734, flat: 1.153543870896101, pod: 30.72920060157776, loss: 33.15896654129028 
Train [20/26] | Epoch [98/160] |	nca: 1.4172141086310148, flat: 1.24286487698555, pod: 31.928020358085632, loss: 34.588099360466 
Train [20/26] | Epoch [99/160] |	nca: 1.2629727087914944, flat: 1.2278892621397972, pod: 31.68845808506012, loss: 34.179320096969604 
Train [20/26] | Epoch [100/160] |	nca: 1.3475970849394798, flat: 1.143636293709278, pod: 30.91751992702484, loss: 33.40875327587128 
Train [20/26] | Epoch [101/160] |	nca: 1.393444113433361, flat: 1.0835270769894123, pod: 29.483094573020935, loss: 31.960065722465515 
Train [20/26] | Epoch [102/160] |	nca: 1.3560487665235996, flat: 1.1569278500974178, pod: 31.11425483226776, loss: 33.6272314786911 
Train [20/26] | Epoch [103/160] |	nca: 1.3226812779903412, flat: 1.0951907373964787, pod: 28.279651045799255, loss: 30.69752323627472 
Train [20/26] | Epoch [104/160] |	nca: 1.325887307524681, flat: 1.1461672447621822, pod: 29.197337985038757, loss: 31.669392585754395 
Train [20/26] | Epoch [105/160] |	nca: 1.2628669366240501, flat: 1.0883393846452236, pod: 28.00711941719055, loss: 30.358325719833374 
Train [20/26] | Epoch [106/160] |	nca: 1.2739555649459362, flat: 1.0273479521274567, pod: 27.6020485162735, loss: 29.90335202217102 
Train [20/26] | Epoch [107/160] |	nca: 1.3666439540684223, flat: 1.0617034249007702, pod: 28.141469836235046, loss: 30.569817066192627 
Train [20/26] | Epoch [108/160] |	nca: 1.196113996207714, flat: 1.052969466894865, pod: 29.342851161956787, loss: 31.59193456172943 
Train [20/26] | Epoch [109/160] |	nca: 1.1851333566009998, flat: 1.0180012062191963, pod: 28.613913536071777, loss: 30.817047834396362 
Train [20/26] | Epoch [110/160] |	nca: 1.3032876029610634, flat: 0.9925955906510353, pod: 27.405088305473328, loss: 29.700971484184265 
Train [20/26] | Epoch [111/160] |	nca: 1.1528462879359722, flat: 0.924165541306138, pod: 27.368777632713318, loss: 29.445789217948914 
Train [20/26] | Epoch [112/160] |	nca: 1.3125924095511436, flat: 1.0340423323214054, pod: 29.19973874092102, loss: 31.54637348651886 
Train [20/26] | Epoch [113/160] |	nca: 1.233904905617237, flat: 0.988616406917572, pod: 27.1820068359375, loss: 29.40452814102173 
Train [20/26] | Epoch [114/160] |	nca: 1.2658520936965942, flat: 0.938089445233345, pod: 26.308028042316437, loss: 28.511969447135925 
Train [20/26] | Epoch [115/160] |	nca: 1.2027321755886078, flat: 0.9309471007436514, pod: 26.244358777999878, loss: 28.37803816795349 
Train [20/26] | Epoch [116/160] |	nca: 1.2255389094352722, flat: 0.9276405870914459, pod: 26.748119473457336, loss: 28.901298761367798 
Train [20/26] | Epoch [117/160] |	nca: 1.380777683109045, flat: 1.0023745372891426, pod: 27.21159267425537, loss: 29.5947448015213 
Train [20/26] | Epoch [118/160] |	nca: 1.3750204108655453, flat: 0.9968620389699936, pod: 26.229934811592102, loss: 28.60181713104248 
Train [20/26] | Epoch [119/160] |	nca: 1.3658283911645412, flat: 0.8456842079758644, pod: 25.251716017723083, loss: 27.463228583335876 
Train [20/26] | Epoch [120/160] |	nca: 1.2141259610652924, flat: 0.9224199391901493, pod: 26.31528127193451, loss: 28.45182728767395 
Train [20/26] | Epoch [121/160] |	nca: 1.359242882579565, flat: 0.9919013008475304, pod: 27.385594248771667, loss: 29.736738562583923 
Train [20/26] | Epoch [122/160] |	nca: 1.2890481539070606, flat: 0.9905352964997292, pod: 27.173401474952698, loss: 29.45298480987549 
Train [20/26] | Epoch [123/160] |	nca: 1.2441946268081665, flat: 0.9102753978222609, pod: 25.960896253585815, loss: 28.115366220474243 
Train [20/26] | Epoch [124/160] |	nca: 1.3072849474847317, flat: 0.820883259177208, pod: 24.50297200679779, loss: 26.63114023208618 
Train [20/26] | Epoch [125/160] |	nca: 1.2136475332081318, flat: 0.8277991451323032, pod: 23.277428150177002, loss: 25.318874776363373 
Train [20/26] | Epoch [126/160] |	nca: 1.2149332538247108, flat: 0.8059943523257971, pod: 23.946630716323853, loss: 25.96755826473236 
Train [20/26] | Epoch [127/160] |	nca: 1.2037603110074997, flat: 0.844423733651638, pod: 24.554591596126556, loss: 26.60277545452118 
Train [20/26] | Epoch [128/160] |	nca: 1.155038945376873, flat: 0.851705389097333, pod: 25.20505303144455, loss: 27.21179747581482 
Train [20/26] | Epoch [129/160] |	nca: 1.3002426959574223, flat: 0.8380636945366859, pod: 23.869782209396362, loss: 26.0080885887146 
Train [20/26] | Epoch [130/160] |	nca: 1.2170429304242134, flat: 0.7314111813902855, pod: 22.653191030025482, loss: 24.601645469665527 
Train [20/26] | Epoch [131/160] |	nca: 1.1974012106657028, flat: 0.7658352237194777, pod: 22.84451001882553, loss: 24.807746291160583 
Train [20/26] | Epoch [132/160] |	nca: 1.2382745034992695, flat: 0.7710098102688789, pod: 22.581015825271606, loss: 24.590299904346466 
Train [20/26] | Epoch [133/160] |	nca: 1.2297541946172714, flat: 0.752326650545001, pod: 22.878807723522186, loss: 24.860888600349426 
Train [20/26] | Epoch [134/160] |	nca: 1.316587932407856, flat: 0.7355921119451523, pod: 22.34344893693924, loss: 24.395628809928894 
Train [20/26] | Epoch [135/160] |	nca: 1.1537212394177914, flat: 0.7558018192648888, pod: 22.967819094657898, loss: 24.877341985702515 
Train [20/26] | Epoch [136/160] |	nca: 1.209614846855402, flat: 0.6705835945904255, pod: 20.841804146766663, loss: 22.722002506256104 
Train [20/26] | Epoch [137/160] |	nca: 1.2056285180151463, flat: 0.7568329870700836, pod: 22.261423408985138, loss: 24.223885118961334 
Train [20/26] | Epoch [138/160] |	nca: 1.1870978586375713, flat: 0.6959372460842133, pod: 21.649553179740906, loss: 23.532588183879852 
Train [20/26] | Epoch [139/160] |	nca: 1.218110378831625, flat: 0.7167459689080715, pod: 22.562708377838135, loss: 24.497564733028412 
Train [20/26] | Epoch [140/160] |	nca: 1.2600830756127834, flat: 0.7038070727139711, pod: 21.258875250816345, loss: 23.22276544570923 
Train [20/26] | Epoch [141/160] |	nca: 1.2943002320826054, flat: 0.658582853153348, pod: 20.634942889213562, loss: 22.58782595396042 
Train [20/26] | Epoch [142/160] |	nca: 1.2005071081221104, flat: 0.6661522034555674, pod: 20.560758113861084, loss: 22.427417278289795 
Train [20/26] | Epoch [143/160] |	nca: 1.246862368658185, flat: 0.6759358327835798, pod: 20.063790917396545, loss: 21.98658913373947 
Train [20/26] | Epoch [144/160] |	nca: 1.2494723908603191, flat: 0.7233761884272099, pod: 20.72262930870056, loss: 22.69547814130783 
Train [20/26] | Epoch [145/160] |	nca: 1.2680344842374325, flat: 0.6311968490481377, pod: 19.38798326253891, loss: 21.287214875221252 
Train [20/26] | Epoch [146/160] |	nca: 1.2465547919273376, flat: 0.6977051720023155, pod: 20.381850600242615, loss: 22.326110541820526 
Train [20/26] | Epoch [147/160] |	nca: 1.2505717538297176, flat: 0.6657028160989285, pod: 19.787052631378174, loss: 21.703327000141144 
Train [20/26] | Epoch [148/160] |	nca: 1.279211837798357, flat: 0.6511707939207554, pod: 19.994475603103638, loss: 21.92485809326172 
Train [20/26] | Epoch [149/160] |	nca: 1.2353739216923714, flat: 0.6671825274825096, pod: 19.827390789985657, loss: 21.729947328567505 
Train [20/26] | Epoch [150/160] |	nca: 1.23526681214571, flat: 0.575413865968585, pod: 18.52799242734909, loss: 20.33867311477661 
Train [20/26] | Epoch [151/160] |	nca: 1.2924121618270874, flat: 0.5968265645205975, pod: 17.78970217704773, loss: 19.678940773010254 
Train [20/26] | Epoch [152/160] |	nca: 1.186265992000699, flat: 0.5590517213568091, pod: 18.05437523126602, loss: 19.7996928691864 
Train [20/26] | Epoch [153/160] |	nca: 1.2442752569913864, flat: 0.6040633618831635, pod: 18.629895091056824, loss: 20.478233635425568 
Train [20/26] | Epoch [154/160] |	nca: 1.3010182678699493, flat: 0.5873948950320482, pod: 18.067436933517456, loss: 19.95585036277771 
Train [20/26] | Epoch [155/160] |	nca: 1.2042617723345757, flat: 0.6042130868881941, pod: 18.54328542947769, loss: 20.35176020860672 
Train [20/26] | Epoch [156/160] |	nca: 1.1507088914513588, flat: 0.5478470660746098, pod: 17.649272799491882, loss: 19.34782898426056 
Train [20/26] | Epoch [157/160] |	nca: 1.2441652230918407, flat: 0.6142853125929832, pod: 18.702800035476685, loss: 20.561250507831573 
Train [20/26] | Epoch [158/160] |	nca: 1.2132805101573467, flat: 0.6013838276267052, pod: 18.153501629829407, loss: 19.968165814876556 
Train [20/26] | Epoch [159/160] |	nca: 1.294975820928812, flat: 0.673797395080328, pod: 19.625187277793884, loss: 21.59396058320999 
Train [20/26] | Epoch [160/160] |	nca: 1.2133055217564106, flat: 0.5686836801469326, pod: 18.16908997297287, loss: 19.95107924938202 
Fine-tuning
Building & updating memory.
Train [20/26] | Epoch [161/180] |	nca: 1.0413905791938305, flat: 0.9849898964166641, pod: 19.620165824890137, loss: 21.646546125411987 
Train [20/26] | Epoch [162/180] |	nca: 0.6565343476831913, flat: 1.023231990635395, pod: 20.024420380592346, loss: 21.70418667793274 
Train [20/26] | Epoch [163/180] |	nca: 0.6532899085432291, flat: 1.0032162703573704, pod: 19.5882226228714, loss: 21.244728803634644 
Train [20/26] | Epoch [164/180] |	nca: 0.5880752913653851, flat: 0.9818233586847782, pod: 19.82638120651245, loss: 21.39627993106842 
Train [20/26] | Epoch [165/180] |	nca: 0.5174233559519053, flat: 0.9516101330518723, pod: 19.467548966407776, loss: 20.936582326889038 
Train [20/26] | Epoch [166/180] |	nca: 0.49867269210517406, flat: 0.9680917672812939, pod: 19.118532061576843, loss: 20.585296511650085 
Train [20/26] | Epoch [167/180] |	nca: 0.5310424901545048, flat: 0.9614070579409599, pod: 19.020376324653625, loss: 20.512825965881348 
Train [20/26] | Epoch [168/180] |	nca: 0.4946448504924774, flat: 1.0130110010504723, pod: 19.8305082321167, loss: 21.33816409111023 
Train [20/26] | Epoch [169/180] |	nca: 0.5280642304569483, flat: 0.9866670556366444, pod: 19.832614421844482, loss: 21.34734582901001 
Train [20/26] | Epoch [170/180] |	nca: 0.5168514829128981, flat: 0.9593262150883675, pod: 19.515339970588684, loss: 20.991517782211304 
Train [20/26] | Epoch [171/180] |	nca: 0.5116843059659004, flat: 0.9818095676600933, pod: 19.466525435447693, loss: 20.96001935005188 
Train [20/26] | Epoch [172/180] |	nca: 0.49044700153172016, flat: 1.0126162432134151, pod: 20.036247491836548, loss: 21.539310693740845 
Train [20/26] | Epoch [173/180] |	nca: 0.5009097494184971, flat: 0.9647932164371014, pod: 19.18785262107849, loss: 20.653555393218994 
Train [20/26] | Epoch [174/180] |	nca: 0.4615585505962372, flat: 0.9505021832883358, pod: 19.07910430431366, loss: 20.491164922714233 
Train [20/26] | Epoch [175/180] |	nca: 0.49847462028265, flat: 0.9545802921056747, pod: 19.337977409362793, loss: 20.791032195091248 
Train [20/26] | Epoch [176/180] |	nca: 0.456726623699069, flat: 0.9771182239055634, pod: 19.62106764316559, loss: 21.054912567138672 
Train [20/26] | Epoch [177/180] |	nca: 0.4695282578468323, flat: 0.9941226094961166, pod: 19.6432204246521, loss: 21.106871247291565 
Train [20/26] | Epoch [178/180] |	nca: 0.4737626928836107, flat: 0.9843132272362709, pod: 19.41896641254425, loss: 20.877042174339294 
Train [20/26] | Epoch [179/180] |	nca: 0.4529055245220661, flat: 1.007707092911005, pod: 19.86027717590332, loss: 21.320889830589294 
Train [20/26] | Epoch [180/180] |	nca: 0.47514987736940384, flat: 0.9700661152601242, pod: 19.454583406448364, loss: 20.899799466133118 
after task
Building & updating memory.
after task
Eval on 0->88.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6287999999999999.
Current acc: {'total': 0.566, '00-09': 0.619, '10-19': 0.558, '20-29': 0.453, '30-39': 0.527, '40-49': 0.548, '50-59': 0.55, '60-69': 0.487, '70-79': 0.643, '80-89': 0.745}.
Avg inc acc top5: 0.8728499999999997.
Current acc top5: {'total': 0.836}.
Forgetting: 0.1991.
Cord metric: 0.64.
Old accuracy: 0.56, mean: 0.62.
New accuracy: 0.89, mean: 0.80.
================Task 20 Start!================
Testing on False unseen tasks (max class = 90).
Set memory of size: 1760.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 20 Training!================
The training samples number: 2760
Train on 88->90.
train task
nb 2760.
Train [21/26] | Epoch [1/160] |	nca: 10.273419827222824, flat: 5.523031771183014, pod: 61.6176518201828, loss: 77.4141035079956 
Train [21/26] | Epoch [2/160] |	nca: 6.195515960454941, flat: 5.171241819858551, pod: 65.18109703063965, loss: 76.54785490036011 
Train [21/26] | Epoch [3/160] |	nca: 5.020754620432854, flat: 4.515802949666977, pod: 61.89671540260315, loss: 71.43327236175537 
Train [21/26] | Epoch [4/160] |	nca: 4.284489810466766, flat: 4.0590682327747345, pod: 59.72743248939514, loss: 68.0709900856018 
Train [21/26] | Epoch [5/160] |	nca: 3.5343255549669266, flat: 3.4988024532794952, pod: 56.62099289894104, loss: 63.65412092208862 
Train [21/26] | Epoch [6/160] |	nca: 3.0964159816503525, flat: 3.0341928005218506, pod: 53.0932674407959, loss: 59.223875999450684 
Train [21/26] | Epoch [7/160] |	nca: 2.761287659406662, flat: 2.8720995038747787, pod: 52.087831020355225, loss: 57.72121858596802 
Train [21/26] | Epoch [8/160] |	nca: 2.9367129653692245, flat: 2.934264987707138, pod: 53.416725397109985, loss: 59.28770327568054 
Train [21/26] | Epoch [9/160] |	nca: 2.8683816492557526, flat: 2.9272219389677048, pod: 54.134106397628784, loss: 59.929710388183594 
Train [21/26] | Epoch [10/160] |	nca: 3.3385888412594795, flat: 3.290585979819298, pod: 54.946239709854126, loss: 61.57541489601135 
Train [21/26] | Epoch [11/160] |	nca: 2.7303681299090385, flat: 2.8628671690821648, pod: 51.076273679733276, loss: 56.669509172439575 
Train [21/26] | Epoch [12/160] |	nca: 2.7716884836554527, flat: 2.9412165358662605, pod: 53.768584966659546, loss: 59.48149037361145 
Train [21/26] | Epoch [13/160] |	nca: 2.742617554962635, flat: 2.909796379506588, pod: 52.97892999649048, loss: 58.63134407997131 
Train [21/26] | Epoch [14/160] |	nca: 2.3746453672647476, flat: 2.6919257193803787, pod: 50.5298011302948, loss: 55.59637236595154 
Train [21/26] | Epoch [15/160] |	nca: 2.5666130259633064, flat: 2.6630918979644775, pod: 52.55009126663208, loss: 57.77979588508606 
Train [21/26] | Epoch [16/160] |	nca: 2.24928680062294, flat: 2.5687168017029762, pod: 49.94717264175415, loss: 54.76517605781555 
Train [21/26] | Epoch [17/160] |	nca: 2.3871525675058365, flat: 2.487423852086067, pod: 50.07838535308838, loss: 54.952962160110474 
Train [21/26] | Epoch [18/160] |	nca: 2.4079728573560715, flat: 2.525188960134983, pod: 48.51571202278137, loss: 53.44887399673462 
Train [21/26] | Epoch [19/160] |	nca: 2.642862379550934, flat: 2.6909676268696785, pod: 51.703657150268555, loss: 57.03748679161072 
Train [21/26] | Epoch [20/160] |	nca: 2.607896998524666, flat: 2.6131055876612663, pod: 49.29709339141846, loss: 54.51809620857239 
Train [21/26] | Epoch [21/160] |	nca: 2.3658789545297623, flat: 2.6051096990704536, pod: 49.336522459983826, loss: 54.3075110912323 
Train [21/26] | Epoch [22/160] |	nca: 2.5242316722869873, flat: 2.8598986864089966, pod: 52.9656035900116, loss: 58.34973406791687 
Train [21/26] | Epoch [23/160] |	nca: 2.381595626473427, flat: 2.5547467097640038, pod: 48.85020399093628, loss: 53.78654670715332 
Train [21/26] | Epoch [24/160] |	nca: 2.2470370307564735, flat: 2.6326809003949165, pod: 50.90447187423706, loss: 55.7841899394989 
Train [21/26] | Epoch [25/160] |	nca: 2.732828065752983, flat: 2.595231421291828, pod: 48.85888338088989, loss: 54.18694305419922 
Train [21/26] | Epoch [26/160] |	nca: 2.185414746403694, flat: 2.317732095718384, pod: 46.647019386291504, loss: 51.150166273117065 
Train [21/26] | Epoch [27/160] |	nca: 2.1698657870292664, flat: 2.2002291455864906, pod: 45.03488910198212, loss: 49.40498328208923 
Train [21/26] | Epoch [28/160] |	nca: 2.1709695383906364, flat: 2.3127215281128883, pod: 46.54041337966919, loss: 51.02410387992859 
Train [21/26] | Epoch [29/160] |	nca: 2.3272007927298546, flat: 2.3407257348299026, pod: 47.91101360321045, loss: 52.57894039154053 
Train [21/26] | Epoch [30/160] |	nca: 2.554035894572735, flat: 2.505783885717392, pod: 47.951438426971436, loss: 53.011258602142334 
Train [21/26] | Epoch [31/160] |	nca: 2.2213705331087112, flat: 2.3735856860876083, pod: 47.07051455974579, loss: 51.665470600128174 
Train [21/26] | Epoch [32/160] |	nca: 2.2128256410360336, flat: 2.243975393474102, pod: 45.76712167263031, loss: 50.223923087120056 
Train [21/26] | Epoch [33/160] |	nca: 2.2239193245768547, flat: 2.3920455276966095, pod: 47.55840587615967, loss: 52.174371004104614 
Train [21/26] | Epoch [34/160] |	nca: 2.3975948095321655, flat: 2.3405646905303, pod: 48.385064244270325, loss: 53.123223543167114 
Train [21/26] | Epoch [35/160] |	nca: 2.2020567134022713, flat: 2.377488538622856, pod: 49.080156683921814, loss: 53.65970230102539 
Train [21/26] | Epoch [36/160] |	nca: 2.0186847001314163, flat: 2.2108800411224365, pod: 45.40717089176178, loss: 49.636735677719116 
Train [21/26] | Epoch [37/160] |	nca: 2.218935798853636, flat: 2.42716696113348, pod: 49.14844846725464, loss: 53.794551372528076 
Train [21/26] | Epoch [38/160] |	nca: 2.200795106589794, flat: 2.3339382633566856, pod: 47.945138335227966, loss: 52.47987174987793 
Train [21/26] | Epoch [39/160] |	nca: 2.139409400522709, flat: 2.277492418885231, pod: 46.91373312473297, loss: 51.33063530921936 
Train [21/26] | Epoch [40/160] |	nca: 2.0288278833031654, flat: 2.1254069954156876, pod: 45.4675213098526, loss: 49.621755838394165 
Train [21/26] | Epoch [41/160] |	nca: 2.0698772966861725, flat: 2.091763988137245, pod: 44.191638231277466, loss: 48.35327982902527 
Train [21/26] | Epoch [42/160] |	nca: 2.3075529262423515, flat: 2.196070335805416, pod: 45.453680872917175, loss: 49.95730495452881 
Train [21/26] | Epoch [43/160] |	nca: 2.116170320659876, flat: 2.3833948150277138, pod: 48.732872009277344, loss: 53.23243689537048 
Train [21/26] | Epoch [44/160] |	nca: 2.136822935193777, flat: 2.2797164618968964, pod: 46.13671398162842, loss: 50.553253531455994 
Train [21/26] | Epoch [45/160] |	nca: 2.0823955833911896, flat: 2.110879510641098, pod: 44.58976674079895, loss: 48.78304159641266 
Train [21/26] | Epoch [46/160] |	nca: 2.1733958311378956, flat: 2.2561108842492104, pod: 47.66126012802124, loss: 52.09076714515686 
Train [21/26] | Epoch [47/160] |	nca: 2.1199827678501606, flat: 2.333824507892132, pod: 47.832237124443054, loss: 52.28604435920715 
Train [21/26] | Epoch [48/160] |	nca: 1.9631182290613651, flat: 2.0960359796881676, pod: 44.422715067863464, loss: 48.48186898231506 
Train [21/26] | Epoch [49/160] |	nca: 2.058761965483427, flat: 2.130312480032444, pod: 45.086745262145996, loss: 49.27582025527954 
Train [21/26] | Epoch [50/160] |	nca: 2.0035862252116203, flat: 2.015568681061268, pod: 43.307665944099426, loss: 47.32682132720947 
Train [21/26] | Epoch [51/160] |	nca: 2.006058894097805, flat: 1.9667618051171303, pod: 42.401947259902954, loss: 46.374767541885376 
Train [21/26] | Epoch [52/160] |	nca: 1.9393288306891918, flat: 2.009910523891449, pod: 43.100475430488586, loss: 47.04971539974213 
Train [21/26] | Epoch [53/160] |	nca: 2.077758200466633, flat: 1.9222805872559547, pod: 43.27858817577362, loss: 47.278626561164856 
Train [21/26] | Epoch [54/160] |	nca: 1.9202819243073463, flat: 1.8744148388504982, pod: 42.46957874298096, loss: 46.264275908470154 
Train [21/26] | Epoch [55/160] |	nca: 1.8598783425986767, flat: 1.826506033539772, pod: 41.45615780353546, loss: 45.142542362213135 
Train [21/26] | Epoch [56/160] |	nca: 1.8958066180348396, flat: 1.8687234744429588, pod: 42.199655413627625, loss: 45.96418511867523 
Train [21/26] | Epoch [57/160] |	nca: 1.960515558719635, flat: 1.9370783567428589, pod: 42.914732217788696, loss: 46.812325954437256 
Train [21/26] | Epoch [58/160] |	nca: 1.9382005333900452, flat: 1.9131197482347488, pod: 41.537959694862366, loss: 45.38927972316742 
Train [21/26] | Epoch [59/160] |	nca: 1.756812423467636, flat: 1.7767796516418457, pod: 40.67910552024841, loss: 44.212698101997375 
Train [21/26] | Epoch [60/160] |	nca: 1.7292026653885841, flat: 1.6206647157669067, pod: 38.31743788719177, loss: 41.66730499267578 
Train [21/26] | Epoch [61/160] |	nca: 1.9209910482168198, flat: 1.7868536710739136, pod: 40.22928464412689, loss: 43.93712937831879 
Train [21/26] | Epoch [62/160] |	nca: 2.0746447257697582, flat: 1.8796237334609032, pod: 40.692702770233154, loss: 44.646971106529236 
Train [21/26] | Epoch [63/160] |	nca: 1.8653521053493023, flat: 1.8430114537477493, pod: 41.31446397304535, loss: 45.02282738685608 
Train [21/26] | Epoch [64/160] |	nca: 1.890916895121336, flat: 1.7226525098085403, pod: 40.848757147789, loss: 44.46232628822327 
Train [21/26] | Epoch [65/160] |	nca: 2.0731806829571724, flat: 1.98273403942585, pod: 42.3202668428421, loss: 46.376181840896606 
Train [21/26] | Epoch [66/160] |	nca: 1.8408108353614807, flat: 1.7918608486652374, pod: 41.131308794021606, loss: 44.76398050785065 
Train [21/26] | Epoch [67/160] |	nca: 1.9491758272051811, flat: 1.880801945924759, pod: 41.10638189315796, loss: 44.93635952472687 
Train [21/26] | Epoch [68/160] |	nca: 1.9413371160626411, flat: 1.8030183389782906, pod: 41.55232620239258, loss: 45.29668152332306 
Train [21/26] | Epoch [69/160] |	nca: 1.8017980009317398, flat: 1.808474026620388, pod: 41.67253375053406, loss: 45.28280591964722 
Train [21/26] | Epoch [70/160] |	nca: 1.8890189714729786, flat: 1.6624824032187462, pod: 40.79137825965881, loss: 44.34287905693054 
Train [21/26] | Epoch [71/160] |	nca: 1.9080474227666855, flat: 1.6857542134821415, pod: 40.54492175579071, loss: 44.138723611831665 
Train [21/26] | Epoch [72/160] |	nca: 1.7673644609749317, flat: 1.5843618027865887, pod: 39.01929247379303, loss: 42.371018409729004 
Train [21/26] | Epoch [73/160] |	nca: 1.8287235237658024, flat: 1.6114946268498898, pod: 38.393247842788696, loss: 41.833465814590454 
Train [21/26] | Epoch [74/160] |	nca: 1.9187278375029564, flat: 1.5822147317230701, pod: 38.12195909023285, loss: 41.62290143966675 
Train [21/26] | Epoch [75/160] |	nca: 1.7433501929044724, flat: 1.8120287582278252, pod: 41.58399963378906, loss: 45.13937866687775 
Train [21/26] | Epoch [76/160] |	nca: 1.849312860518694, flat: 1.5883609913289547, pod: 38.78402888774872, loss: 42.22170269489288 
Train [21/26] | Epoch [77/160] |	nca: 1.7409079745411873, flat: 1.6687835827469826, pod: 39.782811880111694, loss: 43.192503690719604 
Train [21/26] | Epoch [78/160] |	nca: 1.694362610578537, flat: 1.5474652647972107, pod: 37.09049439430237, loss: 40.33232259750366 
Train [21/26] | Epoch [79/160] |	nca: 1.9365243539214134, flat: 1.573942419141531, pod: 38.280470848083496, loss: 41.790937542915344 
Train [21/26] | Epoch [80/160] |	nca: 1.7972386255860329, flat: 1.4302615895867348, pod: 34.92543089389801, loss: 38.152931213378906 
Train [21/26] | Epoch [81/160] |	nca: 1.7286526411771774, flat: 1.5269260704517365, pod: 37.670931935310364, loss: 40.92651069164276 
Train [21/26] | Epoch [82/160] |	nca: 1.8994649723172188, flat: 1.6214362420141697, pod: 39.371567130088806, loss: 42.89246845245361 
Train [21/26] | Epoch [83/160] |	nca: 1.6499741449952126, flat: 1.409835048019886, pod: 36.131529688835144, loss: 39.191338539123535 
Train [21/26] | Epoch [84/160] |	nca: 1.7280606739223003, flat: 1.44594282284379, pod: 36.068888425827026, loss: 39.24289166927338 
Train [21/26] | Epoch [85/160] |	nca: 1.7281192652881145, flat: 1.3800045773386955, pod: 35.376402735710144, loss: 38.48452651500702 
Train [21/26] | Epoch [86/160] |	nca: 1.6901643574237823, flat: 1.325752131640911, pod: 35.490612506866455, loss: 38.50652897357941 
Train [21/26] | Epoch [87/160] |	nca: 1.8633722960948944, flat: 1.3998603001236916, pod: 36.09256839752197, loss: 39.35580086708069 
Train [21/26] | Epoch [88/160] |	nca: 1.712652277201414, flat: 1.3726086281239986, pod: 35.60387372970581, loss: 38.68913459777832 
Train [21/26] | Epoch [89/160] |	nca: 1.7291721738874912, flat: 1.4448566809296608, pod: 36.12158000469208, loss: 39.29560887813568 
Train [21/26] | Epoch [90/160] |	nca: 1.609429795295, flat: 1.2840376943349838, pod: 34.28807079792023, loss: 37.181538224220276 
Train [21/26] | Epoch [91/160] |	nca: 1.739861685782671, flat: 1.406413123011589, pod: 36.976338624954224, loss: 40.12261343002319 
Train [21/26] | Epoch [92/160] |	nca: 1.746651541441679, flat: 1.4109749384224415, pod: 35.9420166015625, loss: 39.09964311122894 
Train [21/26] | Epoch [93/160] |	nca: 1.7913472466170788, flat: 1.3176219128072262, pod: 33.88815987110138, loss: 36.99712896347046 
Train [21/26] | Epoch [94/160] |	nca: 1.6968022212386131, flat: 1.3058340065181255, pod: 34.006121039390564, loss: 37.00875723361969 
Train [21/26] | Epoch [95/160] |	nca: 1.6456301659345627, flat: 1.2770006619393826, pod: 33.76371788978577, loss: 36.68634879589081 
Train [21/26] | Epoch [96/160] |	nca: 1.6715883240103722, flat: 1.3303936310112476, pod: 34.44637882709503, loss: 37.4483608007431 
Train [21/26] | Epoch [97/160] |	nca: 1.6911399886012077, flat: 1.3400120176374912, pod: 34.57222664356232, loss: 37.60337841510773 
Train [21/26] | Epoch [98/160] |	nca: 1.8402117416262627, flat: 1.2744874842464924, pod: 33.26364874839783, loss: 36.378347873687744 
Train [21/26] | Epoch [99/160] |	nca: 1.714205987751484, flat: 1.2495306394994259, pod: 31.66816246509552, loss: 34.63189911842346 
Train [21/26] | Epoch [100/160] |	nca: 1.7409855350852013, flat: 1.2469379715621471, pod: 32.24106764793396, loss: 35.22899115085602 
Train [21/26] | Epoch [101/160] |	nca: 1.5071808844804764, flat: 1.2039004042744637, pod: 32.5873829126358, loss: 35.29846405982971 
Train [21/26] | Epoch [102/160] |	nca: 1.6905447691679, flat: 1.1132969297468662, pod: 31.980934262275696, loss: 34.78477585315704 
Train [21/26] | Epoch [103/160] |	nca: 1.5883316956460476, flat: 1.0821114890277386, pod: 30.974560856819153, loss: 33.64500403404236 
Train [21/26] | Epoch [104/160] |	nca: 1.644504938274622, flat: 1.187964666634798, pod: 31.72117805480957, loss: 34.55364751815796 
Train [21/26] | Epoch [105/160] |	nca: 1.5745946988463402, flat: 1.0837455429136753, pod: 30.526326060295105, loss: 33.18466579914093 
Train [21/26] | Epoch [106/160] |	nca: 1.5614044666290283, flat: 0.9924621246755123, pod: 29.236485362052917, loss: 31.79035174846649 
Train [21/26] | Epoch [107/160] |	nca: 1.6931328885257244, flat: 1.0661768801510334, pod: 30.01888334751129, loss: 32.77819311618805 
Train [21/26] | Epoch [108/160] |	nca: 1.6421503238379955, flat: 1.1736796610057354, pod: 31.23307228088379, loss: 34.04890215396881 
Train [21/26] | Epoch [109/160] |	nca: 1.5348324961960316, flat: 1.0157951712608337, pod: 29.436216831207275, loss: 31.986844658851624 
Train [21/26] | Epoch [110/160] |	nca: 1.6427870355546474, flat: 1.0682679042220116, pod: 31.113394498825073, loss: 33.82444953918457 
Train [21/26] | Epoch [111/160] |	nca: 1.4923919774591923, flat: 1.0386779233813286, pod: 28.70554792881012, loss: 31.236617922782898 
Train [21/26] | Epoch [112/160] |	nca: 1.6762266159057617, flat: 1.0137772038578987, pod: 30.51549518108368, loss: 33.205499053001404 
Train [21/26] | Epoch [113/160] |	nca: 1.5620473809540272, flat: 0.9479162283241749, pod: 29.46804702281952, loss: 31.978010416030884 
Train [21/26] | Epoch [114/160] |	nca: 1.743954811245203, flat: 0.97691585496068, pod: 28.361931204795837, loss: 31.082801818847656 
Train [21/26] | Epoch [115/160] |	nca: 1.561121940612793, flat: 0.9867649879306555, pod: 28.305819392204285, loss: 30.85370647907257 
Train [21/26] | Epoch [116/160] |	nca: 1.5642009302973747, flat: 0.885415380820632, pod: 27.467390418052673, loss: 29.917006611824036 
Train [21/26] | Epoch [117/160] |	nca: 1.6035313829779625, flat: 0.8485794011503458, pod: 27.40044414997101, loss: 29.85255491733551 
Train [21/26] | Epoch [118/160] |	nca: 1.5782765224575996, flat: 0.8933372609317303, pod: 27.036343574523926, loss: 29.507957458496094 
Train [21/26] | Epoch [119/160] |	nca: 1.6088405475020409, flat: 0.924861166626215, pod: 28.429630398750305, loss: 30.963332176208496 
Train [21/26] | Epoch [120/160] |	nca: 1.5204733833670616, flat: 0.9410159662365913, pod: 28.4770667552948, loss: 30.93855631351471 
Train [21/26] | Epoch [121/160] |	nca: 1.6109466813504696, flat: 0.8865092135965824, pod: 28.088520765304565, loss: 30.585976600646973 
Train [21/26] | Epoch [122/160] |	nca: 1.4925330467522144, flat: 0.861392306163907, pod: 26.48677408695221, loss: 28.840699434280396 
Train [21/26] | Epoch [123/160] |	nca: 1.511223442852497, flat: 0.7915884479880333, pod: 25.655247271060944, loss: 27.958059072494507 
Train [21/26] | Epoch [124/160] |	nca: 1.5885066948831081, flat: 0.8196059558540583, pod: 25.652007222175598, loss: 28.06011974811554 
Train [21/26] | Epoch [125/160] |	nca: 1.5906329527497292, flat: 0.8372064679861069, pod: 25.997554540634155, loss: 28.42539381980896 
Train [21/26] | Epoch [126/160] |	nca: 1.47957568988204, flat: 0.8166237305849791, pod: 26.12101435661316, loss: 28.417213916778564 
Train [21/26] | Epoch [127/160] |	nca: 1.527981348335743, flat: 0.8030323646962643, pod: 25.14723891019821, loss: 27.47825253009796 
Train [21/26] | Epoch [128/160] |	nca: 1.5258127190172672, flat: 0.7683154232800007, pod: 24.73949432373047, loss: 27.03362238407135 
Train [21/26] | Epoch [129/160] |	nca: 1.506763480603695, flat: 0.7623208351433277, pod: 24.87617588043213, loss: 27.145260095596313 
Train [21/26] | Epoch [130/160] |	nca: 1.5895631611347198, flat: 0.7926050014793873, pod: 25.255232512950897, loss: 27.63740050792694 
Train [21/26] | Epoch [131/160] |	nca: 1.5255875810980797, flat: 0.7922724988311529, pod: 25.184598207473755, loss: 27.502458333969116 
Train [21/26] | Epoch [132/160] |	nca: 1.547808464616537, flat: 0.7240224685519934, pod: 23.852007627487183, loss: 26.123838543891907 
Train [21/26] | Epoch [133/160] |	nca: 1.5294469445943832, flat: 0.736439635977149, pod: 23.62568438053131, loss: 25.89157098531723 
Train [21/26] | Epoch [134/160] |	nca: 1.6089340224862099, flat: 0.7145375870168209, pod: 23.049073576927185, loss: 25.37254500389099 
Train [21/26] | Epoch [135/160] |	nca: 1.4111501388251781, flat: 0.7260096706449986, pod: 23.44412136077881, loss: 25.581281304359436 
Train [21/26] | Epoch [136/160] |	nca: 1.554212350398302, flat: 0.6738745663315058, pod: 22.91969919204712, loss: 25.14778620004654 
Train [21/26] | Epoch [137/160] |	nca: 1.522381380200386, flat: 0.6730620209127665, pod: 22.62417721748352, loss: 24.819620549678802 
Train [21/26] | Epoch [138/160] |	nca: 1.4761089645326138, flat: 0.6673717889934778, pod: 22.223767518997192, loss: 24.367248475551605 
Train [21/26] | Epoch [139/160] |	nca: 1.4489504545927048, flat: 0.6455689370632172, pod: 21.813173472881317, loss: 23.907692790031433 
Train [21/26] | Epoch [140/160] |	nca: 1.565601833164692, flat: 0.6239267233759165, pod: 22.006173253059387, loss: 24.195701956748962 
Train [21/26] | Epoch [141/160] |	nca: 1.4942144677042961, flat: 0.6304155178368092, pod: 21.667273461818695, loss: 23.791903614997864 
Train [21/26] | Epoch [142/160] |	nca: 1.5198811292648315, flat: 0.6486323531717062, pod: 21.66105145215988, loss: 23.829564809799194 
Train [21/26] | Epoch [143/160] |	nca: 1.452833529561758, flat: 0.5771953165531158, pod: 20.546453893184662, loss: 22.576482713222504 
Train [21/26] | Epoch [144/160] |	nca: 1.5334855690598488, flat: 0.6551465969532728, pod: 21.34818857908249, loss: 23.53682106733322 
Train [21/26] | Epoch [145/160] |	nca: 1.5244957469403744, flat: 0.6364961750805378, pod: 21.925139486789703, loss: 24.0861314535141 
Train [21/26] | Epoch [146/160] |	nca: 1.553356260061264, flat: 0.6220398601144552, pod: 20.96096897125244, loss: 23.136365234851837 
Train [21/26] | Epoch [147/160] |	nca: 1.4947038553655148, flat: 0.5934029761701822, pod: 20.896178483963013, loss: 22.98428523540497 
Train [21/26] | Epoch [148/160] |	nca: 1.5338611863553524, flat: 0.5980145987123251, pod: 20.339083969593048, loss: 22.470959782600403 
Train [21/26] | Epoch [149/160] |	nca: 1.5640720836818218, flat: 0.5886290483176708, pod: 20.72233420610428, loss: 22.87503558397293 
Train [21/26] | Epoch [150/160] |	nca: 1.4300515092909336, flat: 0.6039565298706293, pod: 20.224487006664276, loss: 22.258494794368744 
Train [21/26] | Epoch [151/160] |	nca: 1.5679922513663769, flat: 0.5843178909271955, pod: 20.491430521011353, loss: 22.643740713596344 
Train [21/26] | Epoch [152/160] |	nca: 1.6298010423779488, flat: 0.540746483951807, pod: 18.887019395828247, loss: 21.057566821575165 
Train [21/26] | Epoch [153/160] |	nca: 1.4661837592720985, flat: 0.6066014152020216, pod: 20.998209178447723, loss: 23.070994436740875 
Train [21/26] | Epoch [154/160] |	nca: 1.4369074366986752, flat: 0.5188664216548204, pod: 19.442338526248932, loss: 21.39811259508133 
Train [21/26] | Epoch [155/160] |	nca: 1.5111028738319874, flat: 0.6201980020850897, pod: 20.8380047082901, loss: 22.969305872917175 
Train [21/26] | Epoch [156/160] |	nca: 1.4907965511083603, flat: 0.5542330481112003, pod: 19.888634502887726, loss: 21.933664202690125 
Train [21/26] | Epoch [157/160] |	nca: 1.5223622024059296, flat: 0.5674199014902115, pod: 20.00067901611328, loss: 22.090461134910583 
Train [21/26] | Epoch [158/160] |	nca: 1.4932421706616879, flat: 0.5564376376569271, pod: 19.288702368736267, loss: 21.338382303714752 
Train [21/26] | Epoch [159/160] |	nca: 1.4701288156211376, flat: 0.5692587345838547, pod: 20.083873391151428, loss: 22.123260974884033 
Train [21/26] | Epoch [160/160] |	nca: 1.536966897547245, flat: 0.5408762134611607, pod: 19.223791122436523, loss: 21.30163425207138 
Fine-tuning
Building & updating memory.
Train [21/26] | Epoch [161/180] |	nca: 1.1734003722667694, flat: 1.1475067622959614, pod: 21.228636741638184, loss: 23.549543976783752 
Train [21/26] | Epoch [162/180] |	nca: 1.2105785124003887, flat: 1.1195254810154438, pod: 20.591102480888367, loss: 22.92120659351349 
Train [21/26] | Epoch [163/180] |	nca: 1.6526076719164848, flat: 1.2578434087336063, pod: 21.552696228027344, loss: 24.463147044181824 
Train [21/26] | Epoch [164/180] |	nca: 1.3160672299563885, flat: 1.113003358244896, pod: 21.21025323867798, loss: 23.639323711395264 
Train [21/26] | Epoch [165/180] |	nca: 2.045063052326441, flat: 1.2949450872838497, pod: 21.241333663463593, loss: 24.581342101097107 
Train [21/26] | Epoch [166/180] |	nca: 3.7435362488031387, flat: 1.0176591258496046, pod: 20.620893836021423, loss: 25.382089257240295 
Train [21/26] | Epoch [167/180] |	nca: 2.3177699521183968, flat: 0.9332930222153664, pod: 20.38064455986023, loss: 23.631707549095154 
Train [21/26] | Epoch [168/180] |	nca: 1.5563021451234818, flat: 1.0145616009831429, pod: 20.735751748085022, loss: 23.306615471839905 
Train [21/26] | Epoch [169/180] |	nca: 1.7489300295710564, flat: 1.0804425105452538, pod: 20.880003809928894, loss: 23.709376454353333 
Train [21/26] | Epoch [170/180] |	nca: 1.9213042594492435, flat: 1.0590175427496433, pod: 21.360980987548828, loss: 24.341302633285522 
Train [21/26] | Epoch [171/180] |	nca: 1.9206374399363995, flat: 1.158246275037527, pod: 21.585186779499054, loss: 24.66407036781311 
Train [21/26] | Epoch [172/180] |	nca: 3.585229404270649, flat: 1.1718680709600449, pod: 21.95904004573822, loss: 26.716137528419495 
Train [21/26] | Epoch [173/180] |	nca: 1.875922553241253, flat: 1.2121563963592052, pod: 21.4002548456192, loss: 24.48833405971527 
Train [21/26] | Epoch [174/180] |	nca: 3.2242912873625755, flat: 1.3449454940855503, pod: 21.93794345855713, loss: 26.507179975509644 
Train [21/26] | Epoch [175/180] |	nca: 3.5100129917263985, flat: 1.176211578771472, pod: 21.239075899124146, loss: 25.92530083656311 
Train [21/26] | Epoch [176/180] |	nca: 4.040541484951973, flat: 1.181064747273922, pod: 21.756728768348694, loss: 26.97833514213562 
Train [21/26] | Epoch [177/180] |	nca: 3.838570401072502, flat: 1.0650274232029915, pod: 21.0356662273407, loss: 25.939264178276062 
Train [21/26] | Epoch [178/180] |	nca: 2.2884079553186893, flat: 1.0234450735151768, pod: 20.843570470809937, loss: 24.155423521995544 
Train [21/26] | Epoch [179/180] |	nca: 3.6751972809433937, flat: 1.1975915059447289, pod: 21.335224628448486, loss: 26.20801341533661 
Train [21/26] | Epoch [180/180] |	nca: 3.3387698754668236, flat: 1.068732250481844, pod: 21.01276558637619, loss: 25.420267581939697 
after task
Building & updating memory.
after task
Eval on 0->90.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6242380952380951.
Current acc: {'total': 0.533, '00-09': 0.621, '10-19': 0.516, '20-29': 0.449, '30-39': 0.48, '40-49': 0.568, '50-59': 0.533, '60-69': 0.434, '70-79': 0.579, '80-89': 0.613}.
Avg inc acc top5: 0.8703333333333331.
Current acc top5: {'total': 0.82}.
Forgetting: 0.23280000000000003.
Cord metric: 0.62.
Old accuracy: 0.53, mean: 0.61.
New accuracy: 0.48, mean: 0.79.
================Task 21 Start!================
Testing on False unseen tasks (max class = 92).
Set memory of size: 1800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 21 Training!================
The training samples number: 2800
Train on 90->92.
train task
nb 2800.
Train [22/26] | Epoch [1/160] |	nca: 13.462197870016098, flat: 5.592846103012562, pod: 55.947824001312256, loss: 75.00286817550659 
Train [22/26] | Epoch [2/160] |	nca: 8.386023730039597, flat: 5.617443114519119, pod: 63.023372650146484, loss: 77.02683925628662 
Train [22/26] | Epoch [3/160] |	nca: 6.54878856241703, flat: 4.836642786860466, pod: 61.09317421913147, loss: 72.47860550880432 
Train [22/26] | Epoch [4/160] |	nca: 5.901932552456856, flat: 4.3974111676216125, pod: 59.46725940704346, loss: 69.76660346984863 
Train [22/26] | Epoch [5/160] |	nca: 4.290700189769268, flat: 3.56559582054615, pod: 54.46299457550049, loss: 62.31928992271423 
Train [22/26] | Epoch [6/160] |	nca: 3.990768887102604, flat: 3.2856648564338684, pod: 53.527663707733154, loss: 60.804097175598145 
Train [22/26] | Epoch [7/160] |	nca: 3.764957442879677, flat: 3.000980146229267, pod: 51.211066484451294, loss: 57.977004528045654 
Train [22/26] | Epoch [8/160] |	nca: 3.7814146503806114, flat: 2.98751300573349, pod: 50.77470898628235, loss: 57.5436372756958 
Train [22/26] | Epoch [9/160] |	nca: 3.6511639431118965, flat: 3.009843736886978, pod: 51.135722160339355, loss: 57.79672980308533 
Train [22/26] | Epoch [10/160] |	nca: 3.6698131784796715, flat: 3.021337777376175, pod: 50.0847270488739, loss: 56.775877952575684 
Train [22/26] | Epoch [11/160] |	nca: 4.0453865975141525, flat: 3.388066902756691, pod: 54.0820472240448, loss: 61.51550102233887 
Train [22/26] | Epoch [12/160] |	nca: 3.2278311401605606, flat: 2.999857097864151, pod: 51.83286690711975, loss: 58.06055545806885 
Train [22/26] | Epoch [13/160] |	nca: 2.992494523525238, flat: 2.7674426659941673, pod: 50.23798680305481, loss: 55.99792408943176 
Train [22/26] | Epoch [14/160] |	nca: 3.3705931082367897, flat: 2.7086002603173256, pod: 47.92672872543335, loss: 54.005921602249146 
Train [22/26] | Epoch [15/160] |	nca: 3.144095756113529, flat: 2.7452885806560516, pod: 46.90951108932495, loss: 52.79889512062073 
Train [22/26] | Epoch [16/160] |	nca: 2.8830601349473, flat: 2.476417660713196, pod: 46.187559723854065, loss: 51.54703712463379 
Train [22/26] | Epoch [17/160] |	nca: 3.072191007435322, flat: 2.5270486623048782, pod: 46.88413369655609, loss: 52.483373165130615 
Train [22/26] | Epoch [18/160] |	nca: 3.1013279482722282, flat: 2.6172500625252724, pod: 48.80053353309631, loss: 54.51911234855652 
Train [22/26] | Epoch [19/160] |	nca: 2.9147576689720154, flat: 2.5615945011377335, pod: 47.40567994117737, loss: 52.88203263282776 
Train [22/26] | Epoch [20/160] |	nca: 2.861512303352356, flat: 2.4951513782143593, pod: 46.83812475204468, loss: 52.19478893280029 
Train [22/26] | Epoch [21/160] |	nca: 3.1701700091362, flat: 2.4236410707235336, pod: 45.21355330944061, loss: 50.807363986968994 
Train [22/26] | Epoch [22/160] |	nca: 3.1902308017015457, flat: 2.6592082530260086, pod: 46.65466523170471, loss: 52.50410437583923 
Train [22/26] | Epoch [23/160] |	nca: 2.7848567590117455, flat: 2.4879796281456947, pod: 46.33878302574158, loss: 51.61161971092224 
Train [22/26] | Epoch [24/160] |	nca: 2.946536898612976, flat: 2.444898322224617, pod: 46.973058342933655, loss: 52.36449337005615 
Train [22/26] | Epoch [25/160] |	nca: 2.7982596829533577, flat: 2.4732169285416603, pod: 46.89929986000061, loss: 52.17077660560608 
Train [22/26] | Epoch [26/160] |	nca: 2.685813643038273, flat: 2.36189241707325, pod: 44.84500968456268, loss: 49.8927161693573 
Train [22/26] | Epoch [27/160] |	nca: 2.8713654279708862, flat: 2.344680219888687, pod: 45.378321409225464, loss: 50.594367265701294 
Train [22/26] | Epoch [28/160] |	nca: 2.8051538839936256, flat: 2.4749816358089447, pod: 45.402677059173584, loss: 50.682812213897705 
Train [22/26] | Epoch [29/160] |	nca: 2.548256553709507, flat: 2.347103200852871, pod: 45.45514190196991, loss: 50.350502014160156 
Train [22/26] | Epoch [30/160] |	nca: 2.7276850640773773, flat: 2.3854821175336838, pod: 45.70378291606903, loss: 50.8169504404068 
Train [22/26] | Epoch [31/160] |	nca: 2.923091769218445, flat: 2.5476541966199875, pod: 47.7038733959198, loss: 53.17461967468262 
Train [22/26] | Epoch [32/160] |	nca: 2.7146850749850273, flat: 2.326752170920372, pod: 42.9097763299942, loss: 47.95121359825134 
Train [22/26] | Epoch [33/160] |	nca: 2.6218960881233215, flat: 2.2450327575206757, pod: 44.32513105869293, loss: 49.1920599937439 
Train [22/26] | Epoch [34/160] |	nca: 2.6963329389691353, flat: 2.293589860200882, pod: 44.54169809818268, loss: 49.5316207408905 
Train [22/26] | Epoch [35/160] |	nca: 2.5561838895082474, flat: 2.11617648601532, pod: 42.84180498123169, loss: 47.51416540145874 
Train [22/26] | Epoch [36/160] |	nca: 2.5580044090747833, flat: 2.2893895506858826, pod: 44.212175726890564, loss: 49.05956959724426 
Train [22/26] | Epoch [37/160] |	nca: 2.9707012102007866, flat: 2.46624568849802, pod: 47.501927614212036, loss: 52.9388747215271 
Train [22/26] | Epoch [38/160] |	nca: 2.513636536896229, flat: 2.3054548129439354, pod: 45.843618392944336, loss: 50.66270971298218 
Train [22/26] | Epoch [39/160] |	nca: 2.806026205420494, flat: 2.3095763698220253, pod: 44.864983320236206, loss: 49.98058581352234 
Train [22/26] | Epoch [40/160] |	nca: 2.4572872146964073, flat: 2.1492935717105865, pod: 42.16644763946533, loss: 46.773027777671814 
Train [22/26] | Epoch [41/160] |	nca: 2.7330827862024307, flat: 2.2639113143086433, pod: 44.858046770095825, loss: 49.85504102706909 
Train [22/26] | Epoch [42/160] |	nca: 2.9041343182325363, flat: 2.4480376839637756, pod: 46.75842905044556, loss: 52.11060118675232 
Train [22/26] | Epoch [43/160] |	nca: 2.5343750417232513, flat: 2.3391500040888786, pod: 45.270232915878296, loss: 50.143758058547974 
Train [22/26] | Epoch [44/160] |	nca: 2.7519894912838936, flat: 2.2938274294137955, pod: 44.52938365936279, loss: 49.57520031929016 
Train [22/26] | Epoch [45/160] |	nca: 2.567551851272583, flat: 2.1966165974736214, pod: 43.14137601852417, loss: 47.90554475784302 
Train [22/26] | Epoch [46/160] |	nca: 2.8336314111948013, flat: 2.2346692457795143, pod: 43.32445275783539, loss: 48.39275348186493 
Train [22/26] | Epoch [47/160] |	nca: 2.6327498629689217, flat: 2.0633734688162804, pod: 41.71171021461487, loss: 46.40783357620239 
Train [22/26] | Epoch [48/160] |	nca: 2.6932635977864265, flat: 2.3842013999819756, pod: 45.11794698238373, loss: 50.195411920547485 
Train [22/26] | Epoch [49/160] |	nca: 2.345615677535534, flat: 2.0810707733035088, pod: 42.2513827085495, loss: 46.67806959152222 
Train [22/26] | Epoch [50/160] |	nca: 2.6516346856951714, flat: 2.0482683405280113, pod: 42.307974219322205, loss: 47.00787663459778 
Train [22/26] | Epoch [51/160] |	nca: 2.8312184885144234, flat: 2.1339096426963806, pod: 42.83841001987457, loss: 47.80353784561157 
Train [22/26] | Epoch [52/160] |	nca: 2.4339236840605736, flat: 2.15378500521183, pod: 43.1019252538681, loss: 47.68963420391083 
Train [22/26] | Epoch [53/160] |	nca: 2.312825731933117, flat: 1.8750493824481964, pod: 40.75178360939026, loss: 44.939658522605896 
Train [22/26] | Epoch [54/160] |	nca: 2.300184942781925, flat: 1.9879641830921173, pod: 41.50895392894745, loss: 45.79710292816162 
Train [22/26] | Epoch [55/160] |	nca: 2.4108113572001457, flat: 1.9243812784552574, pod: 41.25633001327515, loss: 45.59152269363403 
Train [22/26] | Epoch [56/160] |	nca: 2.477839268743992, flat: 2.0971860885620117, pod: 42.35340714454651, loss: 46.92843246459961 
Train [22/26] | Epoch [57/160] |	nca: 2.499495480209589, flat: 2.0816437155008316, pod: 42.101688742637634, loss: 46.682828068733215 
Train [22/26] | Epoch [58/160] |	nca: 2.521704338490963, flat: 2.0646302178502083, pod: 41.9803010225296, loss: 46.566635847091675 
Train [22/26] | Epoch [59/160] |	nca: 2.4570758044719696, flat: 2.0212833508849144, pod: 40.53534817695618, loss: 45.013707399368286 
Train [22/26] | Epoch [60/160] |	nca: 2.387854792177677, flat: 1.8484700545668602, pod: 39.23021054267883, loss: 43.466535806655884 
Train [22/26] | Epoch [61/160] |	nca: 2.495027080178261, flat: 1.8950538486242294, pod: 40.0069500207901, loss: 44.39703106880188 
Train [22/26] | Epoch [62/160] |	nca: 2.1760941594839096, flat: 1.64314304292202, pod: 36.61187386512756, loss: 40.431111574172974 
Train [22/26] | Epoch [63/160] |	nca: 2.3198572397232056, flat: 1.711482122540474, pod: 38.59334945678711, loss: 42.62468886375427 
Train [22/26] | Epoch [64/160] |	nca: 2.3625225126743317, flat: 1.9107077345252037, pod: 39.682846546173096, loss: 43.95607662200928 
Train [22/26] | Epoch [65/160] |	nca: 2.4489080756902695, flat: 1.971366822719574, pod: 41.56046283245087, loss: 45.98073756694794 
Train [22/26] | Epoch [66/160] |	nca: 2.2693622037768364, flat: 1.7271981686353683, pod: 37.58404886722565, loss: 41.58060932159424 
Train [22/26] | Epoch [67/160] |	nca: 2.3096669763326645, flat: 1.7306201681494713, pod: 38.29439055919647, loss: 42.33467745780945 
Train [22/26] | Epoch [68/160] |	nca: 2.4206106439232826, flat: 1.6802613362669945, pod: 37.13283634185791, loss: 41.23370802402496 
Train [22/26] | Epoch [69/160] |	nca: 2.2440457940101624, flat: 1.7216797396540642, pod: 37.647972106933594, loss: 41.61369740962982 
Train [22/26] | Epoch [70/160] |	nca: 2.3121179789304733, flat: 1.6790460906922817, pod: 37.22144305706024, loss: 41.21260714530945 
Train [22/26] | Epoch [71/160] |	nca: 2.364045448601246, flat: 1.8657396361231804, pod: 40.82755923271179, loss: 45.05734431743622 
Train [22/26] | Epoch [72/160] |	nca: 2.278538964688778, flat: 1.7042818069458008, pod: 38.565640926361084, loss: 42.54846155643463 
Train [22/26] | Epoch [73/160] |	nca: 2.3155839294195175, flat: 1.703226026147604, pod: 38.56674671173096, loss: 42.585556626319885 
Train [22/26] | Epoch [74/160] |	nca: 2.4301709830760956, flat: 1.766056090593338, pod: 38.96185624599457, loss: 43.15808343887329 
Train [22/26] | Epoch [75/160] |	nca: 2.327085368335247, flat: 1.7844727784395218, pod: 38.039156556129456, loss: 42.150714635849 
Train [22/26] | Epoch [76/160] |	nca: 2.2154830619692802, flat: 1.5901644974946976, pod: 35.881213426589966, loss: 39.68686127662659 
Train [22/26] | Epoch [77/160] |	nca: 2.242847591638565, flat: 1.5255348943173885, pod: 35.52370536327362, loss: 39.29208767414093 
Train [22/26] | Epoch [78/160] |	nca: 2.1176812797784805, flat: 1.4658151417970657, pod: 34.96542739868164, loss: 38.54892385005951 
Train [22/26] | Epoch [79/160] |	nca: 2.2198388278484344, flat: 1.5209663324058056, pod: 34.855618953704834, loss: 38.59642422199249 
Train [22/26] | Epoch [80/160] |	nca: 2.284839317202568, flat: 1.5421993918716908, pod: 34.71321153640747, loss: 38.540249824523926 
Train [22/26] | Epoch [81/160] |	nca: 2.262986049056053, flat: 1.5955247431993484, pod: 36.929394602775574, loss: 40.78790557384491 
Train [22/26] | Epoch [82/160] |	nca: 2.3374447524547577, flat: 1.4916512593626976, pod: 35.39651894569397, loss: 39.22561502456665 
Train [22/26] | Epoch [83/160] |	nca: 2.222717948257923, flat: 1.5229004546999931, pod: 35.1706782579422, loss: 38.91629660129547 
Train [22/26] | Epoch [84/160] |	nca: 2.127705901861191, flat: 1.447453286498785, pod: 34.407352685928345, loss: 37.98251211643219 
Train [22/26] | Epoch [85/160] |	nca: 2.1404064409434795, flat: 1.408340685069561, pod: 34.41207432746887, loss: 37.96082150936127 
Train [22/26] | Epoch [86/160] |	nca: 2.315003290772438, flat: 1.4419121034443378, pod: 34.37086260318756, loss: 38.12777817249298 
Train [22/26] | Epoch [87/160] |	nca: 2.0555900037288666, flat: 1.426677718758583, pod: 34.028101086616516, loss: 37.51036870479584 
Train [22/26] | Epoch [88/160] |	nca: 2.082206793129444, flat: 1.4353571869432926, pod: 34.061647176742554, loss: 37.57921099662781 
Train [22/26] | Epoch [89/160] |	nca: 2.1396040841937065, flat: 1.4154298566281796, pod: 34.81060290336609, loss: 38.36563718318939 
Train [22/26] | Epoch [90/160] |	nca: 2.0494058951735497, flat: 1.414230514317751, pod: 33.708223938941956, loss: 37.171860337257385 
Train [22/26] | Epoch [91/160] |	nca: 2.0091908127069473, flat: 1.3528441116213799, pod: 32.73969495296478, loss: 36.10172951221466 
Train [22/26] | Epoch [92/160] |	nca: 2.06391454488039, flat: 1.2677884213626385, pod: 31.624154806137085, loss: 34.95585739612579 
Train [22/26] | Epoch [93/160] |	nca: 2.0789505057036877, flat: 1.3413885831832886, pod: 32.79570436477661, loss: 36.21604359149933 
Train [22/26] | Epoch [94/160] |	nca: 2.0236528143286705, flat: 1.3693988472223282, pod: 33.80544435977936, loss: 37.19849646091461 
Train [22/26] | Epoch [95/160] |	nca: 2.1884825825691223, flat: 1.3380051888525486, pod: 32.748090624809265, loss: 36.274578332901 
Train [22/26] | Epoch [96/160] |	nca: 2.0912598967552185, flat: 1.3073701336979866, pod: 33.33506214618683, loss: 36.733692049980164 
Train [22/26] | Epoch [97/160] |	nca: 2.093569979071617, flat: 1.2898961789906025, pod: 31.874404788017273, loss: 35.25787091255188 
Train [22/26] | Epoch [98/160] |	nca: 2.1616063602268696, flat: 1.3628182671964169, pod: 33.20932173728943, loss: 36.7337464094162 
Train [22/26] | Epoch [99/160] |	nca: 2.160758815705776, flat: 1.2184673510491848, pod: 31.224104285240173, loss: 34.60333037376404 
Train [22/26] | Epoch [100/160] |	nca: 2.0243957862257957, flat: 1.2528423182666302, pod: 31.865500450134277, loss: 35.142738819122314 
Train [22/26] | Epoch [101/160] |	nca: 2.0261737294495106, flat: 1.2104810364544392, pod: 31.252497911453247, loss: 34.489152669906616 
Train [22/26] | Epoch [102/160] |	nca: 2.0656148120760918, flat: 1.1998278386890888, pod: 30.98345458507538, loss: 34.248897433280945 
Train [22/26] | Epoch [103/160] |	nca: 2.0046225674450397, flat: 1.1539883613586426, pod: 30.73737382888794, loss: 33.89598476886749 
Train [22/26] | Epoch [104/160] |	nca: 2.167234845459461, flat: 1.1822522319853306, pod: 31.1468608379364, loss: 34.49634790420532 
Train [22/26] | Epoch [105/160] |	nca: 2.1659079790115356, flat: 1.1414545178413391, pod: 29.849246740341187, loss: 33.15660917758942 
Train [22/26] | Epoch [106/160] |	nca: 1.8615187630057335, flat: 1.14761134237051, pod: 29.913504481315613, loss: 32.92263460159302 
Train [22/26] | Epoch [107/160] |	nca: 2.024936944246292, flat: 1.070706531405449, pod: 28.784409403800964, loss: 31.88005268573761 
Train [22/26] | Epoch [108/160] |	nca: 1.8756470829248428, flat: 1.0619488805532455, pod: 28.073528051376343, loss: 31.01112413406372 
Train [22/26] | Epoch [109/160] |	nca: 2.176112540066242, flat: 1.0108604580163956, pod: 27.087941765785217, loss: 30.274914622306824 
Train [22/26] | Epoch [110/160] |	nca: 2.1531385704874992, flat: 1.1263289414346218, pod: 29.44379496574402, loss: 32.723262429237366 
Train [22/26] | Epoch [111/160] |	nca: 2.0042183622717857, flat: 1.0078624375164509, pod: 27.38519948720932, loss: 30.39728033542633 
Train [22/26] | Epoch [112/160] |	nca: 1.9036460369825363, flat: 0.9471902288496494, pod: 26.666619777679443, loss: 29.51745629310608 
Train [22/26] | Epoch [113/160] |	nca: 1.9601066559553146, flat: 1.0000799223780632, pod: 27.512808799743652, loss: 30.472995162010193 
Train [22/26] | Epoch [114/160] |	nca: 1.8952877074480057, flat: 0.9938884936273098, pod: 26.555084228515625, loss: 29.444260478019714 
Train [22/26] | Epoch [115/160] |	nca: 1.9117244631052017, flat: 0.9153959937393665, pod: 25.958345353603363, loss: 28.785466194152832 
Train [22/26] | Epoch [116/160] |	nca: 1.9648001343011856, flat: 0.9689117036759853, pod: 26.712907433509827, loss: 29.646619200706482 
Train [22/26] | Epoch [117/160] |	nca: 2.109387833625078, flat: 0.9001934789121151, pod: 25.052480697631836, loss: 28.06206226348877 
Train [22/26] | Epoch [118/160] |	nca: 1.9357097297906876, flat: 0.8928769156336784, pod: 26.433648228645325, loss: 29.262235045433044 
Train [22/26] | Epoch [119/160] |	nca: 1.9161347262561321, flat: 0.9259644243866205, pod: 25.95930564403534, loss: 28.80140483379364 
Train [22/26] | Epoch [120/160] |	nca: 1.9276415258646011, flat: 0.9152125436812639, pod: 25.971248149871826, loss: 28.814102292060852 
Train [22/26] | Epoch [121/160] |	nca: 2.022751960903406, flat: 0.9128784090280533, pod: 25.87234914302826, loss: 28.807979583740234 
Train [22/26] | Epoch [122/160] |	nca: 1.9797816574573517, flat: 0.8482097424566746, pod: 25.33178734779358, loss: 28.159778714179993 
Train [22/26] | Epoch [123/160] |	nca: 1.881952192634344, flat: 0.8560898620635271, pod: 25.48718172311783, loss: 28.225224018096924 
Train [22/26] | Epoch [124/160] |	nca: 1.9803334288299084, flat: 0.805989159271121, pod: 24.020196199417114, loss: 26.80651867389679 
Train [22/26] | Epoch [125/160] |	nca: 1.8902412727475166, flat: 0.8077394217252731, pod: 24.688252985477448, loss: 27.386233687400818 
Train [22/26] | Epoch [126/160] |	nca: 1.7771430686116219, flat: 0.8177590314298868, pod: 23.87007164955139, loss: 26.46497392654419 
Train [22/26] | Epoch [127/160] |	nca: 2.0178061053156853, flat: 0.8025296479463577, pod: 23.288737058639526, loss: 26.10907292366028 
Train [22/26] | Epoch [128/160] |	nca: 1.9215369299054146, flat: 0.7879757713526487, pod: 22.394325971603394, loss: 25.103838562965393 
Train [22/26] | Epoch [129/160] |	nca: 1.8836329653859138, flat: 0.7317588552832603, pod: 22.028917491436005, loss: 24.644309163093567 
Train [22/26] | Epoch [130/160] |	nca: 2.0715619139373302, flat: 0.8232537470757961, pod: 23.89429211616516, loss: 26.78910768032074 
Train [22/26] | Epoch [131/160] |	nca: 1.9442382007837296, flat: 0.7632717732340097, pod: 22.582658231258392, loss: 25.29016822576523 
Train [22/26] | Epoch [132/160] |	nca: 1.8656156994402409, flat: 0.7524187490344048, pod: 22.339392840862274, loss: 24.957427501678467 
Train [22/26] | Epoch [133/160] |	nca: 1.9300921112298965, flat: 0.786076121032238, pod: 22.617090463638306, loss: 25.333258748054504 
Train [22/26] | Epoch [134/160] |	nca: 1.8249059841036797, flat: 0.7467186897993088, pod: 21.784989595413208, loss: 24.356614232063293 
Train [22/26] | Epoch [135/160] |	nca: 2.081450402736664, flat: 0.7336142137646675, pod: 21.66670525074005, loss: 24.481769740581512 
Train [22/26] | Epoch [136/160] |	nca: 2.029603499919176, flat: 0.7534502502530813, pod: 22.0577831864357, loss: 24.840836942195892 
Train [22/26] | Epoch [137/160] |	nca: 1.9161596857011318, flat: 0.7632871270179749, pod: 22.41942459344864, loss: 25.098871290683746 
Train [22/26] | Epoch [138/160] |	nca: 1.947501353919506, flat: 0.7138675078749657, pod: 21.326962113380432, loss: 23.988330841064453 
Train [22/26] | Epoch [139/160] |	nca: 1.9333342015743256, flat: 0.7012608256191015, pod: 20.829852640628815, loss: 23.464447557926178 
Train [22/26] | Epoch [140/160] |	nca: 1.8759233839809895, flat: 0.681776275858283, pod: 20.55334734916687, loss: 23.11104702949524 
Train [22/26] | Epoch [141/160] |	nca: 1.8611211255192757, flat: 0.6736861243844032, pod: 20.77037423849106, loss: 23.30518138408661 
Train [22/26] | Epoch [142/160] |	nca: 1.839431844651699, flat: 0.677173400297761, pod: 20.731111347675323, loss: 23.2477166056633 
Train [22/26] | Epoch [143/160] |	nca: 2.034068562090397, flat: 0.6523232739418745, pod: 19.86399406194687, loss: 22.550386011600494 
Train [22/26] | Epoch [144/160] |	nca: 1.9477608166635036, flat: 0.6865489631891251, pod: 20.22171688079834, loss: 22.856026649475098 
Train [22/26] | Epoch [145/160] |	nca: 1.8858901262283325, flat: 0.6201369185000658, pod: 19.14199161529541, loss: 21.64801859855652 
Train [22/26] | Epoch [146/160] |	nca: 2.0254936814308167, flat: 0.6305355411022902, pod: 19.709381639957428, loss: 22.365410923957825 
Train [22/26] | Epoch [147/160] |	nca: 2.0511125922203064, flat: 0.6764504946768284, pod: 20.06445598602295, loss: 22.792018949985504 
Train [22/26] | Epoch [148/160] |	nca: 1.9384010508656502, flat: 0.6716708429157734, pod: 19.708232641220093, loss: 22.31830459833145 
Train [22/26] | Epoch [149/160] |	nca: 1.891789972782135, flat: 0.5711873583495617, pod: 18.37867259979248, loss: 20.84164994955063 
Train [22/26] | Epoch [150/160] |	nca: 1.8631232865154743, flat: 0.6348667573183775, pod: 18.52869939804077, loss: 21.02668935060501 
Train [22/26] | Epoch [151/160] |	nca: 1.8950503319501877, flat: 0.6176146529614925, pod: 19.128778398036957, loss: 21.641443371772766 
Train [22/26] | Epoch [152/160] |	nca: 1.9539606645703316, flat: 0.6337086036801338, pod: 19.27338844537735, loss: 21.8610577583313 
Train [22/26] | Epoch [153/160] |	nca: 1.8363567739725113, flat: 0.6246070079505444, pod: 19.03186398744583, loss: 21.492827713489532 
Train [22/26] | Epoch [154/160] |	nca: 1.9588290825486183, flat: 0.6117761954665184, pod: 18.601154148578644, loss: 21.17175930738449 
Train [22/26] | Epoch [155/160] |	nca: 1.9909764155745506, flat: 0.626899678260088, pod: 18.798150718212128, loss: 21.416026830673218 
Train [22/26] | Epoch [156/160] |	nca: 1.8439251221716404, flat: 0.6018513683229685, pod: 18.277209877967834, loss: 20.722986340522766 
Train [22/26] | Epoch [157/160] |	nca: 1.9093299955129623, flat: 0.6460577473044395, pod: 19.337300539016724, loss: 21.892688512802124 
Train [22/26] | Epoch [158/160] |	nca: 1.9778574407100677, flat: 0.6320991292595863, pod: 18.56320571899414, loss: 21.173162162303925 
Train [22/26] | Epoch [159/160] |	nca: 1.8319451175630093, flat: 0.6231176815927029, pod: 18.400845050811768, loss: 20.85590797662735 
Train [22/26] | Epoch [160/160] |	nca: 1.9032768607139587, flat: 0.6110507976263762, pod: 18.23491406440735, loss: 20.749241709709167 
Fine-tuning
Building & updating memory.
Train [22/26] | Epoch [161/180] |	nca: 1.6447677090764046, flat: 0.9382053911685944, pod: 18.384279251098633, loss: 20.967252373695374 
Train [22/26] | Epoch [162/180] |	nca: 1.0387553572654724, flat: 0.9953694753348827, pod: 19.083067297935486, loss: 21.11719250679016 
Train [22/26] | Epoch [163/180] |	nca: 0.9065017849206924, flat: 0.9656732901930809, pod: 18.68636155128479, loss: 20.558536767959595 
Train [22/26] | Epoch [164/180] |	nca: 0.7579828500747681, flat: 0.9552594944834709, pod: 18.480382204055786, loss: 20.19362437725067 
Train [22/26] | Epoch [165/180] |	nca: 0.7621817700564861, flat: 0.9663504771888256, pod: 19.009486973285675, loss: 20.738019227981567 
Train [22/26] | Epoch [166/180] |	nca: 0.721103198826313, flat: 0.9905694350600243, pod: 18.91444218158722, loss: 20.626114904880524 
Train [22/26] | Epoch [167/180] |	nca: 0.7255705967545509, flat: 1.0010719560086727, pod: 19.033700466156006, loss: 20.760342836380005 
Train [22/26] | Epoch [168/180] |	nca: 0.686219222843647, flat: 0.9571899883449078, pod: 18.64644157886505, loss: 20.2898508310318 
Train [22/26] | Epoch [169/180] |	nca: 0.7021074369549751, flat: 0.9653424322605133, pod: 18.697534799575806, loss: 20.36498475074768 
Train [22/26] | Epoch [170/180] |	nca: 0.6852130405604839, flat: 0.9516741447150707, pod: 18.44642174243927, loss: 20.083309054374695 
Train [22/26] | Epoch [171/180] |	nca: 0.6900314036756754, flat: 0.9565884098410606, pod: 18.791622281074524, loss: 20.438241958618164 
Train [22/26] | Epoch [172/180] |	nca: 0.6538396514952183, flat: 0.9751240238547325, pod: 18.83065813779831, loss: 20.45962166786194 
Train [22/26] | Epoch [173/180] |	nca: 0.668644892051816, flat: 0.9765765741467476, pod: 18.83014714717865, loss: 20.475368857383728 
Train [22/26] | Epoch [174/180] |	nca: 0.6536224856972694, flat: 1.02239478379488, pod: 19.279966235160828, loss: 20.95598328113556 
Train [22/26] | Epoch [175/180] |	nca: 0.5977744795382023, flat: 0.9588179290294647, pod: 18.862800359725952, loss: 20.419392824172974 
Train [22/26] | Epoch [176/180] |	nca: 0.6178119406104088, flat: 0.9886593222618103, pod: 19.415434658527374, loss: 21.021905779838562 
Train [22/26] | Epoch [177/180] |	nca: 0.6156020443886518, flat: 1.0334244668483734, pod: 19.421909272670746, loss: 21.07093572616577 
Train [22/26] | Epoch [178/180] |	nca: 0.5948350727558136, flat: 1.0033557824790478, pod: 19.147388637065887, loss: 20.745579600334167 
Train [22/26] | Epoch [179/180] |	nca: 0.5856189653277397, flat: 0.935225423425436, pod: 18.17835783958435, loss: 19.699202179908752 
Train [22/26] | Epoch [180/180] |	nca: 0.5627569518983364, flat: 0.9695164933800697, pod: 18.749603986740112, loss: 20.281877398490906 
after task
Building & updating memory.
after task
Eval on 0->92.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6204090909090908.
Current acc: {'total': 0.54, '00-09': 0.588, '10-19': 0.54, '20-29': 0.454, '30-39': 0.506, '40-49': 0.555, '50-59': 0.517, '60-69': 0.461, '70-79': 0.583, '80-89': 0.619, '90-99': 0.71}.
Avg inc acc top5: 0.8681818181818179.
Current acc top5: {'total': 0.823}.
Forgetting: 0.14436363636363636.
Cord metric: 0.62.
Old accuracy: 0.54, mean: 0.61.
New accuracy: 0.71, mean: 0.78.
================Task 22 Start!================
Testing on False unseen tasks (max class = 94).
Set memory of size: 1840.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 22 Training!================
The training samples number: 2840
Train on 92->94.
train task
nb 2840.
Train [23/26] | Epoch [1/160] |	nca: 13.436076432466507, flat: 6.168062079697847, pod: 65.2601625919342, loss: 84.86430084705353 
Train [23/26] | Epoch [2/160] |	nca: 14.285480290651321, flat: 9.911260724067688, pod: 87.07703065872192, loss: 111.2737717628479 
Train [23/26] | Epoch [3/160] |	nca: 12.492931365966797, flat: 9.22968778014183, pod: 84.64947438240051, loss: 106.37209367752075 
Train [23/26] | Epoch [4/160] |	nca: 8.687174081802368, flat: 7.3288533091545105, pod: 77.11842155456543, loss: 93.13444924354553 
Train [23/26] | Epoch [5/160] |	nca: 6.9827263206243515, flat: 6.2754723727703094, pod: 73.23342180252075, loss: 86.49162030220032 
Train [23/26] | Epoch [6/160] |	nca: 6.63643853366375, flat: 5.860568135976791, pod: 72.56803488731384, loss: 85.0650417804718 
Train [23/26] | Epoch [7/160] |	nca: 4.832294926047325, flat: 4.865007057785988, pod: 65.14473271369934, loss: 74.84203481674194 
Train [23/26] | Epoch [8/160] |	nca: 4.13273249566555, flat: 4.355893924832344, pod: 62.53948402404785, loss: 71.02810955047607 
Train [23/26] | Epoch [9/160] |	nca: 4.4652693048119545, flat: 4.61786262691021, pod: 64.19269919395447, loss: 73.27583169937134 
Train [23/26] | Epoch [10/160] |	nca: 5.259264960885048, flat: 5.1578946858644485, pod: 68.92090106010437, loss: 79.3380606174469 
Train [23/26] | Epoch [11/160] |	nca: 4.306261800229549, flat: 4.433399215340614, pod: 62.256632566452026, loss: 70.99629330635071 
Train [23/26] | Epoch [12/160] |	nca: 3.502978578209877, flat: 3.8362548649311066, pod: 58.733704805374146, loss: 66.07293796539307 
Train [23/26] | Epoch [13/160] |	nca: 3.742327682673931, flat: 4.236369386315346, pod: 61.50186824798584, loss: 69.48056507110596 
Train [23/26] | Epoch [14/160] |	nca: 3.5862510204315186, flat: 4.044484451413155, pod: 61.79486894607544, loss: 69.42560386657715 
Train [23/26] | Epoch [15/160] |	nca: 3.818585582077503, flat: 4.117777928709984, pod: 60.93267369270325, loss: 68.86903667449951 
Train [23/26] | Epoch [16/160] |	nca: 3.9111950173974037, flat: 4.009360268712044, pod: 58.960747957229614, loss: 66.88130354881287 
Train [23/26] | Epoch [17/160] |	nca: 3.7908423244953156, flat: 3.8229221403598785, pod: 56.41142916679382, loss: 64.02519392967224 
Train [23/26] | Epoch [18/160] |	nca: 3.7824116721749306, flat: 3.7665342539548874, pod: 58.46579456329346, loss: 66.01474070549011 
Train [23/26] | Epoch [19/160] |	nca: 3.2624722197651863, flat: 3.441123552620411, pod: 54.98063278198242, loss: 61.68422794342041 
Train [23/26] | Epoch [20/160] |	nca: 3.730835907161236, flat: 3.7932461500167847, pod: 58.13881969451904, loss: 65.66290187835693 
Train [23/26] | Epoch [21/160] |	nca: 2.9716970026493073, flat: 3.429317682981491, pod: 57.17431020736694, loss: 63.57532501220703 
Train [23/26] | Epoch [22/160] |	nca: 3.0944044962525368, flat: 3.1214905828237534, pod: 54.43833327293396, loss: 60.65422821044922 
Train [23/26] | Epoch [23/160] |	nca: 3.90511342138052, flat: 3.630893751978874, pod: 57.62117648124695, loss: 65.15718364715576 
Train [23/26] | Epoch [24/160] |	nca: 4.098182626068592, flat: 3.8000676184892654, pod: 56.05101037025452, loss: 63.949260234832764 
Train [23/26] | Epoch [25/160] |	nca: 2.822478286921978, flat: 3.4657814726233482, pod: 54.647743940353394, loss: 60.93600416183472 
Train [23/26] | Epoch [26/160] |	nca: 2.8449148386716843, flat: 3.08901284635067, pod: 54.89443922042847, loss: 60.82836627960205 
Train [23/26] | Epoch [27/160] |	nca: 3.3041393607854843, flat: 3.2657957896590233, pod: 53.3636212348938, loss: 59.93355584144592 
Train [23/26] | Epoch [28/160] |	nca: 3.58376257866621, flat: 3.540781691670418, pod: 54.50910663604736, loss: 61.6336510181427 
Train [23/26] | Epoch [29/160] |	nca: 2.7501215264201164, flat: 3.3640699684619904, pod: 57.0529043674469, loss: 63.16709613800049 
Train [23/26] | Epoch [30/160] |	nca: 2.9339140877127647, flat: 3.080421358346939, pod: 51.79141390323639, loss: 57.80574989318848 
Train [23/26] | Epoch [31/160] |	nca: 2.5634744986891747, flat: 3.1097399070858955, pod: 55.195255756378174, loss: 60.868470430374146 
Train [23/26] | Epoch [32/160] |	nca: 2.962627738714218, flat: 3.1039109900593758, pod: 54.6047568321228, loss: 60.671295404434204 
Train [23/26] | Epoch [33/160] |	nca: 2.6130493506789207, flat: 2.727131001651287, pod: 50.3637273311615, loss: 55.70390772819519 
Train [23/26] | Epoch [34/160] |	nca: 3.448871359229088, flat: 3.055786684155464, pod: 51.34968078136444, loss: 57.85433864593506 
Train [23/26] | Epoch [35/160] |	nca: 3.083977498114109, flat: 3.2684667482972145, pod: 53.63473296165466, loss: 59.98717713356018 
Train [23/26] | Epoch [36/160] |	nca: 3.1975663751363754, flat: 3.501204453408718, pod: 54.46148085594177, loss: 61.1602520942688 
Train [23/26] | Epoch [37/160] |	nca: 2.6938851177692413, flat: 3.1213689148426056, pod: 54.859103202819824, loss: 60.674357175827026 
Train [23/26] | Epoch [38/160] |	nca: 2.7826749086380005, flat: 2.76413656771183, pod: 51.07524585723877, loss: 56.62205719947815 
Train [23/26] | Epoch [39/160] |	nca: 2.7913196459412575, flat: 3.1372553259134293, pod: 52.297924280166626, loss: 58.22649908065796 
Train [23/26] | Epoch [40/160] |	nca: 2.6732219830155373, flat: 3.004102110862732, pod: 52.31894493103027, loss: 57.99626851081848 
Train [23/26] | Epoch [41/160] |	nca: 2.4886373206973076, flat: 2.6964085698127747, pod: 50.815216064453125, loss: 56.00026202201843 
Train [23/26] | Epoch [42/160] |	nca: 2.5832227766513824, flat: 2.691752791404724, pod: 50.03549325466156, loss: 55.310468912124634 
Train [23/26] | Epoch [43/160] |	nca: 2.6563084572553635, flat: 2.5821590423583984, pod: 49.14347517490387, loss: 54.38194298744202 
Train [23/26] | Epoch [44/160] |	nca: 3.045955717563629, flat: 2.781322941184044, pod: 50.4327826499939, loss: 56.260061264038086 
Train [23/26] | Epoch [45/160] |	nca: 3.7698626443743706, flat: 3.5107376277446747, pod: 52.713048219680786, loss: 59.993648052215576 
Train [23/26] | Epoch [46/160] |	nca: 3.4681092277169228, flat: 3.560229778289795, pod: 53.28194451332092, loss: 60.31028389930725 
Train [23/26] | Epoch [47/160] |	nca: 3.163490854203701, flat: 3.2212030962109566, pod: 52.7650043964386, loss: 59.14969825744629 
Train [23/26] | Epoch [48/160] |	nca: 2.3994204998016357, flat: 2.5856146588921547, pod: 47.77088105678558, loss: 52.755916357040405 
Train [23/26] | Epoch [49/160] |	nca: 2.923061780631542, flat: 2.803150363266468, pod: 50.18249571323395, loss: 55.908708572387695 
Train [23/26] | Epoch [50/160] |	nca: 2.3867157846689224, flat: 2.545113228261471, pod: 47.58461892604828, loss: 52.51644802093506 
Train [23/26] | Epoch [51/160] |	nca: 2.543601706624031, flat: 2.6619110628962517, pod: 47.57674312591553, loss: 52.78225636482239 
Train [23/26] | Epoch [52/160] |	nca: 3.155670687556267, flat: 2.876797467470169, pod: 49.06766164302826, loss: 55.1001296043396 
Train [23/26] | Epoch [53/160] |	nca: 2.939667731523514, flat: 2.8098905459046364, pod: 47.97051680088043, loss: 53.72007489204407 
Train [23/26] | Epoch [54/160] |	nca: 2.697569504380226, flat: 2.6348463892936707, pod: 48.80467903614044, loss: 54.13709545135498 
Train [23/26] | Epoch [55/160] |	nca: 2.661361962556839, flat: 2.787100024521351, pod: 48.35957467556, loss: 53.80803632736206 
Train [23/26] | Epoch [56/160] |	nca: 2.5719384625554085, flat: 2.4349992349743843, pod: 46.2588586807251, loss: 51.265795946121216 
Train [23/26] | Epoch [57/160] |	nca: 2.8215096555650234, flat: 2.567830801010132, pod: 48.827868580818176, loss: 54.21720862388611 
Train [23/26] | Epoch [58/160] |	nca: 2.5874448753893375, flat: 2.836584597826004, pod: 49.89487969875336, loss: 55.31890845298767 
Train [23/26] | Epoch [59/160] |	nca: 2.4578511118888855, flat: 2.2955960258841515, pod: 45.741599440574646, loss: 50.495046615600586 
Train [23/26] | Epoch [60/160] |	nca: 2.42477960139513, flat: 2.411699816584587, pod: 47.189438819885254, loss: 52.02591800689697 
Train [23/26] | Epoch [61/160] |	nca: 3.071466937661171, flat: 2.5601441115140915, pod: 48.55694127082825, loss: 54.188552021980286 
Train [23/26] | Epoch [62/160] |	nca: 2.4733143746852875, flat: 2.6431964933872223, pod: 48.275346159935, loss: 53.391857504844666 
Train [23/26] | Epoch [63/160] |	nca: 2.3397266380488873, flat: 2.1766191720962524, pod: 43.47145652770996, loss: 47.987802147865295 
Train [23/26] | Epoch [64/160] |	nca: 2.1995523646473885, flat: 2.3147978857159615, pod: 46.05408728122711, loss: 50.56843817234039 
Train [23/26] | Epoch [65/160] |	nca: 2.4574495032429695, flat: 2.2025313675403595, pod: 44.19756746292114, loss: 48.85754883289337 
Train [23/26] | Epoch [66/160] |	nca: 2.8610969632864, flat: 2.8678165301680565, pod: 48.21985399723053, loss: 53.94876766204834 
Train [23/26] | Epoch [67/160] |	nca: 2.5640221424400806, flat: 2.43085303157568, pod: 46.453749895095825, loss: 51.44862520694733 
Train [23/26] | Epoch [68/160] |	nca: 2.547137774527073, flat: 2.411566324532032, pod: 45.197409868240356, loss: 50.156113386154175 
Train [23/26] | Epoch [69/160] |	nca: 2.2530995458364487, flat: 2.2277999594807625, pod: 44.50397861003876, loss: 48.984878063201904 
Train [23/26] | Epoch [70/160] |	nca: 2.524558939039707, flat: 2.4029799923300743, pod: 46.07565951347351, loss: 51.00319862365723 
Train [23/26] | Epoch [71/160] |	nca: 2.562320239841938, flat: 2.3369457721710205, pod: 45.70618939399719, loss: 50.60545527935028 
Train [23/26] | Epoch [72/160] |	nca: 2.3880538418889046, flat: 2.617274135351181, pod: 45.70102822780609, loss: 50.706356048583984 
Train [23/26] | Epoch [73/160] |	nca: 2.4570522978901863, flat: 2.41198867559433, pod: 46.678269267082214, loss: 51.54730987548828 
Train [23/26] | Epoch [74/160] |	nca: 2.1412233747541904, flat: 2.0908978804945946, pod: 44.36120247840881, loss: 48.593323707580566 
Train [23/26] | Epoch [75/160] |	nca: 2.133011896163225, flat: 1.9921299144625664, pod: 41.094247579574585, loss: 45.21938931941986 
Train [23/26] | Epoch [76/160] |	nca: 2.415049582719803, flat: 2.1811386719346046, pod: 44.3269464969635, loss: 48.92313504219055 
Train [23/26] | Epoch [77/160] |	nca: 2.1088711842894554, flat: 1.9692001193761826, pod: 41.417893290519714, loss: 45.49596452713013 
Train [23/26] | Epoch [78/160] |	nca: 2.224695436656475, flat: 1.8135357350111008, pod: 38.87811875343323, loss: 42.91635012626648 
Train [23/26] | Epoch [79/160] |	nca: 2.3198426477611065, flat: 1.9415061697363853, pod: 41.94045686721802, loss: 46.20180547237396 
Train [23/26] | Epoch [80/160] |	nca: 2.4655804336071014, flat: 1.8137323893606663, pod: 39.687175154685974, loss: 43.966488003730774 
Train [23/26] | Epoch [81/160] |	nca: 2.198518991470337, flat: 2.0000514835119247, pod: 40.44067299365997, loss: 44.639243602752686 
Train [23/26] | Epoch [82/160] |	nca: 2.3678093925118446, flat: 1.9340995103120804, pod: 39.44731163978577, loss: 43.74922037124634 
Train [23/26] | Epoch [83/160] |	nca: 2.2577850334346294, flat: 2.0094933286309242, pod: 40.93421161174774, loss: 45.20148980617523 
Train [23/26] | Epoch [84/160] |	nca: 2.2561950013041496, flat: 1.8748172372579575, pod: 39.550392389297485, loss: 43.68140494823456 
Train [23/26] | Epoch [85/160] |	nca: 2.210884053260088, flat: 1.9118925482034683, pod: 39.40141570568085, loss: 43.524192214012146 
Train [23/26] | Epoch [86/160] |	nca: 2.1586745604872704, flat: 1.8517109975218773, pod: 39.16948056221008, loss: 43.17986571788788 
Train [23/26] | Epoch [87/160] |	nca: 2.2532591596245766, flat: 1.880444947630167, pod: 39.719305634498596, loss: 43.85300958156586 
Train [23/26] | Epoch [88/160] |	nca: 2.3383183255791664, flat: 1.7659483812749386, pod: 39.07226002216339, loss: 43.17652702331543 
Train [23/26] | Epoch [89/160] |	nca: 2.0461773611605167, flat: 1.7723409608006477, pod: 37.63495337963104, loss: 41.4534717798233 
Train [23/26] | Epoch [90/160] |	nca: 2.1882091090083122, flat: 1.810039333999157, pod: 39.56150031089783, loss: 43.55974864959717 
Train [23/26] | Epoch [91/160] |	nca: 2.011697828769684, flat: 1.6017227470874786, pod: 37.92453217506409, loss: 41.53795289993286 
Train [23/26] | Epoch [92/160] |	nca: 2.0380828008055687, flat: 1.7113914750516415, pod: 38.45922362804413, loss: 42.20869791507721 
Train [23/26] | Epoch [93/160] |	nca: 2.1289080306887627, flat: 1.6395673230290413, pod: 36.646748423576355, loss: 40.415223717689514 
Train [23/26] | Epoch [94/160] |	nca: 2.1018990017473698, flat: 1.642334919422865, pod: 38.610589265823364, loss: 42.3548229932785 
Train [23/26] | Epoch [95/160] |	nca: 2.112538702785969, flat: 1.7388813681900501, pod: 38.34036886692047, loss: 42.19178903102875 
Train [23/26] | Epoch [96/160] |	nca: 2.038749113678932, flat: 1.6051889061927795, pod: 36.16079294681549, loss: 39.804731011390686 
Train [23/26] | Epoch [97/160] |	nca: 1.9195375703275204, flat: 1.585592370480299, pod: 35.92902672290802, loss: 39.43415653705597 
Train [23/26] | Epoch [98/160] |	nca: 1.9379100278019905, flat: 1.5513687245547771, pod: 36.01432693004608, loss: 39.50360596179962 
Train [23/26] | Epoch [99/160] |	nca: 2.2931623309850693, flat: 1.5461283884942532, pod: 35.422149896621704, loss: 39.2614403963089 
Train [23/26] | Epoch [100/160] |	nca: 2.359632760286331, flat: 1.741472851485014, pod: 36.69950187206268, loss: 40.800607562065125 
Train [23/26] | Epoch [101/160] |	nca: 1.9817765727639198, flat: 1.562944132834673, pod: 36.41831576824188, loss: 39.96303653717041 
Train [23/26] | Epoch [102/160] |	nca: 1.9288135021924973, flat: 1.4627426527440548, pod: 35.00299036502838, loss: 38.39454674720764 
Train [23/26] | Epoch [103/160] |	nca: 2.209291994571686, flat: 1.4871298484504223, pod: 34.59519910812378, loss: 38.29162096977234 
Train [23/26] | Epoch [104/160] |	nca: 1.9663623906672, flat: 1.5702791027724743, pod: 35.228485107421875, loss: 38.7651264667511 
Train [23/26] | Epoch [105/160] |	nca: 2.1494417674839497, flat: 1.593862134963274, pod: 34.613892674446106, loss: 38.35719645023346 
Train [23/26] | Epoch [106/160] |	nca: 2.4184487387537956, flat: 1.6759385392069817, pod: 36.63579988479614, loss: 40.73018753528595 
Train [23/26] | Epoch [107/160] |	nca: 2.2373914904892445, flat: 1.7151615023612976, pod: 36.94796371459961, loss: 40.900516867637634 
Train [23/26] | Epoch [108/160] |	nca: 1.9456844069063663, flat: 1.4432721324265003, pod: 33.90705192089081, loss: 37.296008706092834 
Train [23/26] | Epoch [109/160] |	nca: 2.082770351320505, flat: 1.4122380502521992, pod: 33.567803144454956, loss: 37.062811493873596 
Train [23/26] | Epoch [110/160] |	nca: 1.9202942922711372, flat: 1.4284851513803005, pod: 32.63587808609009, loss: 35.984657406806946 
Train [23/26] | Epoch [111/160] |	nca: 2.154913492500782, flat: 1.3085597306489944, pod: 32.40280246734619, loss: 35.86627542972565 
Train [23/26] | Epoch [112/160] |	nca: 1.874592650681734, flat: 1.315760362893343, pod: 32.838852286338806, loss: 36.029205083847046 
Train [23/26] | Epoch [113/160] |	nca: 1.8918590657413006, flat: 1.3384938426315784, pod: 31.547786474227905, loss: 34.77813971042633 
Train [23/26] | Epoch [114/160] |	nca: 1.8763011954724789, flat: 1.2375515475869179, pod: 30.90821099281311, loss: 34.02206373214722 
Train [23/26] | Epoch [115/160] |	nca: 2.003566462546587, flat: 1.2319663725793362, pod: 31.109726667404175, loss: 34.34525942802429 
Train [23/26] | Epoch [116/160] |	nca: 1.941349096596241, flat: 1.285963661968708, pod: 31.406086683273315, loss: 34.63339948654175 
Train [23/26] | Epoch [117/160] |	nca: 1.9706984236836433, flat: 1.2801070809364319, pod: 32.17978608608246, loss: 35.430591464042664 
Train [23/26] | Epoch [118/160] |	nca: 1.9886794984340668, flat: 1.2004453130066395, pod: 30.3332302570343, loss: 33.52235519886017 
Train [23/26] | Epoch [119/160] |	nca: 2.0123144388198853, flat: 1.2636228278279305, pod: 31.6203693151474, loss: 34.89630675315857 
Train [23/26] | Epoch [120/160] |	nca: 1.880787868052721, flat: 1.134147010743618, pod: 29.80807662010193, loss: 32.82301139831543 
Train [23/26] | Epoch [121/160] |	nca: 2.0484051443636417, flat: 1.1731183491647243, pod: 30.2954283952713, loss: 33.5169517993927 
Train [23/26] | Epoch [122/160] |	nca: 1.8334024138748646, flat: 1.0963623374700546, pod: 27.946030259132385, loss: 30.875795006752014 
Train [23/26] | Epoch [123/160] |	nca: 2.2021985575556755, flat: 1.3168532215058804, pod: 30.39517390727997, loss: 33.914225459098816 
Train [23/26] | Epoch [124/160] |	nca: 2.1215341091156006, flat: 1.2425395846366882, pod: 29.601767897605896, loss: 32.96584153175354 
Train [23/26] | Epoch [125/160] |	nca: 1.842782586812973, flat: 1.1128034517168999, pod: 27.954583168029785, loss: 30.91016936302185 
Train [23/26] | Epoch [126/160] |	nca: 1.8969135954976082, flat: 1.0622453801333904, pod: 27.536482870578766, loss: 30.495641827583313 
Train [23/26] | Epoch [127/160] |	nca: 2.0379783511161804, flat: 1.0864688958972692, pod: 28.452791571617126, loss: 31.57723891735077 
Train [23/26] | Epoch [128/160] |	nca: 2.2058014310896397, flat: 1.1848734319210052, pod: 28.578133940696716, loss: 31.96880877017975 
Train [23/26] | Epoch [129/160] |	nca: 1.9124291017651558, flat: 1.1787392236292362, pod: 28.865571796894073, loss: 31.956740021705627 
Train [23/26] | Epoch [130/160] |	nca: 1.889923445880413, flat: 1.111872186884284, pod: 28.878515124320984, loss: 31.880310535430908 
Train [23/26] | Epoch [131/160] |	nca: 1.8669286258518696, flat: 0.9875362925231457, pod: 26.6047460436821, loss: 29.45921093225479 
Train [23/26] | Epoch [132/160] |	nca: 1.9379574246704578, flat: 1.0196819379925728, pod: 26.663286209106445, loss: 29.620925545692444 
Train [23/26] | Epoch [133/160] |	nca: 2.067395854741335, flat: 1.0733624454587698, pod: 26.530522644519806, loss: 29.67128098011017 
Train [23/26] | Epoch [134/160] |	nca: 1.8985154777765274, flat: 0.9365657325834036, pod: 25.07224065065384, loss: 27.907321453094482 
Train [23/26] | Epoch [135/160] |	nca: 1.844566985964775, flat: 0.9652578681707382, pod: 26.467725694179535, loss: 29.27755093574524 
Train [23/26] | Epoch [136/160] |	nca: 1.7655826546251774, flat: 0.9420645534992218, pod: 25.064293384552002, loss: 27.771940410137177 
Train [23/26] | Epoch [137/160] |	nca: 1.9146922565996647, flat: 0.913815451785922, pod: 25.225325047969818, loss: 28.05383265018463 
Train [23/26] | Epoch [138/160] |	nca: 1.9266973324120045, flat: 0.944413349032402, pod: 24.84368497133255, loss: 27.71479570865631 
Train [23/26] | Epoch [139/160] |	nca: 1.9994166009128094, flat: 0.9468429666012526, pod: 25.2698455452919, loss: 28.216105103492737 
Train [23/26] | Epoch [140/160] |	nca: 1.8890131749212742, flat: 0.960757177323103, pod: 25.580665946006775, loss: 28.43043625354767 
Train [23/26] | Epoch [141/160] |	nca: 1.8012059889733791, flat: 0.8721538633108139, pod: 24.001916646957397, loss: 26.67527663707733 
Train [23/26] | Epoch [142/160] |	nca: 1.8616250306367874, flat: 0.8965972680598497, pod: 24.296084105968475, loss: 27.054306209087372 
Train [23/26] | Epoch [143/160] |	nca: 1.8593423329293728, flat: 0.9036315623670816, pod: 24.32778924703598, loss: 27.090763092041016 
Train [23/26] | Epoch [144/160] |	nca: 1.9317709617316723, flat: 0.7686865404248238, pod: 22.372739791870117, loss: 25.07319736480713 
Train [23/26] | Epoch [145/160] |	nca: 1.8491714112460613, flat: 0.8547653090208769, pod: 23.421169817447662, loss: 26.12510645389557 
Train [23/26] | Epoch [146/160] |	nca: 1.83206382766366, flat: 0.8420074041932821, pod: 23.284408926963806, loss: 25.958480060100555 
Train [23/26] | Epoch [147/160] |	nca: 1.82321335375309, flat: 0.8069711569696665, pod: 22.310428857803345, loss: 24.940613389015198 
Train [23/26] | Epoch [148/160] |	nca: 1.862438015639782, flat: 0.7776456326246262, pod: 21.874745190143585, loss: 24.51482880115509 
Train [23/26] | Epoch [149/160] |	nca: 2.0219449922442436, flat: 0.894585745409131, pod: 24.05280888080597, loss: 26.96933937072754 
Train [23/26] | Epoch [150/160] |	nca: 2.0377805940806866, flat: 0.8286683186888695, pod: 22.382366180419922, loss: 25.248815059661865 
Train [23/26] | Epoch [151/160] |	nca: 1.80690972879529, flat: 0.8656767196953297, pod: 23.25972181558609, loss: 25.93230837583542 
Train [23/26] | Epoch [152/160] |	nca: 1.792099267244339, flat: 0.8109698798507452, pod: 22.00295978784561, loss: 24.606028854846954 
Train [23/26] | Epoch [153/160] |	nca: 1.753619197756052, flat: 0.8205884732306004, pod: 22.1660315990448, loss: 24.740239202976227 
Train [23/26] | Epoch [154/160] |	nca: 1.8445564024150372, flat: 0.8731743451207876, pod: 22.60770308971405, loss: 25.32543396949768 
Train [23/26] | Epoch [155/160] |	nca: 1.7080740705132484, flat: 0.8682608604431152, pod: 23.337463557720184, loss: 25.913798451423645 
Train [23/26] | Epoch [156/160] |	nca: 1.8356713131070137, flat: 0.7644640821963549, pod: 21.585419237613678, loss: 24.18555462360382 
Train [23/26] | Epoch [157/160] |	nca: 1.7586351446807384, flat: 0.8027079794555902, pod: 22.61479389667511, loss: 25.176137030124664 
Train [23/26] | Epoch [158/160] |	nca: 1.7671247012913227, flat: 0.7563265077769756, pod: 21.76260620355606, loss: 24.286057233810425 
Train [23/26] | Epoch [159/160] |	nca: 1.809932567179203, flat: 0.8268884867429733, pod: 21.703063189983368, loss: 24.339884281158447 
Train [23/26] | Epoch [160/160] |	nca: 1.8366849273443222, flat: 0.8531630113720894, pod: 22.803675889968872, loss: 25.49352377653122 
Fine-tuning
Building & updating memory.
Train [23/26] | Epoch [161/180] |	nca: 1.0809547640383244, flat: 0.9100979603827, pod: 17.425014197826385, loss: 19.41606694459915 
Train [23/26] | Epoch [162/180] |	nca: 0.7105161380022764, flat: 0.8794558644294739, pod: 17.03837013244629, loss: 18.628342151641846 
Train [23/26] | Epoch [163/180] |	nca: 0.5991601683199406, flat: 0.858733668923378, pod: 17.152254283428192, loss: 18.610148191452026 
Train [23/26] | Epoch [164/180] |	nca: 0.5977778472006321, flat: 0.8760500252246857, pod: 17.297527551651, loss: 18.771355271339417 
Train [23/26] | Epoch [165/180] |	nca: 0.5806432068347931, flat: 0.8918626606464386, pod: 17.26098346710205, loss: 18.733489394187927 
Train [23/26] | Epoch [166/180] |	nca: 0.5232218690216541, flat: 0.8937808014452457, pod: 17.03958010673523, loss: 18.45658278465271 
Train [23/26] | Epoch [167/180] |	nca: 0.5348537508398294, flat: 0.8582023568451405, pod: 16.991800606250763, loss: 18.384856581687927 
Train [23/26] | Epoch [168/180] |	nca: 0.5098846517503262, flat: 0.8878170624375343, pod: 17.300736725330353, loss: 18.6984384059906 
Train [23/26] | Epoch [169/180] |	nca: 0.5240214020013809, flat: 0.9098795242607594, pod: 17.468768298625946, loss: 18.902668952941895 
Train [23/26] | Epoch [170/180] |	nca: 0.5106870550662279, flat: 0.8618882782757282, pod: 17.02739417552948, loss: 18.399969339370728 
Train [23/26] | Epoch [171/180] |	nca: 0.46900190599262714, flat: 0.8861524984240532, pod: 17.30795133113861, loss: 18.663105607032776 
Train [23/26] | Epoch [172/180] |	nca: 0.49256621673703194, flat: 0.8968836925923824, pod: 17.540563225746155, loss: 18.930013060569763 
Train [23/26] | Epoch [173/180] |	nca: 0.5083272811025381, flat: 0.8788119629025459, pod: 17.248858213424683, loss: 18.635997533798218 
Train [23/26] | Epoch [174/180] |	nca: 0.4412709902971983, flat: 0.8710821084678173, pod: 16.83670538663864, loss: 18.14905858039856 
Train [23/26] | Epoch [175/180] |	nca: 0.5073062982410192, flat: 0.9071085564792156, pod: 17.349569439888, loss: 18.763984322547913 
Train [23/26] | Epoch [176/180] |	nca: 0.4632501732558012, flat: 0.900852132588625, pod: 17.49665653705597, loss: 18.860758423805237 
Train [23/26] | Epoch [177/180] |	nca: 0.46197816357016563, flat: 0.8897453658282757, pod: 17.457472443580627, loss: 18.8091961145401 
Train [23/26] | Epoch [178/180] |	nca: 0.4413001425564289, flat: 0.9106107838451862, pod: 17.515681505203247, loss: 18.867592453956604 
Train [23/26] | Epoch [179/180] |	nca: 0.4510284885764122, flat: 0.9075747355818748, pod: 17.57009267807007, loss: 18.928695917129517 
Train [23/26] | Epoch [180/180] |	nca: 0.4667118452489376, flat: 0.9294554963707924, pod: 17.62141728401184, loss: 19.017584681510925 
after task
Building & updating memory.
after task
Eval on 0->94.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.616782608695652.
Current acc: {'total': 0.537, '00-09': 0.589, '10-19': 0.521, '20-29': 0.435, '30-39': 0.492, '40-49': 0.541, '50-59': 0.526, '60-69': 0.44, '70-79': 0.581, '80-89': 0.621, '90-99': 0.762}.
Avg inc acc top5: 0.8661304347826085.
Current acc top5: {'total': 0.821}.
Forgetting: 0.21118181818181817.
Cord metric: 0.62.
Old accuracy: 0.53, mean: 0.60.
New accuracy: 0.80, mean: 0.78.
================Task 23 Start!================
Testing on False unseen tasks (max class = 96).
Set memory of size: 1880.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 23 Training!================
The training samples number: 2880
Train on 94->96.
train task
nb 2880.
Train [24/26] | Epoch [1/160] |	nca: 15.274105280637741, flat: 5.789526730775833, pod: 60.206569612026215, loss: 81.27020120620728 
Train [24/26] | Epoch [2/160] |	nca: 10.031784415245056, flat: 6.213510140776634, pod: 71.84457516670227, loss: 88.08986902236938 
Train [24/26] | Epoch [3/160] |	nca: 7.548612684011459, flat: 5.490282788872719, pod: 65.62686157226562, loss: 78.6657567024231 
Train [24/26] | Epoch [4/160] |	nca: 6.422722682356834, flat: 4.7635437697172165, pod: 62.239551305770874, loss: 73.42581748962402 
Train [24/26] | Epoch [5/160] |	nca: 5.5234329998493195, flat: 4.350475996732712, pod: 61.570667028427124, loss: 71.44457626342773 
Train [24/26] | Epoch [6/160] |	nca: 5.031894460320473, flat: 3.980633467435837, pod: 59.22130107879639, loss: 68.23382925987244 
Train [24/26] | Epoch [7/160] |	nca: 3.9091791808605194, flat: 3.2292167618870735, pod: 55.403470277786255, loss: 62.541865825653076 
Train [24/26] | Epoch [8/160] |	nca: 4.0572377145290375, flat: 3.356613516807556, pod: 57.17557120323181, loss: 64.58942246437073 
Train [24/26] | Epoch [9/160] |	nca: 4.056626781821251, flat: 3.187924340367317, pod: 54.44001054763794, loss: 61.68456196784973 
Train [24/26] | Epoch [10/160] |	nca: 4.278061002492905, flat: 3.287345916032791, pod: 54.65370965003967, loss: 62.21911644935608 
Train [24/26] | Epoch [11/160] |	nca: 3.881501689553261, flat: 3.0611781552433968, pod: 54.0513072013855, loss: 60.99398756027222 
Train [24/26] | Epoch [12/160] |	nca: 3.514998771250248, flat: 2.901738330721855, pod: 51.54857349395752, loss: 57.96531081199646 
Train [24/26] | Epoch [13/160] |	nca: 3.273562639951706, flat: 2.8074610009789467, pod: 52.182730197906494, loss: 58.26375389099121 
Train [24/26] | Epoch [14/160] |	nca: 3.217109754681587, flat: 2.7565730586647987, pod: 51.44179630279541, loss: 57.41547894477844 
Train [24/26] | Epoch [15/160] |	nca: 3.4042277187108994, flat: 2.6287601068615913, pod: 50.457597613334656, loss: 56.49058556556702 
Train [24/26] | Epoch [16/160] |	nca: 3.3135146647691727, flat: 2.7332158759236336, pod: 50.054245829582214, loss: 56.10097670555115 
Train [24/26] | Epoch [17/160] |	nca: 3.3766753524541855, flat: 2.8762475103139877, pod: 51.0067937374115, loss: 57.25971698760986 
Train [24/26] | Epoch [18/160] |	nca: 3.4315086007118225, flat: 2.8069728165864944, pod: 51.93522262573242, loss: 58.17370390892029 
Train [24/26] | Epoch [19/160] |	nca: 3.533294327557087, flat: 2.894493855535984, pod: 51.15514421463013, loss: 57.582932233810425 
Train [24/26] | Epoch [20/160] |	nca: 3.5407055616378784, flat: 2.870630383491516, pod: 50.80780565738678, loss: 57.219141483306885 
Train [24/26] | Epoch [21/160] |	nca: 3.37652537971735, flat: 2.662872053682804, pod: 48.910568833351135, loss: 54.94996643066406 
Train [24/26] | Epoch [22/160] |	nca: 3.391982950270176, flat: 2.956967480480671, pod: 53.21228337287903, loss: 59.56123352050781 
Train [24/26] | Epoch [23/160] |	nca: 3.2022280544042587, flat: 2.873447798192501, pod: 52.49009609222412, loss: 58.56577205657959 
Train [24/26] | Epoch [24/160] |	nca: 3.527448333799839, flat: 2.7393125742673874, pod: 49.61762070655823, loss: 55.88438129425049 
Train [24/26] | Epoch [25/160] |	nca: 3.343570902943611, flat: 2.8300859555602074, pod: 50.26621377468109, loss: 56.439870834350586 
Train [24/26] | Epoch [26/160] |	nca: 3.721974842250347, flat: 2.96152962744236, pod: 52.93352031707764, loss: 59.61702513694763 
Train [24/26] | Epoch [27/160] |	nca: 3.737074561417103, flat: 2.878511317074299, pod: 50.439149141311646, loss: 57.05473470687866 
Train [24/26] | Epoch [28/160] |	nca: 3.117488369345665, flat: 2.7968984618782997, pod: 51.05607461929321, loss: 56.97046113014221 
Train [24/26] | Epoch [29/160] |	nca: 2.750899948179722, flat: 2.4113141894340515, pod: 46.78167724609375, loss: 51.943891525268555 
Train [24/26] | Epoch [30/160] |	nca: 3.209729380905628, flat: 2.449863977730274, pod: 47.6966438293457, loss: 53.356237173080444 
Train [24/26] | Epoch [31/160] |	nca: 3.0952058732509613, flat: 2.539431780576706, pod: 48.62766230106354, loss: 54.26230025291443 
Train [24/26] | Epoch [32/160] |	nca: 2.9442959874868393, flat: 2.5073713809251785, pod: 48.527140736579895, loss: 53.97880792617798 
Train [24/26] | Epoch [33/160] |	nca: 2.9007854387164116, flat: 2.348257079720497, pod: 46.06063234806061, loss: 51.309674978256226 
Train [24/26] | Epoch [34/160] |	nca: 2.9466511607170105, flat: 2.398406893014908, pod: 47.780423283576965, loss: 53.12548089027405 
Train [24/26] | Epoch [35/160] |	nca: 2.6149409636855125, flat: 2.4401173889636993, pod: 47.947120785713196, loss: 53.00217890739441 
Train [24/26] | Epoch [36/160] |	nca: 2.9040661305189133, flat: 2.286161944270134, pod: 46.848888993263245, loss: 52.039117217063904 
Train [24/26] | Epoch [37/160] |	nca: 2.893125005066395, flat: 2.500614173710346, pod: 48.49729359149933, loss: 53.89103293418884 
Train [24/26] | Epoch [38/160] |	nca: 2.7781329452991486, flat: 2.4278754517436028, pod: 47.778273820877075, loss: 52.98428273200989 
Train [24/26] | Epoch [39/160] |	nca: 2.6809063851833344, flat: 2.37353502959013, pod: 47.21044456958771, loss: 52.264885902404785 
Train [24/26] | Epoch [40/160] |	nca: 2.9940366968512535, flat: 2.4063758701086044, pod: 46.579012513160706, loss: 51.97942495346069 
Train [24/26] | Epoch [41/160] |	nca: 2.946425013244152, flat: 2.269253082573414, pod: 43.97621977329254, loss: 49.19189786911011 
Train [24/26] | Epoch [42/160] |	nca: 3.0838007032871246, flat: 2.4306563958525658, pod: 47.35498404502869, loss: 52.86944079399109 
Train [24/26] | Epoch [43/160] |	nca: 3.038379415869713, flat: 2.4579206705093384, pod: 47.2743444442749, loss: 52.770644187927246 
Train [24/26] | Epoch [44/160] |	nca: 2.8780831769108772, flat: 2.321345239877701, pod: 45.87731206417084, loss: 51.07674026489258 
Train [24/26] | Epoch [45/160] |	nca: 3.030357025563717, flat: 2.374701924622059, pod: 46.256430864334106, loss: 51.661489725112915 
Train [24/26] | Epoch [46/160] |	nca: 2.8478147983551025, flat: 2.4817017316818237, pod: 48.71026432514191, loss: 54.03978133201599 
Train [24/26] | Epoch [47/160] |	nca: 2.9471056312322617, flat: 2.360419437289238, pod: 47.595576763153076, loss: 52.903101444244385 
Train [24/26] | Epoch [48/160] |	nca: 2.887573041021824, flat: 2.4643504917621613, pod: 47.43580090999603, loss: 52.78772473335266 
Train [24/26] | Epoch [49/160] |	nca: 2.800629712641239, flat: 2.4667781591415405, pod: 47.91990780830383, loss: 53.187315464019775 
Train [24/26] | Epoch [50/160] |	nca: 2.8853674903512, flat: 2.1544180437922478, pod: 44.71020567417145, loss: 49.749990463256836 
Train [24/26] | Epoch [51/160] |	nca: 3.0015395656228065, flat: 2.2765313014388084, pod: 44.336156725883484, loss: 49.61422777175903 
Train [24/26] | Epoch [52/160] |	nca: 2.676041327416897, flat: 2.182403400540352, pod: 43.372071385383606, loss: 48.23051607608795 
Train [24/26] | Epoch [53/160] |	nca: 2.7856194153428078, flat: 2.182499445974827, pod: 43.82159972190857, loss: 48.78971874713898 
Train [24/26] | Epoch [54/160] |	nca: 2.782227046787739, flat: 2.14075668156147, pod: 42.62533640861511, loss: 47.54832065105438 
Train [24/26] | Epoch [55/160] |	nca: 2.7033429741859436, flat: 2.00671299546957, pod: 42.7783887386322, loss: 47.488444805145264 
Train [24/26] | Epoch [56/160] |	nca: 2.558843992650509, flat: 2.0968819111585617, pod: 44.42520582675934, loss: 49.08093190193176 
Train [24/26] | Epoch [57/160] |	nca: 2.628823295235634, flat: 2.1193538308143616, pod: 42.840874552726746, loss: 47.589051723480225 
Train [24/26] | Epoch [58/160] |	nca: 2.850339502096176, flat: 2.1096714437007904, pod: 44.43265163898468, loss: 49.39266300201416 
Train [24/26] | Epoch [59/160] |	nca: 2.722020775079727, flat: 2.1027059704065323, pod: 43.130759596824646, loss: 47.95548617839813 
Train [24/26] | Epoch [60/160] |	nca: 2.6440462842583656, flat: 2.2308676093816757, pod: 45.51110303401947, loss: 50.38601624965668 
Train [24/26] | Epoch [61/160] |	nca: 2.455396182835102, flat: 2.1843886971473694, pod: 44.090121030807495, loss: 48.72990548610687 
Train [24/26] | Epoch [62/160] |	nca: 2.7860964983701706, flat: 2.096897304058075, pod: 45.26077914237976, loss: 50.14377284049988 
Train [24/26] | Epoch [63/160] |	nca: 2.5911542177200317, flat: 2.0439346581697464, pod: 41.75513529777527, loss: 46.39022386074066 
Train [24/26] | Epoch [64/160] |	nca: 2.4410187527537346, flat: 1.9364985153079033, pod: 42.740477323532104, loss: 47.11799490451813 
Train [24/26] | Epoch [65/160] |	nca: 2.498159281909466, flat: 1.903083935379982, pod: 41.560930490493774, loss: 45.96217370033264 
Train [24/26] | Epoch [66/160] |	nca: 2.593448616564274, flat: 2.0523635670542717, pod: 44.72913146018982, loss: 49.374942779541016 
Train [24/26] | Epoch [67/160] |	nca: 2.649728089570999, flat: 1.90469940751791, pod: 41.84426808357239, loss: 46.39869570732117 
Train [24/26] | Epoch [68/160] |	nca: 2.458379030227661, flat: 1.816197618842125, pod: 40.789392590522766, loss: 45.063969135284424 
Train [24/26] | Epoch [69/160] |	nca: 2.4750446528196335, flat: 1.9028599262237549, pod: 42.163262367248535, loss: 46.54116725921631 
Train [24/26] | Epoch [70/160] |	nca: 2.4071407318115234, flat: 1.868436798453331, pod: 41.351358294487, loss: 45.62693548202515 
Train [24/26] | Epoch [71/160] |	nca: 2.6804678067564964, flat: 2.0661258846521378, pod: 43.26061153411865, loss: 48.00720512866974 
Train [24/26] | Epoch [72/160] |	nca: 2.631108596920967, flat: 1.9690912514925003, pod: 41.94988751411438, loss: 46.550087571144104 
Train [24/26] | Epoch [73/160] |	nca: 2.679590627551079, flat: 2.121073566377163, pod: 44.89675295352936, loss: 49.69741725921631 
Train [24/26] | Epoch [74/160] |	nca: 2.4120689183473587, flat: 1.8486331552267075, pod: 39.848573207855225, loss: 44.109275221824646 
Train [24/26] | Epoch [75/160] |	nca: 2.201437532901764, flat: 1.7704134434461594, pod: 39.29066622257233, loss: 43.26251721382141 
Train [24/26] | Epoch [76/160] |	nca: 2.3668139576911926, flat: 1.7473370395600796, pod: 39.63391375541687, loss: 43.74806499481201 
Train [24/26] | Epoch [77/160] |	nca: 2.4952835887670517, flat: 1.8143391832709312, pod: 41.41277086734772, loss: 45.72239410877228 
Train [24/26] | Epoch [78/160] |	nca: 2.3609247878193855, flat: 1.7723222710192204, pod: 39.84252882003784, loss: 43.975775837898254 
Train [24/26] | Epoch [79/160] |	nca: 2.2791518047451973, flat: 1.646092887967825, pod: 37.69928789138794, loss: 41.62453258037567 
Train [24/26] | Epoch [80/160] |	nca: 2.3275348618626595, flat: 1.4771009013056755, pod: 35.43374526500702, loss: 39.23838126659393 
Train [24/26] | Epoch [81/160] |	nca: 2.3070195838809013, flat: 1.5250935032963753, pod: 36.757184743881226, loss: 40.589298129081726 
Train [24/26] | Epoch [82/160] |	nca: 2.5047615095973015, flat: 1.706692636013031, pod: 39.48804748058319, loss: 43.699501633644104 
Train [24/26] | Epoch [83/160] |	nca: 2.338854640722275, flat: 1.5720963515341282, pod: 37.20187950134277, loss: 41.11283040046692 
Train [24/26] | Epoch [84/160] |	nca: 2.4877746254205704, flat: 1.5173512436449528, pod: 34.680373191833496, loss: 38.68549883365631 
Train [24/26] | Epoch [85/160] |	nca: 2.755104973912239, flat: 1.6125459633767605, pod: 38.01247525215149, loss: 42.38012611865997 
Train [24/26] | Epoch [86/160] |	nca: 2.2981004118919373, flat: 1.4938839711248875, pod: 36.20861828327179, loss: 40.00060284137726 
Train [24/26] | Epoch [87/160] |	nca: 2.2148307636380196, flat: 1.4817172326147556, pod: 35.706751346588135, loss: 39.40329957008362 
Train [24/26] | Epoch [88/160] |	nca: 2.279596172273159, flat: 1.4759395197033882, pod: 35.05836081504822, loss: 38.81389653682709 
Train [24/26] | Epoch [89/160] |	nca: 2.5815882831811905, flat: 1.5749504417181015, pod: 37.83291757106781, loss: 41.98945641517639 
Train [24/26] | Epoch [90/160] |	nca: 2.4189194813370705, flat: 1.6167515777051449, pod: 38.399853587150574, loss: 42.435524702072144 
Train [24/26] | Epoch [91/160] |	nca: 2.2487632110714912, flat: 1.4668518379330635, pod: 35.9499568939209, loss: 39.66557216644287 
Train [24/26] | Epoch [92/160] |	nca: 2.270309753715992, flat: 1.5014390759170055, pod: 35.59713327884674, loss: 39.368882060050964 
Train [24/26] | Epoch [93/160] |	nca: 2.2327563986182213, flat: 1.3970146961510181, pod: 35.06551194190979, loss: 38.69528329372406 
Train [24/26] | Epoch [94/160] |	nca: 2.299372024834156, flat: 1.4653837606310844, pod: 34.816399335861206, loss: 38.58115482330322 
Train [24/26] | Epoch [95/160] |	nca: 2.2209823727607727, flat: 1.4318301789462566, pod: 34.484450459480286, loss: 38.13726317882538 
Train [24/26] | Epoch [96/160] |	nca: 2.3462132811546326, flat: 1.4747519046068192, pod: 35.598403453826904, loss: 39.419368505477905 
Train [24/26] | Epoch [97/160] |	nca: 2.223944239318371, flat: 1.4064627662301064, pod: 34.57752215862274, loss: 38.207929253578186 
Train [24/26] | Epoch [98/160] |	nca: 2.212829850614071, flat: 1.3488740995526314, pod: 33.67865061759949, loss: 37.24035453796387 
Train [24/26] | Epoch [99/160] |	nca: 2.090595670044422, flat: 1.3051592260599136, pod: 32.61413383483887, loss: 36.00988852977753 
Train [24/26] | Epoch [100/160] |	nca: 2.1177763156592846, flat: 1.3382747694849968, pod: 33.638711810112, loss: 37.09476292133331 
Train [24/26] | Epoch [101/160] |	nca: 2.182354025542736, flat: 1.2923472598195076, pod: 32.675140380859375, loss: 36.14984166622162 
Train [24/26] | Epoch [102/160] |	nca: 2.281309563666582, flat: 1.20762250572443, pod: 31.64596128463745, loss: 35.13489353656769 
Train [24/26] | Epoch [103/160] |	nca: 2.182409092783928, flat: 1.3528643921017647, pod: 34.35642206668854, loss: 37.891695618629456 
Train [24/26] | Epoch [104/160] |	nca: 2.1406598538160324, flat: 1.235246516764164, pod: 32.13064980506897, loss: 35.506556153297424 
Train [24/26] | Epoch [105/160] |	nca: 2.2138692177832127, flat: 1.301813080906868, pod: 32.81391143798828, loss: 36.329593896865845 
Train [24/26] | Epoch [106/160] |	nca: 2.23331718146801, flat: 1.2307840511202812, pod: 32.104092478752136, loss: 35.568193554878235 
Train [24/26] | Epoch [107/160] |	nca: 2.1719714403152466, flat: 1.2676551043987274, pod: 33.151202917099, loss: 36.590829253196716 
Train [24/26] | Epoch [108/160] |	nca: 2.288676641881466, flat: 1.159513384103775, pod: 30.558971762657166, loss: 34.00716185569763 
Train [24/26] | Epoch [109/160] |	nca: 2.010200124233961, flat: 1.1332985050976276, pod: 31.25266182422638, loss: 34.39616024494171 
Train [24/26] | Epoch [110/160] |	nca: 2.2423693388700485, flat: 1.1155352666974068, pod: 30.267215251922607, loss: 33.62511956691742 
Train [24/26] | Epoch [111/160] |	nca: 2.2737880498170853, flat: 1.1917052417993546, pod: 32.50543141365051, loss: 35.970924615859985 
Train [24/26] | Epoch [112/160] |	nca: 2.138767346739769, flat: 1.089539248496294, pod: 29.516867876052856, loss: 32.745174407958984 
Train [24/26] | Epoch [113/160] |	nca: 2.100603360682726, flat: 1.1467224545776844, pod: 31.011808276176453, loss: 34.25913405418396 
Train [24/26] | Epoch [114/160] |	nca: 2.1556709110736847, flat: 1.0858867950737476, pod: 29.15839385986328, loss: 32.399951577186584 
Train [24/26] | Epoch [115/160] |	nca: 2.0795149356126785, flat: 1.1039809435606003, pod: 29.90752935409546, loss: 33.09102523326874 
Train [24/26] | Epoch [116/160] |	nca: 2.0568337589502335, flat: 1.05518564209342, pod: 29.669153571128845, loss: 32.78117299079895 
Train [24/26] | Epoch [117/160] |	nca: 2.224550299346447, flat: 1.0908488593995571, pod: 31.380019545555115, loss: 34.69541847705841 
Train [24/26] | Epoch [118/160] |	nca: 2.0714497566223145, flat: 1.074713196605444, pod: 29.581761837005615, loss: 32.727924942970276 
Train [24/26] | Epoch [119/160] |	nca: 2.0270335860550404, flat: 1.0069399997591972, pod: 28.510077238082886, loss: 31.54405105113983 
Train [24/26] | Epoch [120/160] |	nca: 2.0292022675275803, flat: 0.9645152948796749, pod: 27.177004158496857, loss: 30.170721769332886 
Train [24/26] | Epoch [121/160] |	nca: 2.0299727767705917, flat: 0.9779774639755487, pod: 28.253505527973175, loss: 31.261455297470093 
Train [24/26] | Epoch [122/160] |	nca: 2.0523955784738064, flat: 0.9026386737823486, pod: 25.975904166698456, loss: 28.930938482284546 
Train [24/26] | Epoch [123/160] |	nca: 2.315257266163826, flat: 0.9565080814063549, pod: 26.707804679870605, loss: 29.979570150375366 
Train [24/26] | Epoch [124/160] |	nca: 2.227588813751936, flat: 1.025503072887659, pod: 27.710003912448883, loss: 30.963095664978027 
Train [24/26] | Epoch [125/160] |	nca: 2.071799486875534, flat: 0.9299075119197369, pod: 26.029323279857635, loss: 29.03103017807007 
Train [24/26] | Epoch [126/160] |	nca: 2.0831641107797623, flat: 0.8835948798805475, pod: 25.50702393054962, loss: 28.473782539367676 
Train [24/26] | Epoch [127/160] |	nca: 2.087427295744419, flat: 0.9386805538088083, pod: 27.545090913772583, loss: 30.57119846343994 
Train [24/26] | Epoch [128/160] |	nca: 1.9659797996282578, flat: 0.8874620962888002, pod: 26.071941435337067, loss: 28.92538332939148 
Train [24/26] | Epoch [129/160] |	nca: 1.9563616961240768, flat: 0.8365250751376152, pod: 24.4301655292511, loss: 27.223052620887756 
Train [24/26] | Epoch [130/160] |	nca: 2.0495725944638252, flat: 0.7950676903128624, pod: 23.37727552652359, loss: 26.22191560268402 
Train [24/26] | Epoch [131/160] |	nca: 2.145870693027973, flat: 0.817697387188673, pod: 24.44287669658661, loss: 27.40644472837448 
Train [24/26] | Epoch [132/160] |	nca: 2.035820595920086, flat: 0.8546328954398632, pod: 24.63939517736435, loss: 27.52984893321991 
Train [24/26] | Epoch [133/160] |	nca: 2.012613445520401, flat: 0.8293027263134718, pod: 24.69547414779663, loss: 27.53739035129547 
Train [24/26] | Epoch [134/160] |	nca: 2.1190706863999367, flat: 0.8605035059154034, pod: 24.473519146442413, loss: 27.45309281349182 
Train [24/26] | Epoch [135/160] |	nca: 2.097025066614151, flat: 0.8220771308988333, pod: 23.803961515426636, loss: 26.723063707351685 
Train [24/26] | Epoch [136/160] |	nca: 2.0514556281268597, flat: 0.8163118455559015, pod: 24.234215259552002, loss: 27.101982712745667 
Train [24/26] | Epoch [137/160] |	nca: 2.097177617251873, flat: 0.8227927833795547, pod: 23.626064658164978, loss: 26.546034932136536 
Train [24/26] | Epoch [138/160] |	nca: 1.9939114041626453, flat: 0.8018684666603804, pod: 23.579820156097412, loss: 26.3756000995636 
Train [24/26] | Epoch [139/160] |	nca: 2.077759452164173, flat: 0.7426093872636557, pod: 22.021660149097443, loss: 24.84202891588211 
Train [24/26] | Epoch [140/160] |	nca: 1.9948695041239262, flat: 0.7664134036749601, pod: 22.26688849925995, loss: 25.02817142009735 
Train [24/26] | Epoch [141/160] |	nca: 2.0012079253792763, flat: 0.736055376008153, pod: 21.72867715358734, loss: 24.465940415859222 
Train [24/26] | Epoch [142/160] |	nca: 2.025234133005142, flat: 0.700147969648242, pod: 21.274653136730194, loss: 24.000035285949707 
Train [24/26] | Epoch [143/160] |	nca: 2.1381376683712006, flat: 0.7128660473972559, pod: 21.24110996723175, loss: 24.09211367368698 
Train [24/26] | Epoch [144/160] |	nca: 1.9740954004228115, flat: 0.6833266168832779, pod: 21.42545521259308, loss: 24.082877218723297 
Train [24/26] | Epoch [145/160] |	nca: 2.1584023907780647, flat: 0.7172268629074097, pod: 21.543103218078613, loss: 24.418732464313507 
Train [24/26] | Epoch [146/160] |	nca: 2.0596729665994644, flat: 0.7051367629319429, pod: 21.21348124742508, loss: 23.97829097509384 
Train [24/26] | Epoch [147/160] |	nca: 2.036295495927334, flat: 0.6786206718534231, pod: 20.78764510154724, loss: 23.502561211586 
Train [24/26] | Epoch [148/160] |	nca: 2.0396005734801292, flat: 0.6939995791763067, pod: 20.780684888362885, loss: 23.514285266399384 
Train [24/26] | Epoch [149/160] |	nca: 2.115107338875532, flat: 0.7366836331784725, pod: 21.685756146907806, loss: 24.537547409534454 
Train [24/26] | Epoch [150/160] |	nca: 2.0438447445631027, flat: 0.7035545166581869, pod: 20.556637823581696, loss: 23.304037153720856 
Train [24/26] | Epoch [151/160] |	nca: 2.043415881693363, flat: 0.6636245902627707, pod: 19.87099254131317, loss: 22.578032910823822 
Train [24/26] | Epoch [152/160] |	nca: 1.947506569325924, flat: 0.6752900332212448, pod: 20.414104759693146, loss: 23.03690141439438 
Train [24/26] | Epoch [153/160] |	nca: 1.8972671702504158, flat: 0.6773050930351019, pod: 20.809877336025238, loss: 23.384449541568756 
Train [24/26] | Epoch [154/160] |	nca: 2.077803637832403, flat: 0.6445556413382292, pod: 19.858290433883667, loss: 22.58064967393875 
Train [24/26] | Epoch [155/160] |	nca: 1.9710387662053108, flat: 0.6155777666717768, pod: 19.72168004512787, loss: 22.308296620845795 
Train [24/26] | Epoch [156/160] |	nca: 2.0301097109913826, flat: 0.6744363810867071, pod: 20.427574038505554, loss: 23.132120192050934 
Train [24/26] | Epoch [157/160] |	nca: 1.9701225608587265, flat: 0.6333938036113977, pod: 19.763009667396545, loss: 22.366526067256927 
Train [24/26] | Epoch [158/160] |	nca: 2.0212848149240017, flat: 0.6166980136185884, pod: 19.877096116542816, loss: 22.515079021453857 
Train [24/26] | Epoch [159/160] |	nca: 2.0285688266158104, flat: 0.6333844047039747, pod: 19.03406012058258, loss: 21.696013271808624 
Train [24/26] | Epoch [160/160] |	nca: 2.095182839781046, flat: 0.6423161514103413, pod: 19.313380122184753, loss: 22.05087912082672 
Fine-tuning
Building & updating memory.
Train [24/26] | Epoch [161/180] |	nca: 1.0587387271225452, flat: 0.6757632158696651, pod: 15.707262992858887, loss: 17.44176495075226 
Train [24/26] | Epoch [162/180] |	nca: 0.7876674775034189, flat: 0.6810620538890362, pod: 15.770991742610931, loss: 17.239721298217773 
Train [24/26] | Epoch [163/180] |	nca: 0.6378198321908712, flat: 0.6853667534887791, pod: 15.768312096595764, loss: 17.09149867296219 
Train [24/26] | Epoch [164/180] |	nca: 0.6582595314830542, flat: 0.7142159957438707, pod: 15.87578797340393, loss: 17.248263478279114 
Train [24/26] | Epoch [165/180] |	nca: 0.6505694948136806, flat: 0.6691130921244621, pod: 15.704990983009338, loss: 17.024673402309418 
Train [24/26] | Epoch [166/180] |	nca: 0.5934341941028833, flat: 0.6987805925309658, pod: 15.928214848041534, loss: 17.22042965888977 
Train [24/26] | Epoch [167/180] |	nca: 0.5730902869254351, flat: 0.6698998287320137, pod: 15.451158344745636, loss: 16.694148242473602 
Train [24/26] | Epoch [168/180] |	nca: 0.5643190331757069, flat: 0.676751559600234, pod: 16.223260819911957, loss: 17.464331448078156 
Train [24/26] | Epoch [169/180] |	nca: 0.5556820500642061, flat: 0.6969126760959625, pod: 15.91182255744934, loss: 17.16441720724106 
Train [24/26] | Epoch [170/180] |	nca: 0.5346500892192125, flat: 0.6965321246534586, pod: 15.82572203874588, loss: 17.056904196739197 
Train [24/26] | Epoch [171/180] |	nca: 0.5848392527550459, flat: 0.6799322068691254, pod: 15.819052159786224, loss: 17.08382374048233 
Train [24/26] | Epoch [172/180] |	nca: 0.5966986306011677, flat: 0.6637580953538418, pod: 15.446312487125397, loss: 16.706769287586212 
Train [24/26] | Epoch [173/180] |	nca: 0.5389349292963743, flat: 0.7024387568235397, pod: 15.710848927497864, loss: 16.952222764492035 
Train [24/26] | Epoch [174/180] |	nca: 0.5470087379217148, flat: 0.7181251086294651, pod: 16.63749063014984, loss: 17.902624368667603 
Train [24/26] | Epoch [175/180] |	nca: 0.5484857521951199, flat: 0.6757237426936626, pod: 15.576923429965973, loss: 16.80113309621811 
Train [24/26] | Epoch [176/180] |	nca: 0.5000099474564195, flat: 0.6821116618812084, pod: 15.81016981601715, loss: 16.9922913312912 
Train [24/26] | Epoch [177/180] |	nca: 0.5055655892938375, flat: 0.7029054276645184, pod: 15.726560115814209, loss: 16.935031175613403 
Train [24/26] | Epoch [178/180] |	nca: 0.5635072905570269, flat: 0.6548684630542994, pod: 15.315103888511658, loss: 16.53347957134247 
Train [24/26] | Epoch [179/180] |	nca: 0.5356921721249819, flat: 0.7144057676196098, pod: 15.95127934217453, loss: 17.201377391815186 
Train [24/26] | Epoch [180/180] |	nca: 0.5110931191593409, flat: 0.6770844422280788, pod: 15.544818043708801, loss: 16.732995569705963 
after task
Building & updating memory.
after task
Eval on 0->96.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6126249999999999.
Current acc: {'total': 0.517, '00-09': 0.595, '10-19': 0.508, '20-29': 0.411, '30-39': 0.471, '40-49': 0.555, '50-59': 0.508, '60-69': 0.383, '70-79': 0.539, '80-89': 0.583, '90-99': 0.692}.
Avg inc acc top5: 0.8638333333333331.
Current acc top5: {'total': 0.811}.
Forgetting: 0.2398181818181819.
Cord metric: 0.61.
Old accuracy: 0.51, mean: 0.60.
New accuracy: 0.68, mean: 0.78.
================Task 24 Start!================
Testing on False unseen tasks (max class = 98).
Set memory of size: 1920.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 24 Training!================
The training samples number: 2920
Train on 96->98.
train task
nb 2920.
Train [25/26] | Epoch [1/160] |	nca: 12.881286859512329, flat: 6.019063539803028, pod: 63.04823112487793, loss: 81.9485821723938 
Train [25/26] | Epoch [2/160] |	nca: 8.976706981658936, flat: 6.532283067703247, pod: 70.36315083503723, loss: 85.87214088439941 
Train [25/26] | Epoch [3/160] |	nca: 7.280359551310539, flat: 6.102230340242386, pod: 68.67789030075073, loss: 82.06048035621643 
Train [25/26] | Epoch [4/160] |	nca: 6.494936838746071, flat: 5.285104721784592, pod: 65.89243531227112, loss: 77.67247724533081 
Train [25/26] | Epoch [5/160] |	nca: 3.9693182706832886, flat: 3.9280650913715363, pod: 58.048696756362915, loss: 65.94607996940613 
Train [25/26] | Epoch [6/160] |	nca: 3.736493870615959, flat: 3.67057341337204, pod: 58.70598578453064, loss: 66.1130530834198 
Train [25/26] | Epoch [7/160] |	nca: 3.436994321644306, flat: 3.38166406750679, pod: 56.39876103401184, loss: 63.21741986274719 
Train [25/26] | Epoch [8/160] |	nca: 3.2512926906347275, flat: 3.103811554610729, pod: 53.9532573223114, loss: 60.308361530303955 
Train [25/26] | Epoch [9/160] |	nca: 3.0280579552054405, flat: 3.129118874669075, pod: 56.582651138305664, loss: 62.73982858657837 
Train [25/26] | Epoch [10/160] |	nca: 2.8743788674473763, flat: 2.9063396379351616, pod: 53.1318576335907, loss: 58.91257572174072 
Train [25/26] | Epoch [11/160] |	nca: 2.8788197189569473, flat: 2.959541939198971, pod: 54.30298125743866, loss: 60.14134359359741 
Train [25/26] | Epoch [12/160] |	nca: 3.0077009946107864, flat: 2.9118056669831276, pod: 52.98405456542969, loss: 58.90356159210205 
Train [25/26] | Epoch [13/160] |	nca: 2.8264416456222534, flat: 2.7236750796437263, pod: 50.13473868370056, loss: 55.68485474586487 
Train [25/26] | Epoch [14/160] |	nca: 3.028122328221798, flat: 2.921967327594757, pod: 51.83750653266907, loss: 57.787595987319946 
Train [25/26] | Epoch [15/160] |	nca: 2.7006886675953865, flat: 2.792614124715328, pod: 50.702698826789856, loss: 56.19600200653076 
Train [25/26] | Epoch [16/160] |	nca: 3.2246016040444374, flat: 2.9597579538822174, pod: 52.13164186477661, loss: 58.31600093841553 
Train [25/26] | Epoch [17/160] |	nca: 2.710658200085163, flat: 2.816873289644718, pod: 50.77157378196716, loss: 56.29910492897034 
Train [25/26] | Epoch [18/160] |	nca: 2.811342116445303, flat: 2.5379028394818306, pod: 48.46080541610718, loss: 53.81005120277405 
Train [25/26] | Epoch [19/160] |	nca: 3.116169571876526, flat: 2.9669204354286194, pod: 52.887608766555786, loss: 58.970698595047 
Train [25/26] | Epoch [20/160] |	nca: 3.3083619847893715, flat: 3.186868891119957, pod: 54.1478807926178, loss: 60.64311194419861 
Train [25/26] | Epoch [21/160] |	nca: 3.0848325937986374, flat: 3.276947595179081, pod: 55.10869836807251, loss: 61.470478773117065 
Train [25/26] | Epoch [22/160] |	nca: 2.801143169403076, flat: 2.7530574649572372, pod: 48.53117859363556, loss: 54.085379123687744 
Train [25/26] | Epoch [23/160] |	nca: 2.7620361112058163, flat: 2.725443087518215, pod: 49.207358598709106, loss: 54.694838523864746 
Train [25/26] | Epoch [24/160] |	nca: 3.143761456012726, flat: 2.8898813128471375, pod: 51.85322976112366, loss: 57.88687300682068 
Train [25/26] | Epoch [25/160] |	nca: 2.711638331413269, flat: 2.676218532025814, pod: 48.62880063056946, loss: 54.01665759086609 
Train [25/26] | Epoch [26/160] |	nca: 2.719523698091507, flat: 2.6157616302371025, pod: 48.19416677951813, loss: 53.52945160865784 
Train [25/26] | Epoch [27/160] |	nca: 2.6399327740073204, flat: 2.6258354410529137, pod: 48.483237862586975, loss: 53.749006271362305 
Train [25/26] | Epoch [28/160] |	nca: 2.7143796905875206, flat: 2.5905773118138313, pod: 48.2115513086319, loss: 53.51650834083557 
Train [25/26] | Epoch [29/160] |	nca: 2.964229851961136, flat: 2.8604317978024483, pod: 51.785889625549316, loss: 57.61055111885071 
Train [25/26] | Epoch [30/160] |	nca: 2.746820867061615, flat: 2.605290174484253, pod: 49.657066822052, loss: 55.009178161621094 
Train [25/26] | Epoch [31/160] |	nca: 2.6300285384058952, flat: 2.618527963757515, pod: 49.44763517379761, loss: 54.69619131088257 
Train [25/26] | Epoch [32/160] |	nca: 2.603889025747776, flat: 2.654468208551407, pod: 50.89754891395569, loss: 56.155906200408936 
Train [25/26] | Epoch [33/160] |	nca: 2.4576136469841003, flat: 2.5527229830622673, pod: 48.129804611206055, loss: 53.140140771865845 
Train [25/26] | Epoch [34/160] |	nca: 2.6281889528036118, flat: 2.54142265021801, pod: 47.58153033256531, loss: 52.75114178657532 
Train [25/26] | Epoch [35/160] |	nca: 2.4837883710861206, flat: 2.5568992123007774, pod: 50.140697598457336, loss: 55.18138527870178 
Train [25/26] | Epoch [36/160] |	nca: 2.59071758762002, flat: 2.6059884428977966, pod: 50.37327814102173, loss: 55.569983959198 
Train [25/26] | Epoch [37/160] |	nca: 2.6361662447452545, flat: 2.598702073097229, pod: 50.40529263019562, loss: 55.64016008377075 
Train [25/26] | Epoch [38/160] |	nca: 2.5000449791550636, flat: 2.5848663225769997, pod: 48.843066334724426, loss: 53.927977561950684 
Train [25/26] | Epoch [39/160] |	nca: 2.823505498468876, flat: 2.6736488714814186, pod: 48.22487258911133, loss: 53.72202754020691 
Train [25/26] | Epoch [40/160] |	nca: 2.4169992804527283, flat: 2.4075204581022263, pod: 47.17137253284454, loss: 51.99589276313782 
Train [25/26] | Epoch [41/160] |	nca: 2.4635936059057713, flat: 2.486047200858593, pod: 48.63572371006012, loss: 53.58536434173584 
Train [25/26] | Epoch [42/160] |	nca: 2.676110554486513, flat: 2.5223378688097, pod: 48.130377888679504, loss: 53.328826904296875 
Train [25/26] | Epoch [43/160] |	nca: 2.382426254451275, flat: 2.4730070009827614, pod: 47.55915713310242, loss: 52.41459035873413 
Train [25/26] | Epoch [44/160] |	nca: 2.675910972058773, flat: 2.4572137221693993, pod: 47.67402243614197, loss: 52.80714750289917 
Train [25/26] | Epoch [45/160] |	nca: 2.3930065110325813, flat: 2.3241313695907593, pod: 45.219269037246704, loss: 49.93640673160553 
Train [25/26] | Epoch [46/160] |	nca: 2.3454182744026184, flat: 2.3074797689914703, pod: 46.05315601825714, loss: 50.70605385303497 
Train [25/26] | Epoch [47/160] |	nca: 2.6554988473653793, flat: 2.5153255462646484, pod: 47.798935413360596, loss: 52.96976017951965 
Train [25/26] | Epoch [48/160] |	nca: 2.34643816947937, flat: 2.3395393937826157, pod: 46.45713722705841, loss: 51.14311468601227 
Train [25/26] | Epoch [49/160] |	nca: 2.3544600158929825, flat: 2.273510344326496, pod: 45.764957547187805, loss: 50.392927408218384 
Train [25/26] | Epoch [50/160] |	nca: 2.1180625408887863, flat: 2.0382213816046715, pod: 41.47186231613159, loss: 45.62814664840698 
Train [25/26] | Epoch [51/160] |	nca: 2.4269913993775845, flat: 2.122581087052822, pod: 43.25788497924805, loss: 47.80745792388916 
Train [25/26] | Epoch [52/160] |	nca: 2.3107633367180824, flat: 2.053898461163044, pod: 43.623711943626404, loss: 47.9883736371994 
Train [25/26] | Epoch [53/160] |	nca: 2.393308337777853, flat: 1.983048401772976, pod: 42.511415123939514, loss: 46.887771248817444 
Train [25/26] | Epoch [54/160] |	nca: 2.368510451167822, flat: 2.156279593706131, pod: 43.87887632846832, loss: 48.403666377067566 
Train [25/26] | Epoch [55/160] |	nca: 2.2348735854029655, flat: 2.1292825043201447, pod: 43.76571428775787, loss: 48.1298702955246 
Train [25/26] | Epoch [56/160] |	nca: 2.267226330935955, flat: 2.0584181249141693, pod: 43.47407102584839, loss: 47.79971539974213 
Train [25/26] | Epoch [57/160] |	nca: 2.1438365802168846, flat: 2.026109166443348, pod: 43.43649482727051, loss: 47.60644042491913 
Train [25/26] | Epoch [58/160] |	nca: 2.295246072113514, flat: 2.0674340650439262, pod: 45.093042492866516, loss: 49.45572328567505 
Train [25/26] | Epoch [59/160] |	nca: 2.277081932872534, flat: 2.1372834146022797, pod: 44.94130325317383, loss: 49.355668783187866 
Train [25/26] | Epoch [60/160] |	nca: 2.3427331149578094, flat: 1.9882453307509422, pod: 41.49808692932129, loss: 45.829065799713135 
Train [25/26] | Epoch [61/160] |	nca: 2.2896140813827515, flat: 2.063097357749939, pod: 42.93623352050781, loss: 47.288944244384766 
Train [25/26] | Epoch [62/160] |	nca: 2.1861557364463806, flat: 1.9495636150240898, pod: 41.89816236495972, loss: 46.0338819026947 
Train [25/26] | Epoch [63/160] |	nca: 2.3039717376232147, flat: 2.1457998156547546, pod: 44.636220812797546, loss: 49.08599281311035 
Train [25/26] | Epoch [64/160] |	nca: 2.641213472932577, flat: 2.203305661678314, pod: 44.807942271232605, loss: 49.652461767196655 
Train [25/26] | Epoch [65/160] |	nca: 2.2908527478575706, flat: 2.0994296967983246, pod: 44.12847924232483, loss: 48.51876223087311 
Train [25/26] | Epoch [66/160] |	nca: 2.3755960166454315, flat: 2.183191753923893, pod: 43.804869651794434, loss: 48.363656759262085 
Train [25/26] | Epoch [67/160] |	nca: 2.2370770946145058, flat: 2.031644433736801, pod: 42.92042624950409, loss: 47.18914794921875 
Train [25/26] | Epoch [68/160] |	nca: 2.283667027950287, flat: 1.8141790702939034, pod: 41.144615650177, loss: 45.24246144294739 
Train [25/26] | Epoch [69/160] |	nca: 2.158713426440954, flat: 1.8452591188251972, pod: 40.623698472976685, loss: 44.627671122550964 
Train [25/26] | Epoch [70/160] |	nca: 2.1446762159466743, flat: 1.777521014213562, pod: 41.34797286987305, loss: 45.27017033100128 
Train [25/26] | Epoch [71/160] |	nca: 2.1634852662682533, flat: 1.8279579058289528, pod: 40.619014501571655, loss: 44.6104576587677 
Train [25/26] | Epoch [72/160] |	nca: 2.1570042818784714, flat: 1.6913085132837296, pod: 38.57457959651947, loss: 42.422892451286316 
Train [25/26] | Epoch [73/160] |	nca: 2.2978512458503246, flat: 1.753603108227253, pod: 39.70484519004822, loss: 43.75629925727844 
Train [25/26] | Epoch [74/160] |	nca: 1.976287130266428, flat: 1.685633398592472, pod: 38.41358423233032, loss: 42.075504660606384 
Train [25/26] | Epoch [75/160] |	nca: 2.2202349603176117, flat: 1.7962034530937672, pod: 39.310550689697266, loss: 43.32698893547058 
Train [25/26] | Epoch [76/160] |	nca: 2.1849283389747143, flat: 1.7844185158610344, pod: 40.34310233592987, loss: 44.31244933605194 
Train [25/26] | Epoch [77/160] |	nca: 2.108653001487255, flat: 1.7024551033973694, pod: 38.223602533340454, loss: 42.03471040725708 
Train [25/26] | Epoch [78/160] |	nca: 2.30552114546299, flat: 1.7357629984617233, pod: 38.15270674228668, loss: 42.19399118423462 
Train [25/26] | Epoch [79/160] |	nca: 2.1437273547053337, flat: 1.797295667231083, pod: 40.04457950592041, loss: 43.985602259635925 
Train [25/26] | Epoch [80/160] |	nca: 2.2988447174429893, flat: 1.823352724313736, pod: 40.58001351356506, loss: 44.702211141586304 
Train [25/26] | Epoch [81/160] |	nca: 2.192309319972992, flat: 1.8054027706384659, pod: 40.72050404548645, loss: 44.71821594238281 
Train [25/26] | Epoch [82/160] |	nca: 2.0402538143098354, flat: 1.5637756511569023, pod: 37.219807147979736, loss: 40.82383668422699 
Train [25/26] | Epoch [83/160] |	nca: 2.047228168696165, flat: 1.4923052042722702, pod: 35.07291352748871, loss: 38.612446784973145 
Train [25/26] | Epoch [84/160] |	nca: 2.0397315695881844, flat: 1.534039732068777, pod: 36.641322016716, loss: 40.21509337425232 
Train [25/26] | Epoch [85/160] |	nca: 2.0035272240638733, flat: 1.5804617330431938, pod: 38.91529715061188, loss: 42.49928605556488 
Train [25/26] | Epoch [86/160] |	nca: 2.146847903728485, flat: 1.5816257037222385, pod: 38.00970017910004, loss: 41.738173842430115 
Train [25/26] | Epoch [87/160] |	nca: 1.9944063164293766, flat: 1.602665912359953, pod: 37.091798067092896, loss: 40.688870549201965 
Train [25/26] | Epoch [88/160] |	nca: 2.001534603536129, flat: 1.6064177751541138, pod: 36.83671712875366, loss: 40.444669127464294 
Train [25/26] | Epoch [89/160] |	nca: 2.148180030286312, flat: 1.4483486711978912, pod: 35.44304132461548, loss: 39.03957009315491 
Train [25/26] | Epoch [90/160] |	nca: 2.1127080246806145, flat: 1.4297496937215328, pod: 35.37446308135986, loss: 38.91692090034485 
Train [25/26] | Epoch [91/160] |	nca: 1.9564292095601559, flat: 1.4118279442191124, pod: 34.685197591781616, loss: 38.053454756736755 
Train [25/26] | Epoch [92/160] |	nca: 1.8257032334804535, flat: 1.3357471078634262, pod: 34.783708810806274, loss: 37.94515883922577 
Train [25/26] | Epoch [93/160] |	nca: 1.9945035018026829, flat: 1.340956211090088, pod: 33.949304938316345, loss: 37.284764885902405 
Train [25/26] | Epoch [94/160] |	nca: 2.0437933281064034, flat: 1.3920065686106682, pod: 34.94991362094879, loss: 38.38571345806122 
Train [25/26] | Epoch [95/160] |	nca: 1.9497132040560246, flat: 1.3553767278790474, pod: 33.696011424064636, loss: 37.00110101699829 
Train [25/26] | Epoch [96/160] |	nca: 1.8044550195336342, flat: 1.3590990044176579, pod: 33.68192458152771, loss: 36.845478773117065 
Train [25/26] | Epoch [97/160] |	nca: 2.1772079579532146, flat: 1.3271431773900986, pod: 34.1163524389267, loss: 37.62070381641388 
Train [25/26] | Epoch [98/160] |	nca: 1.9686827845871449, flat: 1.2261536344885826, pod: 31.89220380783081, loss: 35.087040185928345 
Train [25/26] | Epoch [99/160] |	nca: 1.8989651165902615, flat: 1.264881830662489, pod: 32.53409445285797, loss: 35.69794166088104 
Train [25/26] | Epoch [100/160] |	nca: 2.0429273322224617, flat: 1.3832539021968842, pod: 34.27992630004883, loss: 37.70610773563385 
Train [25/26] | Epoch [101/160] |	nca: 1.9213505983352661, flat: 1.2044953256845474, pod: 31.780563473701477, loss: 34.90640950202942 
Train [25/26] | Epoch [102/160] |	nca: 1.9719664715230465, flat: 1.2374066710472107, pod: 32.642871499061584, loss: 35.85224449634552 
Train [25/26] | Epoch [103/160] |	nca: 2.0305211022496223, flat: 1.2108998410403728, pod: 32.317848443984985, loss: 35.559269428253174 
Train [25/26] | Epoch [104/160] |	nca: 1.8447392284870148, flat: 1.2376605682075024, pod: 32.16901743412018, loss: 35.2514169216156 
Train [25/26] | Epoch [105/160] |	nca: 1.9072632603347301, flat: 1.195707529783249, pod: 31.75287890434265, loss: 34.85584998130798 
Train [25/26] | Epoch [106/160] |	nca: 2.1007049195468426, flat: 1.3014812134206295, pod: 34.222715616226196, loss: 37.62490177154541 
Train [25/26] | Epoch [107/160] |	nca: 2.0442648753523827, flat: 1.3691284246742725, pod: 36.26021206378937, loss: 39.67360544204712 
Train [25/26] | Epoch [108/160] |	nca: 1.8795559369027615, flat: 1.2151686549186707, pod: 32.53049445152283, loss: 35.625219106674194 
Train [25/26] | Epoch [109/160] |	nca: 1.826087273657322, flat: 1.1476105339825153, pod: 32.08222150802612, loss: 35.05591928958893 
Train [25/26] | Epoch [110/160] |	nca: 1.7769392281770706, flat: 1.1056670993566513, pod: 30.160708785057068, loss: 33.043314933776855 
Train [25/26] | Epoch [111/160] |	nca: 2.046582393348217, flat: 1.2085504494607449, pod: 31.86289381980896, loss: 35.11802685260773 
Train [25/26] | Epoch [112/160] |	nca: 1.8547585867345333, flat: 1.0264241211116314, pod: 28.61934721469879, loss: 31.500529885292053 
Train [25/26] | Epoch [113/160] |	nca: 1.8573511838912964, flat: 1.0069748051464558, pod: 28.22745180130005, loss: 31.091777801513672 
Train [25/26] | Epoch [114/160] |	nca: 1.9335601888597012, flat: 1.1348148584365845, pod: 31.211770057678223, loss: 34.280144929885864 
Train [25/26] | Epoch [115/160] |	nca: 1.887213334441185, flat: 1.119529165327549, pod: 30.324799060821533, loss: 33.331541299819946 
Train [25/26] | Epoch [116/160] |	nca: 1.8476802930235863, flat: 1.0282240733504295, pod: 28.073006987571716, loss: 30.94891119003296 
Train [25/26] | Epoch [117/160] |	nca: 2.102931037545204, flat: 1.042441550642252, pod: 29.013375401496887, loss: 32.158748149871826 
Train [25/26] | Epoch [118/160] |	nca: 1.753919541835785, flat: 0.9562311917543411, pod: 27.198014497756958, loss: 29.90816557407379 
Train [25/26] | Epoch [119/160] |	nca: 1.7548777647316456, flat: 1.0025921761989594, pod: 29.18129026889801, loss: 31.93876004219055 
Train [25/26] | Epoch [120/160] |	nca: 1.8402161076664925, flat: 1.0129736214876175, pod: 28.296297907829285, loss: 31.149487495422363 
Train [25/26] | Epoch [121/160] |	nca: 1.9410309083759785, flat: 0.9863499850034714, pod: 27.12652152776718, loss: 30.05390202999115 
Train [25/26] | Epoch [122/160] |	nca: 1.9217552915215492, flat: 0.9291888028383255, pod: 27.623893082141876, loss: 30.47483718395233 
Train [25/26] | Epoch [123/160] |	nca: 1.8476306721568108, flat: 0.9147539641708136, pod: 26.922537744045258, loss: 29.684922456741333 
Train [25/26] | Epoch [124/160] |	nca: 1.726158320903778, flat: 0.9518497455865145, pod: 27.51349377632141, loss: 30.19150173664093 
Train [25/26] | Epoch [125/160] |	nca: 1.8581006899476051, flat: 0.8855288736522198, pod: 27.50247985124588, loss: 30.24610936641693 
Train [25/26] | Epoch [126/160] |	nca: 1.9298053942620754, flat: 0.950917037203908, pod: 28.026400804519653, loss: 30.90712332725525 
Train [25/26] | Epoch [127/160] |	nca: 1.9366377256810665, flat: 0.8554775360971689, pod: 25.55994337797165, loss: 28.3520587682724 
Train [25/26] | Epoch [128/160] |	nca: 1.8275430276989937, flat: 0.8310596067458391, pod: 24.541899025440216, loss: 27.20050185918808 
Train [25/26] | Epoch [129/160] |	nca: 1.8855449333786964, flat: 0.7708265502005816, pod: 23.955540418624878, loss: 26.61191213130951 
Train [25/26] | Epoch [130/160] |	nca: 1.7759989574551582, flat: 0.8272087704390287, pod: 24.349821388721466, loss: 26.953029096126556 
Train [25/26] | Epoch [131/160] |	nca: 1.8930380530655384, flat: 0.8500936646014452, pod: 24.90576881170273, loss: 27.648900389671326 
Train [25/26] | Epoch [132/160] |	nca: 1.701656486839056, flat: 0.7709280960261822, pod: 24.13822829723358, loss: 26.610812604427338 
Train [25/26] | Epoch [133/160] |	nca: 1.8008897304534912, flat: 0.81264503672719, pod: 24.207740902900696, loss: 26.821275532245636 
Train [25/26] | Epoch [134/160] |	nca: 1.8274624906480312, flat: 0.7433636914938688, pod: 23.19858741760254, loss: 25.769413948059082 
Train [25/26] | Epoch [135/160] |	nca: 1.9359892196953297, flat: 0.7671204973012209, pod: 23.478236615657806, loss: 26.181346654891968 
Train [25/26] | Epoch [136/160] |	nca: 1.8113053441047668, flat: 0.7263754587620497, pod: 22.02861726284027, loss: 24.566298007965088 
Train [25/26] | Epoch [137/160] |	nca: 1.8357550017535686, flat: 0.7591050155460835, pod: 23.34746140241623, loss: 25.942321300506592 
Train [25/26] | Epoch [138/160] |	nca: 1.857725590467453, flat: 0.7836686931550503, pod: 23.571186780929565, loss: 26.212581038475037 
Train [25/26] | Epoch [139/160] |	nca: 1.7996205352246761, flat: 0.7840610351413488, pod: 23.05080235004425, loss: 25.634484350681305 
Train [25/26] | Epoch [140/160] |	nca: 1.8168848976492882, flat: 0.6672385726124048, pod: 21.339721262454987, loss: 23.823844850063324 
Train [25/26] | Epoch [141/160] |	nca: 1.9047730006277561, flat: 0.6950694136321545, pod: 21.22425150871277, loss: 23.824093997478485 
Train [25/26] | Epoch [142/160] |	nca: 1.8609642386436462, flat: 0.7752531133592129, pod: 23.456558227539062, loss: 26.092775583267212 
Train [25/26] | Epoch [143/160] |	nca: 1.8386841975152493, flat: 0.7242200765758753, pod: 22.2446728348732, loss: 24.807576954364777 
Train [25/26] | Epoch [144/160] |	nca: 1.8771465606987476, flat: 0.6765856854617596, pod: 21.16283679008484, loss: 23.716569364070892 
Train [25/26] | Epoch [145/160] |	nca: 1.8626400791108608, flat: 0.7260326221585274, pod: 22.22239887714386, loss: 24.81107133626938 
Train [25/26] | Epoch [146/160] |	nca: 1.7994621023535728, flat: 0.7040339354425669, pod: 21.300276160240173, loss: 23.803771913051605 
Train [25/26] | Epoch [147/160] |	nca: 1.7816948033869267, flat: 0.6866542901843786, pod: 21.09810781478882, loss: 23.566456854343414 
Train [25/26] | Epoch [148/160] |	nca: 1.8886282928287983, flat: 0.677541883662343, pod: 20.673851788043976, loss: 23.24002182483673 
Train [25/26] | Epoch [149/160] |	nca: 1.8231738731265068, flat: 0.6458045858889818, pod: 20.701172173023224, loss: 23.170150876045227 
Train [25/26] | Epoch [150/160] |	nca: 1.862282183021307, flat: 0.6877721026539803, pod: 20.652002573013306, loss: 23.20205694437027 
Train [25/26] | Epoch [151/160] |	nca: 1.8321728073060513, flat: 0.6918438617140055, pod: 20.79408848285675, loss: 23.318105220794678 
Train [25/26] | Epoch [152/160] |	nca: 1.7719625905156136, flat: 0.7011815719306469, pod: 21.289349853992462, loss: 23.76249408721924 
Train [25/26] | Epoch [153/160] |	nca: 1.8387814722955227, flat: 0.6753304041922092, pod: 20.81015145778656, loss: 23.324263155460358 
Train [25/26] | Epoch [154/160] |	nca: 1.7617703303694725, flat: 0.5956967119127512, pod: 18.90455549955368, loss: 21.262022614479065 
Train [25/26] | Epoch [155/160] |	nca: 1.9003484658896923, flat: 0.6874112114310265, pod: 20.70040613412857, loss: 23.288166046142578 
Train [25/26] | Epoch [156/160] |	nca: 1.8413763679564, flat: 0.6430431101471186, pod: 20.07201373577118, loss: 22.556432902812958 
Train [25/26] | Epoch [157/160] |	nca: 1.7069273553788662, flat: 0.6615569405257702, pod: 20.10976004600525, loss: 22.478244423866272 
Train [25/26] | Epoch [158/160] |	nca: 1.8138414211571217, flat: 0.6419641003012657, pod: 19.80513423681259, loss: 22.26093977689743 
Train [25/26] | Epoch [159/160] |	nca: 1.6735631562769413, flat: 0.6469591241329908, pod: 19.65185534954071, loss: 21.97237753868103 
Train [25/26] | Epoch [160/160] |	nca: 1.8169119954109192, flat: 0.6111249141395092, pod: 18.998965740203857, loss: 21.427002489566803 
Fine-tuning
Building & updating memory.
Train [25/26] | Epoch [161/180] |	nca: 1.1719681285321712, flat: 1.01216322183609, pod: 21.628966152668, loss: 23.81309735774994 
Train [25/26] | Epoch [162/180] |	nca: 0.9122077189385891, flat: 0.9060560092329979, pod: 20.58585250377655, loss: 22.40411627292633 
Train [25/26] | Epoch [163/180] |	nca: 0.8093138113617897, flat: 0.9561435095965862, pod: 20.86472487449646, loss: 22.63018226623535 
Train [25/26] | Epoch [164/180] |	nca: 0.7947915121912956, flat: 0.8827297985553741, pod: 20.575119376182556, loss: 22.25264084339142 
Train [25/26] | Epoch [165/180] |	nca: 0.6963212192058563, flat: 0.9587200358510017, pod: 20.961572289466858, loss: 22.616613388061523 
Train [25/26] | Epoch [166/180] |	nca: 0.683754850178957, flat: 0.9558504968881607, pod: 20.754849433898926, loss: 22.394454956054688 
Train [25/26] | Epoch [167/180] |	nca: 0.6627677641808987, flat: 0.9265244342386723, pod: 20.729121923446655, loss: 22.318413734436035 
Train [25/26] | Epoch [168/180] |	nca: 0.65728510171175, flat: 0.9313895478844643, pod: 20.626158952713013, loss: 22.214833617210388 
Train [25/26] | Epoch [169/180] |	nca: 0.6737475283443928, flat: 0.9609524123370647, pod: 20.99141526222229, loss: 22.626115083694458 
Train [25/26] | Epoch [170/180] |	nca: 0.6623180955648422, flat: 0.9505273401737213, pod: 20.950327575206757, loss: 22.563172936439514 
Train [25/26] | Epoch [171/180] |	nca: 0.5958248879760504, flat: 0.9130677841603756, pod: 20.627439498901367, loss: 22.136332035064697 
Train [25/26] | Epoch [172/180] |	nca: 0.6091778539121151, flat: 0.9528020732104778, pod: 20.749057710170746, loss: 22.3110374212265 
Train [25/26] | Epoch [173/180] |	nca: 0.583491800352931, flat: 0.9115644544363022, pod: 20.545539379119873, loss: 22.040595769882202 
Train [25/26] | Epoch [174/180] |	nca: 0.5763634406030178, flat: 0.9074197970330715, pod: 20.256895840168, loss: 21.740678906440735 
Train [25/26] | Epoch [175/180] |	nca: 0.6452991347759962, flat: 0.9438396170735359, pod: 20.56279456615448, loss: 22.151933073997498 
Train [25/26] | Epoch [176/180] |	nca: 0.5830008313059807, flat: 0.9152864515781403, pod: 20.51978826522827, loss: 22.018075704574585 
Train [25/26] | Epoch [177/180] |	nca: 0.6327034384012222, flat: 0.98990049213171, pod: 21.274205684661865, loss: 22.896809816360474 
Train [25/26] | Epoch [178/180] |	nca: 0.6056459005922079, flat: 0.8632653802633286, pod: 20.125426769256592, loss: 21.594337940216064 
Train [25/26] | Epoch [179/180] |	nca: 0.6190299466252327, flat: 0.9442448727786541, pod: 20.224517047405243, loss: 21.78779172897339 
Train [25/26] | Epoch [180/180] |	nca: 0.6128762010484934, flat: 0.9607762284576893, pod: 21.340856194496155, loss: 22.914508819580078 
after task
Building & updating memory.
after task
Eval on 0->98.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6088399999999999.
Current acc: {'total': 0.518, '00-09': 0.595, '10-19': 0.487, '20-29': 0.421, '30-39': 0.466, '40-49': 0.545, '50-59': 0.507, '60-69': 0.402, '70-79': 0.543, '80-89': 0.584, '90-99': 0.659}.
Avg inc acc top5: 0.8613999999999998.
Current acc top5: {'total': 0.803}.
Forgetting: 0.24309090909090905.
Cord metric: 0.61.
Old accuracy: 0.51, mean: 0.60.
New accuracy: 0.78, mean: 0.78.
================Task 25 Start!================
Testing on False unseen tasks (max class = 100).
Set memory of size: 1960.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 25 Training!================
The training samples number: 2960
Train on 98->100.
train task
nb 2960.
Train [26/26] | Epoch [1/160] |	nca: 14.424865484237671, flat: 7.972376205027103, pod: 71.44461059570312, loss: 93.84185266494751 
Train [26/26] | Epoch [2/160] |	nca: 14.481469571590424, flat: 10.753090888261795, pod: 93.09790205955505, loss: 118.33246183395386 
Train [26/26] | Epoch [3/160] |	nca: 12.984574109315872, flat: 9.873475193977356, pod: 91.6041259765625, loss: 114.46217441558838 
Train [26/26] | Epoch [4/160] |	nca: 10.595185816287994, flat: 8.916988521814346, pod: 86.33706140518188, loss: 105.84923648834229 
Train [26/26] | Epoch [5/160] |	nca: 7.028383672237396, flat: 6.88004469871521, pod: 77.27374172210693, loss: 91.18217015266418 
Train [26/26] | Epoch [6/160] |	nca: 5.916101798415184, flat: 5.919192090630531, pod: 73.66208291053772, loss: 85.49737620353699 
Train [26/26] | Epoch [7/160] |	nca: 6.056089803576469, flat: 5.916661411523819, pod: 71.4905788898468, loss: 83.4633297920227 
Train [26/26] | Epoch [8/160] |	nca: 9.362692683935165, flat: 7.986946642398834, pod: 84.29619717597961, loss: 101.64583706855774 
Train [26/26] | Epoch [9/160] |	nca: 5.629001095890999, flat: 6.129561275243759, pod: 73.4218966960907, loss: 85.18045973777771 
Train [26/26] | Epoch [10/160] |	nca: 4.375999756157398, flat: 4.923338770866394, pod: 67.86893057823181, loss: 77.16826939582825 
Train [26/26] | Epoch [11/160] |	nca: 4.024851463735104, flat: 4.275233179330826, pod: 65.16097378730774, loss: 73.46105885505676 
Train [26/26] | Epoch [12/160] |	nca: 4.483023777604103, flat: 4.706820473074913, pod: 65.58947920799255, loss: 74.77932357788086 
Train [26/26] | Epoch [13/160] |	nca: 3.7848935276269913, flat: 4.303909584879875, pod: 63.49277997016907, loss: 71.58158326148987 
Train [26/26] | Epoch [14/160] |	nca: 4.104721434414387, flat: 4.182655036449432, pod: 62.5678026676178, loss: 70.85517907142639 
Train [26/26] | Epoch [15/160] |	nca: 5.055954143404961, flat: 5.312738224864006, pod: 68.2764220237732, loss: 78.64511442184448 
Train [26/26] | Epoch [16/160] |	nca: 3.7361728474497795, flat: 4.133622586727142, pod: 62.84895706176758, loss: 70.71875286102295 
Train [26/26] | Epoch [17/160] |	nca: 3.864862158894539, flat: 4.136976107954979, pod: 62.66099190711975, loss: 70.66283106803894 
Train [26/26] | Epoch [18/160] |	nca: 4.906366810202599, flat: 4.8612146228551865, pod: 64.29544234275818, loss: 74.06302332878113 
Train [26/26] | Epoch [19/160] |	nca: 5.0052595138549805, flat: 5.260204434394836, pod: 66.05159640312195, loss: 76.31706094741821 
Train [26/26] | Epoch [20/160] |	nca: 3.9536335095763206, flat: 4.2098821103572845, pod: 62.79441237449646, loss: 70.95792770385742 
Train [26/26] | Epoch [21/160] |	nca: 3.5746987238526344, flat: 4.280733987689018, pod: 63.21580123901367, loss: 71.07123398780823 
Train [26/26] | Epoch [22/160] |	nca: 3.2526298500597477, flat: 3.498663440346718, pod: 58.169917821884155, loss: 64.92121124267578 
Train [26/26] | Epoch [23/160] |	nca: 3.764067441225052, flat: 3.8727262765169144, pod: 60.15599012374878, loss: 67.79278349876404 
Train [26/26] | Epoch [24/160] |	nca: 3.698448896408081, flat: 4.115479201078415, pod: 61.08519530296326, loss: 68.8991231918335 
Train [26/26] | Epoch [25/160] |	nca: 3.560596190392971, flat: 4.24637271463871, pod: 63.754218339920044, loss: 71.56118679046631 
Train [26/26] | Epoch [26/160] |	nca: 3.183656744658947, flat: 3.811832994222641, pod: 61.849175453186035, loss: 68.84466433525085 
Train [26/26] | Epoch [27/160] |	nca: 3.8466035798192024, flat: 3.886180631816387, pod: 60.62535071372986, loss: 68.35813498497009 
Train [26/26] | Epoch [28/160] |	nca: 4.103886052966118, flat: 4.762198582291603, pod: 65.57816195487976, loss: 74.44424629211426 
Train [26/26] | Epoch [29/160] |	nca: 3.43370757997036, flat: 3.8545508682727814, pod: 61.51469326019287, loss: 68.80295205116272 
Train [26/26] | Epoch [30/160] |	nca: 3.97932893037796, flat: 3.7289894744753838, pod: 59.84517049789429, loss: 67.5534884929657 
Train [26/26] | Epoch [31/160] |	nca: 4.485786870121956, flat: 5.032573446631432, pod: 65.48807883262634, loss: 75.00643873214722 
Train [26/26] | Epoch [32/160] |	nca: 3.531667321920395, flat: 4.239941403269768, pod: 60.77449035644531, loss: 68.54609847068787 
Train [26/26] | Epoch [33/160] |	nca: 3.2455649375915527, flat: 3.6464164927601814, pod: 59.3006796836853, loss: 66.19266080856323 
Train [26/26] | Epoch [34/160] |	nca: 4.386408381164074, flat: 4.609866306185722, pod: 65.42203092575073, loss: 74.41830563545227 
Train [26/26] | Epoch [35/160] |	nca: 4.02214041352272, flat: 4.404163226485252, pod: 61.91295099258423, loss: 70.3392550945282 
Train [26/26] | Epoch [36/160] |	nca: 2.8350236490368843, flat: 3.573819622397423, pod: 57.0252149105072, loss: 63.43405842781067 
Train [26/26] | Epoch [37/160] |	nca: 2.905967339873314, flat: 3.108501337468624, pod: 55.348464012145996, loss: 61.36293268203735 
Train [26/26] | Epoch [38/160] |	nca: 3.4119077026844025, flat: 3.689554125070572, pod: 58.87533211708069, loss: 65.97679400444031 
Train [26/26] | Epoch [39/160] |	nca: 2.9102922715246677, flat: 3.601784460246563, pod: 59.2231650352478, loss: 65.73524260520935 
Train [26/26] | Epoch [40/160] |	nca: 2.6288235634565353, flat: 2.9138567075133324, pod: 52.569939494132996, loss: 58.11261963844299 
Train [26/26] | Epoch [41/160] |	nca: 3.551399886608124, flat: 3.8430686816573143, pod: 59.679707050323486, loss: 67.07417511940002 
Train [26/26] | Epoch [42/160] |	nca: 3.656840965151787, flat: 3.9562598019838333, pod: 60.119160890579224, loss: 67.73226165771484 
Train [26/26] | Epoch [43/160] |	nca: 2.972957082092762, flat: 3.0995443910360336, pod: 55.44862079620361, loss: 61.5211226940155 
Train [26/26] | Epoch [44/160] |	nca: 3.0835112258791924, flat: 3.4280959740281105, pod: 57.723113775253296, loss: 64.2347207069397 
Train [26/26] | Epoch [45/160] |	nca: 2.541023902595043, flat: 2.7887876853346825, pod: 52.52413356304169, loss: 57.8539457321167 
Train [26/26] | Epoch [46/160] |	nca: 2.288094751536846, flat: 2.8407566100358963, pod: 52.09786128997803, loss: 57.226712465286255 
Train [26/26] | Epoch [47/160] |	nca: 2.4753961339592934, flat: 2.556184560060501, pod: 50.24248147010803, loss: 55.274062752723694 
Train [26/26] | Epoch [48/160] |	nca: 3.090808354318142, flat: 3.1629678532481194, pod: 54.61641180515289, loss: 60.87018847465515 
Train [26/26] | Epoch [49/160] |	nca: 2.834267608821392, flat: 3.1947322636842728, pod: 54.68491888046265, loss: 60.713918924331665 
Train [26/26] | Epoch [50/160] |	nca: 2.853363998234272, flat: 3.295319765806198, pod: 55.71819615364075, loss: 61.86687970161438 
Train [26/26] | Epoch [51/160] |	nca: 2.7642979845404625, flat: 3.004445441067219, pod: 52.871299505233765, loss: 58.64004325866699 
Train [26/26] | Epoch [52/160] |	nca: 3.5763470605015755, flat: 3.4098449423909187, pod: 54.94154977798462, loss: 61.92774224281311 
Train [26/26] | Epoch [53/160] |	nca: 4.78263857960701, flat: 4.54563969373703, pod: 63.48423790931702, loss: 72.81251621246338 
Train [26/26] | Epoch [54/160] |	nca: 6.3798245415091515, flat: 5.9851299822330475, pod: 68.09402990341187, loss: 80.458984375 
Train [26/26] | Epoch [55/160] |	nca: 4.309908956289291, flat: 4.617493391036987, pod: 63.262868881225586, loss: 72.1902711391449 
Train [26/26] | Epoch [56/160] |	nca: 3.689240701496601, flat: 3.8219345584511757, pod: 56.05875778198242, loss: 63.56993293762207 
Train [26/26] | Epoch [57/160] |	nca: 3.977579288184643, flat: 4.514102190732956, pod: 61.39186906814575, loss: 69.88355040550232 
Train [26/26] | Epoch [58/160] |	nca: 3.5320089757442474, flat: 3.6123139709234238, pod: 56.44865107536316, loss: 63.5929741859436 
Train [26/26] | Epoch [59/160] |	nca: 3.738767996430397, flat: 4.053292796015739, pod: 58.71981430053711, loss: 66.51187586784363 
Train [26/26] | Epoch [60/160] |	nca: 3.475358121097088, flat: 3.5568713396787643, pod: 54.22332966327667, loss: 61.25555872917175 
Train [26/26] | Epoch [61/160] |	nca: 2.737816747277975, flat: 2.987594872713089, pod: 51.712239146232605, loss: 57.43765091896057 
Train [26/26] | Epoch [62/160] |	nca: 3.027622051537037, flat: 3.014303646981716, pod: 55.00935506820679, loss: 61.05128073692322 
Train [26/26] | Epoch [63/160] |	nca: 2.8856031224131584, flat: 3.0424804016947746, pod: 53.98999238014221, loss: 59.91807556152344 
Train [26/26] | Epoch [64/160] |	nca: 2.7523750737309456, flat: 2.972513645887375, pod: 52.46694374084473, loss: 58.191832065582275 
Train [26/26] | Epoch [65/160] |	nca: 2.5378553569316864, flat: 2.6216122657060623, pod: 50.76229441165924, loss: 55.92176175117493 
Train [26/26] | Epoch [66/160] |	nca: 2.5067123882472515, flat: 2.4291247129440308, pod: 47.34074652194977, loss: 52.276583552360535 
Train [26/26] | Epoch [67/160] |	nca: 2.660600271075964, flat: 2.476522736251354, pod: 47.36389946937561, loss: 52.50102210044861 
Train [26/26] | Epoch [68/160] |	nca: 2.3892140462994576, flat: 2.4761141911149025, pod: 47.99078285694122, loss: 52.85611081123352 
Train [26/26] | Epoch [69/160] |	nca: 2.6454586908221245, flat: 2.803398057818413, pod: 50.095807909965515, loss: 55.54466485977173 
Train [26/26] | Epoch [70/160] |	nca: 2.863323360681534, flat: 2.826193146407604, pod: 51.618457317352295, loss: 57.307974100112915 
Train [26/26] | Epoch [71/160] |	nca: 2.578119684010744, flat: 2.6903268843889236, pod: 50.03087508678436, loss: 55.29932165145874 
Train [26/26] | Epoch [72/160] |	nca: 2.3704258240759373, flat: 2.3536646738648415, pod: 46.28135657310486, loss: 51.005447030067444 
Train [26/26] | Epoch [73/160] |	nca: 2.5531993359327316, flat: 2.6332783326506615, pod: 48.42912971973419, loss: 53.61560773849487 
Train [26/26] | Epoch [74/160] |	nca: 2.1981551498174667, flat: 2.278625003993511, pod: 47.817185163497925, loss: 52.293965578079224 
Train [26/26] | Epoch [75/160] |	nca: 2.2928419895470142, flat: 2.4124472960829735, pod: 48.052969574928284, loss: 52.75825881958008 
Train [26/26] | Epoch [76/160] |	nca: 2.222159843891859, flat: 2.4028744846582413, pod: 47.996209383010864, loss: 52.621243834495544 
Train [26/26] | Epoch [77/160] |	nca: 2.313189025968313, flat: 2.24100624024868, pod: 45.35666036605835, loss: 49.91085588932037 
Train [26/26] | Epoch [78/160] |	nca: 2.7892625741660595, flat: 2.287309154868126, pod: 45.52649259567261, loss: 50.60306441783905 
Train [26/26] | Epoch [79/160] |	nca: 2.495194710791111, flat: 2.4563115164637566, pod: 44.93992841243744, loss: 49.89143443107605 
Train [26/26] | Epoch [80/160] |	nca: 2.370514042675495, flat: 2.2065139189362526, pod: 44.36204719543457, loss: 48.939075231552124 
Train [26/26] | Epoch [81/160] |	nca: 2.4073376320302486, flat: 2.084149282425642, pod: 43.3988561630249, loss: 47.89034330844879 
Train [26/26] | Epoch [82/160] |	nca: 3.0377229675650597, flat: 2.8290192633867264, pod: 48.16981863975525, loss: 54.03656053543091 
Train [26/26] | Epoch [83/160] |	nca: 2.6979928836226463, flat: 2.783118672668934, pod: 49.15028917789459, loss: 54.63140094280243 
Train [26/26] | Epoch [84/160] |	nca: 2.418084628880024, flat: 2.3197088465094566, pod: 46.580281257629395, loss: 51.31807482242584 
Train [26/26] | Epoch [85/160] |	nca: 2.034175865352154, flat: 2.1838850900530815, pod: 45.21408486366272, loss: 49.432145833969116 
Train [26/26] | Epoch [86/160] |	nca: 2.222758464515209, flat: 2.0163975320756435, pod: 42.696102142333984, loss: 46.93525826931 
Train [26/26] | Epoch [87/160] |	nca: 2.20310665294528, flat: 1.8997757323086262, pod: 42.38311815261841, loss: 46.486000418663025 
Train [26/26] | Epoch [88/160] |	nca: 2.429115504026413, flat: 1.9404468536376953, pod: 41.8669239282608, loss: 46.236486196517944 
Train [26/26] | Epoch [89/160] |	nca: 2.482012912631035, flat: 2.3445689231157303, pod: 45.09879517555237, loss: 49.925376653671265 
Train [26/26] | Epoch [90/160] |	nca: 2.4889546521008015, flat: 2.215463861823082, pod: 43.34592008590698, loss: 48.05033826828003 
Train [26/26] | Epoch [91/160] |	nca: 2.4127098508179188, flat: 2.1064914986491203, pod: 42.14028465747833, loss: 46.659485816955566 
Train [26/26] | Epoch [92/160] |	nca: 2.259400948882103, flat: 1.9544686675071716, pod: 40.02679419517517, loss: 44.24066376686096 
Train [26/26] | Epoch [93/160] |	nca: 2.2039353027939796, flat: 2.3316538482904434, pod: 44.84986698627472, loss: 49.38545608520508 
Train [26/26] | Epoch [94/160] |	nca: 2.2961799949407578, flat: 1.9119798243045807, pod: 41.50346481800079, loss: 45.71162462234497 
Train [26/26] | Epoch [95/160] |	nca: 2.0974263064563274, flat: 1.995221123099327, pod: 41.31419110298157, loss: 45.40683829784393 
Train [26/26] | Epoch [96/160] |	nca: 2.4250079095363617, flat: 2.047102238982916, pod: 42.92528414726257, loss: 47.39739429950714 
Train [26/26] | Epoch [97/160] |	nca: 2.210377737879753, flat: 2.230015207082033, pod: 44.11110329627991, loss: 48.55149590969086 
Train [26/26] | Epoch [98/160] |	nca: 2.4996116310358047, flat: 2.337884098291397, pod: 44.796812534332275, loss: 49.634308099746704 
Train [26/26] | Epoch [99/160] |	nca: 2.12459185346961, flat: 2.027024768292904, pod: 42.78184688091278, loss: 46.93346357345581 
Train [26/26] | Epoch [100/160] |	nca: 2.0560814291238785, flat: 1.8939544558525085, pod: 40.50205373764038, loss: 44.4520902633667 
Train [26/26] | Epoch [101/160] |	nca: 2.2471117712557316, flat: 1.923114262521267, pod: 39.06076669692993, loss: 43.230993151664734 
Train [26/26] | Epoch [102/160] |	nca: 2.4874282255768776, flat: 2.0877942256629467, pod: 40.583640694618225, loss: 45.158862948417664 
Train [26/26] | Epoch [103/160] |	nca: 2.4564445838332176, flat: 2.034234642982483, pod: 41.612263560295105, loss: 46.10294270515442 
Train [26/26] | Epoch [104/160] |	nca: 2.288788639008999, flat: 1.919972226023674, pod: 39.57826387882233, loss: 43.78702449798584 
Train [26/26] | Epoch [105/160] |	nca: 2.0622404366731644, flat: 1.6860762871801853, pod: 38.776644468307495, loss: 42.52496087551117 
Train [26/26] | Epoch [106/160] |	nca: 2.158909946680069, flat: 1.6161205098032951, pod: 37.37025535106659, loss: 41.145285964012146 
Train [26/26] | Epoch [107/160] |	nca: 2.222666312009096, flat: 1.6181588098406792, pod: 37.079373240470886, loss: 40.92019832134247 
Train [26/26] | Epoch [108/160] |	nca: 2.2163319028913975, flat: 1.8430022858083248, pod: 37.888683795928955, loss: 41.948018193244934 
Train [26/26] | Epoch [109/160] |	nca: 2.2382294461131096, flat: 1.6962237842381, pod: 37.32221758365631, loss: 41.25667059421539 
Train [26/26] | Epoch [110/160] |	nca: 2.0996629744768143, flat: 1.6227775663137436, pod: 35.3799192905426, loss: 39.102359890937805 
Train [26/26] | Epoch [111/160] |	nca: 2.106012172996998, flat: 1.613929994404316, pod: 36.37869966030121, loss: 40.09864163398743 
Train [26/26] | Epoch [112/160] |	nca: 1.9366856962442398, flat: 1.670081663876772, pod: 36.37966978549957, loss: 39.98643684387207 
Train [26/26] | Epoch [113/160] |	nca: 1.97436061501503, flat: 1.3489647321403027, pod: 33.4235942363739, loss: 36.74691963195801 
Train [26/26] | Epoch [114/160] |	nca: 2.0051656402647495, flat: 1.4066559709608555, pod: 33.234256863594055, loss: 36.64607846736908 
Train [26/26] | Epoch [115/160] |	nca: 2.000401634722948, flat: 1.6731414310634136, pod: 35.792723536491394, loss: 39.4662663936615 
Train [26/26] | Epoch [116/160] |	nca: 1.9370243549346924, flat: 1.420576799660921, pod: 34.26189482212067, loss: 37.61949598789215 
Train [26/26] | Epoch [117/160] |	nca: 1.8938825614750385, flat: 1.5131345354020596, pod: 34.033586740493774, loss: 37.44060409069061 
Train [26/26] | Epoch [118/160] |	nca: 1.9062211588025093, flat: 1.3429010845720768, pod: 32.53618764877319, loss: 35.78530979156494 
Train [26/26] | Epoch [119/160] |	nca: 2.0280897207558155, flat: 1.4608239494264126, pod: 34.00592887401581, loss: 37.494842648506165 
Train [26/26] | Epoch [120/160] |	nca: 2.0159587040543556, flat: 1.5317958928644657, pod: 35.12765693664551, loss: 38.675411343574524 
Train [26/26] | Epoch [121/160] |	nca: 2.177388295531273, flat: 1.6786984726786613, pod: 37.072712540626526, loss: 40.92879927158356 
Train [26/26] | Epoch [122/160] |	nca: 2.1518212519586086, flat: 1.5522096455097198, pod: 34.61401832103729, loss: 38.31804931163788 
Train [26/26] | Epoch [123/160] |	nca: 2.0333713218569756, flat: 1.4675465673208237, pod: 33.57134461402893, loss: 37.07226252555847 
Train [26/26] | Epoch [124/160] |	nca: 2.2575045824050903, flat: 1.4071869812905788, pod: 31.625388860702515, loss: 35.290080428123474 
Train [26/26] | Epoch [125/160] |	nca: 1.9918079562485218, flat: 1.5196106620132923, pod: 32.28112316131592, loss: 35.79254162311554 
Train [26/26] | Epoch [126/160] |	nca: 2.0040194876492023, flat: 1.5135559514164925, pod: 34.35752892494202, loss: 37.87510430812836 
Train [26/26] | Epoch [127/160] |	nca: 2.5390893146395683, flat: 1.547199483960867, pod: 32.21020120382309, loss: 36.29649019241333 
Train [26/26] | Epoch [128/160] |	nca: 2.0671283304691315, flat: 1.4030782505869865, pod: 31.77407479286194, loss: 35.24428141117096 
Train [26/26] | Epoch [129/160] |	nca: 2.0681872479617596, flat: 1.3392379321157932, pod: 30.935479521751404, loss: 34.342904806137085 
Train [26/26] | Epoch [130/160] |	nca: 2.004537831991911, flat: 1.2921478562057018, pod: 31.419488787651062, loss: 34.716174602508545 
Train [26/26] | Epoch [131/160] |	nca: 2.0526662059128284, flat: 1.3467046897858381, pod: 31.186474442481995, loss: 34.58584547042847 
Train [26/26] | Epoch [132/160] |	nca: 1.9883224107325077, flat: 1.2418029643595219, pod: 30.503543734550476, loss: 33.73366892337799 
Train [26/26] | Epoch [133/160] |	nca: 1.8691063858568668, flat: 1.2180036921054125, pod: 29.487390637397766, loss: 32.57450079917908 
Train [26/26] | Epoch [134/160] |	nca: 1.888883102685213, flat: 1.3320928066968918, pod: 29.980151057243347, loss: 33.20112681388855 
Train [26/26] | Epoch [135/160] |	nca: 1.9159404188394547, flat: 1.1829710900783539, pod: 29.606223702430725, loss: 32.705135107040405 
Train [26/26] | Epoch [136/160] |	nca: 1.8987231738865376, flat: 1.078622106462717, pod: 28.237238824367523, loss: 31.21458387374878 
Train [26/26] | Epoch [137/160] |	nca: 1.8186815567314625, flat: 1.1016728468239307, pod: 28.32712608575821, loss: 31.247480630874634 
Train [26/26] | Epoch [138/160] |	nca: 2.1699553318321705, flat: 1.13689617626369, pod: 28.333580493927002, loss: 31.640431761741638 
Train [26/26] | Epoch [139/160] |	nca: 1.9219085089862347, flat: 1.1986447013914585, pod: 28.744474053382874, loss: 31.86502730846405 
Train [26/26] | Epoch [140/160] |	nca: 1.9078772999346256, flat: 1.1672317795455456, pod: 28.11494642496109, loss: 31.19005560874939 
Train [26/26] | Epoch [141/160] |	nca: 1.928700465708971, flat: 1.0917883850634098, pod: 26.821125209331512, loss: 29.841613829135895 
Train [26/26] | Epoch [142/160] |	nca: 1.9102151319384575, flat: 1.0968338567763567, pod: 26.803042709827423, loss: 29.810091495513916 
Train [26/26] | Epoch [143/160] |	nca: 1.823778573423624, flat: 1.0049729831516743, pod: 26.598863005638123, loss: 29.42761504650116 
Train [26/26] | Epoch [144/160] |	nca: 2.029622368514538, flat: 1.068813230842352, pod: 27.197425663471222, loss: 30.29586124420166 
Train [26/26] | Epoch [145/160] |	nca: 1.9409904293715954, flat: 1.138113934546709, pod: 28.380310773849487, loss: 31.45941472053528 
Train [26/26] | Epoch [146/160] |	nca: 1.9136821739375591, flat: 1.0211520493030548, pod: 25.61200648546219, loss: 28.546840608119965 
Train [26/26] | Epoch [147/160] |	nca: 1.9359932281076908, flat: 1.096374198794365, pod: 26.21459275484085, loss: 29.24696046113968 
Train [26/26] | Epoch [148/160] |	nca: 1.8573868498206139, flat: 1.0394524056464434, pod: 25.87268203496933, loss: 28.769521236419678 
Train [26/26] | Epoch [149/160] |	nca: 2.220299232751131, flat: 1.0575262568891048, pod: 26.045300900936127, loss: 29.323126137256622 
Train [26/26] | Epoch [150/160] |	nca: 1.9693854115903378, flat: 1.0438166223466396, pod: 26.168717205524445, loss: 29.18191933631897 
Train [26/26] | Epoch [151/160] |	nca: 1.916434034705162, flat: 1.110543554648757, pod: 26.579253494739532, loss: 29.606231153011322 
Train [26/26] | Epoch [152/160] |	nca: 1.9653675556182861, flat: 1.173040822148323, pod: 27.084484040737152, loss: 30.222892343997955 
Train [26/26] | Epoch [153/160] |	nca: 1.8311377801001072, flat: 1.0720693059265614, pod: 25.662135064601898, loss: 28.56534218788147 
Train [26/26] | Epoch [154/160] |	nca: 1.757800679653883, flat: 1.0248841438442469, pod: 25.35832929611206, loss: 28.141014218330383 
Train [26/26] | Epoch [155/160] |	nca: 1.902595866471529, flat: 0.9955727197229862, pod: 24.942414939403534, loss: 27.84058368206024 
Train [26/26] | Epoch [156/160] |	nca: 1.8297393061220646, flat: 0.9990131594240665, pod: 25.085100293159485, loss: 27.913852870464325 
Train [26/26] | Epoch [157/160] |	nca: 1.7915412783622742, flat: 1.0069628488272429, pod: 24.83279436826706, loss: 27.63129848241806 
Train [26/26] | Epoch [158/160] |	nca: 1.7267489433288574, flat: 1.0007888320833445, pod: 25.3801931142807, loss: 28.10773080587387 
Train [26/26] | Epoch [159/160] |	nca: 1.7947763316333294, flat: 1.033615730702877, pod: 25.328144311904907, loss: 28.156536281108856 
Train [26/26] | Epoch [160/160] |	nca: 1.9665126949548721, flat: 1.0698929373174906, pod: 25.973434507846832, loss: 29.00984001159668 
Fine-tuning
Building & updating memory.
Train [26/26] | Epoch [161/180] |	nca: 1.15596329793334, flat: 1.0242707468569279, pod: 20.36631029844284, loss: 22.546544313430786 
Train [26/26] | Epoch [162/180] |	nca: 0.8731269277632236, flat: 0.9873243570327759, pod: 20.144920110702515, loss: 22.005371570587158 
Train [26/26] | Epoch [163/180] |	nca: 0.7666431441903114, flat: 1.008134637027979, pod: 20.089940190315247, loss: 21.864717960357666 
Train [26/26] | Epoch [164/180] |	nca: 0.794155515730381, flat: 0.9809314049780369, pod: 19.96997058391571, loss: 21.745057463645935 
Train [26/26] | Epoch [165/180] |	nca: 0.7023230269551277, flat: 0.9394598342478275, pod: 19.503676533699036, loss: 21.145459413528442 
Train [26/26] | Epoch [166/180] |	nca: 0.7264470811933279, flat: 1.0263557359576225, pod: 20.377321183681488, loss: 22.13012421131134 
Train [26/26] | Epoch [167/180] |	nca: 0.6542997173964977, flat: 0.94676498696208, pod: 19.82812637090683, loss: 21.42919135093689 
Train [26/26] | Epoch [168/180] |	nca: 0.742279764264822, flat: 0.9938132874667645, pod: 20.2402366399765, loss: 21.976329684257507 
Train [26/26] | Epoch [169/180] |	nca: 0.649506788700819, flat: 0.9744754247367382, pod: 19.761677742004395, loss: 21.38565981388092 
Train [26/26] | Epoch [170/180] |	nca: 0.6466069631278515, flat: 1.009088534861803, pod: 20.021941661834717, loss: 21.677636861801147 
Train [26/26] | Epoch [171/180] |	nca: 0.648843988776207, flat: 1.0225843638181686, pod: 20.191729068756104, loss: 21.863157391548157 
Train [26/26] | Epoch [172/180] |	nca: 0.6688079386949539, flat: 0.980391550809145, pod: 20.234895706176758, loss: 21.884095311164856 
Train [26/26] | Epoch [173/180] |	nca: 0.6600370649248362, flat: 0.9964346289634705, pod: 20.27717161178589, loss: 21.933643341064453 
Train [26/26] | Epoch [174/180] |	nca: 0.6050785388797522, flat: 0.9655791968107224, pod: 19.972341775894165, loss: 21.542999267578125 
Train [26/26] | Epoch [175/180] |	nca: 0.6187925264239311, flat: 0.9969664551317692, pod: 20.042170882225037, loss: 21.65792953968048 
Train [26/26] | Epoch [176/180] |	nca: 0.5964033491909504, flat: 0.9525022879242897, pod: 19.695253133773804, loss: 21.244158625602722 
Train [26/26] | Epoch [177/180] |	nca: 0.5933746472001076, flat: 0.9831683859229088, pod: 20.04264008998871, loss: 21.61918294429779 
Train [26/26] | Epoch [178/180] |	nca: 0.6313692443072796, flat: 0.9837090149521828, pod: 19.81721007823944, loss: 21.432288646697998 
Train [26/26] | Epoch [179/180] |	nca: 0.639766363427043, flat: 1.0599627792835236, pod: 20.511122941970825, loss: 22.21085226535797 
Train [26/26] | Epoch [180/180] |	nca: 0.5993606615811586, flat: 1.0184223353862762, pod: 20.31249487400055, loss: 21.930277824401855 
after task
Building & updating memory.
after task
Saving model at results\dev\podnet\202401\week_1\20240102_podnet_cnn_cifar100_25steps\net_0_task_25.pth.
Saving metadata at results\dev\podnet\202401\week_1\20240102_podnet_cnn_cifar100_25steps\meta_0_task_25.pkl.
Eval on 0->100.
eval task
podnet_cnn_cifar100_25steps
Avg inc acc: 0.6053076923076922.
Current acc: {'total': 0.517, '00-09': 0.592, '10-19': 0.496, '20-29': 0.408, '30-39': 0.463, '40-49': 0.563, '50-59': 0.502, '60-69': 0.422, '70-79': 0.546, '80-89': 0.562, '90-99': 0.612}.
Avg inc acc top5: 0.8589999999999999.
Current acc top5: {'total': 0.799}.
Forgetting: 0.24700000000000008.
Cord metric: 0.60.
Old accuracy: 0.51, mean: 0.59.
New accuracy: 0.74, mean: 0.78.
Average Incremental Accuracy: 0.6053076923076922.
Label was: podnet_cnn_cifar100_25steps
Results done on 1 seeds: avg: 60.53, last: 51.7, forgetting: 24.7
Individual results avg: [60.53]
Individual results last: [51.7]
Individual results forget: [24.7]
Command was C:\Users\Vicco\Desktop\LibContinual\run_trainer.py
Time cost :  8898.69787144661
