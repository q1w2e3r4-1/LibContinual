Label: podnet_cnn_cifar100_10steps
orders : None
{'model': 'podnet', 'convnet': 'rebuffi', 'dropout': 0.0, 'herding': None, 'memory_size': 2000, 'temperature': 1, 'fixed_memory': True, 'dataset': 'cifar100', 'increment': 5, 'batch_size': 128, 'workers': 0, 'threads': 1, 'validation': 0.0, 'random_classes': False, 'max_task': None, 'onehot': False, 'initial_increment': 50, 'sampler': None, 'data_path': '/data/douillard/', 'lr': 0.1, 'weight_decay': 0.0005, 'scheduling': 'cosine', 'lr_decay': 0.1, 'optimizer': 'sgd', 'epochs': 160, 'device': [0], 'label': 'podnet_cnn_cifar100_10steps', 'autolabel': False, 'seed': [1], 'seed_range': None, 'options': None, 'save_model': 'last', 'dump_predictions': False, 'logging': 'info', 'resume': None, 'resume_first': False, 'recompute_meta': False, 'no_benchmark': False, 'detect_anomaly': False, 'dummy': 1, 'includes': ['headers/dummy.yaml'], 'data_root': 'D:/data/douillard/cifar100/cifar100', 'save_path': '.', 'eval_type': 'cnn', 'backbone': {'name': 'resnet18'}, 'classifier': {'name': 'PODNet'}, 'classifier_config': {'type': 'cosine', 'proxy_per_class': 10, 'distance': 'neg_stable_cosine_distance'}, 'postprocessor_config': {'type': 'learned_scaling', 'initial_value': 1.0}, 'pod_flat': {'scheduled_factor': 1.0}, 'pod_spatial': {'scheduled_factor': 3.0, 'collapse_channels': 'spatial'}, 'nca': {'margin': 0.6, 'scale': 1.0, 'exclude_pos_denominator': True}, 'groupwise_factors': {'old_weights': 0.0}, 'finetuning_config': {'sampling': 'undersampling', 'tuning': 'classifier', 'lr': 0.05, 'epochs': 20, 'scaling': None}, 'proxy_per_class': 1, 'weight_generation': {'type': 'imprinted', 'multi_class_diff': 'kmeans'}, 'dataset_transforms': {'color_jitter': True}}
Launching run 1/1
Set seed 1
CUDA algos are determinists but very slow!
Files already downloaded and verified
Files already downloaded and verified
Dataset iCIFAR100: class ordering: [87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39].
Downsampling type stride
Using 10 proxies per class.
Model will be save at this rythm: last.
================Task 0 Start!================
Testing on False unseen tasks (max class = 50).
Before task
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 0 Training!================
The training samples number: 25000
Train on 0->50.
train task
nb 25000.
Train [1/11] | Epoch [1/160] |	nca: 713.3327896595001, loss: 713.3327896595001 
Train [1/11] | Epoch [2/160] |	nca: 628.3272082805634, loss: 628.3272082805634 
Train [1/11] | Epoch [3/160] |	nca: 577.3014988899231, loss: 577.3014988899231 
Train [1/11] | Epoch [4/160] |	nca: 526.8762035369873, loss: 526.8762035369873 
Train [1/11] | Epoch [5/160] |	nca: 476.29854345321655, loss: 476.29854345321655 
Train [1/11] | Epoch [6/160] |	nca: 434.7580976486206, loss: 434.7580976486206 
Train [1/11] | Epoch [7/160] |	nca: 402.5476222038269, loss: 402.5476222038269 
Train [1/11] | Epoch [8/160] |	nca: 377.4512165784836, loss: 377.4512165784836 
Train [1/11] | Epoch [9/160] |	nca: 353.6950296163559, loss: 353.6950296163559 
Train [1/11] | Epoch [10/160] |	nca: 336.0271567106247, loss: 336.0271567106247 
Train [1/11] | Epoch [11/160] |	nca: 321.7692594528198, loss: 321.7692594528198 
Train [1/11] | Epoch [12/160] |	nca: 307.366485953331, loss: 307.366485953331 
Train [1/11] | Epoch [13/160] |	nca: 296.94387340545654, loss: 296.94387340545654 
Train [1/11] | Epoch [14/160] |	nca: 283.57997834682465, loss: 283.57997834682465 
Train [1/11] | Epoch [15/160] |	nca: 276.33422088623047, loss: 276.33422088623047 
Train [1/11] | Epoch [16/160] |	nca: 269.538682281971, loss: 269.538682281971 
Train [1/11] | Epoch [17/160] |	nca: 260.63066178560257, loss: 260.63066178560257 
Train [1/11] | Epoch [18/160] |	nca: 255.72941929101944, loss: 255.72941929101944 
Train [1/11] | Epoch [19/160] |	nca: 249.51113486289978, loss: 249.51113486289978 
Train [1/11] | Epoch [20/160] |	nca: 245.21639907360077, loss: 245.21639907360077 
Train [1/11] | Epoch [21/160] |	nca: 240.58327144384384, loss: 240.58327144384384 
Train [1/11] | Epoch [22/160] |	nca: 234.851029753685, loss: 234.851029753685 
Train [1/11] | Epoch [23/160] |	nca: 229.5619357228279, loss: 229.5619357228279 
Train [1/11] | Epoch [24/160] |	nca: 227.39953714609146, loss: 227.39953714609146 
Train [1/11] | Epoch [25/160] |	nca: 225.92353534698486, loss: 225.92353534698486 
Train [1/11] | Epoch [26/160] |	nca: 224.4534970521927, loss: 224.4534970521927 
Train [1/11] | Epoch [27/160] |	nca: 218.82597184181213, loss: 218.82597184181213 
Train [1/11] | Epoch [28/160] |	nca: 215.67581927776337, loss: 215.67581927776337 
Train [1/11] | Epoch [29/160] |	nca: 214.22910696268082, loss: 214.22910696268082 
Train [1/11] | Epoch [30/160] |	nca: 208.95660364627838, loss: 208.95660364627838 
Train [1/11] | Epoch [31/160] |	nca: 208.31956696510315, loss: 208.31956696510315 
Train [1/11] | Epoch [32/160] |	nca: 207.4496636390686, loss: 207.4496636390686 
Train [1/11] | Epoch [33/160] |	nca: 204.83086824417114, loss: 204.83086824417114 
Train [1/11] | Epoch [34/160] |	nca: 201.23127967119217, loss: 201.23127967119217 
Train [1/11] | Epoch [35/160] |	nca: 198.8278951048851, loss: 198.8278951048851 
Train [1/11] | Epoch [36/160] |	nca: 198.81195271015167, loss: 198.81195271015167 
Train [1/11] | Epoch [37/160] |	nca: 196.14235365390778, loss: 196.14235365390778 
Train [1/11] | Epoch [38/160] |	nca: 194.89857476949692, loss: 194.89857476949692 
Train [1/11] | Epoch [39/160] |	nca: 193.55962252616882, loss: 193.55962252616882 
Train [1/11] | Epoch [40/160] |	nca: 190.9399191737175, loss: 190.9399191737175 
Train [1/11] | Epoch [41/160] |	nca: 187.34536558389664, loss: 187.34536558389664 
Train [1/11] | Epoch [42/160] |	nca: 187.48681211471558, loss: 187.48681211471558 
Train [1/11] | Epoch [43/160] |	nca: 185.3807254433632, loss: 185.3807254433632 
Train [1/11] | Epoch [44/160] |	nca: 184.43927454948425, loss: 184.43927454948425 
Train [1/11] | Epoch [45/160] |	nca: 182.7836490869522, loss: 182.7836490869522 
Train [1/11] | Epoch [46/160] |	nca: 181.450568318367, loss: 181.450568318367 
Train [1/11] | Epoch [47/160] |	nca: 179.74228709936142, loss: 179.74228709936142 
Train [1/11] | Epoch [48/160] |	nca: 178.42179036140442, loss: 178.42179036140442 
Train [1/11] | Epoch [49/160] |	nca: 176.03643441200256, loss: 176.03643441200256 
Train [1/11] | Epoch [50/160] |	nca: 175.0701225399971, loss: 175.0701225399971 
Train [1/11] | Epoch [51/160] |	nca: 171.93328022956848, loss: 171.93328022956848 
Train [1/11] | Epoch [52/160] |	nca: 173.0624572634697, loss: 173.0624572634697 
Train [1/11] | Epoch [53/160] |	nca: 171.13881087303162, loss: 171.13881087303162 
Train [1/11] | Epoch [54/160] |	nca: 168.72464233636856, loss: 168.72464233636856 
Train [1/11] | Epoch [55/160] |	nca: 166.40503245592117, loss: 166.40503245592117 
Train [1/11] | Epoch [56/160] |	nca: 166.6114398241043, loss: 166.6114398241043 
Train [1/11] | Epoch [57/160] |	nca: 164.7209848165512, loss: 164.7209848165512 
Train [1/11] | Epoch [58/160] |	nca: 165.2437545657158, loss: 165.2437545657158 
Train [1/11] | Epoch [59/160] |	nca: 160.34131610393524, loss: 160.34131610393524 
Train [1/11] | Epoch [60/160] |	nca: 159.8929790854454, loss: 159.8929790854454 
Train [1/11] | Epoch [61/160] |	nca: 158.29413586854935, loss: 158.29413586854935 
Train [1/11] | Epoch [62/160] |	nca: 155.9051371216774, loss: 155.9051371216774 
Train [1/11] | Epoch [63/160] |	nca: 153.7566249370575, loss: 153.7566249370575 
Train [1/11] | Epoch [64/160] |	nca: 153.68936771154404, loss: 153.68936771154404 
Train [1/11] | Epoch [65/160] |	nca: 153.4047490954399, loss: 153.4047490954399 
Train [1/11] | Epoch [66/160] |	nca: 151.56537348031998, loss: 151.56537348031998 
Train [1/11] | Epoch [67/160] |	nca: 148.75851994752884, loss: 148.75851994752884 
Train [1/11] | Epoch [68/160] |	nca: 147.51756301522255, loss: 147.51756301522255 
Train [1/11] | Epoch [69/160] |	nca: 146.30455884337425, loss: 146.30455884337425 
Train [1/11] | Epoch [70/160] |	nca: 143.0518063902855, loss: 143.0518063902855 
Train [1/11] | Epoch [71/160] |	nca: 143.66043788194656, loss: 143.66043788194656 
Train [1/11] | Epoch [72/160] |	nca: 141.77636450529099, loss: 141.77636450529099 
Train [1/11] | Epoch [73/160] |	nca: 138.3265722990036, loss: 138.3265722990036 
Train [1/11] | Epoch [74/160] |	nca: 137.67495024204254, loss: 137.67495024204254 
Train [1/11] | Epoch [75/160] |	nca: 132.87086096405983, loss: 132.87086096405983 
Train [1/11] | Epoch [76/160] |	nca: 134.18844732642174, loss: 134.18844732642174 
Train [1/11] | Epoch [77/160] |	nca: 133.50189155340195, loss: 133.50189155340195 
Train [1/11] | Epoch [78/160] |	nca: 132.0957913994789, loss: 132.0957913994789 
Train [1/11] | Epoch [79/160] |	nca: 127.07700455188751, loss: 127.07700455188751 
Train [1/11] | Epoch [80/160] |	nca: 127.07174655795097, loss: 127.07174655795097 
Train [1/11] | Epoch [81/160] |	nca: 123.74156421422958, loss: 123.74156421422958 
Train [1/11] | Epoch [82/160] |	nca: 123.90107759833336, loss: 123.90107759833336 
Train [1/11] | Epoch [83/160] |	nca: 121.97603172063828, loss: 121.97603172063828 
Train [1/11] | Epoch [84/160] |	nca: 123.80399852991104, loss: 123.80399852991104 
Train [1/11] | Epoch [85/160] |	nca: 116.79370433092117, loss: 116.79370433092117 
Train [1/11] | Epoch [86/160] |	nca: 116.38980433344841, loss: 116.38980433344841 
Train [1/11] | Epoch [87/160] |	nca: 115.36340895295143, loss: 115.36340895295143 
Train [1/11] | Epoch [88/160] |	nca: 115.2871961593628, loss: 115.2871961593628 
Train [1/11] | Epoch [89/160] |	nca: 108.65250897407532, loss: 108.65250897407532 
Train [1/11] | Epoch [90/160] |	nca: 110.4365925192833, loss: 110.4365925192833 
Train [1/11] | Epoch [91/160] |	nca: 107.5756873190403, loss: 107.5756873190403 
Train [1/11] | Epoch [92/160] |	nca: 104.66497823596, loss: 104.66497823596 
Train [1/11] | Epoch [93/160] |	nca: 103.09185037016869, loss: 103.09185037016869 
Train [1/11] | Epoch [94/160] |	nca: 100.91307777166367, loss: 100.91307777166367 
Train [1/11] | Epoch [95/160] |	nca: 97.4835898578167, loss: 97.4835898578167 
Train [1/11] | Epoch [96/160] |	nca: 95.36611405014992, loss: 95.36611405014992 
Train [1/11] | Epoch [97/160] |	nca: 94.45547607541084, loss: 94.45547607541084 
Train [1/11] | Epoch [98/160] |	nca: 92.78098738193512, loss: 92.78098738193512 
Train [1/11] | Epoch [99/160] |	nca: 89.88006410002708, loss: 89.88006410002708 
Train [1/11] | Epoch [100/160] |	nca: 87.28178153932095, loss: 87.28178153932095 
Train [1/11] | Epoch [101/160] |	nca: 86.17139855027199, loss: 86.17139855027199 
Train [1/11] | Epoch [102/160] |	nca: 83.83576968312263, loss: 83.83576968312263 
Train [1/11] | Epoch [103/160] |	nca: 82.79320979118347, loss: 82.79320979118347 
Train [1/11] | Epoch [104/160] |	nca: 78.75321497023106, loss: 78.75321497023106 
Train [1/11] | Epoch [105/160] |	nca: 77.20094732940197, loss: 77.20094732940197 
Train [1/11] | Epoch [106/160] |	nca: 76.33898851275444, loss: 76.33898851275444 
Train [1/11] | Epoch [107/160] |	nca: 74.33535605669022, loss: 74.33535605669022 
Train [1/11] | Epoch [108/160] |	nca: 68.5239096134901, loss: 68.5239096134901 
Train [1/11] | Epoch [109/160] |	nca: 66.0238929092884, loss: 66.0238929092884 
Train [1/11] | Epoch [110/160] |	nca: 66.33979533612728, loss: 66.33979533612728 
Train [1/11] | Epoch [111/160] |	nca: 63.10850632190704, loss: 63.10850632190704 
Train [1/11] | Epoch [112/160] |	nca: 59.01657736301422, loss: 59.01657736301422 
Train [1/11] | Epoch [113/160] |	nca: 61.38683134317398, loss: 61.38683134317398 
Train [1/11] | Epoch [114/160] |	nca: 56.02525256574154, loss: 56.02525256574154 
Train [1/11] | Epoch [115/160] |	nca: 54.60176957398653, loss: 54.60176957398653 
Train [1/11] | Epoch [116/160] |	nca: 52.920237585902214, loss: 52.920237585902214 
Train [1/11] | Epoch [117/160] |	nca: 47.87032424658537, loss: 47.87032424658537 
Train [1/11] | Epoch [118/160] |	nca: 46.34751504659653, loss: 46.34751504659653 
Train [1/11] | Epoch [119/160] |	nca: 43.893037743866444, loss: 43.893037743866444 
Train [1/11] | Epoch [120/160] |	nca: 42.154924653470516, loss: 42.154924653470516 
Train [1/11] | Epoch [121/160] |	nca: 39.264733999967575, loss: 39.264733999967575 
Train [1/11] | Epoch [122/160] |	nca: 37.5985152721405, loss: 37.5985152721405 
Train [1/11] | Epoch [123/160] |	nca: 34.628487318754196, loss: 34.628487318754196 
Train [1/11] | Epoch [124/160] |	nca: 31.611117266118526, loss: 31.611117266118526 
Train [1/11] | Epoch [125/160] |	nca: 30.25796215236187, loss: 30.25796215236187 
Train [1/11] | Epoch [126/160] |	nca: 28.510173119604588, loss: 28.510173119604588 
Train [1/11] | Epoch [127/160] |	nca: 26.445318151265383, loss: 26.445318151265383 
Train [1/11] | Epoch [128/160] |	nca: 25.679393850266933, loss: 25.679393850266933 
Train [1/11] | Epoch [129/160] |	nca: 23.922975715249777, loss: 23.922975715249777 
Train [1/11] | Epoch [130/160] |	nca: 22.21016512438655, loss: 22.21016512438655 
Train [1/11] | Epoch [131/160] |	nca: 19.160147547721863, loss: 19.160147547721863 
Train [1/11] | Epoch [132/160] |	nca: 15.978505600243807, loss: 15.978505600243807 
Train [1/11] | Epoch [133/160] |	nca: 16.28939313814044, loss: 16.28939313814044 
Train [1/11] | Epoch [134/160] |	nca: 14.093004209920764, loss: 14.093004209920764 
Train [1/11] | Epoch [135/160] |	nca: 12.767893871292472, loss: 12.767893871292472 
Train [1/11] | Epoch [136/160] |	nca: 11.609669141471386, loss: 11.609669141471386 
Train [1/11] | Epoch [137/160] |	nca: 11.282149538397789, loss: 11.282149538397789 
Train [1/11] | Epoch [138/160] |	nca: 10.696467734873295, loss: 10.696467734873295 
Train [1/11] | Epoch [139/160] |	nca: 10.10805257037282, loss: 10.10805257037282 
Train [1/11] | Epoch [140/160] |	nca: 8.560256831347942, loss: 8.560256831347942 
Train [1/11] | Epoch [141/160] |	nca: 8.601945415139198, loss: 8.601945415139198 
Train [1/11] | Epoch [142/160] |	nca: 7.601029606536031, loss: 7.601029606536031 
Train [1/11] | Epoch [143/160] |	nca: 6.772992568090558, loss: 6.772992568090558 
Train [1/11] | Epoch [144/160] |	nca: 6.812276614829898, loss: 6.812276614829898 
Train [1/11] | Epoch [145/160] |	nca: 6.969553804025054, loss: 6.969553804025054 
Train [1/11] | Epoch [146/160] |	nca: 6.191593151539564, loss: 6.191593151539564 
Train [1/11] | Epoch [147/160] |	nca: 6.029349545016885, loss: 6.029349545016885 
Train [1/11] | Epoch [148/160] |	nca: 5.932551399804652, loss: 5.932551399804652 
Train [1/11] | Epoch [149/160] |	nca: 5.611372150480747, loss: 5.611372150480747 
Train [1/11] | Epoch [150/160] |	nca: 5.535832030698657, loss: 5.535832030698657 
Train [1/11] | Epoch [151/160] |	nca: 5.201608191244304, loss: 5.201608191244304 
Train [1/11] | Epoch [152/160] |	nca: 5.328458424657583, loss: 5.328458424657583 
Train [1/11] | Epoch [153/160] |	nca: 5.380773556418717, loss: 5.380773556418717 
Train [1/11] | Epoch [154/160] |	nca: 5.128821241669357, loss: 5.128821241669357 
Train [1/11] | Epoch [155/160] |	nca: 5.086992840282619, loss: 5.086992840282619 
Train [1/11] | Epoch [156/160] |	nca: 4.876865268684924, loss: 4.876865268684924 
Train [1/11] | Epoch [157/160] |	nca: 4.72267859056592, loss: 4.72267859056592 
Train [1/11] | Epoch [158/160] |	nca: 4.802229950204492, loss: 4.802229950204492 
Train [1/11] | Epoch [159/160] |	nca: 4.912193146534264, loss: 4.912193146534264 
Train [1/11] | Epoch [160/160] |	nca: 4.936569069512188, loss: 4.936569069512188 
after task
Building & updating memory.
after task
Eval on 0->50.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.779.
Current acc: {'total': 0.779, '00-09': 0.81, '10-19': 0.789, '20-29': 0.73, '30-39': 0.759, '40-49': 0.809}.
Avg inc acc top5: 0.949.
Current acc top5: {'total': 0.949}.
Forgetting: 0.0.
Cord metric: 0.78.
================Task 1 Start!================
Testing on False unseen tasks (max class = 55).
Set memory of size: 1000.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 1 Training!================
The training samples number: 3500
Train on 50->55.
train task
nb 3500.
Train [2/11] | Epoch [1/160] |	nca: 46.250181913375854, flat: 36.26296257972717, pod: 135.2052092552185, loss: 217.7183542251587 
Train [2/11] | Epoch [2/160] |	nca: 28.228164553642273, flat: 32.84751361608505, pod: 122.37894916534424, loss: 183.45462846755981 
Train [2/11] | Epoch [3/160] |	nca: 17.685398012399673, flat: 25.28936415910721, pod: 105.31820130348206, loss: 148.2929630279541 
Train [2/11] | Epoch [4/160] |	nca: 13.058966040611267, flat: 21.020197868347168, pod: 95.22797918319702, loss: 129.3071436882019 
Train [2/11] | Epoch [5/160] |	nca: 9.452879443764687, flat: 17.30161064863205, pod: 85.49589824676514, loss: 112.25038766860962 
Train [2/11] | Epoch [6/160] |	nca: 7.702806681394577, flat: 14.66137558221817, pod: 79.34405517578125, loss: 101.70823740959167 
Train [2/11] | Epoch [7/160] |	nca: 6.999553129076958, flat: 13.283509820699692, pod: 75.36130809783936, loss: 95.64437055587769 
Train [2/11] | Epoch [8/160] |	nca: 6.830104425549507, flat: 12.833565294742584, pod: 74.00001955032349, loss: 93.6636893749237 
Train [2/11] | Epoch [9/160] |	nca: 6.181648425757885, flat: 11.443543374538422, pod: 69.85986280441284, loss: 87.48505449295044 
Train [2/11] | Epoch [10/160] |	nca: 6.31416817009449, flat: 11.39144742488861, pod: 69.59026789665222, loss: 87.29588341712952 
Train [2/11] | Epoch [11/160] |	nca: 5.955621533095837, flat: 10.926726281642914, pod: 67.15638709068298, loss: 84.03873491287231 
Train [2/11] | Epoch [12/160] |	nca: 6.197939574718475, flat: 10.76569601893425, pod: 67.29431581497192, loss: 84.25795125961304 
Train [2/11] | Epoch [13/160] |	nca: 5.682318240404129, flat: 10.699173271656036, pod: 68.0943214893341, loss: 84.4758129119873 
Train [2/11] | Epoch [14/160] |	nca: 5.37533587962389, flat: 10.10729330778122, pod: 65.07989287376404, loss: 80.56252217292786 
Train [2/11] | Epoch [15/160] |	nca: 5.6302551329135895, flat: 10.220903664827347, pod: 65.73880505561829, loss: 81.58996438980103 
Train [2/11] | Epoch [16/160] |	nca: 4.6644910126924515, flat: 9.400672018527985, pod: 62.32098078727722, loss: 76.38614392280579 
Train [2/11] | Epoch [17/160] |	nca: 4.4764867797493935, flat: 8.81796446442604, pod: 61.19572591781616, loss: 74.49017715454102 
Train [2/11] | Epoch [18/160] |	nca: 4.219791002571583, flat: 8.273724973201752, pod: 58.70645713806152, loss: 71.19997262954712 
Train [2/11] | Epoch [19/160] |	nca: 4.992817334830761, flat: 8.688119500875473, pod: 60.58534121513367, loss: 74.26627779006958 
Train [2/11] | Epoch [20/160] |	nca: 5.343043841421604, flat: 9.23740816116333, pod: 61.55521750450134, loss: 76.13566899299622 
Train [2/11] | Epoch [21/160] |	nca: 5.338025219738483, flat: 9.514810532331467, pod: 63.74905586242676, loss: 78.60189127922058 
Train [2/11] | Epoch [22/160] |	nca: 4.70515213906765, flat: 9.397892355918884, pod: 62.609248876571655, loss: 76.71229243278503 
Train [2/11] | Epoch [23/160] |	nca: 4.252683594822884, flat: 8.47919636964798, pod: 59.19819927215576, loss: 71.93007898330688 
Train [2/11] | Epoch [24/160] |	nca: 4.029399797320366, flat: 7.9113127291202545, pod: 56.66137647628784, loss: 68.60208892822266 
Train [2/11] | Epoch [25/160] |	nca: 4.436121389269829, flat: 8.104271933436394, pod: 58.28146409988403, loss: 70.82185792922974 
Train [2/11] | Epoch [26/160] |	nca: 4.4609766229987144, flat: 8.337744623422623, pod: 59.33411002159119, loss: 72.13283157348633 
Train [2/11] | Epoch [27/160] |	nca: 4.144388757646084, flat: 7.8761065155267715, pod: 57.641807317733765, loss: 69.66230201721191 
Train [2/11] | Epoch [28/160] |	nca: 5.101863533258438, flat: 8.811289340257645, pod: 61.046268701553345, loss: 74.95942163467407 
Train [2/11] | Epoch [29/160] |	nca: 4.1420813128352165, flat: 7.975049152970314, pod: 57.07456684112549, loss: 69.19169735908508 
Train [2/11] | Epoch [30/160] |	nca: 3.9843332916498184, flat: 7.4953910410404205, pod: 56.267279744148254, loss: 67.74700450897217 
Train [2/11] | Epoch [31/160] |	nca: 4.135617181658745, flat: 7.88323050737381, pod: 57.20980095863342, loss: 69.22864890098572 
Train [2/11] | Epoch [32/160] |	nca: 4.036437898874283, flat: 7.745720326900482, pod: 55.23660910129547, loss: 67.01876783370972 
Train [2/11] | Epoch [33/160] |	nca: 3.8820515125989914, flat: 7.193886861205101, pod: 53.837355852127075, loss: 64.91329455375671 
Train [2/11] | Epoch [34/160] |	nca: 4.106542780995369, flat: 7.725668892264366, pod: 55.86164903640747, loss: 67.69386076927185 
Train [2/11] | Epoch [35/160] |	nca: 4.006988532841206, flat: 8.052035465836525, pod: 56.62851440906525, loss: 68.6875376701355 
Train [2/11] | Epoch [36/160] |	nca: 3.999266631901264, flat: 7.400979116559029, pod: 55.50709927082062, loss: 66.90734529495239 
Train [2/11] | Epoch [37/160] |	nca: 3.8718079179525375, flat: 7.036752790212631, pod: 53.91423940658569, loss: 64.82279992103577 
Train [2/11] | Epoch [38/160] |	nca: 3.2965352460741997, flat: 6.695038601756096, pod: 51.753411173820496, loss: 61.74498510360718 
Train [2/11] | Epoch [39/160] |	nca: 3.3070799335837364, flat: 6.277284100651741, pod: 49.88211214542389, loss: 59.46647644042969 
Train [2/11] | Epoch [40/160] |	nca: 3.9349236115813255, flat: 6.479325115680695, pod: 50.800610303878784, loss: 61.214858531951904 
Train [2/11] | Epoch [41/160] |	nca: 4.35477364808321, flat: 7.564874961972237, pod: 55.73519790172577, loss: 67.65484642982483 
Train [2/11] | Epoch [42/160] |	nca: 4.060441769659519, flat: 7.463212043046951, pod: 56.100627422332764, loss: 67.62428140640259 
Train [2/11] | Epoch [43/160] |	nca: 4.132125921547413, flat: 7.193260908126831, pod: 53.88757073879242, loss: 65.21295833587646 
Train [2/11] | Epoch [44/160] |	nca: 3.359030060470104, flat: 7.086657032370567, pod: 54.898282289505005, loss: 65.34396934509277 
Train [2/11] | Epoch [45/160] |	nca: 3.337528482079506, flat: 6.6087381690740585, pod: 52.43551766872406, loss: 62.381784439086914 
Train [2/11] | Epoch [46/160] |	nca: 3.6608884558081627, flat: 6.601979434490204, pod: 53.26622819900513, loss: 63.52909564971924 
Train [2/11] | Epoch [47/160] |	nca: 3.956639625132084, flat: 6.895755365490913, pod: 53.249632835388184, loss: 64.10202813148499 
Train [2/11] | Epoch [48/160] |	nca: 3.6696421578526497, flat: 7.035978734493256, pod: 54.05000984668732, loss: 64.75563073158264 
Train [2/11] | Epoch [49/160] |	nca: 3.3992439806461334, flat: 6.484523892402649, pod: 51.03752791881561, loss: 60.921295523643494 
Train [2/11] | Epoch [50/160] |	nca: 3.2454817928373814, flat: 6.246807515621185, pod: 49.01704657077789, loss: 58.50933563709259 
Train [2/11] | Epoch [51/160] |	nca: 3.8710210025310516, flat: 6.5531455129384995, pod: 51.91718363761902, loss: 62.34135031700134 
Train [2/11] | Epoch [52/160] |	nca: 3.386646419763565, flat: 6.4184650629758835, pod: 50.92406523227692, loss: 60.72917675971985 
Train [2/11] | Epoch [53/160] |	nca: 3.5575972348451614, flat: 6.132248610258102, pod: 50.60644173622131, loss: 60.29628765583038 
Train [2/11] | Epoch [54/160] |	nca: 3.7032825648784637, flat: 6.0845233500003815, pod: 48.74782061576843, loss: 58.53562641143799 
Train [2/11] | Epoch [55/160] |	nca: 3.2669920176267624, flat: 6.1256004720926285, pod: 48.6882529258728, loss: 58.080845952034 
Train [2/11] | Epoch [56/160] |	nca: 3.0481286346912384, flat: 5.559336334466934, pod: 46.35658073425293, loss: 54.964046001434326 
Train [2/11] | Epoch [57/160] |	nca: 2.8709180019795895, flat: 5.664792418479919, pod: 46.67102038860321, loss: 55.20673131942749 
Train [2/11] | Epoch [58/160] |	nca: 3.0656626485288143, flat: 5.349109947681427, pod: 45.909130692481995, loss: 54.32390332221985 
Train [2/11] | Epoch [59/160] |	nca: 3.6217521131038666, flat: 6.059444680809975, pod: 49.09477770328522, loss: 58.77597427368164 
Train [2/11] | Epoch [60/160] |	nca: 3.4834368526935577, flat: 5.87100625038147, pod: 48.988688468933105, loss: 58.34313094615936 
Train [2/11] | Epoch [61/160] |	nca: 3.6175715029239655, flat: 6.082343578338623, pod: 49.90811061859131, loss: 59.60802519321442 
Train [2/11] | Epoch [62/160] |	nca: 3.4005449898540974, flat: 5.930175468325615, pod: 49.03161871433258, loss: 58.362338066101074 
Train [2/11] | Epoch [63/160] |	nca: 4.026953086256981, flat: 6.145384848117828, pod: 49.30170249938965, loss: 59.474040508270264 
Train [2/11] | Epoch [64/160] |	nca: 4.294194750487804, flat: 6.913562759757042, pod: 53.42900359630585, loss: 64.63676118850708 
Train [2/11] | Epoch [65/160] |	nca: 3.199113577604294, flat: 6.09886933863163, pod: 49.39177191257477, loss: 58.68975496292114 
Train [2/11] | Epoch [66/160] |	nca: 3.469034068286419, flat: 6.275970503687859, pod: 50.63857364654541, loss: 60.383577823638916 
Train [2/11] | Epoch [67/160] |	nca: 3.2912828661501408, flat: 5.938280686736107, pod: 48.96290647983551, loss: 58.19246959686279 
Train [2/11] | Epoch [68/160] |	nca: 3.1535690128803253, flat: 5.922798991203308, pod: 49.35016644001007, loss: 58.42653441429138 
Train [2/11] | Epoch [69/160] |	nca: 3.252094354480505, flat: 5.584970042109489, pod: 48.081456899642944, loss: 56.91852116584778 
Train [2/11] | Epoch [70/160] |	nca: 2.9798463881015778, flat: 5.668601304292679, pod: 47.307910084724426, loss: 55.956358313560486 
Train [2/11] | Epoch [71/160] |	nca: 3.0224831588566303, flat: 5.275215774774551, pod: 44.51020646095276, loss: 52.807905435562134 
Train [2/11] | Epoch [72/160] |	nca: 3.134585462510586, flat: 5.254583343863487, pod: 45.299511671066284, loss: 53.68868029117584 
Train [2/11] | Epoch [73/160] |	nca: 3.3251524828374386, flat: 5.693553149700165, pod: 47.114707946777344, loss: 56.133413910865784 
Train [2/11] | Epoch [74/160] |	nca: 3.0128968209028244, flat: 5.098004788160324, pod: 44.02111780643463, loss: 52.13201951980591 
Train [2/11] | Epoch [75/160] |	nca: 2.8519178815186024, flat: 5.167995736002922, pod: 45.484724044799805, loss: 53.504637598991394 
Train [2/11] | Epoch [76/160] |	nca: 3.3358832634985447, flat: 5.08713598549366, pod: 44.304070353507996, loss: 52.727089643478394 
Train [2/11] | Epoch [77/160] |	nca: 3.2398707792162895, flat: 5.20974463224411, pod: 44.84532165527344, loss: 53.29493737220764 
Train [2/11] | Epoch [78/160] |	nca: 2.9553323164582253, flat: 5.0771583169698715, pod: 44.40368068218231, loss: 52.43617141246796 
Train [2/11] | Epoch [79/160] |	nca: 3.0151499919593334, flat: 4.986732989549637, pod: 43.53953766822815, loss: 51.541420698165894 
Train [2/11] | Epoch [80/160] |	nca: 2.8759462274610996, flat: 5.064155951142311, pod: 44.27929401397705, loss: 52.219396233558655 
Train [2/11] | Epoch [81/160] |	nca: 2.7816994935274124, flat: 4.602036654949188, pod: 42.32528817653656, loss: 49.70902419090271 
Train [2/11] | Epoch [82/160] |	nca: 2.7038624174892902, flat: 4.480227574706078, pod: 40.57834279537201, loss: 47.76243281364441 
Train [2/11] | Epoch [83/160] |	nca: 2.9632688499987125, flat: 4.522597223520279, pod: 41.57501220703125, loss: 49.06087863445282 
Train [2/11] | Epoch [84/160] |	nca: 2.9192490950226784, flat: 4.409101635217667, pod: 40.86928117275238, loss: 48.19763171672821 
Train [2/11] | Epoch [85/160] |	nca: 2.8067731969058514, flat: 4.253185153007507, pod: 40.08577275276184, loss: 47.14573109149933 
Train [2/11] | Epoch [86/160] |	nca: 3.3557605370879173, flat: 4.419360652565956, pod: 41.418158650398254, loss: 49.19327962398529 
Train [2/11] | Epoch [87/160] |	nca: 2.6234735660254955, flat: 4.329561784863472, pod: 40.081987142562866, loss: 47.035022616386414 
Train [2/11] | Epoch [88/160] |	nca: 2.877294320613146, flat: 4.1112802773714066, pod: 39.55848050117493, loss: 46.54705464839935 
Train [2/11] | Epoch [89/160] |	nca: 3.0533096566796303, flat: 4.602933645248413, pod: 41.32227921485901, loss: 48.97852265834808 
Train [2/11] | Epoch [90/160] |	nca: 2.903219148516655, flat: 4.390189349651337, pod: 40.448827505111694, loss: 47.74223613739014 
Train [2/11] | Epoch [91/160] |	nca: 2.965727638453245, flat: 4.319853022694588, pod: 39.70061767101288, loss: 46.98619854450226 
Train [2/11] | Epoch [92/160] |	nca: 3.0363942235708237, flat: 4.3275385573506355, pod: 39.99768424034119, loss: 47.36161720752716 
Train [2/11] | Epoch [93/160] |	nca: 2.843157861381769, flat: 4.172425143420696, pod: 39.36982452869415, loss: 46.38540744781494 
Train [2/11] | Epoch [94/160] |	nca: 2.911092944443226, flat: 4.102242976427078, pod: 38.84422552585602, loss: 45.857561230659485 
Train [2/11] | Epoch [95/160] |	nca: 2.6780690662562847, flat: 3.9739806726574898, pod: 37.70352554321289, loss: 44.35557556152344 
Train [2/11] | Epoch [96/160] |	nca: 2.562917049974203, flat: 3.9332788214087486, pod: 37.38455784320831, loss: 43.88075387477875 
Train [2/11] | Epoch [97/160] |	nca: 2.8682205118238926, flat: 3.8918304294347763, pod: 37.206069588661194, loss: 43.9661203622818 
Train [2/11] | Epoch [98/160] |	nca: 2.7791706696152687, flat: 3.7802335917949677, pod: 37.22679376602173, loss: 43.786197900772095 
Train [2/11] | Epoch [99/160] |	nca: 2.6675979755818844, flat: 3.8729551509022713, pod: 37.76552939414978, loss: 44.306082367897034 
Train [2/11] | Epoch [100/160] |	nca: 3.011714067310095, flat: 3.7966086640954018, pod: 37.21056139469147, loss: 44.01888418197632 
Train [2/11] | Epoch [101/160] |	nca: 2.805874079465866, flat: 4.096308693289757, pod: 39.193968534469604, loss: 46.09615159034729 
Train [2/11] | Epoch [102/160] |	nca: 2.6268223971128464, flat: 3.773411087691784, pod: 36.7878143787384, loss: 43.188048243522644 
Train [2/11] | Epoch [103/160] |	nca: 2.428136046975851, flat: 3.4895501881837845, pod: 35.465535402297974, loss: 41.38322174549103 
Train [2/11] | Epoch [104/160] |	nca: 3.0469298101961613, flat: 3.6390629187226295, pod: 36.08158266544342, loss: 42.76757574081421 
Train [2/11] | Epoch [105/160] |	nca: 2.9369941242039204, flat: 3.6926745995879173, pod: 35.92054724693298, loss: 42.55021607875824 
Train [2/11] | Epoch [106/160] |	nca: 2.7041076719760895, flat: 3.7506460174918175, pod: 36.98627197742462, loss: 43.441025376319885 
Train [2/11] | Epoch [107/160] |	nca: 2.8042934611439705, flat: 3.6589294895529747, pod: 35.50487756729126, loss: 41.96810066699982 
Train [2/11] | Epoch [108/160] |	nca: 2.6066891439259052, flat: 3.447974868118763, pod: 34.239073038101196, loss: 40.293736815452576 
Train [2/11] | Epoch [109/160] |	nca: 2.402900565415621, flat: 3.3414785638451576, pod: 33.42014276981354, loss: 39.16452181339264 
Train [2/11] | Epoch [110/160] |	nca: 2.5593823343515396, flat: 3.3990076556801796, pod: 33.898083090782166, loss: 39.85647356510162 
Train [2/11] | Epoch [111/160] |	nca: 2.5614085532724857, flat: 3.1869977861642838, pod: 33.126957416534424, loss: 38.875363945961 
Train [2/11] | Epoch [112/160] |	nca: 2.817765597254038, flat: 3.289983421564102, pod: 34.18266320228577, loss: 40.290412068367004 
Train [2/11] | Epoch [113/160] |	nca: 2.6861949283629656, flat: 3.4000709876418114, pod: 35.433165431022644, loss: 41.519431710243225 
Train [2/11] | Epoch [114/160] |	nca: 2.7305963784456253, flat: 3.3590933233499527, pod: 34.56643879413605, loss: 40.65612852573395 
Train [2/11] | Epoch [115/160] |	nca: 2.6040672585368156, flat: 3.2241708859801292, pod: 32.92701292037964, loss: 38.75525116920471 
Train [2/11] | Epoch [116/160] |	nca: 2.5363958589732647, flat: 3.2332848086953163, pod: 33.686904311180115, loss: 39.45658504962921 
Train [2/11] | Epoch [117/160] |	nca: 2.840975470840931, flat: 3.1784852892160416, pod: 32.564574003219604, loss: 38.5840345621109 
Train [2/11] | Epoch [118/160] |	nca: 2.700260028243065, flat: 3.0263858288526535, pod: 32.15154016017914, loss: 37.8781863451004 
Train [2/11] | Epoch [119/160] |	nca: 2.6711988411843777, flat: 3.1682723090052605, pod: 32.33098566532135, loss: 38.17045617103577 
Train [2/11] | Epoch [120/160] |	nca: 2.783338639885187, flat: 3.0956097841262817, pod: 32.37468993663788, loss: 38.25363790988922 
Train [2/11] | Epoch [121/160] |	nca: 2.6383861005306244, flat: 3.0573509335517883, pod: 31.683415055274963, loss: 37.379151701927185 
Train [2/11] | Epoch [122/160] |	nca: 2.5638223104178905, flat: 2.9948585480451584, pod: 32.10475409030914, loss: 37.663435101509094 
Train [2/11] | Epoch [123/160] |	nca: 2.483620051294565, flat: 2.877956695854664, pod: 30.25984787940979, loss: 35.6214245557785 
Train [2/11] | Epoch [124/160] |	nca: 2.5602312237024307, flat: 2.7950849011540413, pod: 30.765042185783386, loss: 36.12035846710205 
Train [2/11] | Epoch [125/160] |	nca: 2.437323734164238, flat: 2.797236628830433, pod: 29.9335196018219, loss: 35.16807997226715 
Train [2/11] | Epoch [126/160] |	nca: 2.6607423685491085, flat: 2.6825320795178413, pod: 29.60595053434372, loss: 34.949225306510925 
Train [2/11] | Epoch [127/160] |	nca: 2.61457622051239, flat: 2.859034352004528, pod: 30.661018133163452, loss: 36.134629130363464 
Train [2/11] | Epoch [128/160] |	nca: 2.245840508490801, flat: 2.7251676097512245, pod: 29.283645927906036, loss: 34.25465416908264 
Train [2/11] | Epoch [129/160] |	nca: 2.6363918781280518, flat: 2.6407849714159966, pod: 29.113438069820404, loss: 34.39061486721039 
Train [2/11] | Epoch [130/160] |	nca: 2.4185273610055447, flat: 2.7496806755661964, pod: 29.423076808452606, loss: 34.59128487110138 
Train [2/11] | Epoch [131/160] |	nca: 2.4820836782455444, flat: 2.6973946020007133, pod: 29.179344058036804, loss: 34.35882234573364 
Train [2/11] | Epoch [132/160] |	nca: 2.35032107681036, flat: 2.608957715332508, pod: 29.399777114391327, loss: 34.35905575752258 
Train [2/11] | Epoch [133/160] |	nca: 2.365141648799181, flat: 2.5977669656276703, pod: 27.804466784000397, loss: 32.767375349998474 
Train [2/11] | Epoch [134/160] |	nca: 2.444557450711727, flat: 2.6273435205221176, pod: 28.366588294506073, loss: 33.43848979473114 
Train [2/11] | Epoch [135/160] |	nca: 2.480342462658882, flat: 2.558980979025364, pod: 28.378105759620667, loss: 33.41742944717407 
Train [2/11] | Epoch [136/160] |	nca: 2.51881255954504, flat: 2.606885574758053, pod: 29.0746031999588, loss: 34.20030117034912 
Train [2/11] | Epoch [137/160] |	nca: 2.4577194564044476, flat: 2.5858608037233353, pod: 28.191512763500214, loss: 33.235092997550964 
Train [2/11] | Epoch [138/160] |	nca: 2.615457110106945, flat: 2.5891337245702744, pod: 28.73126208782196, loss: 33.93585270643234 
Train [2/11] | Epoch [139/160] |	nca: 2.22226644679904, flat: 2.4699618741869926, pod: 27.12942397594452, loss: 31.82165241241455 
Train [2/11] | Epoch [140/160] |	nca: 2.200556952506304, flat: 2.4263218715786934, pod: 27.068545043468475, loss: 31.69542360305786 
Train [2/11] | Epoch [141/160] |	nca: 2.4124259501695633, flat: 2.459408052265644, pod: 27.66918534040451, loss: 32.54101920127869 
Train [2/11] | Epoch [142/160] |	nca: 2.310950268059969, flat: 2.4141303673386574, pod: 26.884777784347534, loss: 31.60985827445984 
Train [2/11] | Epoch [143/160] |	nca: 2.5801012255251408, flat: 2.3855167627334595, pod: 26.760977864265442, loss: 31.726595997810364 
Train [2/11] | Epoch [144/160] |	nca: 2.3617202937602997, flat: 2.4026551619172096, pod: 26.907538771629333, loss: 31.67191433906555 
Train [2/11] | Epoch [145/160] |	nca: 2.3858316093683243, flat: 2.3403002992272377, pod: 26.27466654777527, loss: 31.000798225402832 
Train [2/11] | Epoch [146/160] |	nca: 2.422557767480612, flat: 2.410074770450592, pod: 26.49378001689911, loss: 31.326412618160248 
Train [2/11] | Epoch [147/160] |	nca: 2.496015280485153, flat: 2.3727105855941772, pod: 25.736542642116547, loss: 30.605268716812134 
Train [2/11] | Epoch [148/160] |	nca: 2.2600015103816986, flat: 2.278073161840439, pod: 25.109184563159943, loss: 29.647259056568146 
Train [2/11] | Epoch [149/160] |	nca: 2.3726036064326763, flat: 2.327374279499054, pod: 25.66102945804596, loss: 30.361007571220398 
Train [2/11] | Epoch [150/160] |	nca: 2.4719819612801075, flat: 2.362994998693466, pod: 26.00940042734146, loss: 30.844377636909485 
Train [2/11] | Epoch [151/160] |	nca: 2.1256823539733887, flat: 2.2672612592577934, pod: 25.436270892620087, loss: 29.82921451330185 
Train [2/11] | Epoch [152/160] |	nca: 2.3345001377165318, flat: 2.2478393837809563, pod: 25.27181875705719, loss: 29.8541579246521 
Train [2/11] | Epoch [153/160] |	nca: 2.2479449547827244, flat: 2.264351397752762, pod: 25.436794877052307, loss: 29.949091017246246 
Train [2/11] | Epoch [154/160] |	nca: 2.3984332159161568, flat: 2.2652488723397255, pod: 25.342321157455444, loss: 30.00600302219391 
Train [2/11] | Epoch [155/160] |	nca: 2.2147323228418827, flat: 2.2634967863559723, pod: 24.878686130046844, loss: 29.3569153547287 
Train [2/11] | Epoch [156/160] |	nca: 2.1831809133291245, flat: 2.281290866434574, pod: 25.118840396404266, loss: 29.583311855793 
Train [2/11] | Epoch [157/160] |	nca: 2.563834022730589, flat: 2.265244983136654, pod: 24.85357093811035, loss: 29.682649970054626 
Train [2/11] | Epoch [158/160] |	nca: 2.385306593030691, flat: 2.2759748324751854, pod: 25.28483098745346, loss: 29.946112394332886 
Train [2/11] | Epoch [159/160] |	nca: 2.3198784105479717, flat: 2.301366627216339, pod: 25.29851543903351, loss: 29.91976034641266 
Train [2/11] | Epoch [160/160] |	nca: 2.200804177671671, flat: 2.254871167242527, pod: 25.038870334625244, loss: 29.49454575777054 
Fine-tuning
Building & updating memory.
Train [2/11] | Epoch [161/180] |	nca: 2.0273420363664627, flat: 1.5132640302181244, pod: 13.739781856536865, loss: 17.28038787841797 
Train [2/11] | Epoch [162/180] |	nca: 1.0352305471897125, flat: 1.55841264128685, pod: 13.96712851524353, loss: 16.560771703720093 
Train [2/11] | Epoch [163/180] |	nca: 0.7536084577441216, flat: 1.5247339308261871, pod: 13.611987590789795, loss: 15.890329837799072 
Train [2/11] | Epoch [164/180] |	nca: 0.6730137914419174, flat: 1.5160642713308334, pod: 13.650643229484558, loss: 15.839721322059631 
Train [2/11] | Epoch [165/180] |	nca: 0.46448836475610733, flat: 1.5196324288845062, pod: 13.800844669342041, loss: 15.78496539592743 
Train [2/11] | Epoch [166/180] |	nca: 0.4838130250573158, flat: 1.523738220334053, pod: 13.829001903533936, loss: 15.83655333518982 
Train [2/11] | Epoch [167/180] |	nca: 0.41279393061995506, flat: 1.5236086398363113, pod: 13.804089903831482, loss: 15.740492463111877 
Train [2/11] | Epoch [168/180] |	nca: 0.3933533616364002, flat: 1.5541848838329315, pod: 13.756553053855896, loss: 15.704091548919678 
Train [2/11] | Epoch [169/180] |	nca: 0.3186153769493103, flat: 1.5248236656188965, pod: 13.573306679725647, loss: 15.416745781898499 
Train [2/11] | Epoch [170/180] |	nca: 0.35378393717110157, flat: 1.5350251197814941, pod: 13.893743872642517, loss: 15.78255307674408 
Train [2/11] | Epoch [171/180] |	nca: 0.37518225237727165, flat: 1.555514894425869, pod: 13.74224328994751, loss: 15.672940373420715 
Train [2/11] | Epoch [172/180] |	nca: 0.34035781398415565, flat: 1.5240750461816788, pod: 13.754746794700623, loss: 15.619179487228394 
Train [2/11] | Epoch [173/180] |	nca: 0.289614325389266, flat: 1.5312935709953308, pod: 13.727326154708862, loss: 15.548233985900879 
Train [2/11] | Epoch [174/180] |	nca: 0.2856995053589344, flat: 1.5386192947626114, pod: 13.946861505508423, loss: 15.771180272102356 
Train [2/11] | Epoch [175/180] |	nca: 0.27611005306243896, flat: 1.5196828991174698, pod: 13.736550211906433, loss: 15.53234326839447 
Train [2/11] | Epoch [176/180] |	nca: 0.2756782993674278, flat: 1.51959727704525, pod: 13.556578993797302, loss: 15.3518545627594 
Train [2/11] | Epoch [177/180] |	nca: 0.27284011989831924, flat: 1.5351954847574234, pod: 13.806046605110168, loss: 15.614082098007202 
Train [2/11] | Epoch [178/180] |	nca: 0.2657809667289257, flat: 1.5145307034254074, pod: 13.635647535324097, loss: 15.415959239006042 
Train [2/11] | Epoch [179/180] |	nca: 0.27256864309310913, flat: 1.5260494500398636, pod: 13.85169506072998, loss: 15.650313258171082 
Train [2/11] | Epoch [180/180] |	nca: 0.25334292463958263, flat: 1.4913701117038727, pod: 13.55228841304779, loss: 15.297001481056213 
after task
Building & updating memory.
after task
Eval on 0->55.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.752.
Current acc: {'total': 0.725, '00-09': 0.761, '10-19': 0.704, '20-29': 0.645, '30-39': 0.71, '40-49': 0.77, '50-59': 0.79}.
Avg inc acc top5: 0.94.
Current acc top5: {'total': 0.931}.
Forgetting: -0.06899999999999998.
Cord metric: 0.75.
Old accuracy: 0.72, mean: 0.72.
New accuracy: 0.79, mean: 0.79.
================Task 2 Start!================
Testing on False unseen tasks (max class = 60).
Set memory of size: 1100.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 2 Training!================
The training samples number: 3600
Train on 55->60.
train task
nb 3600.
Train [3/11] | Epoch [1/160] |	nca: 19.592112094163895, flat: 12.213423103094101, pod: 73.23705112934113, loss: 105.04258632659912 
Train [3/11] | Epoch [2/160] |	nca: 15.510925889015198, flat: 17.19324818253517, pod: 90.91333055496216, loss: 123.61750602722168 
Train [3/11] | Epoch [3/160] |	nca: 12.62202200293541, flat: 15.985670447349548, pod: 85.31969809532166, loss: 113.92739129066467 
Train [3/11] | Epoch [4/160] |	nca: 7.900154545903206, flat: 13.178588956594467, pod: 78.15452742576599, loss: 99.23327136039734 
Train [3/11] | Epoch [5/160] |	nca: 6.008188121020794, flat: 10.503215283155441, pod: 71.99909257888794, loss: 88.51049613952637 
Train [3/11] | Epoch [6/160] |	nca: 5.320801377296448, flat: 8.767083287239075, pod: 65.5334370136261, loss: 79.6213219165802 
Train [3/11] | Epoch [7/160] |	nca: 5.606154806911945, flat: 9.363072782754898, pod: 66.68401861190796, loss: 81.65324544906616 
Train [3/11] | Epoch [8/160] |	nca: 4.057544223964214, flat: 7.545582041144371, pod: 59.65894901752472, loss: 71.26207542419434 
Train [3/11] | Epoch [9/160] |	nca: 5.624057859182358, flat: 9.018022999167442, pod: 66.29451012611389, loss: 80.93659043312073 
Train [3/11] | Epoch [10/160] |	nca: 4.501787461340427, flat: 8.134346842765808, pod: 62.71973013877869, loss: 75.35586428642273 
Train [3/11] | Epoch [11/160] |	nca: 5.087522104382515, flat: 8.869750514626503, pod: 65.64672660827637, loss: 79.60399985313416 
Train [3/11] | Epoch [12/160] |	nca: 3.8136625960469246, flat: 6.931152388453484, pod: 57.03528845310211, loss: 67.78010320663452 
Train [3/11] | Epoch [13/160] |	nca: 4.504086025059223, flat: 6.991864487528801, pod: 57.098915457725525, loss: 68.59486627578735 
Train [3/11] | Epoch [14/160] |	nca: 4.105567395687103, flat: 7.001052811741829, pod: 58.889344573020935, loss: 69.99596452713013 
Train [3/11] | Epoch [15/160] |	nca: 5.056965999305248, flat: 7.972017630934715, pod: 60.93565630912781, loss: 73.96464014053345 
Train [3/11] | Epoch [16/160] |	nca: 4.810942247509956, flat: 8.044165134429932, pod: 61.2068727016449, loss: 74.06197953224182 
Train [3/11] | Epoch [17/160] |	nca: 4.264123074710369, flat: 7.52350515127182, pod: 59.73962736129761, loss: 71.52725553512573 
Train [3/11] | Epoch [18/160] |	nca: 5.896493539214134, flat: 9.301313579082489, pod: 66.73112201690674, loss: 81.92892932891846 
Train [3/11] | Epoch [19/160] |	nca: 4.163697585463524, flat: 7.843398109078407, pod: 61.3289909362793, loss: 73.3360857963562 
Train [3/11] | Epoch [20/160] |	nca: 3.4168289937078953, flat: 7.181954026222229, pod: 58.543949007987976, loss: 69.14273190498352 
Train [3/11] | Epoch [21/160] |	nca: 3.113093040883541, flat: 5.884453743696213, pod: 53.89803159236908, loss: 62.89557886123657 
Train [3/11] | Epoch [22/160] |	nca: 3.898460365831852, flat: 6.51445834338665, pod: 56.33468437194824, loss: 66.74760270118713 
Train [3/11] | Epoch [23/160] |	nca: 3.562241591513157, flat: 7.155712753534317, pod: 58.99091875553131, loss: 69.70887303352356 
Train [3/11] | Epoch [24/160] |	nca: 4.110524460673332, flat: 6.920753210783005, pod: 57.821430921554565, loss: 68.85270857810974 
Train [3/11] | Epoch [25/160] |	nca: 4.311039999127388, flat: 7.251136854290962, pod: 58.43642866611481, loss: 69.99860525131226 
Train [3/11] | Epoch [26/160] |	nca: 3.6134365797042847, flat: 6.985211968421936, pod: 56.494544982910156, loss: 67.09319376945496 
Train [3/11] | Epoch [27/160] |	nca: 4.872420497238636, flat: 7.723959341645241, pod: 59.91943609714508, loss: 72.51581621170044 
Train [3/11] | Epoch [28/160] |	nca: 5.1566638350486755, flat: 9.26273426413536, pod: 64.47920799255371, loss: 78.89860582351685 
Train [3/11] | Epoch [29/160] |	nca: 3.765896424651146, flat: 7.383134186267853, pod: 60.58291471004486, loss: 71.73194527626038 
Train [3/11] | Epoch [30/160] |	nca: 3.7235118970274925, flat: 7.148347809910774, pod: 59.57688581943512, loss: 70.4487452507019 
Train [3/11] | Epoch [31/160] |	nca: 3.8942653127014637, flat: 7.3233969658613205, pod: 58.19881355762482, loss: 69.41647553443909 
Train [3/11] | Epoch [32/160] |	nca: 3.489838596433401, flat: 6.598330497741699, pod: 56.27319288253784, loss: 66.36136198043823 
Train [3/11] | Epoch [33/160] |	nca: 3.386825516819954, flat: 5.848307386040688, pod: 53.305471777915955, loss: 62.54060506820679 
Train [3/11] | Epoch [34/160] |	nca: 5.445928320288658, flat: 7.930167555809021, pod: 61.27571892738342, loss: 74.65181493759155 
Train [3/11] | Epoch [35/160] |	nca: 2.9005447924137115, flat: 6.17159777879715, pod: 53.93788242340088, loss: 63.01002514362335 
Train [3/11] | Epoch [36/160] |	nca: 4.298564329743385, flat: 6.879489034414291, pod: 57.07704830169678, loss: 68.25510144233704 
Train [3/11] | Epoch [37/160] |	nca: 4.977030590176582, flat: 8.617913708090782, pod: 63.74500036239624, loss: 77.33994436264038 
Train [3/11] | Epoch [38/160] |	nca: 4.02346308529377, flat: 7.681099355220795, pod: 59.30240750312805, loss: 71.00697016716003 
Train [3/11] | Epoch [39/160] |	nca: 3.244137465953827, flat: 6.7772495448589325, pod: 55.663076400756836, loss: 65.68446338176727 
Train [3/11] | Epoch [40/160] |	nca: 3.709609016776085, flat: 6.59405891597271, pod: 56.84744882583618, loss: 67.15111589431763 
Train [3/11] | Epoch [41/160] |	nca: 3.870923951268196, flat: 6.503011599183083, pod: 55.85522544384003, loss: 66.22916078567505 
Train [3/11] | Epoch [42/160] |	nca: 3.194954752922058, flat: 5.877771943807602, pod: 52.998323917388916, loss: 62.0710506439209 
Train [3/11] | Epoch [43/160] |	nca: 2.744718510657549, flat: 5.298977628350258, pod: 50.39297437667847, loss: 58.43667018413544 
Train [3/11] | Epoch [44/160] |	nca: 3.1291268691420555, flat: 5.206615522503853, pod: 49.45227670669556, loss: 57.78801965713501 
Train [3/11] | Epoch [45/160] |	nca: 3.217481054365635, flat: 5.016375705599785, pod: 48.52833020687103, loss: 56.762187242507935 
Train [3/11] | Epoch [46/160] |	nca: 5.122170154005289, flat: 7.703578293323517, pod: 58.23598754405975, loss: 71.0617356300354 
Train [3/11] | Epoch [47/160] |	nca: 2.94491233676672, flat: 6.121446758508682, pod: 53.46142280101776, loss: 62.5277818441391 
Train [3/11] | Epoch [48/160] |	nca: 2.7193765230476856, flat: 4.999337896704674, pod: 48.69402837753296, loss: 56.41274273395538 
Train [3/11] | Epoch [49/160] |	nca: 3.0416737012565136, flat: 5.44867068529129, pod: 49.49900269508362, loss: 57.98934710025787 
Train [3/11] | Epoch [50/160] |	nca: 2.621874436736107, flat: 4.784973472356796, pod: 47.38087439537048, loss: 54.78772234916687 
Train [3/11] | Epoch [51/160] |	nca: 3.504892211407423, flat: 4.742635905742645, pod: 46.46842622756958, loss: 54.715954422950745 
Train [3/11] | Epoch [52/160] |	nca: 6.239207707345486, flat: 8.921559661626816, pod: 65.20370304584503, loss: 80.36447095870972 
Train [3/11] | Epoch [53/160] |	nca: 5.1561625227332115, flat: 8.9003227353096, pod: 63.475021719932556, loss: 77.53150701522827 
Train [3/11] | Epoch [54/160] |	nca: 3.43839094042778, flat: 6.725774377584457, pod: 55.646148443222046, loss: 65.81031322479248 
Train [3/11] | Epoch [55/160] |	nca: 3.7484268844127655, flat: 6.55278517305851, pod: 55.74307990074158, loss: 66.04429197311401 
Train [3/11] | Epoch [56/160] |	nca: 3.2133291698992252, flat: 6.447709321975708, pod: 55.21452820301056, loss: 64.87556636333466 
Train [3/11] | Epoch [57/160] |	nca: 3.1530435383319855, flat: 5.258431002497673, pod: 49.70336556434631, loss: 58.114840030670166 
Train [3/11] | Epoch [58/160] |	nca: 5.133871704339981, flat: 6.941712573170662, pod: 55.550169706344604, loss: 67.62575376033783 
Train [3/11] | Epoch [59/160] |	nca: 3.7942636981606483, flat: 6.872198849916458, pod: 54.835262417793274, loss: 65.50172519683838 
Train [3/11] | Epoch [60/160] |	nca: 3.1743946447968483, flat: 6.089642778038979, pod: 52.69578266143799, loss: 61.95982003211975 
Train [3/11] | Epoch [61/160] |	nca: 2.6703655794262886, flat: 5.102703586220741, pod: 48.98659908771515, loss: 56.75966811180115 
Train [3/11] | Epoch [62/160] |	nca: 2.8202978000044823, flat: 4.977088302373886, pod: 49.0965359210968, loss: 56.893921852111816 
Train [3/11] | Epoch [63/160] |	nca: 2.786078419536352, flat: 4.842093780636787, pod: 47.65327858924866, loss: 55.28145110607147 
Train [3/11] | Epoch [64/160] |	nca: 3.336329784244299, flat: 5.34633831679821, pod: 49.18160331249237, loss: 57.86427140235901 
Train [3/11] | Epoch [65/160] |	nca: 2.742650542408228, flat: 4.8544382601976395, pod: 46.478559494018555, loss: 54.07564830780029 
Train [3/11] | Epoch [66/160] |	nca: 2.3511368595063686, flat: 4.272458001971245, pod: 44.32433474063873, loss: 50.94792938232422 
Train [3/11] | Epoch [67/160] |	nca: 3.140310849994421, flat: 4.593868896365166, pod: 44.748239159584045, loss: 52.48241889476776 
Train [3/11] | Epoch [68/160] |	nca: 4.6673495545983315, flat: 6.295065179467201, pod: 54.27909469604492, loss: 65.24150907993317 
Train [3/11] | Epoch [69/160] |	nca: 2.836427979171276, flat: 5.283197209239006, pod: 48.81385838985443, loss: 56.933483481407166 
Train [3/11] | Epoch [70/160] |	nca: 2.870647471398115, flat: 4.727557078003883, pod: 46.87677800655365, loss: 54.47498261928558 
Train [3/11] | Epoch [71/160] |	nca: 3.205221675336361, flat: 5.015263646841049, pod: 47.23876440525055, loss: 55.45924973487854 
Train [3/11] | Epoch [72/160] |	nca: 2.3644637279212475, flat: 4.218003928661346, pod: 42.751076459884644, loss: 49.33354413509369 
Train [3/11] | Epoch [73/160] |	nca: 2.3326376900076866, flat: 3.794114038348198, pod: 42.059348464012146, loss: 48.186100125312805 
Train [3/11] | Epoch [74/160] |	nca: 2.734882276505232, flat: 4.041603550314903, pod: 43.56595456600189, loss: 50.342440247535706 
Train [3/11] | Epoch [75/160] |	nca: 3.2274110168218613, flat: 5.224778711795807, pod: 49.469412446022034, loss: 57.92160189151764 
Train [3/11] | Epoch [76/160] |	nca: 2.6659370101988316, flat: 4.2349046021699905, pod: 42.73443603515625, loss: 49.63527774810791 
Train [3/11] | Epoch [77/160] |	nca: 2.516822688281536, flat: 4.136532925069332, pod: 43.189128398895264, loss: 49.84248423576355 
Train [3/11] | Epoch [78/160] |	nca: 2.7529798820614815, flat: 3.9095118641853333, pod: 42.634032249450684, loss: 49.29652416706085 
Train [3/11] | Epoch [79/160] |	nca: 3.025575987994671, flat: 4.522875115275383, pod: 44.52116072177887, loss: 52.06961166858673 
Train [3/11] | Epoch [80/160] |	nca: 2.954377494752407, flat: 4.3923370242118835, pod: 44.35311543941498, loss: 51.69982993602753 
Train [3/11] | Epoch [81/160] |	nca: 2.700466476380825, flat: 4.392402544617653, pod: 45.405112504959106, loss: 52.49798142910004 
Train [3/11] | Epoch [82/160] |	nca: 2.4782980531454086, flat: 3.9377223029732704, pod: 42.84336304664612, loss: 49.25938355922699 
Train [3/11] | Epoch [83/160] |	nca: 2.243867240846157, flat: 3.56826364248991, pod: 39.5493323802948, loss: 45.36146318912506 
Train [3/11] | Epoch [84/160] |	nca: 2.664424955844879, flat: 3.643684044480324, pod: 39.970640420913696, loss: 46.27874934673309 
Train [3/11] | Epoch [85/160] |	nca: 2.758815299719572, flat: 4.034555159509182, pod: 41.89429581165314, loss: 48.687666058540344 
Train [3/11] | Epoch [86/160] |	nca: 2.984819196164608, flat: 3.705866925418377, pod: 39.74510872364044, loss: 46.435794830322266 
Train [3/11] | Epoch [87/160] |	nca: 2.9692251943051815, flat: 3.984484389424324, pod: 42.44692003726959, loss: 49.40062952041626 
Train [3/11] | Epoch [88/160] |	nca: 2.7532474510371685, flat: 4.528697721660137, pod: 45.072500705718994, loss: 52.354445934295654 
Train [3/11] | Epoch [89/160] |	nca: 2.5983287058770657, flat: 3.769463174045086, pod: 40.52665603160858, loss: 46.894447565078735 
Train [3/11] | Epoch [90/160] |	nca: 3.629215382039547, flat: 5.158475771546364, pod: 46.26763463020325, loss: 55.055325984954834 
Train [3/11] | Epoch [91/160] |	nca: 2.485550183802843, flat: 4.328696124255657, pod: 43.743319630622864, loss: 50.55756640434265 
Train [3/11] | Epoch [92/160] |	nca: 2.559448827058077, flat: 3.7587698474526405, pod: 40.09647619724274, loss: 46.41469490528107 
Train [3/11] | Epoch [93/160] |	nca: 2.5834198854863644, flat: 3.5684886127710342, pod: 39.53843307495117, loss: 45.69034171104431 
Train [3/11] | Epoch [94/160] |	nca: 2.7126808874309063, flat: 3.9797319024801254, pod: 42.00477612018585, loss: 48.6971892118454 
Train [3/11] | Epoch [95/160] |	nca: 2.3554591946303844, flat: 3.6008525490760803, pod: 39.930182099342346, loss: 45.8864940404892 
Train [3/11] | Epoch [96/160] |	nca: 2.4790336787700653, flat: 3.5663497895002365, pod: 38.84161138534546, loss: 44.88699460029602 
Train [3/11] | Epoch [97/160] |	nca: 2.659893501549959, flat: 3.5564493760466576, pod: 38.656569480895996, loss: 44.87291216850281 
Train [3/11] | Epoch [98/160] |	nca: 2.632749740034342, flat: 3.6252949237823486, pod: 39.271660804748535, loss: 45.52970516681671 
Train [3/11] | Epoch [99/160] |	nca: 2.6417094133794308, flat: 3.4886038452386856, pod: 38.256479263305664, loss: 44.38679277896881 
Train [3/11] | Epoch [100/160] |	nca: 2.567402794957161, flat: 3.7029720693826675, pod: 39.2533016204834, loss: 45.52367639541626 
Train [3/11] | Epoch [101/160] |	nca: 2.6038170866668224, flat: 3.2807759270071983, pod: 37.270514130592346, loss: 43.155107617378235 
Train [3/11] | Epoch [102/160] |	nca: 2.7116258405148983, flat: 3.6420832946896553, pod: 38.53980565071106, loss: 44.893514752388 
Train [3/11] | Epoch [103/160] |	nca: 2.3509743325412273, flat: 3.172822691500187, pod: 36.63719594478607, loss: 42.160993218421936 
Train [3/11] | Epoch [104/160] |	nca: 2.222611352801323, flat: 3.131740488111973, pod: 36.52550029754639, loss: 41.87985169887543 
Train [3/11] | Epoch [105/160] |	nca: 2.3810566067695618, flat: 3.093345694243908, pod: 35.563026428222656, loss: 41.037428975105286 
Train [3/11] | Epoch [106/160] |	nca: 2.724329423159361, flat: 2.818903185427189, pod: 33.543468594551086, loss: 39.08670103549957 
Train [3/11] | Epoch [107/160] |	nca: 2.660885766148567, flat: 3.492274835705757, pod: 38.844618916511536, loss: 44.99777948856354 
Train [3/11] | Epoch [108/160] |	nca: 2.169577345252037, flat: 2.9622883275151253, pod: 35.28825807571411, loss: 40.42012369632721 
Train [3/11] | Epoch [109/160] |	nca: 2.7139572463929653, flat: 2.8160372748970985, pod: 34.42288327217102, loss: 39.95287811756134 
Train [3/11] | Epoch [110/160] |	nca: 2.5234091095626354, flat: 3.077056460082531, pod: 36.02999413013458, loss: 41.630459785461426 
Train [3/11] | Epoch [111/160] |	nca: 2.286414846777916, flat: 3.077254079282284, pod: 35.0860550403595, loss: 40.449723958969116 
Train [3/11] | Epoch [112/160] |	nca: 2.729679439216852, flat: 2.7855969816446304, pod: 33.95050501823425, loss: 39.46578133106232 
Train [3/11] | Epoch [113/160] |	nca: 2.272959977388382, flat: 2.7417038679122925, pod: 32.956518054008484, loss: 37.971182107925415 
Train [3/11] | Epoch [114/160] |	nca: 2.4201014265418053, flat: 2.7833316028118134, pod: 33.236697256565094, loss: 38.44013071060181 
Train [3/11] | Epoch [115/160] |	nca: 2.396265871822834, flat: 2.8170238211750984, pod: 33.48466366529465, loss: 38.69795298576355 
Train [3/11] | Epoch [116/160] |	nca: 2.371660675853491, flat: 2.778477095067501, pod: 34.22067588567734, loss: 39.370814085006714 
Train [3/11] | Epoch [117/160] |	nca: 2.187552459537983, flat: 2.545787699520588, pod: 31.50328814983368, loss: 36.2366281747818 
Train [3/11] | Epoch [118/160] |	nca: 2.024204194545746, flat: 2.4675730392336845, pod: 31.934375941753387, loss: 36.42615330219269 
Train [3/11] | Epoch [119/160] |	nca: 2.2649133652448654, flat: 2.454270303249359, pod: 30.805752336978912, loss: 35.524935841560364 
Train [3/11] | Epoch [120/160] |	nca: 2.6579971313476562, flat: 2.7149380668997765, pod: 32.61993396282196, loss: 37.99286937713623 
Train [3/11] | Epoch [121/160] |	nca: 2.4140356574207544, flat: 2.6064648628234863, pod: 31.614256501197815, loss: 36.63475716114044 
Train [3/11] | Epoch [122/160] |	nca: 2.3946514911949635, flat: 2.6163257136940956, pod: 31.51235842704773, loss: 36.5233359336853 
Train [3/11] | Epoch [123/160] |	nca: 2.6330459862947464, flat: 2.433407425880432, pod: 31.794194757938385, loss: 36.86064839363098 
Train [3/11] | Epoch [124/160] |	nca: 2.1878696493804455, flat: 2.5269717946648598, pod: 31.266547739505768, loss: 35.98138916492462 
Train [3/11] | Epoch [125/160] |	nca: 2.2142008543014526, flat: 2.384408876299858, pod: 30.496000051498413, loss: 35.09460961818695 
Train [3/11] | Epoch [126/160] |	nca: 2.01815165579319, flat: 2.3129793107509613, pod: 29.633552253246307, loss: 33.964683055877686 
Train [3/11] | Epoch [127/160] |	nca: 2.36229956895113, flat: 2.2568307518959045, pod: 29.131016790866852, loss: 33.750147104263306 
Train [3/11] | Epoch [128/160] |	nca: 2.3980815038084984, flat: 2.2975430078804493, pod: 28.552484929561615, loss: 33.24810963869095 
Train [3/11] | Epoch [129/160] |	nca: 2.2184669971466064, flat: 2.3436932489275932, pod: 29.151368618011475, loss: 33.7135289311409 
Train [3/11] | Epoch [130/160] |	nca: 2.207836203277111, flat: 2.2555212154984474, pod: 28.532939076423645, loss: 32.99629628658295 
Train [3/11] | Epoch [131/160] |	nca: 2.2465222030878067, flat: 2.124056998640299, pod: 27.521203696727753, loss: 31.89178293943405 
Train [3/11] | Epoch [132/160] |	nca: 2.3136804923415184, flat: 2.159359246492386, pod: 28.211757600307465, loss: 32.68479710817337 
Train [3/11] | Epoch [133/160] |	nca: 2.1561604253947735, flat: 2.0932744406163692, pod: 27.446089029312134, loss: 31.695523858070374 
Train [3/11] | Epoch [134/160] |	nca: 2.6517076157033443, flat: 2.111250165849924, pod: 27.650057911872864, loss: 32.413015484809875 
Train [3/11] | Epoch [135/160] |	nca: 2.4534336365759373, flat: 2.3444345965981483, pod: 29.219996333122253, loss: 34.017864644527435 
Train [3/11] | Epoch [136/160] |	nca: 2.251006033271551, flat: 2.306726597249508, pod: 28.120502650737762, loss: 32.678235709667206 
Train [3/11] | Epoch [137/160] |	nca: 2.395931053906679, flat: 2.197921458631754, pod: 27.628599882125854, loss: 32.22245270013809 
Train [3/11] | Epoch [138/160] |	nca: 2.3219474144279957, flat: 2.1146574579179287, pod: 26.72024953365326, loss: 31.156854271888733 
Train [3/11] | Epoch [139/160] |	nca: 2.410398729145527, flat: 2.1489001102745533, pod: 27.74805039167404, loss: 32.3073490858078 
Train [3/11] | Epoch [140/160] |	nca: 2.394618283957243, flat: 2.0416614525020123, pod: 26.93602764606476, loss: 31.372307240962982 
Train [3/11] | Epoch [141/160] |	nca: 2.15167723223567, flat: 2.142906405031681, pod: 27.50397378206253, loss: 31.79855728149414 
Train [3/11] | Epoch [142/160] |	nca: 2.050787530839443, flat: 1.9557038433849812, pod: 25.283283054828644, loss: 29.289774477481842 
Train [3/11] | Epoch [143/160] |	nca: 2.1394099704921246, flat: 1.9701718054711819, pod: 25.605862379074097, loss: 29.715444564819336 
Train [3/11] | Epoch [144/160] |	nca: 2.012011967599392, flat: 2.012769691646099, pod: 26.10916405916214, loss: 30.13394570350647 
Train [3/11] | Epoch [145/160] |	nca: 2.052126716822386, flat: 1.9102745205163956, pod: 25.08010721206665, loss: 29.04250818490982 
Train [3/11] | Epoch [146/160] |	nca: 2.1419221311807632, flat: 1.907067533582449, pod: 25.265571773052216, loss: 29.314561367034912 
Train [3/11] | Epoch [147/160] |	nca: 2.248649377375841, flat: 1.9025936126708984, pod: 25.272226095199585, loss: 29.423469126224518 
Train [3/11] | Epoch [148/160] |	nca: 2.1915662437677383, flat: 1.8583836890757084, pod: 24.84094327688217, loss: 28.89089274406433 
Train [3/11] | Epoch [149/160] |	nca: 1.9565002545714378, flat: 1.8727522753179073, pod: 24.849148094654083, loss: 28.678400576114655 
Train [3/11] | Epoch [150/160] |	nca: 2.102451089769602, flat: 1.8452759198844433, pod: 24.669108748435974, loss: 28.61683577299118 
Train [3/11] | Epoch [151/160] |	nca: 2.269842032343149, flat: 1.8922654055058956, pod: 24.996633112430573, loss: 29.158740520477295 
Train [3/11] | Epoch [152/160] |	nca: 2.183635774999857, flat: 1.8502465151250362, pod: 24.343366742134094, loss: 28.377249121665955 
Train [3/11] | Epoch [153/160] |	nca: 2.1720292642712593, flat: 1.8099667094647884, pod: 23.788181483745575, loss: 27.77017742395401 
Train [3/11] | Epoch [154/160] |	nca: 2.607710588723421, flat: 1.9909468404948711, pod: 24.663150191307068, loss: 29.261807441711426 
Train [3/11] | Epoch [155/160] |	nca: 1.9412825368344784, flat: 1.8377353362739086, pod: 24.404234528541565, loss: 28.183252453804016 
Train [3/11] | Epoch [156/160] |	nca: 2.037993885576725, flat: 1.8376732394099236, pod: 24.32784205675125, loss: 28.203509390354156 
Train [3/11] | Epoch [157/160] |	nca: 2.2123223431408405, flat: 1.81953477114439, pod: 24.115573406219482, loss: 28.147430539131165 
Train [3/11] | Epoch [158/160] |	nca: 2.129051983356476, flat: 1.7965919226408005, pod: 23.989862203598022, loss: 27.91550600528717 
Train [3/11] | Epoch [159/160] |	nca: 2.185695104300976, flat: 1.753135222941637, pod: 23.43848752975464, loss: 27.37731784582138 
Train [3/11] | Epoch [160/160] |	nca: 1.9991043005138636, flat: 1.7781479954719543, pod: 23.910379886627197, loss: 27.687632083892822 
Fine-tuning
Building & updating memory.
Train [3/11] | Epoch [161/180] |	nca: 1.8218562453985214, flat: 1.1637347266077995, pod: 13.386412024497986, loss: 16.372002720832825 
Train [3/11] | Epoch [162/180] |	nca: 0.8539049029350281, flat: 1.1947911381721497, pod: 13.900301098823547, loss: 15.948997139930725 
Train [3/11] | Epoch [163/180] |	nca: 0.7134465537965298, flat: 1.1586895734071732, pod: 13.487575769424438, loss: 15.35971200466156 
Train [3/11] | Epoch [164/180] |	nca: 0.7394023202359676, flat: 1.1989226192235947, pod: 13.859641671180725, loss: 15.797966837882996 
Train [3/11] | Epoch [165/180] |	nca: 0.49908357858657837, flat: 1.1534960120916367, pod: 13.608392715454102, loss: 15.260972261428833 
Train [3/11] | Epoch [166/180] |	nca: 0.4879216365516186, flat: 1.1609260141849518, pod: 13.752772212028503, loss: 15.401619911193848 
Train [3/11] | Epoch [167/180] |	nca: 0.497208371758461, flat: 1.197977103292942, pod: 13.942317962646484, loss: 15.637503266334534 
Train [3/11] | Epoch [168/180] |	nca: 0.4335169941186905, flat: 1.1549658998847008, pod: 13.468669652938843, loss: 15.057152509689331 
Train [3/11] | Epoch [169/180] |	nca: 0.39863143488764763, flat: 1.182659164071083, pod: 13.83856737613678, loss: 15.419857859611511 
Train [3/11] | Epoch [170/180] |	nca: 0.4215678460896015, flat: 1.1783443912863731, pod: 13.529491662979126, loss: 15.129403948783875 
Train [3/11] | Epoch [171/180] |	nca: 0.5233990009874105, flat: 1.1728541404008865, pod: 13.782555103302002, loss: 15.478808164596558 
Train [3/11] | Epoch [172/180] |	nca: 0.41791243106126785, flat: 1.1835203915834427, pod: 13.961192011833191, loss: 15.56262493133545 
Train [3/11] | Epoch [173/180] |	nca: 0.3913451600819826, flat: 1.1755278334021568, pod: 13.77328646183014, loss: 15.34015941619873 
Train [3/11] | Epoch [174/180] |	nca: 0.3934938944876194, flat: 1.1709309220314026, pod: 13.651233911514282, loss: 15.215658783912659 
Train [3/11] | Epoch [175/180] |	nca: 0.38148751482367516, flat: 1.157355286180973, pod: 13.222187638282776, loss: 14.761030435562134 
Train [3/11] | Epoch [176/180] |	nca: 0.3547196052968502, flat: 1.1935510784387589, pod: 13.77556300163269, loss: 15.323833584785461 
Train [3/11] | Epoch [177/180] |	nca: 0.41858531162142754, flat: 1.1764171868562698, pod: 13.698601484298706, loss: 15.293604016304016 
Train [3/11] | Epoch [178/180] |	nca: 0.369586281478405, flat: 1.138670653104782, pod: 13.3524169921875, loss: 14.860673785209656 
Train [3/11] | Epoch [179/180] |	nca: 0.3737063389271498, flat: 1.1669081524014473, pod: 13.668943643569946, loss: 15.209558248519897 
Train [3/11] | Epoch [180/180] |	nca: 0.41379437781870365, flat: 1.2054269909858704, pod: 14.057411670684814, loss: 15.67663311958313 
after task
Building & updating memory.
after task
Eval on 0->60.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.735.
Current acc: {'total': 0.701, '00-09': 0.708, '10-19': 0.69, '20-29': 0.627, '30-39': 0.647, '40-49': 0.733, '50-59': 0.798}.
Avg inc acc top5: 0.9296666666666665.
Current acc top5: {'total': 0.909}.
Forgetting: 0.06914285714285717.
Cord metric: 0.74.
Old accuracy: 0.69, mean: 0.70.
New accuracy: 0.87, mean: 0.83.
================Task 3 Start!================
Testing on False unseen tasks (max class = 65).
Set memory of size: 1200.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 3 Training!================
The training samples number: 3700
Train on 60->65.
train task
nb 3700.
Train [4/11] | Epoch [1/160] |	nca: 33.51998072862625, flat: 12.457487404346466, pod: 75.87610912322998, loss: 121.85357809066772 
Train [4/11] | Epoch [2/160] |	nca: 20.91486942768097, flat: 13.95703187584877, pod: 83.9764449596405, loss: 118.84834694862366 
Train [4/11] | Epoch [3/160] |	nca: 15.463285833597183, flat: 10.56787595152855, pod: 73.15946197509766, loss: 99.19062352180481 
Train [4/11] | Epoch [4/160] |	nca: 12.172288984060287, flat: 9.01145988702774, pod: 67.78751587867737, loss: 88.97126483917236 
Train [4/11] | Epoch [5/160] |	nca: 10.929477006196976, flat: 7.764986753463745, pod: 61.008065819740295, loss: 79.70252871513367 
Train [4/11] | Epoch [6/160] |	nca: 10.329456463456154, flat: 7.400492489337921, pod: 60.237075090408325, loss: 77.96702337265015 
Train [4/11] | Epoch [7/160] |	nca: 10.840601593255997, flat: 7.621324583888054, pod: 61.83310091495514, loss: 80.29502701759338 
Train [4/11] | Epoch [8/160] |	nca: 10.180668264627457, flat: 7.838227391242981, pod: 63.208863854408264, loss: 81.22775983810425 
Train [4/11] | Epoch [9/160] |	nca: 8.45205220580101, flat: 7.338713496923447, pod: 59.72003448009491, loss: 75.51080107688904 
Train [4/11] | Epoch [10/160] |	nca: 8.863445729017258, flat: 7.152660608291626, pod: 61.13698875904083, loss: 77.15309524536133 
Train [4/11] | Epoch [11/160] |	nca: 8.78824071586132, flat: 7.211833596229553, pod: 58.892428517341614, loss: 74.89250302314758 
Train [4/11] | Epoch [12/160] |	nca: 8.081510365009308, flat: 7.097746327519417, pod: 59.167712807655334, loss: 74.34696984291077 
Train [4/11] | Epoch [13/160] |	nca: 8.491976410150528, flat: 7.613747641444206, pod: 63.44055724143982, loss: 79.54628157615662 
Train [4/11] | Epoch [14/160] |	nca: 7.686990812420845, flat: 7.264473959803581, pod: 59.903499722480774, loss: 74.8549644947052 
Train [4/11] | Epoch [15/160] |	nca: 8.343480870127678, flat: 7.369523927569389, pod: 60.90423405170441, loss: 76.61723899841309 
Train [4/11] | Epoch [16/160] |	nca: 8.578334614634514, flat: 7.34850400686264, pod: 59.812719106674194, loss: 75.73955726623535 
Train [4/11] | Epoch [17/160] |	nca: 8.0447349101305, flat: 7.430948033928871, pod: 60.02582025527954, loss: 75.5015037059784 
Train [4/11] | Epoch [18/160] |	nca: 8.156391069293022, flat: 7.674940004944801, pod: 62.38590049743652, loss: 78.2172315120697 
Train [4/11] | Epoch [19/160] |	nca: 7.547736153006554, flat: 7.29238523542881, pod: 59.37096667289734, loss: 74.21108818054199 
Train [4/11] | Epoch [20/160] |	nca: 7.147735074162483, flat: 7.055667981505394, pod: 58.71916174888611, loss: 72.92256546020508 
Train [4/11] | Epoch [21/160] |	nca: 6.76787257194519, flat: 6.914604276418686, pod: 59.45713675022125, loss: 73.13961434364319 
Train [4/11] | Epoch [22/160] |	nca: 7.351419538259506, flat: 6.603792414069176, pod: 56.847933769226074, loss: 70.80314564704895 
Train [4/11] | Epoch [23/160] |	nca: 6.180069208145142, flat: 6.4673759788274765, pod: 56.48945677280426, loss: 69.13690185546875 
Train [4/11] | Epoch [24/160] |	nca: 6.691358521580696, flat: 6.371658653020859, pod: 55.74314737319946, loss: 68.80616450309753 
Train [4/11] | Epoch [25/160] |	nca: 6.695505261421204, flat: 6.760606184601784, pod: 56.78089618682861, loss: 70.2370069026947 
Train [4/11] | Epoch [26/160] |	nca: 6.537183970212936, flat: 6.575898349285126, pod: 56.302000522613525, loss: 69.4150824546814 
Train [4/11] | Epoch [27/160] |	nca: 6.8656570464372635, flat: 6.635718584060669, pod: 57.41915833950043, loss: 70.92053413391113 
Train [4/11] | Epoch [28/160] |	nca: 6.850139290094376, flat: 6.895729959011078, pod: 57.21710443496704, loss: 70.96297359466553 
Train [4/11] | Epoch [29/160] |	nca: 6.073532342910767, flat: 6.302891671657562, pod: 55.57808208465576, loss: 67.95450639724731 
Train [4/11] | Epoch [30/160] |	nca: 5.2347878366708755, flat: 6.105319306254387, pod: 54.91010403633118, loss: 66.2502110004425 
Train [4/11] | Epoch [31/160] |	nca: 5.723412908613682, flat: 6.035012096166611, pod: 54.70216429233551, loss: 66.46058940887451 
Train [4/11] | Epoch [32/160] |	nca: 7.097668215632439, flat: 6.413734883069992, pod: 55.49615728855133, loss: 69.00756072998047 
Train [4/11] | Epoch [33/160] |	nca: 5.822654277086258, flat: 6.338287428021431, pod: 55.85055327415466, loss: 68.01149463653564 
Train [4/11] | Epoch [34/160] |	nca: 5.764655143022537, flat: 6.240477606654167, pod: 55.7335239648819, loss: 67.73865699768066 
Train [4/11] | Epoch [35/160] |	nca: 6.620348535478115, flat: 6.346276119351387, pod: 56.08634853363037, loss: 69.05297327041626 
Train [4/11] | Epoch [36/160] |	nca: 6.45678636431694, flat: 6.560798734426498, pod: 55.92276227474213, loss: 68.94034767150879 
Train [4/11] | Epoch [37/160] |	nca: 6.028348878026009, flat: 6.461563393473625, pod: 54.967448234558105, loss: 67.45736050605774 
Train [4/11] | Epoch [38/160] |	nca: 6.352981075644493, flat: 6.300425574183464, pod: 54.64350998401642, loss: 67.2969172000885 
Train [4/11] | Epoch [39/160] |	nca: 5.649812377989292, flat: 6.258103966712952, pod: 54.464521050453186, loss: 66.37243747711182 
Train [4/11] | Epoch [40/160] |	nca: 5.586596041917801, flat: 6.084049999713898, pod: 53.980220913887024, loss: 65.65086698532104 
Train [4/11] | Epoch [41/160] |	nca: 5.777183599770069, flat: 5.763082265853882, pod: 52.97520411014557, loss: 64.51546955108643 
Train [4/11] | Epoch [42/160] |	nca: 5.459537677466869, flat: 6.1480279713869095, pod: 54.728296518325806, loss: 66.33586287498474 
Train [4/11] | Epoch [43/160] |	nca: 5.539307996630669, flat: 5.984702959656715, pod: 54.12521052360535, loss: 65.64922213554382 
Train [4/11] | Epoch [44/160] |	nca: 6.482292115688324, flat: 6.1954645216465, pod: 54.50446343421936, loss: 67.18222045898438 
Train [4/11] | Epoch [45/160] |	nca: 6.110628455877304, flat: 6.223413214087486, pod: 55.464638233184814, loss: 67.79867935180664 
Train [4/11] | Epoch [46/160] |	nca: 5.690964683890343, flat: 5.975458085536957, pod: 54.595991253852844, loss: 66.26241374015808 
Train [4/11] | Epoch [47/160] |	nca: 5.7108618170022964, flat: 5.8509743213653564, pod: 52.586169481277466, loss: 64.14800500869751 
Train [4/11] | Epoch [48/160] |	nca: 5.735509693622589, flat: 5.748407557606697, pod: 53.16214191913605, loss: 64.64605975151062 
Train [4/11] | Epoch [49/160] |	nca: 5.379198223352432, flat: 5.7951222360134125, pod: 53.29466140270233, loss: 64.46898198127747 
Train [4/11] | Epoch [50/160] |	nca: 5.836043298244476, flat: 5.984514504671097, pod: 53.05521595478058, loss: 64.87577366828918 
Train [4/11] | Epoch [51/160] |	nca: 5.231549859046936, flat: 5.778316602110863, pod: 52.71848654747009, loss: 63.72835326194763 
Train [4/11] | Epoch [52/160] |	nca: 5.61989551782608, flat: 5.599548473954201, pod: 51.74214327335358, loss: 62.96158695220947 
Train [4/11] | Epoch [53/160] |	nca: 5.381345734000206, flat: 5.384684070944786, pod: 51.11200201511383, loss: 61.87803137302399 
Train [4/11] | Epoch [54/160] |	nca: 5.088691137731075, flat: 5.368699014186859, pod: 51.25243139266968, loss: 61.709821462631226 
Train [4/11] | Epoch [55/160] |	nca: 4.6824651658535, flat: 5.173023492097855, pod: 50.333588004112244, loss: 60.1890766620636 
Train [4/11] | Epoch [56/160] |	nca: 5.004682339727879, flat: 5.270427614450455, pod: 50.37135887145996, loss: 60.64646875858307 
Train [4/11] | Epoch [57/160] |	nca: 5.797393165528774, flat: 5.582580670714378, pod: 51.12449836730957, loss: 62.50447225570679 
Train [4/11] | Epoch [58/160] |	nca: 5.9108801782131195, flat: 5.536463975906372, pod: 51.213589668273926, loss: 62.66093313694 
Train [4/11] | Epoch [59/160] |	nca: 5.361553251743317, flat: 5.485021635890007, pod: 50.02628469467163, loss: 60.87285935878754 
Train [4/11] | Epoch [60/160] |	nca: 4.456336930394173, flat: 5.215411871671677, pod: 49.36769890785217, loss: 59.0394481420517 
Train [4/11] | Epoch [61/160] |	nca: 4.771874129772186, flat: 4.792474761605263, pod: 47.172234535217285, loss: 56.73658323287964 
Train [4/11] | Epoch [62/160] |	nca: 5.143507435917854, flat: 5.020267531275749, pod: 48.133679151535034, loss: 58.29745435714722 
Train [4/11] | Epoch [63/160] |	nca: 5.084858752787113, flat: 4.990863993763924, pod: 47.18277359008789, loss: 57.25849652290344 
Train [4/11] | Epoch [64/160] |	nca: 5.05847804248333, flat: 4.945186257362366, pod: 47.3372985124588, loss: 57.3409628868103 
Train [4/11] | Epoch [65/160] |	nca: 5.131175026297569, flat: 4.9358683079481125, pod: 48.96685338020325, loss: 59.033896923065186 
Train [4/11] | Epoch [66/160] |	nca: 4.926440559327602, flat: 4.841155931353569, pod: 46.49682664871216, loss: 56.26442277431488 
Train [4/11] | Epoch [67/160] |	nca: 5.444708526134491, flat: 5.078805431723595, pod: 51.01651203632355, loss: 61.54002583026886 
Train [4/11] | Epoch [68/160] |	nca: 4.919275388121605, flat: 5.0815799832344055, pod: 49.43187606334686, loss: 59.43273186683655 
Train [4/11] | Epoch [69/160] |	nca: 4.617677114903927, flat: 4.796055972576141, pod: 48.88933515548706, loss: 58.30306792259216 
Train [4/11] | Epoch [70/160] |	nca: 4.852632723748684, flat: 4.81465058028698, pod: 48.44113218784332, loss: 58.108415603637695 
Train [4/11] | Epoch [71/160] |	nca: 4.658287450671196, flat: 4.628386124968529, pod: 46.173338890075684, loss: 55.460012555122375 
Train [4/11] | Epoch [72/160] |	nca: 4.475904129445553, flat: 4.480482518672943, pod: 45.834510803222656, loss: 54.790897846221924 
Train [4/11] | Epoch [73/160] |	nca: 4.372197099030018, flat: 4.367887109518051, pod: 43.93539488315582, loss: 52.67547929286957 
Train [4/11] | Epoch [74/160] |	nca: 4.906390331685543, flat: 4.523842126131058, pod: 44.699381589889526, loss: 54.12961459159851 
Train [4/11] | Epoch [75/160] |	nca: 4.753114394843578, flat: 4.3035973608493805, pod: 44.13932287693024, loss: 53.1960346698761 
Train [4/11] | Epoch [76/160] |	nca: 4.476614110171795, flat: 4.412464916706085, pod: 44.6158607006073, loss: 53.504940032958984 
Train [4/11] | Epoch [77/160] |	nca: 5.005962178111076, flat: 4.248613461852074, pod: 43.993528604507446, loss: 53.24810469150543 
Train [4/11] | Epoch [78/160] |	nca: 4.624758496880531, flat: 4.454950615763664, pod: 47.37924337387085, loss: 56.45895254611969 
Train [4/11] | Epoch [79/160] |	nca: 4.339820742607117, flat: 4.290019288659096, pod: 44.80347657203674, loss: 53.43331682682037 
Train [4/11] | Epoch [80/160] |	nca: 4.7551239579916, flat: 4.380079299211502, pod: 44.63730871677399, loss: 53.77251195907593 
Train [4/11] | Epoch [81/160] |	nca: 4.226253256201744, flat: 4.15085781365633, pod: 42.835604667663574, loss: 51.21271586418152 
Train [4/11] | Epoch [82/160] |	nca: 4.603936217725277, flat: 4.070543073117733, pod: 42.536113262176514, loss: 51.21059215068817 
Train [4/11] | Epoch [83/160] |	nca: 4.583507753908634, flat: 4.245473027229309, pod: 43.60745429992676, loss: 52.43643522262573 
Train [4/11] | Epoch [84/160] |	nca: 4.532689854502678, flat: 4.116531327366829, pod: 42.96331512928009, loss: 51.61253595352173 
Train [4/11] | Epoch [85/160] |	nca: 4.773570492863655, flat: 4.1606636345386505, pod: 42.94998049736023, loss: 51.884214639663696 
Train [4/11] | Epoch [86/160] |	nca: 4.327261656522751, flat: 4.191383890807629, pod: 43.9942901134491, loss: 52.512935519218445 
Train [4/11] | Epoch [87/160] |	nca: 4.502132445573807, flat: 4.089091740548611, pod: 43.22131609916687, loss: 51.81254017353058 
Train [4/11] | Epoch [88/160] |	nca: 4.524919390678406, flat: 4.0118237137794495, pod: 42.486612200737, loss: 51.0233553647995 
Train [4/11] | Epoch [89/160] |	nca: 4.219051517546177, flat: 3.938529498875141, pod: 41.43827664852142, loss: 49.59585726261139 
Train [4/11] | Epoch [90/160] |	nca: 4.266416937112808, flat: 3.9853605926036835, pod: 43.306676030159, loss: 51.5584534406662 
Train [4/11] | Epoch [91/160] |	nca: 4.074144847691059, flat: 3.7229661867022514, pod: 40.23847734928131, loss: 48.03558874130249 
Train [4/11] | Epoch [92/160] |	nca: 4.007794968783855, flat: 3.608576774597168, pod: 39.92483878135681, loss: 47.541210651397705 
Train [4/11] | Epoch [93/160] |	nca: 4.801450110971928, flat: 3.6179989352822304, pod: 38.99006140232086, loss: 47.40951085090637 
Train [4/11] | Epoch [94/160] |	nca: 4.002478800714016, flat: 3.7269149124622345, pod: 39.78652906417847, loss: 47.51592254638672 
Train [4/11] | Epoch [95/160] |	nca: 4.110997684299946, flat: 3.5791658982634544, pod: 39.42504668235779, loss: 47.1152104139328 
Train [4/11] | Epoch [96/160] |	nca: 4.392724692821503, flat: 3.628563202917576, pod: 40.909762501716614, loss: 48.931050300598145 
Train [4/11] | Epoch [97/160] |	nca: 3.7381044179201126, flat: 3.5514889508485794, pod: 39.815486907958984, loss: 47.10508060455322 
Train [4/11] | Epoch [98/160] |	nca: 4.12421377748251, flat: 3.397305764257908, pod: 37.64122676849365, loss: 45.16274619102478 
Train [4/11] | Epoch [99/160] |	nca: 4.053143605589867, flat: 3.3835785388946533, pod: 38.247636914253235, loss: 45.684359312057495 
Train [4/11] | Epoch [100/160] |	nca: 3.7845888808369637, flat: 3.288148358464241, pod: 36.83679819107056, loss: 43.90953540802002 
Train [4/11] | Epoch [101/160] |	nca: 4.0951124504208565, flat: 3.278552860021591, pod: 37.241446018218994, loss: 44.615110993385315 
Train [4/11] | Epoch [102/160] |	nca: 3.8063895404338837, flat: 3.1655223965644836, pod: 36.437654972076416, loss: 43.40956676006317 
Train [4/11] | Epoch [103/160] |	nca: 3.955752454698086, flat: 3.15607850253582, pod: 36.77014231681824, loss: 43.88197314739227 
Train [4/11] | Epoch [104/160] |	nca: 3.479465998709202, flat: 2.9583945646882057, pod: 35.24639093875885, loss: 41.68425154685974 
Train [4/11] | Epoch [105/160] |	nca: 3.8097441270947456, flat: 3.0510661378502846, pod: 35.349849224090576, loss: 42.21065974235535 
Train [4/11] | Epoch [106/160] |	nca: 4.008092433214188, flat: 3.075867086648941, pod: 35.90296816825867, loss: 42.98692786693573 
Train [4/11] | Epoch [107/160] |	nca: 3.8192159831523895, flat: 2.976685293018818, pod: 33.87998938560486, loss: 40.6758908033371 
Train [4/11] | Epoch [108/160] |	nca: 3.658391162753105, flat: 2.9821383878588676, pod: 34.638774037361145, loss: 41.279303789138794 
Train [4/11] | Epoch [109/160] |	nca: 4.015148803591728, flat: 3.0362982600927353, pod: 36.62225008010864, loss: 43.67369723320007 
Train [4/11] | Epoch [110/160] |	nca: 3.7610582038760185, flat: 2.938667193055153, pod: 34.58252549171448, loss: 41.28225100040436 
Train [4/11] | Epoch [111/160] |	nca: 3.8860673531889915, flat: 2.9265840873122215, pod: 34.95964342355728, loss: 41.772294878959656 
Train [4/11] | Epoch [112/160] |	nca: 3.9431470036506653, flat: 2.8443607687950134, pod: 33.61650311946869, loss: 40.4040105342865 
Train [4/11] | Epoch [113/160] |	nca: 4.053560957312584, flat: 2.8352871239185333, pod: 33.44258600473404, loss: 40.33143401145935 
Train [4/11] | Epoch [114/160] |	nca: 3.6834609881043434, flat: 2.893707014620304, pod: 35.33637261390686, loss: 41.91354060173035 
Train [4/11] | Epoch [115/160] |	nca: 3.596018336713314, flat: 2.7327373921871185, pod: 33.229777216911316, loss: 39.55853295326233 
Train [4/11] | Epoch [116/160] |	nca: 3.654091514647007, flat: 2.6350409761071205, pod: 32.21295517683029, loss: 38.5020877122879 
Train [4/11] | Epoch [117/160] |	nca: 3.543381482362747, flat: 2.637812040746212, pod: 32.12985610961914, loss: 38.31104934215546 
Train [4/11] | Epoch [118/160] |	nca: 4.028231114149094, flat: 2.5542204454541206, pod: 30.865727603435516, loss: 37.44817924499512 
Train [4/11] | Epoch [119/160] |	nca: 3.8635101690888405, flat: 2.652270019054413, pod: 32.71923440694809, loss: 39.23501479625702 
Train [4/11] | Epoch [120/160] |	nca: 3.607439875602722, flat: 2.5223198011517525, pod: 31.324148416519165, loss: 37.45390820503235 
Train [4/11] | Epoch [121/160] |	nca: 3.4467599913477898, flat: 2.507501184940338, pod: 30.49067986011505, loss: 36.44494104385376 
Train [4/11] | Epoch [122/160] |	nca: 3.9085969254374504, flat: 2.5238904505968094, pod: 30.902508556842804, loss: 37.33499610424042 
Train [4/11] | Epoch [123/160] |	nca: 3.7444368600845337, flat: 2.495755225419998, pod: 31.13895970582962, loss: 37.379151821136475 
Train [4/11] | Epoch [124/160] |	nca: 3.41642764210701, flat: 2.418661244213581, pod: 29.914472341537476, loss: 35.749561190605164 
Train [4/11] | Epoch [125/160] |	nca: 3.4744462445378304, flat: 2.407910443842411, pod: 30.11156791448593, loss: 35.993924617767334 
Train [4/11] | Epoch [126/160] |	nca: 3.5427634716033936, flat: 2.358585588634014, pod: 30.06093806028366, loss: 35.962287068367004 
Train [4/11] | Epoch [127/160] |	nca: 3.644257739186287, flat: 2.326409563422203, pod: 30.04053086042404, loss: 36.01119804382324 
Train [4/11] | Epoch [128/160] |	nca: 3.801149144768715, flat: 2.2857722342014313, pod: 29.03194636106491, loss: 35.1188679933548 
Train [4/11] | Epoch [129/160] |	nca: 3.74652798473835, flat: 2.3580150604248047, pod: 29.398909151554108, loss: 35.50345194339752 
Train [4/11] | Epoch [130/160] |	nca: 3.643572472035885, flat: 2.3133116215467453, pod: 28.825332462787628, loss: 34.78221642971039 
Train [4/11] | Epoch [131/160] |	nca: 3.511355347931385, flat: 2.2677041739225388, pod: 29.855433702468872, loss: 35.63449323177338 
Train [4/11] | Epoch [132/160] |	nca: 3.6213580891489983, flat: 2.1942522153258324, pod: 28.56782031059265, loss: 34.38343095779419 
Train [4/11] | Epoch [133/160] |	nca: 3.4531250335276127, flat: 2.1962816789746284, pod: 28.177012741565704, loss: 33.82641959190369 
Train [4/11] | Epoch [134/160] |	nca: 3.5886287912726402, flat: 2.215894803404808, pod: 28.762045919895172, loss: 34.566569209098816 
Train [4/11] | Epoch [135/160] |	nca: 3.3249159082770348, flat: 2.134848177433014, pod: 28.1870579123497, loss: 33.64682185649872 
Train [4/11] | Epoch [136/160] |	nca: 3.701490968465805, flat: 2.1892150975763798, pod: 29.354650795459747, loss: 35.24535667896271 
Train [4/11] | Epoch [137/160] |	nca: 3.5893509164452553, flat: 2.098363045603037, pod: 27.56844264268875, loss: 33.25615656375885 
Train [4/11] | Epoch [138/160] |	nca: 3.2741494178771973, flat: 2.120953168720007, pod: 27.365898728370667, loss: 32.76100146770477 
Train [4/11] | Epoch [139/160] |	nca: 3.4736994057893753, flat: 2.1064500845968723, pod: 27.18106245994568, loss: 32.76121175289154 
Train [4/11] | Epoch [140/160] |	nca: 3.1754760816693306, flat: 2.0688536539673805, pod: 26.70612633228302, loss: 31.950456380844116 
Train [4/11] | Epoch [141/160] |	nca: 3.3425971046090126, flat: 2.0297795459628105, pod: 26.803882122039795, loss: 32.17625904083252 
Train [4/11] | Epoch [142/160] |	nca: 3.572619281709194, flat: 2.0743769891560078, pod: 26.917542457580566, loss: 32.5645387172699 
Train [4/11] | Epoch [143/160] |	nca: 3.285345457494259, flat: 1.9600906297564507, pod: 25.18220680952072, loss: 30.42764300107956 
Train [4/11] | Epoch [144/160] |	nca: 3.430015817284584, flat: 1.959442414343357, pod: 26.00828456878662, loss: 31.397742867469788 
Train [4/11] | Epoch [145/160] |	nca: 3.4526810944080353, flat: 2.021170776337385, pod: 26.918318450450897, loss: 32.3921702504158 
Train [4/11] | Epoch [146/160] |	nca: 3.414088398218155, flat: 2.0242714919149876, pod: 26.517607808113098, loss: 31.955967783927917 
Train [4/11] | Epoch [147/160] |	nca: 3.3396994546055794, flat: 1.9870718158781528, pod: 26.151261746883392, loss: 31.478032886981964 
Train [4/11] | Epoch [148/160] |	nca: 3.3492767587304115, flat: 1.9316405840218067, pod: 25.45889949798584, loss: 30.739817082881927 
Train [4/11] | Epoch [149/160] |	nca: 3.1524505391716957, flat: 1.9550475738942623, pod: 25.685879707336426, loss: 30.793378174304962 
Train [4/11] | Epoch [150/160] |	nca: 3.2393051832914352, flat: 1.918826624751091, pod: 25.105363368988037, loss: 30.26349502801895 
Train [4/11] | Epoch [151/160] |	nca: 3.349686525762081, flat: 1.9109635576605797, pod: 24.698293924331665, loss: 29.958944141864777 
Train [4/11] | Epoch [152/160] |	nca: 3.505914717912674, flat: 1.884102500975132, pod: 24.18027377128601, loss: 29.5702908039093 
Train [4/11] | Epoch [153/160] |	nca: 3.3658937215805054, flat: 1.911628395318985, pod: 24.684589326381683, loss: 29.962111473083496 
Train [4/11] | Epoch [154/160] |	nca: 3.383100040256977, flat: 1.9347453191876411, pod: 25.36551344394684, loss: 30.683359026908875 
Train [4/11] | Epoch [155/160] |	nca: 3.32868292927742, flat: 1.8790115527808666, pod: 24.344641745090485, loss: 29.552336156368256 
Train [4/11] | Epoch [156/160] |	nca: 3.3030623868107796, flat: 1.8818759098649025, pod: 24.645384192466736, loss: 29.830322265625 
Train [4/11] | Epoch [157/160] |	nca: 3.3449145182967186, flat: 1.8353583924472332, pod: 23.849294364452362, loss: 29.02956712245941 
Train [4/11] | Epoch [158/160] |	nca: 3.2439450472593307, flat: 1.917100440710783, pod: 24.800243616104126, loss: 29.96128898859024 
Train [4/11] | Epoch [159/160] |	nca: 3.5839347168803215, flat: 1.9010516926646233, pod: 25.016113698482513, loss: 30.501100063323975 
Train [4/11] | Epoch [160/160] |	nca: 3.1992760598659515, flat: 1.8788017481565475, pod: 24.355482161045074, loss: 29.43356019258499 
Fine-tuning
Building & updating memory.
Train [4/11] | Epoch [161/180] |	nca: 3.4331329837441444, flat: 2.0057380348443985, pod: 17.99679410457611, loss: 23.435664892196655 
Train [4/11] | Epoch [162/180] |	nca: 1.3584345132112503, flat: 2.0053648352622986, pod: 17.7716943025589, loss: 21.135493397712708 
Train [4/11] | Epoch [163/180] |	nca: 1.0947414301335812, flat: 2.119962513446808, pod: 18.181254744529724, loss: 21.39595890045166 
Train [4/11] | Epoch [164/180] |	nca: 0.8217775225639343, flat: 2.0107908099889755, pod: 17.93357539176941, loss: 20.766143679618835 
Train [4/11] | Epoch [165/180] |	nca: 0.8218275904655457, flat: 2.166987434029579, pod: 18.615534901618958, loss: 21.604349851608276 
Train [4/11] | Epoch [166/180] |	nca: 0.5971102491021156, flat: 2.0090038776397705, pod: 17.88722813129425, loss: 20.4933420419693 
Train [4/11] | Epoch [167/180] |	nca: 0.5722090564668179, flat: 2.0123488903045654, pod: 18.27158522605896, loss: 20.85614323616028 
Train [4/11] | Epoch [168/180] |	nca: 0.587270762771368, flat: 1.977982997894287, pod: 17.846543073654175, loss: 20.411796808242798 
Train [4/11] | Epoch [169/180] |	nca: 0.6019937433302402, flat: 1.9707174003124237, pod: 17.762224435806274, loss: 20.334935545921326 
Train [4/11] | Epoch [170/180] |	nca: 0.5139854811131954, flat: 2.1100010573863983, pod: 18.266246914863586, loss: 20.890233516693115 
Train [4/11] | Epoch [171/180] |	nca: 0.5097386203706264, flat: 2.127421885728836, pod: 18.76245617866516, loss: 21.399616718292236 
Train [4/11] | Epoch [172/180] |	nca: 0.4343970809131861, flat: 2.0833533108234406, pod: 18.23230504989624, loss: 20.75005543231964 
Train [4/11] | Epoch [173/180] |	nca: 0.6805828474462032, flat: 2.155309818685055, pod: 18.700453400611877, loss: 21.536346197128296 
Train [4/11] | Epoch [174/180] |	nca: 0.49268820136785507, flat: 2.1197384744882584, pod: 18.286261916160583, loss: 20.898688673973083 
Train [4/11] | Epoch [175/180] |	nca: 0.5495528131723404, flat: 2.13569113612175, pod: 18.417696356773376, loss: 21.10294020175934 
Train [4/11] | Epoch [176/180] |	nca: 0.521105820313096, flat: 1.9754358977079391, pod: 17.77387285232544, loss: 20.27041459083557 
Train [4/11] | Epoch [177/180] |	nca: 0.5401786155998707, flat: 2.0595687925815582, pod: 18.175942301750183, loss: 20.775689482688904 
Train [4/11] | Epoch [178/180] |	nca: 0.4535826053470373, flat: 1.9770506769418716, pod: 17.905177235603333, loss: 20.335810661315918 
Train [4/11] | Epoch [179/180] |	nca: 0.43138546869158745, flat: 2.1635417342185974, pod: 18.644808888435364, loss: 21.239736199378967 
Train [4/11] | Epoch [180/180] |	nca: 0.49962788075208664, flat: 2.0121296644210815, pod: 17.933483481407166, loss: 20.44524097442627 
after task
Building & updating memory.
after task
Eval on 0->65.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.71675.
Current acc: {'total': 0.662, '00-09': 0.682, '10-19': 0.659, '20-29': 0.544, '30-39': 0.63, '40-49': 0.715, '50-59': 0.74, '60-69': 0.662}.
Avg inc acc top5: 0.9219999999999999.
Current acc top5: {'total': 0.899}.
Forgetting: 0.007875000000000007.
Cord metric: 0.71.
Old accuracy: 0.66, mean: 0.69.
New accuracy: 0.66, mean: 0.77.
================Task 4 Start!================
Testing on False unseen tasks (max class = 70).
Set memory of size: 1300.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 4 Training!================
The training samples number: 3800
Train on 65->70.
train task
nb 3800.
Train [5/11] | Epoch [1/160] |	nca: 29.68228429555893, flat: 9.620539411902428, pod: 71.70172214508057, loss: 111.00454497337341 
Train [5/11] | Epoch [2/160] |	nca: 21.816221177577972, flat: 12.920091897249222, pod: 86.9053750038147, loss: 121.64168787002563 
Train [5/11] | Epoch [3/160] |	nca: 12.501707136631012, flat: 9.286583185195923, pod: 74.62652730941772, loss: 96.41481852531433 
Train [5/11] | Epoch [4/160] |	nca: 11.259243667125702, flat: 7.38045671582222, pod: 66.35803484916687, loss: 84.99773597717285 
Train [5/11] | Epoch [5/160] |	nca: 9.418809175491333, flat: 6.575766459107399, pod: 62.15351092815399, loss: 78.14808702468872 
Train [5/11] | Epoch [6/160] |	nca: 8.942546382546425, flat: 5.950886383652687, pod: 57.99535655975342, loss: 72.88878893852234 
Train [5/11] | Epoch [7/160] |	nca: 7.9144304394721985, flat: 5.835079178214073, pod: 58.577566504478455, loss: 72.32707643508911 
Train [5/11] | Epoch [8/160] |	nca: 7.984616160392761, flat: 5.739866703748703, pod: 57.50480020046234, loss: 71.22928261756897 
Train [5/11] | Epoch [9/160] |	nca: 7.534904107451439, flat: 5.825839266180992, pod: 58.737101316452026, loss: 72.09784412384033 
Train [5/11] | Epoch [10/160] |	nca: 7.9674553126096725, flat: 5.938382774591446, pod: 59.56081664562225, loss: 73.46665477752686 
Train [5/11] | Epoch [11/160] |	nca: 6.9868272095918655, flat: 5.760575607419014, pod: 57.5417343378067, loss: 70.28913712501526 
Train [5/11] | Epoch [12/160] |	nca: 7.499248385429382, flat: 5.620235860347748, pod: 56.95210790634155, loss: 70.07159185409546 
Train [5/11] | Epoch [13/160] |	nca: 7.034988850355148, flat: 5.5388429164886475, pod: 56.57168424129486, loss: 69.14551591873169 
Train [5/11] | Epoch [14/160] |	nca: 6.86929814517498, flat: 5.347334712743759, pod: 55.12529814243317, loss: 67.34193110466003 
Train [5/11] | Epoch [15/160] |	nca: 6.979770943522453, flat: 5.664287969470024, pod: 57.287275552749634, loss: 69.93133401870728 
Train [5/11] | Epoch [16/160] |	nca: 6.151452422142029, flat: 5.3278564512729645, pod: 55.5703307390213, loss: 67.04964017868042 
Train [5/11] | Epoch [17/160] |	nca: 6.1630939692258835, flat: 5.282583594322205, pod: 54.371029019355774, loss: 65.81670641899109 
Train [5/11] | Epoch [18/160] |	nca: 6.0098604410886765, flat: 5.135286405682564, pod: 54.22385287284851, loss: 65.36899995803833 
Train [5/11] | Epoch [19/160] |	nca: 5.887047208845615, flat: 5.22930046916008, pod: 54.477561235427856, loss: 65.59390878677368 
Train [5/11] | Epoch [20/160] |	nca: 6.236405313014984, flat: 5.44284762442112, pod: 55.287386536598206, loss: 66.96663904190063 
Train [5/11] | Epoch [21/160] |	nca: 6.330727353692055, flat: 5.373235762119293, pod: 54.785969734191895, loss: 66.48993253707886 
Train [5/11] | Epoch [22/160] |	nca: 6.335996247828007, flat: 5.24556203186512, pod: 53.332019448280334, loss: 64.91357755661011 
Train [5/11] | Epoch [23/160] |	nca: 5.312702909111977, flat: 5.017891123890877, pod: 53.44043016433716, loss: 63.771023750305176 
Train [5/11] | Epoch [24/160] |	nca: 5.879070550203323, flat: 5.035370886325836, pod: 54.406577944755554, loss: 65.32101905345917 
Train [5/11] | Epoch [25/160] |	nca: 5.496053658425808, flat: 5.116748884320259, pod: 53.78859806060791, loss: 64.4014003276825 
Train [5/11] | Epoch [26/160] |	nca: 5.506954774260521, flat: 5.140078499913216, pod: 54.03295588493347, loss: 64.6799898147583 
Train [5/11] | Epoch [27/160] |	nca: 5.769048631191254, flat: 5.032249718904495, pod: 53.56140160560608, loss: 64.36269998550415 
Train [5/11] | Epoch [28/160] |	nca: 5.669879168272018, flat: 5.289193943142891, pod: 54.56365931034088, loss: 65.52273154258728 
Train [5/11] | Epoch [29/160] |	nca: 5.64089360833168, flat: 5.121966570615768, pod: 54.17751133441925, loss: 64.9403715133667 
Train [5/11] | Epoch [30/160] |	nca: 5.481627203524113, flat: 5.163002476096153, pod: 53.53360211849213, loss: 64.178231716156 
Train [5/11] | Epoch [31/160] |	nca: 5.088678114116192, flat: 5.052735969424248, pod: 53.104485630989075, loss: 63.24589991569519 
Train [5/11] | Epoch [32/160] |	nca: 5.502931572496891, flat: 4.785174548625946, pod: 52.385257720947266, loss: 62.67336404323578 
Train [5/11] | Epoch [33/160] |	nca: 5.7239629328250885, flat: 5.078530251979828, pod: 53.04372048377991, loss: 63.84621345996857 
Train [5/11] | Epoch [34/160] |	nca: 5.659060701727867, flat: 5.243486121296883, pod: 53.36874079704285, loss: 64.27128791809082 
Train [5/11] | Epoch [35/160] |	nca: 5.266379363834858, flat: 4.9069676995277405, pod: 52.43554365634918, loss: 62.608890533447266 
Train [5/11] | Epoch [36/160] |	nca: 5.114561885595322, flat: 4.902051642537117, pod: 51.968852043151855, loss: 61.98546600341797 
Train [5/11] | Epoch [37/160] |	nca: 5.424969561398029, flat: 5.025054946541786, pod: 52.19389998912811, loss: 62.643924713134766 
Train [5/11] | Epoch [38/160] |	nca: 5.149044387042522, flat: 4.8498939126729965, pod: 52.72573220729828, loss: 62.72467052936554 
Train [5/11] | Epoch [39/160] |	nca: 4.9409904554486275, flat: 4.525764614343643, pod: 50.4479296207428, loss: 59.914684653282166 
Train [5/11] | Epoch [40/160] |	nca: 5.146809108555317, flat: 4.681045696139336, pod: 51.00903677940369, loss: 60.836891174316406 
Train [5/11] | Epoch [41/160] |	nca: 4.649204157292843, flat: 4.484245732426643, pod: 48.78663969039917, loss: 57.9200896024704 
Train [5/11] | Epoch [42/160] |	nca: 5.258819013834, flat: 4.5759826600551605, pod: 51.0849152803421, loss: 60.91971743106842 
Train [5/11] | Epoch [43/160] |	nca: 5.806387707591057, flat: 4.800115391612053, pod: 52.480825662612915, loss: 63.08732879161835 
Train [5/11] | Epoch [44/160] |	nca: 5.858850225806236, flat: 5.071963295340538, pod: 52.93347203731537, loss: 63.864285469055176 
Train [5/11] | Epoch [45/160] |	nca: 5.0668812319636345, flat: 4.842068701982498, pod: 52.21196413040161, loss: 62.120914697647095 
Train [5/11] | Epoch [46/160] |	nca: 5.34460923820734, flat: 4.861601069569588, pod: 52.19247627258301, loss: 62.39868640899658 
Train [5/11] | Epoch [47/160] |	nca: 4.770488910377026, flat: 4.591358482837677, pod: 50.22514605522156, loss: 59.58699381351471 
Train [5/11] | Epoch [48/160] |	nca: 4.851849563419819, flat: 4.491882011294365, pod: 48.67802560329437, loss: 58.0217570066452 
Train [5/11] | Epoch [49/160] |	nca: 4.828690633177757, flat: 4.539779514074326, pod: 49.71058630943298, loss: 59.07905673980713 
Train [5/11] | Epoch [50/160] |	nca: 4.533968597650528, flat: 4.464216366410255, pod: 49.07089579105377, loss: 58.06908082962036 
Train [5/11] | Epoch [51/160] |	nca: 5.359381899237633, flat: 4.577804699540138, pod: 50.24609923362732, loss: 60.1832857131958 
Train [5/11] | Epoch [52/160] |	nca: 4.623831398785114, flat: 4.515448957681656, pod: 50.30854904651642, loss: 59.447829604148865 
Train [5/11] | Epoch [53/160] |	nca: 4.40559720993042, flat: 4.137782394886017, pod: 47.4096462726593, loss: 55.953025579452515 
Train [5/11] | Epoch [54/160] |	nca: 4.700515612959862, flat: 4.1787460297346115, pod: 47.88121819496155, loss: 56.7604798078537 
Train [5/11] | Epoch [55/160] |	nca: 4.743645682930946, flat: 4.148466944694519, pod: 46.45773541927338, loss: 55.34984838962555 
Train [5/11] | Epoch [56/160] |	nca: 4.16037031263113, flat: 3.9401133954524994, pod: 45.95660734176636, loss: 54.05709111690521 
Train [5/11] | Epoch [57/160] |	nca: 4.319486364722252, flat: 3.9810153916478157, pod: 46.29522895812988, loss: 54.595730662345886 
Train [5/11] | Epoch [58/160] |	nca: 4.602867014706135, flat: 3.9272647351026535, pod: 45.54872488975525, loss: 54.078856348991394 
Train [5/11] | Epoch [59/160] |	nca: 4.569712094962597, flat: 4.099207065999508, pod: 47.2446174621582, loss: 55.91353678703308 
Train [5/11] | Epoch [60/160] |	nca: 4.925317659974098, flat: 4.037434980273247, pod: 48.21427941322327, loss: 57.17703199386597 
Train [5/11] | Epoch [61/160] |	nca: 5.307962592691183, flat: 4.322221130132675, pod: 48.2664076089859, loss: 57.89659106731415 
Train [5/11] | Epoch [62/160] |	nca: 4.3837780728936195, flat: 4.279460325837135, pod: 48.53531539440155, loss: 57.198554158210754 
Train [5/11] | Epoch [63/160] |	nca: 4.473022736608982, flat: 4.010195627808571, pod: 45.99944019317627, loss: 54.48265874385834 
Train [5/11] | Epoch [64/160] |	nca: 4.00412055850029, flat: 3.910715289413929, pod: 45.17344892024994, loss: 53.088284969329834 
Train [5/11] | Epoch [65/160] |	nca: 4.349334821105003, flat: 3.7137585505843163, pod: 44.84064292907715, loss: 52.90373611450195 
Train [5/11] | Epoch [66/160] |	nca: 4.289283819496632, flat: 3.8862270936369896, pod: 45.126691818237305, loss: 53.3022027015686 
Train [5/11] | Epoch [67/160] |	nca: 3.9364341124892235, flat: 3.6238668635487556, pod: 44.184202551841736, loss: 51.7445033788681 
Train [5/11] | Epoch [68/160] |	nca: 4.202358990907669, flat: 3.747080370783806, pod: 44.62253153324127, loss: 52.57197093963623 
Train [5/11] | Epoch [69/160] |	nca: 4.043364584445953, flat: 3.638340510427952, pod: 43.91251289844513, loss: 51.594218015670776 
Train [5/11] | Epoch [70/160] |	nca: 4.389124542474747, flat: 3.5778709426522255, pod: 43.95762073993683, loss: 51.92461609840393 
Train [5/11] | Epoch [71/160] |	nca: 4.19273067265749, flat: 3.7816483825445175, pod: 45.87310075759888, loss: 53.847479581832886 
Train [5/11] | Epoch [72/160] |	nca: 4.170710012316704, flat: 3.834523618221283, pod: 45.875492215156555, loss: 53.880725741386414 
Train [5/11] | Epoch [73/160] |	nca: 4.282327137887478, flat: 3.5338964015245438, pod: 42.76328229904175, loss: 50.57950556278229 
Train [5/11] | Epoch [74/160] |	nca: 3.644262306392193, flat: 3.400286413729191, pod: 42.070974707603455, loss: 49.11552321910858 
Train [5/11] | Epoch [75/160] |	nca: 4.207583159208298, flat: 3.4600195810198784, pod: 43.417652010917664, loss: 51.08525490760803 
Train [5/11] | Epoch [76/160] |	nca: 3.851755328476429, flat: 3.295470952987671, pod: 40.802509903907776, loss: 47.94973599910736 
Train [5/11] | Epoch [77/160] |	nca: 4.4086213782429695, flat: 3.442363239824772, pod: 42.4647753238678, loss: 50.315760016441345 
Train [5/11] | Epoch [78/160] |	nca: 3.8987283557653427, flat: 3.5649532973766327, pod: 43.16562759876251, loss: 50.62930905818939 
Train [5/11] | Epoch [79/160] |	nca: 4.03847648948431, flat: 3.47848741710186, pod: 43.968148589134216, loss: 51.48511242866516 
Train [5/11] | Epoch [80/160] |	nca: 4.499056279659271, flat: 3.4626876562833786, pod: 42.71131432056427, loss: 50.6730580329895 
Train [5/11] | Epoch [81/160] |	nca: 3.7636034041643143, flat: 3.4050821661949158, pod: 41.55931031703949, loss: 48.72799575328827 
Train [5/11] | Epoch [82/160] |	nca: 3.895298518240452, flat: 3.3376822993159294, pod: 42.131874442100525, loss: 49.36485540866852 
Train [5/11] | Epoch [83/160] |	nca: 3.559211954474449, flat: 3.094145804643631, pod: 40.11471474170685, loss: 46.768072843551636 
Train [5/11] | Epoch [84/160] |	nca: 3.6764342710375786, flat: 3.051844708621502, pod: 39.31892967224121, loss: 46.04720878601074 
Train [5/11] | Epoch [85/160] |	nca: 3.8949104845523834, flat: 3.0928096249699593, pod: 39.5942188501358, loss: 46.58193910121918 
Train [5/11] | Epoch [86/160] |	nca: 3.96540567278862, flat: 3.115281790494919, pod: 40.42403435707092, loss: 47.504721879959106 
Train [5/11] | Epoch [87/160] |	nca: 3.617102764546871, flat: 3.10247839987278, pod: 39.66046392917633, loss: 46.38004541397095 
Train [5/11] | Epoch [88/160] |	nca: 3.7384889498353004, flat: 2.9932415559887886, pod: 38.79741406440735, loss: 45.529144287109375 
Train [5/11] | Epoch [89/160] |	nca: 4.039856314659119, flat: 3.020152159035206, pod: 39.41541540622711, loss: 46.4754239320755 
Train [5/11] | Epoch [90/160] |	nca: 3.8332975953817368, flat: 3.0194255337119102, pod: 39.93543231487274, loss: 46.78815567493439 
Train [5/11] | Epoch [91/160] |	nca: 4.0950000658631325, flat: 3.0871746465563774, pod: 40.139142632484436, loss: 47.321317195892334 
Train [5/11] | Epoch [92/160] |	nca: 3.7139302417635918, flat: 2.985492043197155, pod: 38.7366327047348, loss: 45.436054706573486 
Train [5/11] | Epoch [93/160] |	nca: 3.566771425306797, flat: 2.939242422580719, pod: 38.91356635093689, loss: 45.41958022117615 
Train [5/11] | Epoch [94/160] |	nca: 3.666016146540642, flat: 2.7605680003762245, pod: 36.84545397758484, loss: 43.27203810214996 
Train [5/11] | Epoch [95/160] |	nca: 3.4568973556160927, flat: 2.8510253354907036, pod: 38.248767495155334, loss: 44.55669045448303 
Train [5/11] | Epoch [96/160] |	nca: 3.4394108653068542, flat: 2.7553062960505486, pod: 37.64694607257843, loss: 43.8416633605957 
Train [5/11] | Epoch [97/160] |	nca: 3.662646472454071, flat: 2.7852707356214523, pod: 37.72307360172272, loss: 44.17099106311798 
Train [5/11] | Epoch [98/160] |	nca: 3.7198100462555885, flat: 2.872667469084263, pod: 36.86216187477112, loss: 43.454639315605164 
Train [5/11] | Epoch [99/160] |	nca: 3.594297055155039, flat: 2.613125130534172, pod: 35.30482292175293, loss: 41.512245416641235 
Train [5/11] | Epoch [100/160] |	nca: 3.547596260905266, flat: 2.6932013630867004, pod: 36.59953045845032, loss: 42.840328216552734 
Train [5/11] | Epoch [101/160] |	nca: 3.4950858652591705, flat: 2.5093184113502502, pod: 34.52382671833038, loss: 40.52823090553284 
Train [5/11] | Epoch [102/160] |	nca: 3.7062861770391464, flat: 2.517163924872875, pod: 35.40001845359802, loss: 41.62346816062927 
Train [5/11] | Epoch [103/160] |	nca: 3.3405792117118835, flat: 2.5357188060879707, pod: 34.80253982543945, loss: 40.67883789539337 
Train [5/11] | Epoch [104/160] |	nca: 3.3273222222924232, flat: 2.406092017889023, pod: 33.458408653736115, loss: 39.19182300567627 
Train [5/11] | Epoch [105/160] |	nca: 3.388971768319607, flat: 2.3782641142606735, pod: 33.36770403385162, loss: 39.134939670562744 
Train [5/11] | Epoch [106/160] |	nca: 3.8453244492411613, flat: 2.5222033485770226, pod: 34.53290772438049, loss: 40.90043568611145 
Train [5/11] | Epoch [107/160] |	nca: 3.387281831353903, flat: 2.425608679652214, pod: 33.29401957988739, loss: 39.10691010951996 
Train [5/11] | Epoch [108/160] |	nca: 3.541196372359991, flat: 2.3566122129559517, pod: 33.169375121593475, loss: 39.06718420982361 
Train [5/11] | Epoch [109/160] |	nca: 3.5420224741101265, flat: 2.4063438177108765, pod: 33.24625116586685, loss: 39.19461762905121 
Train [5/11] | Epoch [110/160] |	nca: 3.7648080810904503, flat: 2.468581274151802, pod: 33.886598348617554, loss: 40.11998760700226 
Train [5/11] | Epoch [111/160] |	nca: 3.357538763433695, flat: 2.3436518013477325, pod: 33.40461182594299, loss: 39.10580217838287 
Train [5/11] | Epoch [112/160] |	nca: 3.320150099694729, flat: 2.242123767733574, pod: 32.1718772649765, loss: 37.73415124416351 
Train [5/11] | Epoch [113/160] |	nca: 3.2826705425977707, flat: 2.1967578567564487, pod: 31.73771333694458, loss: 37.21714162826538 
Train [5/11] | Epoch [114/160] |	nca: 3.0942520201206207, flat: 2.082730323076248, pod: 30.393221616744995, loss: 35.57020401954651 
Train [5/11] | Epoch [115/160] |	nca: 3.2430394515395164, flat: 2.0547732040286064, pod: 30.167967975139618, loss: 35.46578097343445 
Train [5/11] | Epoch [116/160] |	nca: 3.1319739893078804, flat: 2.108517926186323, pod: 30.3251433968544, loss: 35.565635085105896 
Train [5/11] | Epoch [117/160] |	nca: 3.52898870408535, flat: 2.043045938014984, pod: 30.010555148124695, loss: 35.582589745521545 
Train [5/11] | Epoch [118/160] |	nca: 3.250169016420841, flat: 2.045703936368227, pod: 29.90135622024536, loss: 35.19722902774811 
Train [5/11] | Epoch [119/160] |	nca: 3.2742831110954285, flat: 1.9944944195449352, pod: 29.893754363059998, loss: 35.16253173351288 
Train [5/11] | Epoch [120/160] |	nca: 3.5149145536124706, flat: 2.1110723800957203, pod: 32.18553227186203, loss: 37.81151902675629 
Train [5/11] | Epoch [121/160] |	nca: 3.2064760625362396, flat: 2.0312043614685535, pod: 30.318159699440002, loss: 35.555840373039246 
Train [5/11] | Epoch [122/160] |	nca: 3.3016748428344727, flat: 2.0075340941548347, pod: 29.946893990039825, loss: 35.25610303878784 
Train [5/11] | Epoch [123/160] |	nca: 3.0254619121551514, flat: 2.0060199350118637, pod: 29.689954936504364, loss: 34.721436858177185 
Train [5/11] | Epoch [124/160] |	nca: 3.1745099797844887, flat: 1.9218805134296417, pod: 28.898372769355774, loss: 33.9947634935379 
Train [5/11] | Epoch [125/160] |	nca: 3.108994297683239, flat: 1.9057947881519794, pod: 27.975053429603577, loss: 32.98984229564667 
Train [5/11] | Epoch [126/160] |	nca: 3.3032391890883446, flat: 1.9676531478762627, pod: 29.960221111774445, loss: 35.23111319541931 
Train [5/11] | Epoch [127/160] |	nca: 3.1500613167881966, flat: 1.8786031864583492, pod: 28.050126671791077, loss: 33.07879155874252 
Train [5/11] | Epoch [128/160] |	nca: 3.234994128346443, flat: 1.821516077965498, pod: 28.279955863952637, loss: 33.33646595478058 
Train [5/11] | Epoch [129/160] |	nca: 3.3109936267137527, flat: 1.7965530008077621, pod: 27.585016131401062, loss: 32.69256269931793 
Train [5/11] | Epoch [130/160] |	nca: 2.953329160809517, flat: 1.793188039213419, pod: 26.90588492155075, loss: 31.6524019241333 
Train [5/11] | Epoch [131/160] |	nca: 3.063629914075136, flat: 1.750950951129198, pod: 26.985374629497528, loss: 31.799955368041992 
Train [5/11] | Epoch [132/160] |	nca: 3.1010022573173046, flat: 1.6904338747262955, pod: 26.330335915088654, loss: 31.1217719912529 
Train [5/11] | Epoch [133/160] |	nca: 3.161629743874073, flat: 1.6878592409193516, pod: 25.552550137043, loss: 30.402039110660553 
Train [5/11] | Epoch [134/160] |	nca: 3.1259139329195023, flat: 1.7179918475449085, pod: 26.586226105690002, loss: 31.43013161420822 
Train [5/11] | Epoch [135/160] |	nca: 3.0993558540940285, flat: 1.8088910393416882, pod: 27.43072909116745, loss: 32.338976204395294 
Train [5/11] | Epoch [136/160] |	nca: 3.1401172131299973, flat: 1.7255692556500435, pod: 26.13579660654068, loss: 31.0014830827713 
Train [5/11] | Epoch [137/160] |	nca: 3.089223250746727, flat: 1.7137799598276615, pod: 26.54065293073654, loss: 31.343656361103058 
Train [5/11] | Epoch [138/160] |	nca: 3.2597692161798477, flat: 1.6621851734817028, pod: 24.99588841199875, loss: 29.917842864990234 
Train [5/11] | Epoch [139/160] |	nca: 2.9390865191817284, flat: 1.6741107739508152, pod: 25.88317847251892, loss: 30.496375381946564 
Train [5/11] | Epoch [140/160] |	nca: 3.0289314091205597, flat: 1.6398376896977425, pod: 25.967227399349213, loss: 30.635996520519257 
Train [5/11] | Epoch [141/160] |	nca: 3.1863124668598175, flat: 1.6113028712570667, pod: 24.440882563591003, loss: 29.23849779367447 
Train [5/11] | Epoch [142/160] |	nca: 3.1987795159220695, flat: 1.5899978280067444, pod: 24.647278606891632, loss: 29.436055958271027 
Train [5/11] | Epoch [143/160] |	nca: 3.1873027086257935, flat: 1.623450431972742, pod: 24.88458001613617, loss: 29.695333063602448 
Train [5/11] | Epoch [144/160] |	nca: 3.127314403653145, flat: 1.5896175242960453, pod: 24.361112236976624, loss: 29.078044176101685 
Train [5/11] | Epoch [145/160] |	nca: 3.1762000992894173, flat: 1.5853106416761875, pod: 24.037041425704956, loss: 28.798551976680756 
Train [5/11] | Epoch [146/160] |	nca: 2.939581520855427, flat: 1.548268135637045, pod: 23.9630269408226, loss: 28.450876474380493 
Train [5/11] | Epoch [147/160] |	nca: 3.0545300506055355, flat: 1.5662322752177715, pod: 24.31913650035858, loss: 28.939898550510406 
Train [5/11] | Epoch [148/160] |	nca: 3.0058530420064926, flat: 1.5472486466169357, pod: 23.31122398376465, loss: 27.864325642585754 
Train [5/11] | Epoch [149/160] |	nca: 3.127744048833847, flat: 1.6028099320828915, pod: 24.095981538295746, loss: 28.82653570175171 
Train [5/11] | Epoch [150/160] |	nca: 2.8119258768856525, flat: 1.556206587702036, pod: 23.996401846408844, loss: 28.364534378051758 
Train [5/11] | Epoch [151/160] |	nca: 3.0207169875502586, flat: 1.541552308946848, pod: 23.65638154745102, loss: 28.21865063905716 
Train [5/11] | Epoch [152/160] |	nca: 2.874832734465599, flat: 1.5099221430718899, pod: 23.662393927574158, loss: 28.04714870452881 
Train [5/11] | Epoch [153/160] |	nca: 3.126227080821991, flat: 1.5256331749260426, pod: 23.360927283763885, loss: 28.012787580490112 
Train [5/11] | Epoch [154/160] |	nca: 3.0093174502253532, flat: 1.5323558412492275, pod: 23.231979727745056, loss: 27.773652970790863 
Train [5/11] | Epoch [155/160] |	nca: 2.8742302507162094, flat: 1.4848334714770317, pod: 22.449244022369385, loss: 26.808307588100433 
Train [5/11] | Epoch [156/160] |	nca: 3.025715619325638, flat: 1.5189500413835049, pod: 23.245010137557983, loss: 27.78967583179474 
Train [5/11] | Epoch [157/160] |	nca: 3.0150588005781174, flat: 1.5011464469134808, pod: 23.2244011759758, loss: 27.740606546401978 
Train [5/11] | Epoch [158/160] |	nca: 2.9710832461714745, flat: 1.5166738368570805, pod: 23.089829802513123, loss: 27.577586829662323 
Train [5/11] | Epoch [159/160] |	nca: 2.8643624633550644, flat: 1.4722683988511562, pod: 22.637636601924896, loss: 26.97426748275757 
Train [5/11] | Epoch [160/160] |	nca: 3.1490668579936028, flat: 1.5297738313674927, pod: 22.92909061908722, loss: 27.60793137550354 
Fine-tuning
Building & updating memory.
Train [5/11] | Epoch [161/180] |	nca: 2.1098890975117683, flat: 1.041512243449688, pod: 12.05730128288269, loss: 15.208702564239502 
Train [5/11] | Epoch [162/180] |	nca: 0.9093161374330521, flat: 1.104441836476326, pod: 12.647587716579437, loss: 14.661345839500427 
Train [5/11] | Epoch [163/180] |	nca: 0.872106559574604, flat: 1.083429180085659, pod: 12.538658499717712, loss: 14.494194149971008 
Train [5/11] | Epoch [164/180] |	nca: 0.7072629481554031, flat: 1.0538222789764404, pod: 12.095804333686829, loss: 13.856889486312866 
Train [5/11] | Epoch [165/180] |	nca: 0.5856078378856182, flat: 1.0836940705776215, pod: 12.41449785232544, loss: 14.083799958229065 
Train [5/11] | Epoch [166/180] |	nca: 0.5951705574989319, flat: 1.1046725064516068, pod: 12.716650128364563, loss: 14.41649329662323 
Train [5/11] | Epoch [167/180] |	nca: 0.5173483528196812, flat: 1.0901936665177345, pod: 12.36471712589264, loss: 13.972259044647217 
Train [5/11] | Epoch [168/180] |	nca: 0.5044368579983711, flat: 1.0976702570915222, pod: 12.567894220352173, loss: 14.17000138759613 
Train [5/11] | Epoch [169/180] |	nca: 0.5152245089411736, flat: 1.1007863581180573, pod: 12.75828242301941, loss: 14.374293446540833 
Train [5/11] | Epoch [170/180] |	nca: 0.4257766604423523, flat: 1.0555628389120102, pod: 12.311586618423462, loss: 13.79292619228363 
Train [5/11] | Epoch [171/180] |	nca: 0.488629337400198, flat: 1.0803363025188446, pod: 12.23062264919281, loss: 13.799588084220886 
Train [5/11] | Epoch [172/180] |	nca: 0.4815371334552765, flat: 1.0662447661161423, pod: 12.408712267875671, loss: 13.956494092941284 
Train [5/11] | Epoch [173/180] |	nca: 0.47127652913331985, flat: 1.1136597022414207, pod: 12.37705260515213, loss: 13.961988806724548 
Train [5/11] | Epoch [174/180] |	nca: 0.48245404846966267, flat: 1.1004113778471947, pod: 12.575584292411804, loss: 14.15844976902008 
Train [5/11] | Epoch [175/180] |	nca: 0.45845628529787064, flat: 1.0856615528464317, pod: 12.409558117389679, loss: 13.953675985336304 
Train [5/11] | Epoch [176/180] |	nca: 0.45036378502845764, flat: 1.0838456973433495, pod: 12.433529317378998, loss: 13.96773886680603 
Train [5/11] | Epoch [177/180] |	nca: 0.4149106293916702, flat: 1.067869022488594, pod: 12.392204105854034, loss: 13.87498390674591 
Train [5/11] | Epoch [178/180] |	nca: 0.42815189994871616, flat: 1.0545450747013092, pod: 12.395551681518555, loss: 13.878248691558838 
Train [5/11] | Epoch [179/180] |	nca: 0.4643012546002865, flat: 1.098692663013935, pod: 12.35026729106903, loss: 13.913261234760284 
Train [5/11] | Epoch [180/180] |	nca: 0.4348815530538559, flat: 1.091069445014, pod: 12.42037433385849, loss: 13.946325540542603 
after task
Building & updating memory.
after task
Eval on 0->70.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6990000000000001.
Current acc: {'total': 0.628, '00-09': 0.672, '10-19': 0.573, '20-29': 0.541, '30-39': 0.589, '40-49': 0.684, '50-59': 0.671, '60-69': 0.665}.
Avg inc acc top5: 0.9136.
Current acc top5: {'total': 0.88}.
Forgetting: 0.12025000000000001.
Cord metric: 0.70.
Old accuracy: 0.62, mean: 0.67.
New accuracy: 0.74, mean: 0.76.
================Task 5 Start!================
Testing on False unseen tasks (max class = 75).
Set memory of size: 1400.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 5 Training!================
The training samples number: 3900
Train on 70->75.
train task
nb 3900.
Train [6/11] | Epoch [1/160] |	nca: 23.681528687477112, flat: 10.071937792003155, pod: 75.374542593956, loss: 109.12800788879395 
Train [6/11] | Epoch [2/160] |	nca: 19.56497609615326, flat: 14.363902777433395, pod: 95.58428144454956, loss: 129.51315927505493 
Train [6/11] | Epoch [3/160] |	nca: 13.366203874349594, flat: 11.869375377893448, pod: 86.90782070159912, loss: 112.14340090751648 
Train [6/11] | Epoch [4/160] |	nca: 9.420989096164703, flat: 9.393285632133484, pod: 77.83399868011475, loss: 96.648273229599 
Train [6/11] | Epoch [5/160] |	nca: 7.136747851967812, flat: 7.1327440440654755, pod: 67.51980185508728, loss: 81.78929376602173 
Train [6/11] | Epoch [6/160] |	nca: 6.802320092916489, flat: 6.3227858543396, pod: 64.13602089881897, loss: 77.26112723350525 
Train [6/11] | Epoch [7/160] |	nca: 6.6713413298130035, flat: 6.221798673272133, pod: 62.48948001861572, loss: 75.3826196193695 
Train [6/11] | Epoch [8/160] |	nca: 6.254439607262611, flat: 5.560992076992989, pod: 59.64049434661865, loss: 71.45592665672302 
Train [6/11] | Epoch [9/160] |	nca: 5.816878579556942, flat: 5.559675395488739, pod: 59.00617229938507, loss: 70.38272666931152 
Train [6/11] | Epoch [10/160] |	nca: 6.723477140069008, flat: 5.844604328274727, pod: 60.74056363105774, loss: 73.3086450099945 
Train [6/11] | Epoch [11/160] |	nca: 5.982351124286652, flat: 5.88164047896862, pod: 60.9731730222702, loss: 72.83716416358948 
Train [6/11] | Epoch [12/160] |	nca: 5.3254284262657166, flat: 5.596026584506035, pod: 59.02859950065613, loss: 69.95005536079407 
Train [6/11] | Epoch [13/160] |	nca: 5.781592532992363, flat: 5.520708128809929, pod: 58.44928956031799, loss: 69.75159025192261 
Train [6/11] | Epoch [14/160] |	nca: 5.400414787232876, flat: 5.257579147815704, pod: 56.66658055782318, loss: 67.32457447052002 
Train [6/11] | Epoch [15/160] |	nca: 5.989924505352974, flat: 5.663702890276909, pod: 59.1652934551239, loss: 70.81892108917236 
Train [6/11] | Epoch [16/160] |	nca: 5.5074875727295876, flat: 5.749137908220291, pod: 60.41642606258392, loss: 71.67305159568787 
Train [6/11] | Epoch [17/160] |	nca: 5.2345606461167336, flat: 5.5870460122823715, pod: 59.00043213367462, loss: 69.8220386505127 
Train [6/11] | Epoch [18/160] |	nca: 4.8303543627262115, flat: 5.14187154173851, pod: 57.47350025177002, loss: 67.44572615623474 
Train [6/11] | Epoch [19/160] |	nca: 4.909554660320282, flat: 4.933992385864258, pod: 55.38116204738617, loss: 65.2247086763382 
Train [6/11] | Epoch [20/160] |	nca: 5.261751987040043, flat: 5.095806255936623, pod: 55.69292116165161, loss: 66.05047905445099 
Train [6/11] | Epoch [21/160] |	nca: 5.511532440781593, flat: 5.187847688794136, pod: 56.213866233825684, loss: 66.91324591636658 
Train [6/11] | Epoch [22/160] |	nca: 5.431008115410805, flat: 5.4813732504844666, pod: 57.933621883392334, loss: 68.84600377082825 
Train [6/11] | Epoch [23/160] |	nca: 5.223872400820255, flat: 5.327025875449181, pod: 58.60339605808258, loss: 69.15429449081421 
Train [6/11] | Epoch [24/160] |	nca: 4.49055003374815, flat: 4.841619789600372, pod: 54.58631134033203, loss: 63.91848087310791 
Train [6/11] | Epoch [25/160] |	nca: 5.369769997894764, flat: 5.079384043812752, pod: 56.049673438072205, loss: 66.49882698059082 
Train [6/11] | Epoch [26/160] |	nca: 4.702037215232849, flat: 5.081665620207787, pod: 56.68271803855896, loss: 66.46642136573792 
Train [6/11] | Epoch [27/160] |	nca: 4.805420383810997, flat: 4.6928113996982574, pod: 54.41959762573242, loss: 63.917829751968384 
Train [6/11] | Epoch [28/160] |	nca: 5.318398661911488, flat: 5.21926474571228, pod: 57.71145701408386, loss: 68.24911999702454 
Train [6/11] | Epoch [29/160] |	nca: 4.9540465995669365, flat: 5.034309357404709, pod: 54.88032126426697, loss: 64.8686773777008 
Train [6/11] | Epoch [30/160] |	nca: 4.917924225330353, flat: 4.973561525344849, pod: 55.44256556034088, loss: 65.33405125141144 
Train [6/11] | Epoch [31/160] |	nca: 4.119032718241215, flat: 4.6586587354540825, pod: 53.451916337013245, loss: 62.229607820510864 
Train [6/11] | Epoch [32/160] |	nca: 4.117198638617992, flat: 4.164495825767517, pod: 50.37316417694092, loss: 58.654857993125916 
Train [6/11] | Epoch [33/160] |	nca: 4.83206133544445, flat: 4.802733480930328, pod: 54.46964609622955, loss: 64.10444045066833 
Train [6/11] | Epoch [34/160] |	nca: 4.556207671761513, flat: 4.721110492944717, pod: 52.61097586154938, loss: 61.888293385505676 
Train [6/11] | Epoch [35/160] |	nca: 4.6972275376319885, flat: 4.82317815721035, pod: 54.255197405815125, loss: 63.77560269832611 
Train [6/11] | Epoch [36/160] |	nca: 4.739402741193771, flat: 4.802192077040672, pod: 54.06911277770996, loss: 63.61070799827576 
Train [6/11] | Epoch [37/160] |	nca: 4.678711913526058, flat: 4.68266299366951, pod: 53.08267962932587, loss: 62.44405436515808 
Train [6/11] | Epoch [38/160] |	nca: 4.493817299604416, flat: 4.603528276085854, pod: 53.923808097839355, loss: 63.02115440368652 
Train [6/11] | Epoch [39/160] |	nca: 4.794329017400742, flat: 4.573070138692856, pod: 52.75582194328308, loss: 62.123220920562744 
Train [6/11] | Epoch [40/160] |	nca: 4.3542632311582565, flat: 4.828108906745911, pod: 57.20919954776764, loss: 66.39157199859619 
Train [6/11] | Epoch [41/160] |	nca: 4.571872003376484, flat: 4.794068522751331, pod: 54.281113624572754, loss: 63.64705455303192 
Train [6/11] | Epoch [42/160] |	nca: 4.579306669533253, flat: 4.490743473172188, pod: 51.87620282173157, loss: 60.946253299713135 
Train [6/11] | Epoch [43/160] |	nca: 4.3232110142707825, flat: 4.642459750175476, pod: 52.51295530796051, loss: 61.47862648963928 
Train [6/11] | Epoch [44/160] |	nca: 4.113127425312996, flat: 4.171129569411278, pod: 49.382673025131226, loss: 57.666929960250854 
Train [6/11] | Epoch [45/160] |	nca: 4.20564442127943, flat: 4.227036267518997, pod: 50.55998682975769, loss: 58.99266719818115 
Train [6/11] | Epoch [46/160] |	nca: 4.146604523062706, flat: 4.260616585612297, pod: 51.40990936756134, loss: 59.81713008880615 
Train [6/11] | Epoch [47/160] |	nca: 3.996283106505871, flat: 4.143115043640137, pod: 50.176798582077026, loss: 58.3161963224411 
Train [6/11] | Epoch [48/160] |	nca: 4.431753344833851, flat: 4.280666336417198, pod: 52.420347809791565, loss: 61.13276815414429 
Train [6/11] | Epoch [49/160] |	nca: 4.243436686694622, flat: 4.073886290192604, pod: 49.73242425918579, loss: 58.049747347831726 
Train [6/11] | Epoch [50/160] |	nca: 4.670540280640125, flat: 4.499429568648338, pod: 53.11595976352692, loss: 62.285929679870605 
Train [6/11] | Epoch [51/160] |	nca: 4.199585467576981, flat: 4.57591712474823, pod: 52.50202834606171, loss: 61.27753150463104 
Train [6/11] | Epoch [52/160] |	nca: 4.1470674723386765, flat: 4.076706297695637, pod: 48.18267774581909, loss: 56.40645170211792 
Train [6/11] | Epoch [53/160] |	nca: 3.9515046179294586, flat: 4.146481044590473, pod: 51.91974925994873, loss: 60.01773464679718 
Train [6/11] | Epoch [54/160] |	nca: 4.1257384121418, flat: 3.917104884982109, pod: 48.92816710472107, loss: 56.97101008892059 
Train [6/11] | Epoch [55/160] |	nca: 4.331044092774391, flat: 4.075187005102634, pod: 50.047263383865356, loss: 58.45349454879761 
Train [6/11] | Epoch [56/160] |	nca: 4.195278316736221, flat: 4.017185300588608, pod: 49.5071747303009, loss: 57.71963834762573 
Train [6/11] | Epoch [57/160] |	nca: 3.775327183306217, flat: 3.898223429918289, pod: 47.838155031204224, loss: 55.51170575618744 
Train [6/11] | Epoch [58/160] |	nca: 4.117669053375721, flat: 3.998070478439331, pod: 49.821059346199036, loss: 57.93679893016815 
Train [6/11] | Epoch [59/160] |	nca: 3.927215598523617, flat: 3.725905142724514, pod: 47.25709688663483, loss: 54.91021764278412 
Train [6/11] | Epoch [60/160] |	nca: 4.193172477185726, flat: 3.867757298052311, pod: 47.11589550971985, loss: 55.176825284957886 
Train [6/11] | Epoch [61/160] |	nca: 3.709628365933895, flat: 3.560119815170765, pod: 46.41485679149628, loss: 53.68460488319397 
Train [6/11] | Epoch [62/160] |	nca: 3.986520193517208, flat: 3.509593151509762, pod: 45.229506611824036, loss: 52.72562003135681 
Train [6/11] | Epoch [63/160] |	nca: 4.066379923373461, flat: 3.5996722280979156, pod: 45.72600030899048, loss: 53.39205253124237 
Train [6/11] | Epoch [64/160] |	nca: 3.9885427206754684, flat: 3.6759744361042976, pod: 47.52699625492096, loss: 55.191513419151306 
Train [6/11] | Epoch [65/160] |	nca: 4.64807266741991, flat: 3.927878752350807, pod: 48.595231771469116, loss: 57.17118322849274 
Train [6/11] | Epoch [66/160] |	nca: 3.8551151379942894, flat: 3.81076493114233, pod: 48.0468373298645, loss: 55.71271729469299 
Train [6/11] | Epoch [67/160] |	nca: 4.045215956866741, flat: 3.701116591691971, pod: 47.85288059711456, loss: 55.5992134809494 
Train [6/11] | Epoch [68/160] |	nca: 3.888479560613632, flat: 3.437855415046215, pod: 44.565611600875854, loss: 51.89194679260254 
Train [6/11] | Epoch [69/160] |	nca: 3.809186965227127, flat: 3.487631045281887, pod: 45.676470160484314, loss: 52.97328782081604 
Train [6/11] | Epoch [70/160] |	nca: 4.336911611258984, flat: 3.709818221628666, pod: 46.976062655448914, loss: 55.02279257774353 
Train [6/11] | Epoch [71/160] |	nca: 3.798280254006386, flat: 3.6500521674752235, pod: 46.113129019737244, loss: 53.561461448669434 
Train [6/11] | Epoch [72/160] |	nca: 4.205709338188171, flat: 3.529988430440426, pod: 46.10415995121002, loss: 53.83985793590546 
Train [6/11] | Epoch [73/160] |	nca: 3.6771285012364388, flat: 3.660238042473793, pod: 47.2939338684082, loss: 54.63130056858063 
Train [6/11] | Epoch [74/160] |	nca: 3.7328737899661064, flat: 3.225962795317173, pod: 42.47592604160309, loss: 49.434762716293335 
Train [6/11] | Epoch [75/160] |	nca: 3.69181752204895, flat: 3.126011736690998, pod: 42.56364285945892, loss: 49.381471991539 
Train [6/11] | Epoch [76/160] |	nca: 3.9171682819724083, flat: 3.288937546312809, pod: 43.05587887763977, loss: 50.26198446750641 
Train [6/11] | Epoch [77/160] |	nca: 3.487809009850025, flat: 3.3144862353801727, pod: 44.7739280462265, loss: 51.57622313499451 
Train [6/11] | Epoch [78/160] |	nca: 3.8600153252482414, flat: 3.0721778720617294, pod: 43.20961630344391, loss: 50.141809582710266 
Train [6/11] | Epoch [79/160] |	nca: 4.010872043669224, flat: 3.2160234451293945, pod: 43.5071462392807, loss: 50.73404133319855 
Train [6/11] | Epoch [80/160] |	nca: 3.482617102563381, flat: 3.0918222814798355, pod: 43.27940130233765, loss: 49.853841066360474 
Train [6/11] | Epoch [81/160] |	nca: 3.504110086709261, flat: 3.025954768061638, pod: 42.77422749996185, loss: 49.30429220199585 
Train [6/11] | Epoch [82/160] |	nca: 4.123856693506241, flat: 3.2513530552387238, pod: 44.41615128517151, loss: 51.79136097431183 
Train [6/11] | Epoch [83/160] |	nca: 3.5529262647032738, flat: 3.0253190845251083, pod: 41.153167486190796, loss: 47.73141300678253 
Train [6/11] | Epoch [84/160] |	nca: 3.438690111041069, flat: 2.867144949734211, pod: 40.48176038265228, loss: 46.78759527206421 
Train [6/11] | Epoch [85/160] |	nca: 3.3451748341321945, flat: 2.649295412003994, pod: 38.56467533111572, loss: 44.55914533138275 
Train [6/11] | Epoch [86/160] |	nca: 3.702002178877592, flat: 2.823147162795067, pod: 39.92162108421326, loss: 46.44677007198334 
Train [6/11] | Epoch [87/160] |	nca: 3.928495854139328, flat: 3.028314858675003, pod: 42.530608773231506, loss: 49.48741960525513 
Train [6/11] | Epoch [88/160] |	nca: 3.955630548298359, flat: 3.024690181016922, pod: 42.15999126434326, loss: 49.14031207561493 
Train [6/11] | Epoch [89/160] |	nca: 3.6891596242785454, flat: 2.9138206839561462, pod: 40.102583169937134, loss: 46.70556378364563 
Train [6/11] | Epoch [90/160] |	nca: 3.5268737077713013, flat: 2.834002450108528, pod: 40.73763644695282, loss: 47.09851264953613 
Train [6/11] | Epoch [91/160] |	nca: 3.7449449449777603, flat: 2.8348536118865013, pod: 39.85219848155975, loss: 46.43199694156647 
Train [6/11] | Epoch [92/160] |	nca: 3.5449994541704655, flat: 2.8258958235383034, pod: 40.04501128196716, loss: 46.41590666770935 
Train [6/11] | Epoch [93/160] |	nca: 3.665946915745735, flat: 2.7037299051880836, pod: 39.3692352771759, loss: 45.73891198635101 
Train [6/11] | Epoch [94/160] |	nca: 3.6474243998527527, flat: 2.7054487764835358, pod: 39.157915472984314, loss: 45.51078820228577 
Train [6/11] | Epoch [95/160] |	nca: 3.3348537497222424, flat: 2.5940050929784775, pod: 38.07360315322876, loss: 44.00246214866638 
Train [6/11] | Epoch [96/160] |	nca: 3.5293152257800102, flat: 2.389186941087246, pod: 37.43271195888519, loss: 43.35121428966522 
Train [6/11] | Epoch [97/160] |	nca: 3.2312504425644875, flat: 2.5276918336749077, pod: 37.86063468456268, loss: 43.619576811790466 
Train [6/11] | Epoch [98/160] |	nca: 3.2392216101288795, flat: 2.403207190334797, pod: 37.43772637844086, loss: 43.08015537261963 
Train [6/11] | Epoch [99/160] |	nca: 3.4424237087368965, flat: 2.4648995622992516, pod: 37.22502827644348, loss: 43.132351756095886 
Train [6/11] | Epoch [100/160] |	nca: 3.198512300848961, flat: 2.423238642513752, pod: 36.55555444955826, loss: 42.17730510234833 
Train [6/11] | Epoch [101/160] |	nca: 3.2326067686080933, flat: 2.400367595255375, pod: 36.410168051719666, loss: 42.04314208030701 
Train [6/11] | Epoch [102/160] |	nca: 3.0112794265151024, flat: 2.411654770374298, pod: 36.4502078294754, loss: 41.87314224243164 
Train [6/11] | Epoch [103/160] |	nca: 3.704321011900902, flat: 2.4017723500728607, pod: 37.443517446517944, loss: 43.54961049556732 
Train [6/11] | Epoch [104/160] |	nca: 3.45467222481966, flat: 2.332065761089325, pod: 36.608993887901306, loss: 42.395731925964355 
Train [6/11] | Epoch [105/160] |	nca: 3.1082783937454224, flat: 2.139266859740019, pod: 34.530692875385284, loss: 39.77823829650879 
Train [6/11] | Epoch [106/160] |	nca: 3.303337976336479, flat: 2.24816632270813, pod: 35.81677687168121, loss: 41.36828136444092 
Train [6/11] | Epoch [107/160] |	nca: 3.272562477737665, flat: 2.203002132475376, pod: 34.9206628203392, loss: 40.39622759819031 
Train [6/11] | Epoch [108/160] |	nca: 3.269734598696232, flat: 2.233457710593939, pod: 34.88826608657837, loss: 40.39145851135254 
Train [6/11] | Epoch [109/160] |	nca: 3.460855782032013, flat: 2.2031804732978344, pod: 34.69643461704254, loss: 40.36047077178955 
Train [6/11] | Epoch [110/160] |	nca: 3.1878746934235096, flat: 2.0861957371234894, pod: 33.6073659658432, loss: 38.881436586380005 
Train [6/11] | Epoch [111/160] |	nca: 3.192205287516117, flat: 2.009525492787361, pod: 32.98154389858246, loss: 38.18327486515045 
Train [6/11] | Epoch [112/160] |	nca: 3.5421787910163403, flat: 2.036061342805624, pod: 33.22569954395294, loss: 38.80393958091736 
Train [6/11] | Epoch [113/160] |	nca: 3.3927659317851067, flat: 2.0854531824588776, pod: 33.83344441652298, loss: 39.31166338920593 
Train [6/11] | Epoch [114/160] |	nca: 3.1595573648810387, flat: 1.9282903373241425, pod: 32.21810108423233, loss: 37.30594885349274 
Train [6/11] | Epoch [115/160] |	nca: 3.336625251919031, flat: 1.8927050232887268, pod: 32.34703588485718, loss: 37.57636630535126 
Train [6/11] | Epoch [116/160] |	nca: 3.1580153591930866, flat: 1.9187141917645931, pod: 31.547056555747986, loss: 36.623786091804504 
Train [6/11] | Epoch [117/160] |	nca: 3.1962296590209007, flat: 1.977291990071535, pod: 33.35335820913315, loss: 38.52687954902649 
Train [6/11] | Epoch [118/160] |	nca: 3.1006021052598953, flat: 1.8904035799205303, pod: 32.61667758226395, loss: 37.607683539390564 
Train [6/11] | Epoch [119/160] |	nca: 3.022882327437401, flat: 1.7609809897840023, pod: 30.305487036705017, loss: 35.08935034275055 
Train [6/11] | Epoch [120/160] |	nca: 3.0365591645240784, flat: 1.744472924619913, pod: 29.98391330242157, loss: 34.764945685863495 
Train [6/11] | Epoch [121/160] |	nca: 3.1722049191594124, flat: 1.7545935697853565, pod: 30.934528350830078, loss: 35.861326932907104 
Train [6/11] | Epoch [122/160] |	nca: 3.231489785015583, flat: 1.7004590779542923, pod: 29.733947813510895, loss: 34.665896356105804 
Train [6/11] | Epoch [123/160] |	nca: 2.984787069261074, flat: 1.7144153490662575, pod: 29.339432775974274, loss: 34.03863525390625 
Train [6/11] | Epoch [124/160] |	nca: 2.9516222290694714, flat: 1.6302921660244465, pod: 29.03821712732315, loss: 33.62013107538223 
Train [6/11] | Epoch [125/160] |	nca: 3.1224633008241653, flat: 1.7002084963023663, pod: 29.382818460464478, loss: 34.20549023151398 
Train [6/11] | Epoch [126/160] |	nca: 3.147062249481678, flat: 1.6773126609623432, pod: 29.327402114868164, loss: 34.15177673101425 
Train [6/11] | Epoch [127/160] |	nca: 3.1395496651530266, flat: 1.693901687860489, pod: 29.813676357269287, loss: 34.64712816476822 
Train [6/11] | Epoch [128/160] |	nca: 3.215821109712124, flat: 1.6868075132369995, pod: 29.293425679206848, loss: 34.19605392217636 
Train [6/11] | Epoch [129/160] |	nca: 2.9538949988782406, flat: 1.6255387663841248, pod: 28.8713441491127, loss: 33.45077806711197 
Train [6/11] | Epoch [130/160] |	nca: 3.163447454571724, flat: 1.565244473516941, pod: 28.077864468097687, loss: 32.80655628442764 
Train [6/11] | Epoch [131/160] |	nca: 3.057477507740259, flat: 1.5048734247684479, pod: 27.127363741397858, loss: 31.6897149682045 
Train [6/11] | Epoch [132/160] |	nca: 3.097100719809532, flat: 1.5436819680035114, pod: 28.0380420088768, loss: 32.67882490158081 
Train [6/11] | Epoch [133/160] |	nca: 3.1555975154042244, flat: 1.5040098614990711, pod: 26.33769577741623, loss: 30.997303128242493 
Train [6/11] | Epoch [134/160] |	nca: 3.0284506157040596, flat: 1.4160430580377579, pod: 26.18661069869995, loss: 30.63110464811325 
Train [6/11] | Epoch [135/160] |	nca: 2.863033927977085, flat: 1.4386573620140553, pod: 26.16825306415558, loss: 30.46994411945343 
Train [6/11] | Epoch [136/160] |	nca: 2.8905209824442863, flat: 1.4242548495531082, pod: 25.9146745800972, loss: 30.229450523853302 
Train [6/11] | Epoch [137/160] |	nca: 3.2013787776231766, flat: 1.4442227110266685, pod: 27.37820291519165, loss: 32.02380406856537 
Train [6/11] | Epoch [138/160] |	nca: 3.15618634596467, flat: 1.3963526338338852, pod: 25.170232236385345, loss: 29.72277134656906 
Train [6/11] | Epoch [139/160] |	nca: 2.9892719872295856, flat: 1.3931235410273075, pod: 25.574246406555176, loss: 29.956642031669617 
Train [6/11] | Epoch [140/160] |	nca: 3.0270408019423485, flat: 1.3348001092672348, pod: 24.879948675632477, loss: 29.241789519786835 
Train [6/11] | Epoch [141/160] |	nca: 3.1144423484802246, flat: 1.360220693051815, pod: 25.568756699562073, loss: 30.04341971874237 
Train [6/11] | Epoch [142/160] |	nca: 3.0869287252426147, flat: 1.3995772078633308, pod: 25.508855521678925, loss: 29.995361328125 
Train [6/11] | Epoch [143/160] |	nca: 2.9759633392095566, flat: 1.3472158871591091, pod: 25.362305104732513, loss: 29.68548423051834 
Train [6/11] | Epoch [144/160] |	nca: 3.057395324110985, flat: 1.2823467068374157, pod: 24.38481616973877, loss: 28.724558174610138 
Train [6/11] | Epoch [145/160] |	nca: 2.943340305238962, flat: 1.2413355968892574, pod: 23.068028926849365, loss: 27.252704739570618 
Train [6/11] | Epoch [146/160] |	nca: 3.0163494274020195, flat: 1.3104252628982067, pod: 24.237966120243073, loss: 28.564740777015686 
Train [6/11] | Epoch [147/160] |	nca: 3.0668088644742966, flat: 1.2952136751264334, pod: 23.84105145931244, loss: 28.20307421684265 
Train [6/11] | Epoch [148/160] |	nca: 2.974332831799984, flat: 1.2339252065867186, pod: 23.348924040794373, loss: 27.557182133197784 
Train [6/11] | Epoch [149/160] |	nca: 2.8674237802624702, flat: 1.2716455943882465, pod: 24.157517850399017, loss: 28.296587109565735 
Train [6/11] | Epoch [150/160] |	nca: 3.002829000353813, flat: 1.2710045650601387, pod: 23.940518021583557, loss: 28.214351773262024 
Train [6/11] | Epoch [151/160] |	nca: 3.1593356281518936, flat: 1.240982785820961, pod: 23.423098385334015, loss: 27.823416650295258 
Train [6/11] | Epoch [152/160] |	nca: 2.8880831748247147, flat: 1.32003877684474, pod: 24.40887701511383, loss: 28.61699891090393 
Train [6/11] | Epoch [153/160] |	nca: 2.9334015175700188, flat: 1.2147679422050714, pod: 22.94047784805298, loss: 27.088647425174713 
Train [6/11] | Epoch [154/160] |	nca: 3.0004194155335426, flat: 1.2496544606983662, pod: 23.54451709985733, loss: 27.79459112882614 
Train [6/11] | Epoch [155/160] |	nca: 2.945808306336403, flat: 1.2375781368464231, pod: 23.309496462345123, loss: 27.49288284778595 
Train [6/11] | Epoch [156/160] |	nca: 2.9396218806505203, flat: 1.2503809425979853, pod: 23.544860780239105, loss: 27.734863460063934 
Train [6/11] | Epoch [157/160] |	nca: 2.8610753566026688, flat: 1.2367128785699606, pod: 23.194927096366882, loss: 27.29271525144577 
Train [6/11] | Epoch [158/160] |	nca: 2.9642693772912025, flat: 1.2243869788944721, pod: 22.82475072145462, loss: 27.013406932353973 
Train [6/11] | Epoch [159/160] |	nca: 2.9616198912262917, flat: 1.1443059090524912, pod: 22.38009339570999, loss: 26.486019134521484 
Train [6/11] | Epoch [160/160] |	nca: 2.940653257071972, flat: 1.1899200100451708, pod: 22.81035029888153, loss: 26.9409236907959 
Fine-tuning
Building & updating memory.
Train [6/11] | Epoch [161/180] |	nca: 1.7290117144584656, flat: 0.9266894273459911, pod: 13.7433140873909, loss: 16.399015188217163 
Train [6/11] | Epoch [162/180] |	nca: 0.9139979891479015, flat: 0.9132985398173332, pod: 13.31128478050232, loss: 15.138581395149231 
Train [6/11] | Epoch [163/180] |	nca: 0.7731630466878414, flat: 0.9319683350622654, pod: 13.43036037683487, loss: 15.135491847991943 
Train [6/11] | Epoch [164/180] |	nca: 0.6672591529786587, flat: 0.9552568309009075, pod: 13.624214828014374, loss: 15.246730923652649 
Train [6/11] | Epoch [165/180] |	nca: 0.5992717929184437, flat: 0.9009121172130108, pod: 13.267302513122559, loss: 14.767486333847046 
Train [6/11] | Epoch [166/180] |	nca: 0.6214396432042122, flat: 0.9142840430140495, pod: 13.575887739658356, loss: 15.111611366271973 
Train [6/11] | Epoch [167/180] |	nca: 0.6297167241573334, flat: 0.9149213880300522, pod: 13.600345373153687, loss: 15.144983291625977 
Train [6/11] | Epoch [168/180] |	nca: 0.6043741963803768, flat: 0.9069095142185688, pod: 13.302844941616058, loss: 14.814128637313843 
Train [6/11] | Epoch [169/180] |	nca: 0.537905864417553, flat: 0.9133661799132824, pod: 13.428721249103546, loss: 14.879993200302124 
Train [6/11] | Epoch [170/180] |	nca: 0.5096033439040184, flat: 0.9174379259347916, pod: 13.648100018501282, loss: 15.075141191482544 
Train [6/11] | Epoch [171/180] |	nca: 0.5292497053742409, flat: 0.8675488643348217, pod: 13.294737994670868, loss: 14.691536545753479 
Train [6/11] | Epoch [172/180] |	nca: 0.4855433702468872, flat: 0.8866514898836613, pod: 13.205394983291626, loss: 14.577589869499207 
Train [6/11] | Epoch [173/180] |	nca: 0.5137885622680187, flat: 0.897978600114584, pod: 13.310057044029236, loss: 14.721824169158936 
Train [6/11] | Epoch [174/180] |	nca: 0.49688393622636795, flat: 0.8889451250433922, pod: 12.925528347492218, loss: 14.311357319355011 
Train [6/11] | Epoch [175/180] |	nca: 0.501611266285181, flat: 0.9106216691434383, pod: 13.685134947299957, loss: 15.097367823123932 
Train [6/11] | Epoch [176/180] |	nca: 0.507589703425765, flat: 0.8984289988875389, pod: 13.420858085155487, loss: 14.826876759529114 
Train [6/11] | Epoch [177/180] |	nca: 0.5226769875735044, flat: 0.9159841947257519, pod: 13.298005402088165, loss: 14.736666679382324 
Train [6/11] | Epoch [178/180] |	nca: 0.4689141232520342, flat: 0.9244692176580429, pod: 13.779702126979828, loss: 15.173085451126099 
Train [6/11] | Epoch [179/180] |	nca: 0.45426854863762856, flat: 0.9175663888454437, pod: 13.530798077583313, loss: 14.902633011341095 
Train [6/11] | Epoch [180/180] |	nca: 0.4781811907887459, flat: 0.890137143433094, pod: 13.273700177669525, loss: 14.642018675804138 
after task
Building & updating memory.
after task
Eval on 0->75.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6861666666666667.
Current acc: {'total': 0.622, '00-09': 0.657, '10-19': 0.559, '20-29': 0.54, '30-39': 0.59, '40-49': 0.676, '50-59': 0.633, '60-69': 0.619, '70-79': 0.78}.
Avg inc acc top5: 0.9076666666666666.
Current acc top5: {'total': 0.878}.
Forgetting: 0.034.
Cord metric: 0.69.
Old accuracy: 0.61, mean: 0.66.
New accuracy: 0.78, mean: 0.77.
================Task 6 Start!================
Testing on False unseen tasks (max class = 80).
Set memory of size: 1500.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 6 Training!================
The training samples number: 4000
Train on 75->80.
train task
nb 4000.
Train [7/11] | Epoch [1/160] |	nca: 25.748762786388397, flat: 9.44234960526228, pod: 75.86706203222275, loss: 111.05817544460297 
Train [7/11] | Epoch [2/160] |	nca: 24.796250194311142, flat: 14.710167914628983, pod: 99.1592538356781, loss: 138.66567134857178 
Train [7/11] | Epoch [3/160] |	nca: 17.00742870569229, flat: 11.585965633392334, pod: 87.92663931846619, loss: 116.52003383636475 
Train [7/11] | Epoch [4/160] |	nca: 11.303457662463188, flat: 8.874882966279984, pod: 77.98345351219177, loss: 98.16179394721985 
Train [7/11] | Epoch [5/160] |	nca: 10.575646296143532, flat: 7.663534790277481, pod: 73.15133929252625, loss: 91.39052033424377 
Train [7/11] | Epoch [6/160] |	nca: 9.338312834501266, flat: 7.283309698104858, pod: 71.02048444747925, loss: 87.64210772514343 
Train [7/11] | Epoch [7/160] |	nca: 8.21378479897976, flat: 6.164886385202408, pod: 64.41114568710327, loss: 78.7898166179657 
Train [7/11] | Epoch [8/160] |	nca: 8.340386807918549, flat: 6.292586550116539, pod: 66.07757461071014, loss: 80.71054816246033 
Train [7/11] | Epoch [9/160] |	nca: 8.519711181521416, flat: 6.269877180457115, pod: 65.47167634963989, loss: 80.26126384735107 
Train [7/11] | Epoch [10/160] |	nca: 7.765064045786858, flat: 6.2239126563072205, pod: 66.84266769886017, loss: 80.83164429664612 
Train [7/11] | Epoch [11/160] |	nca: 7.387879624962807, flat: 5.650739014148712, pod: 61.78139400482178, loss: 74.82001280784607 
Train [7/11] | Epoch [12/160] |	nca: 7.319787874817848, flat: 5.811642214655876, pod: 62.382973074913025, loss: 75.5144031047821 
Train [7/11] | Epoch [13/160] |	nca: 7.147409230470657, flat: 5.443589970469475, pod: 61.460188031196594, loss: 74.05118775367737 
Train [7/11] | Epoch [14/160] |	nca: 6.21087696403265, flat: 5.148032113909721, pod: 58.43744361400604, loss: 69.79635286331177 
Train [7/11] | Epoch [15/160] |	nca: 7.112316966056824, flat: 5.479761183261871, pod: 62.09478580951691, loss: 74.68686437606812 
Train [7/11] | Epoch [16/160] |	nca: 7.435538902878761, flat: 5.767415672540665, pod: 60.93108284473419, loss: 74.13403749465942 
Train [7/11] | Epoch [17/160] |	nca: 6.982521802186966, flat: 5.71598507463932, pod: 60.897449135780334, loss: 73.59595608711243 
Train [7/11] | Epoch [18/160] |	nca: 6.051349811255932, flat: 5.394820064306259, pod: 59.30432748794556, loss: 70.7504974603653 
Train [7/11] | Epoch [19/160] |	nca: 6.751516945660114, flat: 5.434863448143005, pod: 61.059181332588196, loss: 73.24556159973145 
Train [7/11] | Epoch [20/160] |	nca: 6.341123059391975, flat: 5.510847792029381, pod: 63.687878131866455, loss: 75.53984832763672 
Train [7/11] | Epoch [21/160] |	nca: 6.14063061773777, flat: 5.162409007549286, pod: 60.1285480260849, loss: 71.43158769607544 
Train [7/11] | Epoch [22/160] |	nca: 5.638407304883003, flat: 4.983868792653084, pod: 59.24102532863617, loss: 69.86330127716064 
Train [7/11] | Epoch [23/160] |	nca: 6.121254205703735, flat: 5.161307156085968, pod: 58.94673836231232, loss: 70.2292994260788 
Train [7/11] | Epoch [24/160] |	nca: 5.803293004631996, flat: 4.611843630671501, pod: 54.762078166007996, loss: 65.17721498012543 
Train [7/11] | Epoch [25/160] |	nca: 7.666778847575188, flat: 5.692499369382858, pod: 60.60951805114746, loss: 73.96879601478577 
Train [7/11] | Epoch [26/160] |	nca: 6.93659482896328, flat: 6.0197444409132, pod: 62.45260953903198, loss: 75.40894865989685 
Train [7/11] | Epoch [27/160] |	nca: 6.266350671648979, flat: 5.350973263382912, pod: 60.369858741760254, loss: 71.98718237876892 
Train [7/11] | Epoch [28/160] |	nca: 6.536771297454834, flat: 5.709985077381134, pod: 62.93366467952728, loss: 75.18042159080505 
Train [7/11] | Epoch [29/160] |	nca: 6.129206970334053, flat: 5.314034968614578, pod: 58.97924757003784, loss: 70.42248916625977 
Train [7/11] | Epoch [30/160] |	nca: 4.91875533759594, flat: 4.611811555922031, pod: 55.08924853801727, loss: 64.61981558799744 
Train [7/11] | Epoch [31/160] |	nca: 5.818807013332844, flat: 4.685036361217499, pod: 56.74995744228363, loss: 67.25380074977875 
Train [7/11] | Epoch [32/160] |	nca: 5.474500797688961, flat: 4.615860089659691, pod: 56.281489849090576, loss: 66.3718513250351 
Train [7/11] | Epoch [33/160] |	nca: 5.664321750402451, flat: 4.648728668689728, pod: 55.082990407943726, loss: 65.39604079723358 
Train [7/11] | Epoch [34/160] |	nca: 6.405830457806587, flat: 5.2444426119327545, pod: 58.97376203536987, loss: 70.62403535842896 
Train [7/11] | Epoch [35/160] |	nca: 5.72564422339201, flat: 4.856693670153618, pod: 56.60131311416626, loss: 67.18365120887756 
Train [7/11] | Epoch [36/160] |	nca: 5.579489968717098, flat: 4.8946602791547775, pod: 58.34608256816864, loss: 68.82023334503174 
Train [7/11] | Epoch [37/160] |	nca: 5.367020055651665, flat: 4.752142854034901, pod: 56.688286781311035, loss: 66.80744910240173 
Train [7/11] | Epoch [38/160] |	nca: 4.932934232056141, flat: 4.478066101670265, pod: 54.2254364490509, loss: 63.636436462402344 
Train [7/11] | Epoch [39/160] |	nca: 5.447907947003841, flat: 4.461932569742203, pod: 54.14535570144653, loss: 64.0551962852478 
Train [7/11] | Epoch [40/160] |	nca: 5.82089851051569, flat: 4.998169764876366, pod: 57.15887451171875, loss: 67.97794318199158 
Train [7/11] | Epoch [41/160] |	nca: 5.297527842223644, flat: 4.696413159370422, pod: 56.018940925598145, loss: 66.01288115978241 
Train [7/11] | Epoch [42/160] |	nca: 4.998588092625141, flat: 4.496250212192535, pod: 55.36962401866913, loss: 64.864462018013 
Train [7/11] | Epoch [43/160] |	nca: 5.09112936258316, flat: 4.25440127402544, pod: 53.40644967556, loss: 62.75198006629944 
Train [7/11] | Epoch [44/160] |	nca: 6.014028385281563, flat: 4.646567404270172, pod: 56.5393728017807, loss: 67.19996869564056 
Train [7/11] | Epoch [45/160] |	nca: 6.236908987164497, flat: 5.127294540405273, pod: 58.417635440826416, loss: 69.78183913230896 
Train [7/11] | Epoch [46/160] |	nca: 5.837315119802952, flat: 5.284374386072159, pod: 58.60469329357147, loss: 69.72638285160065 
Train [7/11] | Epoch [47/160] |	nca: 5.324301294982433, flat: 4.69491246342659, pod: 56.14472961425781, loss: 66.16394364833832 
Train [7/11] | Epoch [48/160] |	nca: 5.174605838954449, flat: 4.368011310696602, pod: 53.917168378829956, loss: 63.45978558063507 
Train [7/11] | Epoch [49/160] |	nca: 5.375434339046478, flat: 4.571183517575264, pod: 55.87843370437622, loss: 65.82505142688751 
Train [7/11] | Epoch [50/160] |	nca: 5.084306210279465, flat: 4.311116345226765, pod: 53.78799617290497, loss: 63.18341851234436 
Train [7/11] | Epoch [51/160] |	nca: 6.2503650188446045, flat: 4.974654674530029, pod: 57.05622947216034, loss: 68.2812489271164 
Train [7/11] | Epoch [52/160] |	nca: 5.405313141644001, flat: 4.647303335368633, pod: 54.90803396701813, loss: 64.96065020561218 
Train [7/11] | Epoch [53/160] |	nca: 5.106999441981316, flat: 4.275000222027302, pod: 53.31301164627075, loss: 62.695011138916016 
Train [7/11] | Epoch [54/160] |	nca: 4.920413985848427, flat: 4.220399342477322, pod: 53.130552530288696, loss: 62.27136552333832 
Train [7/11] | Epoch [55/160] |	nca: 4.201139912009239, flat: 3.7930675074458122, pod: 50.11893081665039, loss: 58.11313831806183 
Train [7/11] | Epoch [56/160] |	nca: 4.367045342922211, flat: 3.666020855307579, pod: 50.90458285808563, loss: 58.93764901161194 
Train [7/11] | Epoch [57/160] |	nca: 4.701896600425243, flat: 3.8078679218888283, pod: 51.53842914104462, loss: 60.04819357395172 
Train [7/11] | Epoch [58/160] |	nca: 4.919589035212994, flat: 3.894867517054081, pod: 50.539931416511536, loss: 59.35438776016235 
Train [7/11] | Epoch [59/160] |	nca: 4.612666636705399, flat: 3.740362584590912, pod: 50.730677127838135, loss: 59.08370625972748 
Train [7/11] | Epoch [60/160] |	nca: 4.875478081405163, flat: 4.057104013860226, pod: 54.06947422027588, loss: 63.00205612182617 
Train [7/11] | Epoch [61/160] |	nca: 4.494877889752388, flat: 4.12528619915247, pod: 52.90948212146759, loss: 61.529646158218384 
Train [7/11] | Epoch [62/160] |	nca: 4.005973018705845, flat: 3.6206768825650215, pod: 49.445308208465576, loss: 57.07195830345154 
Train [7/11] | Epoch [63/160] |	nca: 4.166220523416996, flat: 3.292384408414364, pod: 46.731348156929016, loss: 54.189953207969666 
Train [7/11] | Epoch [64/160] |	nca: 4.783907532691956, flat: 3.3627279549837112, pod: 47.65866935253143, loss: 55.805304408073425 
Train [7/11] | Epoch [65/160] |	nca: 5.542064242064953, flat: 4.390619546175003, pod: 53.70194983482361, loss: 63.63463342189789 
Train [7/11] | Epoch [66/160] |	nca: 4.458369538187981, flat: 3.726529724895954, pod: 49.01376914978027, loss: 57.19866859912872 
Train [7/11] | Epoch [67/160] |	nca: 4.550749056041241, flat: 3.472382865846157, pod: 48.92732620239258, loss: 56.95045804977417 
Train [7/11] | Epoch [68/160] |	nca: 4.019556015729904, flat: 3.1617511808872223, pod: 45.342642307281494, loss: 52.52394986152649 
Train [7/11] | Epoch [69/160] |	nca: 4.756354957818985, flat: 3.4476142153143883, pod: 47.93745577335358, loss: 56.141425013542175 
Train [7/11] | Epoch [70/160] |	nca: 4.99217938631773, flat: 3.8099607974290848, pod: 50.491124629974365, loss: 59.293264627456665 
Train [7/11] | Epoch [71/160] |	nca: 4.260491229593754, flat: 3.555686838924885, pod: 48.26951336860657, loss: 56.0856910943985 
Train [7/11] | Epoch [72/160] |	nca: 4.054028443992138, flat: 3.1623806804418564, pod: 45.77397632598877, loss: 52.99038565158844 
Train [7/11] | Epoch [73/160] |	nca: 3.9310430213809013, flat: 3.032912105321884, pod: 44.91996383666992, loss: 51.8839191198349 
Train [7/11] | Epoch [74/160] |	nca: 4.053618241101503, flat: 3.104279212653637, pod: 45.542827010154724, loss: 52.700724482536316 
Train [7/11] | Epoch [75/160] |	nca: 4.156777963042259, flat: 3.097580760717392, pod: 45.19207322597504, loss: 52.4464316368103 
Train [7/11] | Epoch [76/160] |	nca: 4.2229577377438545, flat: 3.3725471198558807, pod: 47.00240767002106, loss: 54.597912549972534 
Train [7/11] | Epoch [77/160] |	nca: 4.05143079161644, flat: 3.1209996342658997, pod: 44.76087760925293, loss: 51.93330764770508 
Train [7/11] | Epoch [78/160] |	nca: 4.025707375258207, flat: 3.0895595401525497, pod: 44.5301011800766, loss: 51.64536774158478 
Train [7/11] | Epoch [79/160] |	nca: 4.17479020357132, flat: 3.085447758436203, pod: 44.997554898262024, loss: 52.257792592048645 
Train [7/11] | Epoch [80/160] |	nca: 3.9302041605114937, flat: 2.9623385220766068, pod: 43.216790199279785, loss: 50.10933315753937 
Train [7/11] | Epoch [81/160] |	nca: 4.208171591162682, flat: 3.1529706344008446, pod: 45.141043066978455, loss: 52.502184987068176 
Train [7/11] | Epoch [82/160] |	nca: 4.190052784979343, flat: 3.1601802557706833, pod: 45.928367614746094, loss: 53.2786009311676 
Train [7/11] | Epoch [83/160] |	nca: 4.152268677949905, flat: 2.9973471388220787, pod: 43.87632179260254, loss: 51.02593743801117 
Train [7/11] | Epoch [84/160] |	nca: 4.294229060411453, flat: 2.956899367272854, pod: 43.52509927749634, loss: 50.776227831840515 
Train [7/11] | Epoch [85/160] |	nca: 4.379802390933037, flat: 3.1029207035899162, pod: 44.49676263332367, loss: 51.97948598861694 
Train [7/11] | Epoch [86/160] |	nca: 4.435275167226791, flat: 3.001705899834633, pod: 43.086024045944214, loss: 50.52300524711609 
Train [7/11] | Epoch [87/160] |	nca: 4.255254179239273, flat: 3.0074008479714394, pod: 43.690608739852905, loss: 50.95326375961304 
Train [7/11] | Epoch [88/160] |	nca: 3.9106261804699898, flat: 2.731056362390518, pod: 42.02533519268036, loss: 48.66701781749725 
Train [7/11] | Epoch [89/160] |	nca: 4.127395942807198, flat: 3.024300329387188, pod: 43.994969964027405, loss: 51.14666664600372 
Train [7/11] | Epoch [90/160] |	nca: 3.8585055992007256, flat: 2.7704173251986504, pod: 42.66150104999542, loss: 49.29042434692383 
Train [7/11] | Epoch [91/160] |	nca: 4.127525597810745, flat: 2.685930758714676, pod: 42.00784170627594, loss: 48.82129776477814 
Train [7/11] | Epoch [92/160] |	nca: 4.362080127000809, flat: 2.8413954600691795, pod: 42.63447415828705, loss: 49.83794987201691 
Train [7/11] | Epoch [93/160] |	nca: 4.356542192399502, flat: 2.9405159801244736, pod: 43.569621443748474, loss: 50.866679668426514 
Train [7/11] | Epoch [94/160] |	nca: 3.8301248401403427, flat: 2.7386065497994423, pod: 41.68328881263733, loss: 48.25202012062073 
Train [7/11] | Epoch [95/160] |	nca: 3.659298613667488, flat: 2.5324296727776527, pod: 40.548656702041626, loss: 46.74038529396057 
Train [7/11] | Epoch [96/160] |	nca: 3.802684150636196, flat: 2.724690690636635, pod: 41.02263426780701, loss: 47.55000925064087 
Train [7/11] | Epoch [97/160] |	nca: 4.044988378882408, flat: 2.664216049015522, pod: 41.59642004966736, loss: 48.30562472343445 
Train [7/11] | Epoch [98/160] |	nca: 3.8708355091512203, flat: 2.468105211853981, pod: 38.68135893344879, loss: 45.020299434661865 
Train [7/11] | Epoch [99/160] |	nca: 3.802168145775795, flat: 2.476610168814659, pod: 40.015958189964294, loss: 46.29473662376404 
Train [7/11] | Epoch [100/160] |	nca: 3.6899168118834496, flat: 2.3127530738711357, pod: 38.0307594537735, loss: 44.03342950344086 
Train [7/11] | Epoch [101/160] |	nca: 3.5918999388813972, flat: 2.272905331104994, pod: 37.50670790672302, loss: 43.37151324748993 
Train [7/11] | Epoch [102/160] |	nca: 3.698042768985033, flat: 2.1482300236821175, pod: 36.51470243930817, loss: 42.3609756231308 
Train [7/11] | Epoch [103/160] |	nca: 3.475238710641861, flat: 2.167744692414999, pod: 36.40288972854614, loss: 42.04587280750275 
Train [7/11] | Epoch [104/160] |	nca: 3.771359134465456, flat: 2.21864378079772, pod: 36.382267475128174, loss: 42.372270345687866 
Train [7/11] | Epoch [105/160] |	nca: 4.362289719283581, flat: 2.2572658099234104, pod: 37.41063833236694, loss: 44.03019392490387 
Train [7/11] | Epoch [106/160] |	nca: 3.6765210777521133, flat: 2.2593161575496197, pod: 38.361655950546265, loss: 44.29749310016632 
Train [7/11] | Epoch [107/160] |	nca: 3.4425177574157715, flat: 2.1779465302824974, pod: 36.989147901535034, loss: 42.60961198806763 
Train [7/11] | Epoch [108/160] |	nca: 3.7200688272714615, flat: 2.026223514229059, pod: 34.300430834293365, loss: 40.04672300815582 
Train [7/11] | Epoch [109/160] |	nca: 3.757838487625122, flat: 2.045750394463539, pod: 35.38003587722778, loss: 41.183624505996704 
Train [7/11] | Epoch [110/160] |	nca: 3.6921496465802193, flat: 1.9925090558826923, pod: 35.177284955978394, loss: 40.86194372177124 
Train [7/11] | Epoch [111/160] |	nca: 3.6401899307966232, flat: 2.0602994337677956, pod: 35.99000841379166, loss: 41.69049787521362 
Train [7/11] | Epoch [112/160] |	nca: 3.548213627189398, flat: 2.059956446290016, pod: 35.78187996149063, loss: 41.39004981517792 
Train [7/11] | Epoch [113/160] |	nca: 3.424895092844963, flat: 1.7909049950540066, pod: 32.46326422691345, loss: 37.67906439304352 
Train [7/11] | Epoch [114/160] |	nca: 3.5595511198043823, flat: 1.8860838748514652, pod: 33.9313246011734, loss: 39.376959443092346 
Train [7/11] | Epoch [115/160] |	nca: 3.708662435412407, flat: 1.9087269343435764, pod: 34.42977732419968, loss: 40.04716670513153 
Train [7/11] | Epoch [116/160] |	nca: 3.628236308693886, flat: 1.8790677189826965, pod: 33.273707032203674, loss: 38.78101086616516 
Train [7/11] | Epoch [117/160] |	nca: 3.668347142636776, flat: 1.8661741614341736, pod: 33.136139273643494, loss: 38.67066037654877 
Train [7/11] | Epoch [118/160] |	nca: 3.5205161049962044, flat: 1.793278481811285, pod: 33.32691407203674, loss: 38.640708446502686 
Train [7/11] | Epoch [119/160] |	nca: 3.5813700035214424, flat: 1.7754488475620747, pod: 32.22669768333435, loss: 37.583516359329224 
Train [7/11] | Epoch [120/160] |	nca: 3.5490058064460754, flat: 1.744586504995823, pod: 30.870154798030853, loss: 36.16374695301056 
Train [7/11] | Epoch [121/160] |	nca: 3.707857921719551, flat: 1.7187799215316772, pod: 30.73568558692932, loss: 36.16232347488403 
Train [7/11] | Epoch [122/160] |	nca: 3.366965852677822, flat: 1.7962921671569347, pod: 32.36690229177475, loss: 37.53016012907028 
Train [7/11] | Epoch [123/160] |	nca: 3.555076513439417, flat: 1.6604332216084003, pod: 31.02659833431244, loss: 36.242108047008514 
Train [7/11] | Epoch [124/160] |	nca: 3.7419890090823174, flat: 1.6332987882196903, pod: 30.754187166690826, loss: 36.12947505712509 
Train [7/11] | Epoch [125/160] |	nca: 3.3569517359137535, flat: 1.5926904417574406, pod: 30.09245401620865, loss: 35.04209619760513 
Train [7/11] | Epoch [126/160] |	nca: 3.192773710936308, flat: 1.489990022033453, pod: 29.06643855571747, loss: 33.749202251434326 
Train [7/11] | Epoch [127/160] |	nca: 3.27010602876544, flat: 1.5296093933284283, pod: 29.017711877822876, loss: 33.81742715835571 
Train [7/11] | Epoch [128/160] |	nca: 3.3722357749938965, flat: 1.4851111583411694, pod: 28.601894855499268, loss: 33.45924150943756 
Train [7/11] | Epoch [129/160] |	nca: 3.1177885457873344, flat: 1.5045680478215218, pod: 29.416978776454926, loss: 34.03933525085449 
Train [7/11] | Epoch [130/160] |	nca: 3.4269915148615837, flat: 1.43671690300107, pod: 27.990767061710358, loss: 32.85447543859482 
Train [7/11] | Epoch [131/160] |	nca: 3.512453056871891, flat: 1.468230940401554, pod: 28.66553944349289, loss: 33.64622360467911 
Train [7/11] | Epoch [132/160] |	nca: 3.416855961084366, flat: 1.5011096522212029, pod: 28.38022530078888, loss: 33.298190891742706 
Train [7/11] | Epoch [133/160] |	nca: 3.301866188645363, flat: 1.4628897421061993, pod: 28.2416912317276, loss: 33.00644737482071 
Train [7/11] | Epoch [134/160] |	nca: 3.3306747674942017, flat: 1.4314882643520832, pod: 27.482115864753723, loss: 32.24427890777588 
Train [7/11] | Epoch [135/160] |	nca: 3.4175686463713646, flat: 1.4087481871247292, pod: 27.57006561756134, loss: 32.39638268947601 
Train [7/11] | Epoch [136/160] |	nca: 3.4472059532999992, flat: 1.359105158597231, pod: 26.955682456493378, loss: 31.761993646621704 
Train [7/11] | Epoch [137/160] |	nca: 3.308134365826845, flat: 1.3633589893579483, pod: 27.194937109947205, loss: 31.866430342197418 
Train [7/11] | Epoch [138/160] |	nca: 3.314546562731266, flat: 1.35306616127491, pod: 27.214970648288727, loss: 31.882583498954773 
Train [7/11] | Epoch [139/160] |	nca: 3.408079870045185, flat: 1.328581903129816, pod: 26.350486993789673, loss: 31.08714884519577 
Train [7/11] | Epoch [140/160] |	nca: 3.423883877694607, flat: 1.2845026813447475, pod: 26.412457883358, loss: 31.12084448337555 
Train [7/11] | Epoch [141/160] |	nca: 3.178589142858982, flat: 1.2707539852708578, pod: 25.619292378425598, loss: 30.0686354637146 
Train [7/11] | Epoch [142/160] |	nca: 3.4781651869416237, flat: 1.3221963942050934, pod: 25.98833739757538, loss: 30.78869891166687 
Train [7/11] | Epoch [143/160] |	nca: 3.3734938353300095, flat: 1.3420953005552292, pod: 26.380802392959595, loss: 31.096391439437866 
Train [7/11] | Epoch [144/160] |	nca: 3.2063748612999916, flat: 1.2181645892560482, pod: 24.84510064125061, loss: 29.269640028476715 
Train [7/11] | Epoch [145/160] |	nca: 3.117939256131649, flat: 1.2349961716681719, pod: 24.943082213401794, loss: 29.296017706394196 
Train [7/11] | Epoch [146/160] |	nca: 3.4852102994918823, flat: 1.2034145891666412, pod: 24.870026886463165, loss: 29.558651864528656 
Train [7/11] | Epoch [147/160] |	nca: 3.3571846894919872, flat: 1.2149846218526363, pod: 24.72626805305481, loss: 29.298437416553497 
Train [7/11] | Epoch [148/160] |	nca: 3.3092346228659153, flat: 1.2613806277513504, pod: 25.166871905326843, loss: 29.737487316131592 
Train [7/11] | Epoch [149/160] |	nca: 3.3984193988144398, flat: 1.1950901299715042, pod: 24.27023357152939, loss: 28.863743126392365 
Train [7/11] | Epoch [150/160] |	nca: 3.2336843237280846, flat: 1.2118728309869766, pod: 24.574973702430725, loss: 29.020530879497528 
Train [7/11] | Epoch [151/160] |	nca: 3.258226364850998, flat: 1.1862986609339714, pod: 24.108236253261566, loss: 28.552761018276215 
Train [7/11] | Epoch [152/160] |	nca: 3.3258608654141426, flat: 1.2334573343396187, pod: 25.162041068077087, loss: 29.721359133720398 
Train [7/11] | Epoch [153/160] |	nca: 3.295759007334709, flat: 1.1892920434474945, pod: 24.409159541130066, loss: 28.89421057701111 
Train [7/11] | Epoch [154/160] |	nca: 3.1592440754175186, flat: 1.1928765289485455, pod: 24.43338245153427, loss: 28.785503149032593 
Train [7/11] | Epoch [155/160] |	nca: 3.354745864868164, flat: 1.2363314498215914, pod: 24.923681259155273, loss: 29.514758467674255 
Train [7/11] | Epoch [156/160] |	nca: 3.0837613977491856, flat: 1.184708060696721, pod: 24.307203829288483, loss: 28.575673401355743 
Train [7/11] | Epoch [157/160] |	nca: 3.2011466324329376, flat: 1.1948324963450432, pod: 24.420353770256042, loss: 28.81633287668228 
Train [7/11] | Epoch [158/160] |	nca: 3.330508776009083, flat: 1.1635099165141582, pod: 23.631779432296753, loss: 28.125798046588898 
Train [7/11] | Epoch [159/160] |	nca: 3.0789173990488052, flat: 1.1377375852316618, pod: 23.4203023314476, loss: 27.63695740699768 
Train [7/11] | Epoch [160/160] |	nca: 3.3000218644738197, flat: 1.1594971492886543, pod: 23.49932873249054, loss: 27.958847761154175 
Fine-tuning
Building & updating memory.
Train [7/11] | Epoch [161/180] |	nca: 2.1139675453305244, flat: 0.9144169017672539, pod: 14.717719495296478, loss: 17.746103823184967 
Train [7/11] | Epoch [162/180] |	nca: 0.9846802987158298, flat: 0.8663495369255543, pod: 14.367525100708008, loss: 16.218554973602295 
Train [7/11] | Epoch [163/180] |	nca: 0.9527208209037781, flat: 0.8885548077523708, pod: 14.564447700977325, loss: 16.405723452568054 
Train [7/11] | Epoch [164/180] |	nca: 0.8037473317235708, flat: 0.9358836524188519, pod: 14.609181523323059, loss: 16.348812520503998 
Train [7/11] | Epoch [165/180] |	nca: 0.7406959943473339, flat: 0.8983763046562672, pod: 14.771503686904907, loss: 16.410576164722443 
Train [7/11] | Epoch [166/180] |	nca: 0.7248029485344887, flat: 0.8863321989774704, pod: 14.780571401119232, loss: 16.39170664548874 
Train [7/11] | Epoch [167/180] |	nca: 0.7182956263422966, flat: 0.8851629830896854, pod: 14.422273576259613, loss: 16.025732338428497 
Train [7/11] | Epoch [168/180] |	nca: 0.7772266007959843, flat: 0.9094905108213425, pod: 14.637529492378235, loss: 16.324246525764465 
Train [7/11] | Epoch [169/180] |	nca: 0.7139554060995579, flat: 0.904082328081131, pod: 14.597622275352478, loss: 16.215659856796265 
Train [7/11] | Epoch [170/180] |	nca: 0.6919018514454365, flat: 0.9043760485947132, pod: 14.73717325925827, loss: 16.33345103263855 
Train [7/11] | Epoch [171/180] |	nca: 0.6574312523007393, flat: 0.9089002311229706, pod: 14.562304973602295, loss: 16.128636360168457 
Train [7/11] | Epoch [172/180] |	nca: 0.6144396550953388, flat: 0.9367676489055157, pod: 15.057638883590698, loss: 16.608846306800842 
Train [7/11] | Epoch [173/180] |	nca: 0.656679529696703, flat: 0.8777213580906391, pod: 14.334423899650574, loss: 15.86882483959198 
Train [7/11] | Epoch [174/180] |	nca: 0.5714788772165775, flat: 0.902295395731926, pod: 14.660579681396484, loss: 16.13435387611389 
Train [7/11] | Epoch [175/180] |	nca: 0.6154309771955013, flat: 0.8543112203478813, pod: 14.255532264709473, loss: 15.725274682044983 
Train [7/11] | Epoch [176/180] |	nca: 0.5703076682984829, flat: 0.8849154114723206, pod: 14.648138403892517, loss: 16.10336136817932 
Train [7/11] | Epoch [177/180] |	nca: 0.5705320183187723, flat: 0.8957826420664787, pod: 14.7537339925766, loss: 16.220048666000366 
Train [7/11] | Epoch [178/180] |	nca: 0.6427480466663837, flat: 0.9430059567093849, pod: 14.748331904411316, loss: 16.334085762500763 
Train [7/11] | Epoch [179/180] |	nca: 0.5580826550722122, flat: 0.895540963858366, pod: 14.625702261924744, loss: 16.079325795173645 
Train [7/11] | Epoch [180/180] |	nca: 0.5527892597019672, flat: 0.9155809804797173, pod: 14.770645022392273, loss: 16.239015221595764 
after task
Building & updating memory.
after task
Eval on 0->80.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6741428571428572.
Current acc: {'total': 0.602, '00-09': 0.641, '10-19': 0.563, '20-29': 0.513, '30-39': 0.56, '40-49': 0.634, '50-59': 0.611, '60-69': 0.555, '70-79': 0.742}.
Avg inc acc top5: 0.9009999999999999.
Current acc top5: {'total': 0.861}.
Forgetting: 0.14677777777777778.
Cord metric: 0.67.
Old accuracy: 0.59, mean: 0.65.
New accuracy: 0.73, mean: 0.76.
================Task 7 Start!================
Testing on False unseen tasks (max class = 85).
Set memory of size: 1600.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 7 Training!================
The training samples number: 4100
Train on 80->85.
train task
nb 4100.
Train [8/11] | Epoch [1/160] |	nca: 26.261205971240997, flat: 9.928881525993347, pod: 82.69308495521545, loss: 118.88317155838013 
Train [8/11] | Epoch [2/160] |	nca: 56.23762845993042, flat: 26.818748772144318, pod: 147.9421226978302, loss: 230.99849939346313 
Train [8/11] | Epoch [3/160] |	nca: 43.86091095209122, flat: 23.408958852291107, pod: 137.2546718120575, loss: 204.52453994750977 
Train [8/11] | Epoch [4/160] |	nca: 34.49358868598938, flat: 21.225541412830353, pod: 126.93504762649536, loss: 182.65417766571045 
Train [8/11] | Epoch [5/160] |	nca: 26.295591086149216, flat: 17.36236947774887, pod: 113.73726916313171, loss: 157.39522886276245 
Train [8/11] | Epoch [6/160] |	nca: 41.21325558423996, flat: 23.73969703912735, pod: 138.57299709320068, loss: 203.52594804763794 
Train [8/11] | Epoch [7/160] |	nca: 25.227309495210648, flat: 17.904702305793762, pod: 116.65502977371216, loss: 159.78704261779785 
Train [8/11] | Epoch [8/160] |	nca: 22.839202165603638, flat: 16.030504643917084, pod: 110.35735964775085, loss: 149.2270667552948 
Train [8/11] | Epoch [9/160] |	nca: 27.543227434158325, flat: 18.90148976445198, pod: 116.60729360580444, loss: 163.052011013031 
Train [8/11] | Epoch [10/160] |	nca: 18.65770474076271, flat: 14.75967076420784, pod: 103.73532509803772, loss: 137.15270066261292 
Train [8/11] | Epoch [11/160] |	nca: 17.4042746424675, flat: 13.381649821996689, pod: 97.7192530632019, loss: 128.50517773628235 
Train [8/11] | Epoch [12/160] |	nca: 26.314514309167862, flat: 17.188142746686935, pod: 111.84212279319763, loss: 155.34478068351746 
Train [8/11] | Epoch [13/160] |	nca: 32.07572205364704, flat: 21.391638696193695, pod: 128.62661814689636, loss: 182.09397888183594 
Train [8/11] | Epoch [14/160] |	nca: 19.905051290988922, flat: 14.508121132850647, pod: 102.41194701194763, loss: 136.82511925697327 
Train [8/11] | Epoch [15/160] |	nca: 24.908634215593338, flat: 16.56486290693283, pod: 107.54049873352051, loss: 149.01399517059326 
Train [8/11] | Epoch [16/160] |	nca: 15.174149945378304, flat: 14.071444571018219, pod: 100.37236404418945, loss: 129.61795830726624 
Train [8/11] | Epoch [17/160] |	nca: 13.892130345106125, flat: 11.408779919147491, pod: 89.262699842453, loss: 114.56360983848572 
Train [8/11] | Epoch [18/160] |	nca: 23.58788487315178, flat: 16.236154854297638, pod: 107.92777943611145, loss: 147.75181889533997 
Train [8/11] | Epoch [19/160] |	nca: 23.309869825839996, flat: 16.77670070528984, pod: 112.99177145957947, loss: 153.07834196090698 
Train [8/11] | Epoch [20/160] |	nca: 18.655114948749542, flat: 14.293939262628555, pod: 103.32574725151062, loss: 136.27480125427246 
Train [8/11] | Epoch [21/160] |	nca: 17.829817801713943, flat: 15.690758228302002, pod: 105.65681409835815, loss: 139.17739033699036 
Train [8/11] | Epoch [22/160] |	nca: 15.104140922427177, flat: 13.533942222595215, pod: 99.31097507476807, loss: 127.94905829429626 
Train [8/11] | Epoch [23/160] |	nca: 11.904373109340668, flat: 11.259285807609558, pod: 89.89632296562195, loss: 113.05998253822327 
Train [8/11] | Epoch [24/160] |	nca: 15.06093978881836, flat: 13.459460198879242, pod: 99.03761672973633, loss: 127.55801725387573 
Train [8/11] | Epoch [25/160] |	nca: 9.758605852723122, flat: 10.537256002426147, pod: 86.5156421661377, loss: 106.81150412559509 
Train [8/11] | Epoch [26/160] |	nca: 11.487517893314362, flat: 10.969845294952393, pod: 87.50412559509277, loss: 109.96148943901062 
Train [8/11] | Epoch [27/160] |	nca: 15.617571115493774, flat: 12.130641132593155, pod: 93.34818816184998, loss: 121.09640097618103 
Train [8/11] | Epoch [28/160] |	nca: 15.580957919359207, flat: 12.316015869379044, pod: 93.76259851455688, loss: 121.65957188606262 
Train [8/11] | Epoch [29/160] |	nca: 14.856033131480217, flat: 12.170675665140152, pod: 92.10567569732666, loss: 119.13238382339478 
Train [8/11] | Epoch [30/160] |	nca: 10.463967710733414, flat: 11.14386197924614, pod: 88.36486268043518, loss: 109.97269201278687 
Train [8/11] | Epoch [31/160] |	nca: 8.530776090919971, flat: 9.075462564826012, pod: 79.23315405845642, loss: 96.8393931388855 
Train [8/11] | Epoch [32/160] |	nca: 13.381679326295853, flat: 10.877976879477501, pod: 86.17581796646118, loss: 110.43547463417053 
Train [8/11] | Epoch [33/160] |	nca: 16.983088433742523, flat: 12.536729663610458, pod: 93.71275353431702, loss: 123.23257231712341 
Train [8/11] | Epoch [34/160] |	nca: 15.040725961327553, flat: 12.515530854463577, pod: 91.92157435417175, loss: 119.47783136367798 
Train [8/11] | Epoch [35/160] |	nca: 20.63003298640251, flat: 14.994598984718323, pod: 101.80074143409729, loss: 137.42537331581116 
Train [8/11] | Epoch [36/160] |	nca: 16.449114471673965, flat: 13.41774320602417, pod: 96.15443730354309, loss: 126.02129435539246 
Train [8/11] | Epoch [37/160] |	nca: 15.336756974458694, flat: 13.041396260261536, pod: 94.95459938049316, loss: 123.33275318145752 
Train [8/11] | Epoch [38/160] |	nca: 8.546579480171204, flat: 9.659715384244919, pod: 81.49148344993591, loss: 99.69777727127075 
Train [8/11] | Epoch [39/160] |	nca: 11.455625861883163, flat: 11.459695756435394, pod: 88.43581128120422, loss: 111.3511335849762 
Train [8/11] | Epoch [40/160] |	nca: 9.679855212569237, flat: 9.673242688179016, pod: 81.10192680358887, loss: 100.4550244808197 
Train [8/11] | Epoch [41/160] |	nca: 12.435509026050568, flat: 10.693571045994759, pod: 85.07980489730835, loss: 108.2088851928711 
Train [8/11] | Epoch [42/160] |	nca: 21.052610531449318, flat: 15.699274182319641, pod: 106.48250317573547, loss: 143.234388589859 
Train [8/11] | Epoch [43/160] |	nca: 10.228999227285385, flat: 10.650169789791107, pod: 85.63687586784363, loss: 106.51604509353638 
Train [8/11] | Epoch [44/160] |	nca: 7.912590906023979, flat: 9.45224641263485, pod: 81.59306216239929, loss: 98.95789957046509 
Train [8/11] | Epoch [45/160] |	nca: 6.367420628666878, flat: 8.023780137300491, pod: 74.51948761940002, loss: 88.91068863868713 
Train [8/11] | Epoch [46/160] |	nca: 10.58390425145626, flat: 9.246580824255943, pod: 79.79948258399963, loss: 99.62996768951416 
Train [8/11] | Epoch [47/160] |	nca: 25.15610173344612, flat: 16.673487186431885, pod: 111.06863188743591, loss: 152.89822149276733 
Train [8/11] | Epoch [48/160] |	nca: 15.968308314681053, flat: 13.621589004993439, pod: 96.31694221496582, loss: 125.90684080123901 
Train [8/11] | Epoch [49/160] |	nca: 11.950683489441872, flat: 12.21922191977501, pod: 90.24068665504456, loss: 114.4105920791626 
Train [8/11] | Epoch [50/160] |	nca: 8.25726281106472, flat: 10.133717477321625, pod: 82.41170167922974, loss: 100.80268216133118 
Train [8/11] | Epoch [51/160] |	nca: 7.54271300137043, flat: 8.60458019375801, pod: 76.48216366767883, loss: 92.62945652008057 
Train [8/11] | Epoch [52/160] |	nca: 18.85387995839119, flat: 14.162841796875, pod: 99.70284485816956, loss: 132.71956729888916 
Train [8/11] | Epoch [53/160] |	nca: 16.054454788565636, flat: 13.817428141832352, pod: 100.31297874450684, loss: 130.18486189842224 
Train [8/11] | Epoch [54/160] |	nca: 16.020896092057228, flat: 12.060551047325134, pod: 92.20901703834534, loss: 120.29046368598938 
Train [8/11] | Epoch [55/160] |	nca: 16.813104674220085, flat: 13.24558836221695, pod: 93.1369960308075, loss: 123.19569039344788 
Train [8/11] | Epoch [56/160] |	nca: 7.815071061253548, flat: 9.767721399664879, pod: 81.70981478691101, loss: 99.29260778427124 
Train [8/11] | Epoch [57/160] |	nca: 8.342505484819412, flat: 8.058099523186684, pod: 73.753178358078, loss: 90.15378332138062 
Train [8/11] | Epoch [58/160] |	nca: 13.600412786006927, flat: 11.195493027567863, pod: 87.69811534881592, loss: 112.49402117729187 
Train [8/11] | Epoch [59/160] |	nca: 13.7543805539608, flat: 11.858807682991028, pod: 90.25342130661011, loss: 115.86660957336426 
Train [8/11] | Epoch [60/160] |	nca: 9.56071288883686, flat: 10.194033294916153, pod: 82.93275046348572, loss: 102.68749618530273 
Train [8/11] | Epoch [61/160] |	nca: 7.107399232685566, flat: 8.223969429731369, pod: 74.35245704650879, loss: 89.68382596969604 
Train [8/11] | Epoch [62/160] |	nca: 10.778846681118011, flat: 10.165361642837524, pod: 82.65187191963196, loss: 103.59607887268066 
Train [8/11] | Epoch [63/160] |	nca: 11.22102889418602, flat: 11.16918569803238, pod: 84.73291540145874, loss: 107.12313032150269 
Train [8/11] | Epoch [64/160] |	nca: 11.143545597791672, flat: 10.690118670463562, pod: 84.0075855255127, loss: 105.84124994277954 
Train [8/11] | Epoch [65/160] |	nca: 10.83327142894268, flat: 11.243583619594574, pod: 89.48000168800354, loss: 111.55685591697693 
Train [8/11] | Epoch [66/160] |	nca: 12.88476525247097, flat: 10.727015048265457, pod: 84.76505661010742, loss: 108.3768367767334 
Train [8/11] | Epoch [67/160] |	nca: 16.008647114038467, flat: 12.801478058099747, pod: 94.11851024627686, loss: 122.928635597229 
Train [8/11] | Epoch [68/160] |	nca: 9.66218777000904, flat: 9.997235745191574, pod: 83.95745038986206, loss: 103.61687469482422 
Train [8/11] | Epoch [69/160] |	nca: 11.990883320569992, flat: 11.316675424575806, pod: 90.52888464927673, loss: 113.83644342422485 
Train [8/11] | Epoch [70/160] |	nca: 9.380223542451859, flat: 9.662959814071655, pod: 81.44784760475159, loss: 100.49103116989136 
Train [8/11] | Epoch [71/160] |	nca: 13.193075507879257, flat: 12.011100620031357, pod: 87.81484532356262, loss: 113.01902198791504 
Train [8/11] | Epoch [72/160] |	nca: 14.090052381157875, flat: 10.860319197177887, pod: 86.10334873199463, loss: 111.05372047424316 
Train [8/11] | Epoch [73/160] |	nca: 13.531282678246498, flat: 12.476815938949585, pod: 90.22887325286865, loss: 116.236971616745 
Train [8/11] | Epoch [74/160] |	nca: 9.333029836416245, flat: 10.200249746441841, pod: 81.7408094406128, loss: 101.27408933639526 
Train [8/11] | Epoch [75/160] |	nca: 8.012318760156631, flat: 9.724011734127998, pod: 79.15297532081604, loss: 96.88930583000183 
Train [8/11] | Epoch [76/160] |	nca: 5.835778512060642, flat: 7.704097047448158, pod: 71.46792829036713, loss: 85.00780320167542 
Train [8/11] | Epoch [77/160] |	nca: 5.374377220869064, flat: 7.589485093951225, pod: 70.55710244178772, loss: 83.5209641456604 
Train [8/11] | Epoch [78/160] |	nca: 5.8734859600663185, flat: 6.802022963762283, pod: 66.65301370620728, loss: 79.32852268218994 
Train [8/11] | Epoch [79/160] |	nca: 9.92973393201828, flat: 8.57107363641262, pod: 75.91395676136017, loss: 94.4147641658783 
Train [8/11] | Epoch [80/160] |	nca: 8.187986478209496, flat: 9.413956686854362, pod: 77.10459530353546, loss: 94.70653748512268 
Train [8/11] | Epoch [81/160] |	nca: 5.792562380433083, flat: 7.762122005224228, pod: 69.40520668029785, loss: 82.95989084243774 
Train [8/11] | Epoch [82/160] |	nca: 5.434939026832581, flat: 6.688384532928467, pod: 66.0273368358612, loss: 78.15066003799438 
Train [8/11] | Epoch [83/160] |	nca: 9.503318518400192, flat: 9.195833057165146, pod: 77.46780800819397, loss: 96.16695928573608 
Train [8/11] | Epoch [84/160] |	nca: 9.957373283803463, flat: 9.540302634239197, pod: 79.09519290924072, loss: 98.59286904335022 
Train [8/11] | Epoch [85/160] |	nca: 13.141641914844513, flat: 10.82382020354271, pod: 81.89979076385498, loss: 105.86525297164917 
Train [8/11] | Epoch [86/160] |	nca: 13.222958579659462, flat: 11.355866342782974, pod: 86.73297071456909, loss: 111.3117949962616 
Train [8/11] | Epoch [87/160] |	nca: 14.02994941174984, flat: 12.80154812335968, pod: 91.94958424568176, loss: 118.78108310699463 
Train [8/11] | Epoch [88/160] |	nca: 6.507460728287697, flat: 8.476881384849548, pod: 75.12501585483551, loss: 90.10935831069946 
Train [8/11] | Epoch [89/160] |	nca: 7.490040123462677, flat: 8.396580427885056, pod: 73.0710963010788, loss: 88.95771718025208 
Train [8/11] | Epoch [90/160] |	nca: 8.932742699980736, flat: 9.780325829982758, pod: 82.60436224937439, loss: 101.31743121147156 
Train [8/11] | Epoch [91/160] |	nca: 7.340057909488678, flat: 7.92521008849144, pod: 72.18359625339508, loss: 87.44886445999146 
Train [8/11] | Epoch [92/160] |	nca: 8.741680979728699, flat: 8.584258750081062, pod: 75.40877985954285, loss: 92.73471927642822 
Train [8/11] | Epoch [93/160] |	nca: 6.2545678317546844, flat: 7.7548727840185165, pod: 72.49535179138184, loss: 86.5047926902771 
Train [8/11] | Epoch [94/160] |	nca: 5.904882878065109, flat: 7.433050513267517, pod: 68.73573565483093, loss: 82.07366895675659 
Train [8/11] | Epoch [95/160] |	nca: 5.428068362176418, flat: 7.185380637645721, pod: 67.26574051380157, loss: 79.87919020652771 
Train [8/11] | Epoch [96/160] |	nca: 4.509467825293541, flat: 6.922870472073555, pod: 66.16059637069702, loss: 77.59293460845947 
Train [8/11] | Epoch [97/160] |	nca: 4.7848958522081375, flat: 6.183327451348305, pod: 62.13007855415344, loss: 73.09830164909363 
Train [8/11] | Epoch [98/160] |	nca: 7.03737635165453, flat: 6.963028848171234, pod: 66.58476102352142, loss: 80.58516597747803 
Train [8/11] | Epoch [99/160] |	nca: 6.361024379730225, flat: 7.694187894463539, pod: 68.90271508693695, loss: 82.95792818069458 
Train [8/11] | Epoch [100/160] |	nca: 5.739726729691029, flat: 6.593663245439529, pod: 64.1236846446991, loss: 76.4570746421814 
Train [8/11] | Epoch [101/160] |	nca: 7.998614899814129, flat: 8.568356722593307, pod: 72.7242261171341, loss: 89.29119825363159 
Train [8/11] | Epoch [102/160] |	nca: 5.767719656229019, flat: 6.086007982492447, pod: 62.16575491428375, loss: 74.0194821357727 
Train [8/11] | Epoch [103/160] |	nca: 8.515853755176067, flat: 7.914827436208725, pod: 69.12082719802856, loss: 85.551509141922 
Train [8/11] | Epoch [104/160] |	nca: 6.714535161852837, flat: 7.692988216876984, pod: 67.95137798786163, loss: 82.35890126228333 
Train [8/11] | Epoch [105/160] |	nca: 6.052951971068978, flat: 6.771498620510101, pod: 66.3771265745163, loss: 79.20157742500305 
Train [8/11] | Epoch [106/160] |	nca: 3.6555707305669785, flat: 5.604916512966156, pod: 59.57375955581665, loss: 68.83424663543701 
Train [8/11] | Epoch [107/160] |	nca: 5.273287706077099, flat: 5.435217186808586, pod: 56.892412424087524, loss: 67.60091698169708 
Train [8/11] | Epoch [108/160] |	nca: 5.114080607891083, flat: 6.327714562416077, pod: 62.57492172718048, loss: 74.016716837883 
Train [8/11] | Epoch [109/160] |	nca: 6.720154024660587, flat: 6.071547299623489, pod: 61.26725447177887, loss: 74.05895519256592 
Train [8/11] | Epoch [110/160] |	nca: 7.140399880707264, flat: 7.299388989806175, pod: 67.91876816749573, loss: 82.35855746269226 
Train [8/11] | Epoch [111/160] |	nca: 5.441606096923351, flat: 6.887807473540306, pod: 63.56304228305817, loss: 75.89245581626892 
Train [8/11] | Epoch [112/160] |	nca: 4.967483967542648, flat: 6.637680992484093, pod: 63.742432594299316, loss: 75.34759724140167 
Train [8/11] | Epoch [113/160] |	nca: 5.143032252788544, flat: 6.073296844959259, pod: 58.55148446559906, loss: 69.76781380176544 
Train [8/11] | Epoch [114/160] |	nca: 7.3834215849637985, flat: 6.31769685447216, pod: 60.886765480041504, loss: 74.58788454532623 
Train [8/11] | Epoch [115/160] |	nca: 9.833552673459053, flat: 7.705431029200554, pod: 66.66628551483154, loss: 84.20526933670044 
Train [8/11] | Epoch [116/160] |	nca: 6.022920399904251, flat: 6.98198863863945, pod: 61.98976290225983, loss: 74.99467170238495 
Train [8/11] | Epoch [117/160] |	nca: 5.557625271379948, flat: 6.172605976462364, pod: 61.29271411895752, loss: 73.02294647693634 
Train [8/11] | Epoch [118/160] |	nca: 6.0982968881726265, flat: 7.09999193251133, pod: 62.70334589481354, loss: 75.90163493156433 
Train [8/11] | Epoch [119/160] |	nca: 6.494651779532433, flat: 6.436709523200989, pod: 62.86646246910095, loss: 75.79782366752625 
Train [8/11] | Epoch [120/160] |	nca: 6.132424287497997, flat: 6.114482805132866, pod: 60.01693153381348, loss: 72.26383924484253 
Train [8/11] | Epoch [121/160] |	nca: 10.521213173866272, flat: 6.578791484236717, pod: 62.99892032146454, loss: 80.09892523288727 
Train [8/11] | Epoch [122/160] |	nca: 5.835225246846676, flat: 6.9568284302949905, pod: 61.74024820327759, loss: 74.5323017835617 
Train [8/11] | Epoch [123/160] |	nca: 4.685719899833202, flat: 5.728516101837158, pod: 57.69030773639679, loss: 68.10454428195953 
Train [8/11] | Epoch [124/160] |	nca: 4.837275229394436, flat: 5.569570019841194, pod: 57.37072443962097, loss: 67.77756989002228 
Train [8/11] | Epoch [125/160] |	nca: 4.1971175745129585, flat: 5.521212518215179, pod: 56.78263986110687, loss: 66.5009697675705 
Train [8/11] | Epoch [126/160] |	nca: 4.443057641386986, flat: 5.268841654062271, pod: 55.80587029457092, loss: 65.51776921749115 
Train [8/11] | Epoch [127/160] |	nca: 3.9364978447556496, flat: 5.400036796927452, pod: 55.970377922058105, loss: 65.30691266059875 
Train [8/11] | Epoch [128/160] |	nca: 4.726634964346886, flat: 4.953947797417641, pod: 52.79977834224701, loss: 62.480361223220825 
Train [8/11] | Epoch [129/160] |	nca: 4.528649814426899, flat: 5.238645747303963, pod: 55.374422669410706, loss: 65.14171814918518 
Train [8/11] | Epoch [130/160] |	nca: 3.905783489346504, flat: 4.899717628955841, pod: 53.75112986564636, loss: 62.556630969047546 
Train [8/11] | Epoch [131/160] |	nca: 3.9594764932990074, flat: 5.021209269762039, pod: 53.86383414268494, loss: 62.84451949596405 
Train [8/11] | Epoch [132/160] |	nca: 4.7259470373392105, flat: 4.98618296533823, pod: 52.25962734222412, loss: 61.97175753116608 
Train [8/11] | Epoch [133/160] |	nca: 3.853545959107578, flat: 5.267318621277809, pod: 54.975746393203735, loss: 64.09661090373993 
Train [8/11] | Epoch [134/160] |	nca: 4.140760738402605, flat: 4.531628400087357, pod: 51.59979069232941, loss: 60.27217960357666 
Train [8/11] | Epoch [135/160] |	nca: 4.660004176199436, flat: 4.724451966583729, pod: 51.50208795070648, loss: 60.8865442276001 
Train [8/11] | Epoch [136/160] |	nca: 5.0593637228012085, flat: 4.881611347198486, pod: 51.6879688501358, loss: 61.62894368171692 
Train [8/11] | Epoch [137/160] |	nca: 3.9762435480952263, flat: 4.7100775465369225, pod: 50.560473799705505, loss: 59.24679505825043 
Train [8/11] | Epoch [138/160] |	nca: 4.239684797823429, flat: 4.641555204987526, pod: 50.79860818386078, loss: 59.679847717285156 
Train [8/11] | Epoch [139/160] |	nca: 4.232754863798618, flat: 4.651540890336037, pod: 50.93482744693756, loss: 59.81912350654602 
Train [8/11] | Epoch [140/160] |	nca: 3.3733916506171227, flat: 4.772754602134228, pod: 51.86636531352997, loss: 60.01251149177551 
Train [8/11] | Epoch [141/160] |	nca: 4.72483516484499, flat: 4.835140623152256, pod: 50.30339968204498, loss: 59.8633759021759 
Train [8/11] | Epoch [142/160] |	nca: 3.522555537521839, flat: 4.408634588122368, pod: 49.23691785335541, loss: 57.168107867240906 
Train [8/11] | Epoch [143/160] |	nca: 4.845566883683205, flat: 4.604073643684387, pod: 49.75559675693512, loss: 59.20523726940155 
Train [8/11] | Epoch [144/160] |	nca: 3.45625476539135, flat: 4.4045359417796135, pod: 49.21504628658295, loss: 57.07583689689636 
Train [8/11] | Epoch [145/160] |	nca: 3.3269792310893536, flat: 4.700243443250656, pod: 49.81916093826294, loss: 57.846384048461914 
Train [8/11] | Epoch [146/160] |	nca: 4.150169640779495, flat: 4.725544556975365, pod: 49.383584856987, loss: 58.25929880142212 
Train [8/11] | Epoch [147/160] |	nca: 3.4304816275835037, flat: 4.462351255118847, pod: 48.79867398738861, loss: 56.69150674343109 
Train [8/11] | Epoch [148/160] |	nca: 4.158756956458092, flat: 4.301132149994373, pod: 47.79676425457001, loss: 56.25665366649628 
Train [8/11] | Epoch [149/160] |	nca: 4.081958379596472, flat: 4.571895986795425, pod: 49.14869153499603, loss: 57.80254626274109 
Train [8/11] | Epoch [150/160] |	nca: 3.5791321620345116, flat: 4.415677219629288, pod: 47.933117508888245, loss: 55.927926778793335 
Train [8/11] | Epoch [151/160] |	nca: 3.172137349843979, flat: 4.322199873626232, pod: 48.393282651901245, loss: 55.88762009143829 
Train [8/11] | Epoch [152/160] |	nca: 3.6168908774852753, flat: 4.300432175397873, pod: 48.831241846084595, loss: 56.74856460094452 
Train [8/11] | Epoch [153/160] |	nca: 2.9721551053225994, flat: 4.1772060468792915, pod: 47.23145091533661, loss: 54.38081216812134 
Train [8/11] | Epoch [154/160] |	nca: 3.8633978590369225, flat: 4.445703387260437, pod: 47.86765491962433, loss: 56.176756143569946 
Train [8/11] | Epoch [155/160] |	nca: 3.428497925400734, flat: 4.537256710231304, pod: 49.23681569099426, loss: 57.20257067680359 
Train [8/11] | Epoch [156/160] |	nca: 4.299173027276993, flat: 4.349184408783913, pod: 48.72667384147644, loss: 57.37503135204315 
Train [8/11] | Epoch [157/160] |	nca: 3.003945969045162, flat: 4.2066357880830765, pod: 47.15507972240448, loss: 54.36566150188446 
Train [8/11] | Epoch [158/160] |	nca: 2.96383835375309, flat: 4.171797841787338, pod: 47.19417428970337, loss: 54.32981061935425 
Train [8/11] | Epoch [159/160] |	nca: 4.334675941616297, flat: 4.278863243758678, pod: 48.01176142692566, loss: 56.62530064582825 
Train [8/11] | Epoch [160/160] |	nca: 4.460271883755922, flat: 4.226724423468113, pod: 47.68701195716858, loss: 56.37400817871094 
Fine-tuning
Building & updating memory.
Train [8/11] | Epoch [161/180] |	nca: 2.9556144922971725, flat: 2.260853797197342, pod: 26.043622255325317, loss: 31.260090589523315 
Train [8/11] | Epoch [162/180] |	nca: 1.5154578611254692, flat: 2.221024990081787, pod: 25.70212209224701, loss: 29.438604831695557 
Train [8/11] | Epoch [163/180] |	nca: 1.1592759639024734, flat: 2.235616609454155, pod: 25.884804487228394, loss: 29.279697060585022 
Train [8/11] | Epoch [164/180] |	nca: 1.1809788271784782, flat: 2.1938449442386627, pod: 25.709213376045227, loss: 29.084036469459534 
Train [8/11] | Epoch [165/180] |	nca: 1.172484613955021, flat: 2.2406855672597885, pod: 25.950016260147095, loss: 29.363186478614807 
Train [8/11] | Epoch [166/180] |	nca: 1.1991480067372322, flat: 2.239077612757683, pod: 25.987494826316833, loss: 29.42572009563446 
Train [8/11] | Epoch [167/180] |	nca: 1.0838515907526016, flat: 2.227715954184532, pod: 25.92113757133484, loss: 29.23270535469055 
Train [8/11] | Epoch [168/180] |	nca: 1.1778516843914986, flat: 2.3136670887470245, pod: 26.290125846862793, loss: 29.781644225120544 
Train [8/11] | Epoch [169/180] |	nca: 1.1146756671369076, flat: 2.2238283455371857, pod: 25.960317015647888, loss: 29.298820972442627 
Train [8/11] | Epoch [170/180] |	nca: 1.0158974304795265, flat: 2.2160999849438667, pod: 25.751320004463196, loss: 28.983317136764526 
Train [8/11] | Epoch [171/180] |	nca: 0.9995020367205143, flat: 2.23807929456234, pod: 25.97671365737915, loss: 29.214295029640198 
Train [8/11] | Epoch [172/180] |	nca: 0.9756142646074295, flat: 2.2074231654405594, pod: 25.738409280776978, loss: 28.921446561813354 
Train [8/11] | Epoch [173/180] |	nca: 0.9881124645471573, flat: 2.206248462200165, pod: 25.821579694747925, loss: 29.01594042778015 
Train [8/11] | Epoch [174/180] |	nca: 0.9235936291515827, flat: 2.2474002093076706, pod: 26.299076676368713, loss: 29.470070481300354 
Train [8/11] | Epoch [175/180] |	nca: 0.888334795832634, flat: 2.250678911805153, pod: 26.193645477294922, loss: 29.332659244537354 
Train [8/11] | Epoch [176/180] |	nca: 1.0078042261302471, flat: 2.2196897864341736, pod: 25.713879704475403, loss: 28.941373586654663 
Train [8/11] | Epoch [177/180] |	nca: 0.9440877810120583, flat: 2.262404218316078, pod: 26.076963663101196, loss: 29.28345537185669 
Train [8/11] | Epoch [178/180] |	nca: 0.8636303059756756, flat: 2.271313324570656, pod: 26.01437556743622, loss: 29.149319410324097 
Train [8/11] | Epoch [179/180] |	nca: 0.9445712305605412, flat: 2.3049159198999405, pod: 26.27655339241028, loss: 29.52604067325592 
Train [8/11] | Epoch [180/180] |	nca: 0.8985389992594719, flat: 2.2078536450862885, pod: 25.72001814842224, loss: 28.82641088962555 
after task
Building & updating memory.
after task
Eval on 0->85.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6627500000000001.
Current acc: {'total': 0.583, '00-09': 0.622, '10-19': 0.546, '20-29': 0.486, '30-39': 0.54, '40-49': 0.619, '50-59': 0.575, '60-69': 0.515, '70-79': 0.652, '80-89': 0.808}.
Avg inc acc top5: 0.8953749999999999.
Current acc top5: {'total': 0.856}.
Forgetting: 0.07770000000000003.
Cord metric: 0.66.
Old accuracy: 0.57, mean: 0.64.
New accuracy: 0.81, mean: 0.77.
================Task 8 Start!================
Testing on False unseen tasks (max class = 90).
Set memory of size: 1700.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 8 Training!================
The training samples number: 4200
Train on 85->90.
train task
nb 4200.
Train [9/11] | Epoch [1/160] |	nca: 14.25713711977005, flat: 3.642745263874531, pod: 52.19219672679901, loss: 70.09207940101624 
Train [9/11] | Epoch [2/160] |	nca: 9.304387897253036, flat: 3.471179388463497, pod: 54.339927673339844, loss: 67.1154955625534 
Train [9/11] | Epoch [3/160] |	nca: 7.636985123157501, flat: 3.3577136918902397, pod: 52.143081188201904, loss: 63.13778018951416 
Train [9/11] | Epoch [4/160] |	nca: 7.517613440752029, flat: 3.1553075313568115, pod: 51.4715713262558, loss: 62.14449203014374 
Train [9/11] | Epoch [5/160] |	nca: 7.65733402967453, flat: 3.17593289911747, pod: 52.502888202667236, loss: 63.33615505695343 
Train [9/11] | Epoch [6/160] |	nca: 6.4726748168468475, flat: 3.0862073078751564, pod: 51.27092254161835, loss: 60.82980418205261 
Train [9/11] | Epoch [7/160] |	nca: 6.04966626316309, flat: 3.1836452931165695, pod: 53.196402192115784, loss: 62.42971324920654 
Train [9/11] | Epoch [8/160] |	nca: 6.336430452764034, flat: 3.177459217607975, pod: 51.96262192726135, loss: 61.47651159763336 
Train [9/11] | Epoch [9/160] |	nca: 5.813115112483501, flat: 3.0374494418501854, pod: 50.918073654174805, loss: 59.768638372421265 
Train [9/11] | Epoch [10/160] |	nca: 5.705677703022957, flat: 3.0963250175118446, pod: 50.811797976493835, loss: 59.613800287246704 
Train [9/11] | Epoch [11/160] |	nca: 6.288821414113045, flat: 3.4460645467042923, pod: 53.25908434391022, loss: 62.99397027492523 
Train [9/11] | Epoch [12/160] |	nca: 5.853669710457325, flat: 3.2041415125131607, pod: 51.98637080192566, loss: 61.04418218135834 
Train [9/11] | Epoch [13/160] |	nca: 5.531784377992153, flat: 2.867689922451973, pod: 47.52136826515198, loss: 55.92084240913391 
Train [9/11] | Epoch [14/160] |	nca: 5.3407150357961655, flat: 2.901261016726494, pod: 48.678802132606506, loss: 56.92077815532684 
Train [9/11] | Epoch [15/160] |	nca: 5.280185237526894, flat: 2.883442811667919, pod: 48.51198434829712, loss: 56.67561221122742 
Train [9/11] | Epoch [16/160] |	nca: 5.340602375566959, flat: 3.1222718358039856, pod: 51.18131113052368, loss: 59.644185304641724 
Train [9/11] | Epoch [17/160] |	nca: 5.42195887863636, flat: 2.908355712890625, pod: 47.987186551094055, loss: 56.3175014257431 
Train [9/11] | Epoch [18/160] |	nca: 5.500692941248417, flat: 3.2380393147468567, pod: 51.760531067848206, loss: 60.499263525009155 
Train [9/11] | Epoch [19/160] |	nca: 5.6766577288508415, flat: 3.4454015865921974, pod: 54.35857152938843, loss: 63.4806307554245 
Train [9/11] | Epoch [20/160] |	nca: 5.361012540757656, flat: 3.3882712721824646, pod: 51.987061500549316, loss: 60.736345410346985 
Train [9/11] | Epoch [21/160] |	nca: 5.327505178749561, flat: 3.2307290583848953, pod: 50.527991771698, loss: 59.08622586727142 
Train [9/11] | Epoch [22/160] |	nca: 5.182438962161541, flat: 2.9507627859711647, pod: 47.813838839530945, loss: 55.94704055786133 
Train [9/11] | Epoch [23/160] |	nca: 5.19143133610487, flat: 3.13133192807436, pod: 50.4726984500885, loss: 58.795461773872375 
Train [9/11] | Epoch [24/160] |	nca: 5.792855143547058, flat: 3.5733031034469604, pod: 54.77587342262268, loss: 64.14203190803528 
Train [9/11] | Epoch [25/160] |	nca: 4.963588014245033, flat: 3.245182991027832, pod: 51.97272551059723, loss: 60.181496381759644 
Train [9/11] | Epoch [26/160] |	nca: 5.171706736087799, flat: 3.4308368787169456, pod: 54.696462750434875, loss: 63.29900598526001 
Train [9/11] | Epoch [27/160] |	nca: 5.340129643678665, flat: 3.357758767902851, pod: 52.39940333366394, loss: 61.097291350364685 
Train [9/11] | Epoch [28/160] |	nca: 4.8088304325938225, flat: 3.164913348853588, pod: 51.06795334815979, loss: 59.04169714450836 
Train [9/11] | Epoch [29/160] |	nca: 5.283464431762695, flat: 3.44345186650753, pod: 53.603188276290894, loss: 62.33010447025299 
Train [9/11] | Epoch [30/160] |	nca: 5.223487980663776, flat: 3.3648669868707657, pod: 51.045249223709106, loss: 59.63360416889191 
Train [9/11] | Epoch [31/160] |	nca: 5.253738164901733, flat: 3.3427348509430885, pod: 51.963557839393616, loss: 60.5600301027298 
Train [9/11] | Epoch [32/160] |	nca: 5.1188904121518135, flat: 3.2840769961476326, pod: 51.21322548389435, loss: 59.61619305610657 
Train [9/11] | Epoch [33/160] |	nca: 4.956766426563263, flat: 3.213372476398945, pod: 51.3595404624939, loss: 59.52967929840088 
Train [9/11] | Epoch [34/160] |	nca: 4.968547105789185, flat: 3.3209411948919296, pod: 51.503990054130554, loss: 59.79347848892212 
Train [9/11] | Epoch [35/160] |	nca: 5.229494154453278, flat: 3.3819904774427414, pod: 52.71548628807068, loss: 61.32697105407715 
Train [9/11] | Epoch [36/160] |	nca: 5.004560820758343, flat: 3.1813026070594788, pod: 50.92219650745392, loss: 59.108059763908386 
Train [9/11] | Epoch [37/160] |	nca: 5.161520101130009, flat: 3.2109623178839684, pod: 50.709962010383606, loss: 59.08244466781616 
Train [9/11] | Epoch [38/160] |	nca: 4.6841530203819275, flat: 2.9940697699785233, pod: 48.51226830482483, loss: 56.19049108028412 
Train [9/11] | Epoch [39/160] |	nca: 4.563259266316891, flat: 3.0185435861349106, pod: 48.90498924255371, loss: 56.48679184913635 
Train [9/11] | Epoch [40/160] |	nca: 4.734196096658707, flat: 3.191928319633007, pod: 50.91197144985199, loss: 58.838096141815186 
Train [9/11] | Epoch [41/160] |	nca: 4.283248700201511, flat: 2.8053251430392265, pod: 47.0199716091156, loss: 54.108545660972595 
Train [9/11] | Epoch [42/160] |	nca: 4.54840574413538, flat: 2.822177730500698, pod: 47.61157548427582, loss: 54.98215913772583 
Train [9/11] | Epoch [43/160] |	nca: 5.003764905035496, flat: 3.116861969232559, pod: 49.34290838241577, loss: 57.46353530883789 
Train [9/11] | Epoch [44/160] |	nca: 4.546214863657951, flat: 3.0584575086832047, pod: 48.48659670352936, loss: 56.09126901626587 
Train [9/11] | Epoch [45/160] |	nca: 5.02743923664093, flat: 3.1328062266111374, pod: 50.357595920562744, loss: 58.51784157752991 
Train [9/11] | Epoch [46/160] |	nca: 4.713840693235397, flat: 3.067843921482563, pod: 48.64802968502045, loss: 56.42971432209015 
Train [9/11] | Epoch [47/160] |	nca: 4.427100487053394, flat: 2.9925597831606865, pod: 50.82399523258209, loss: 58.24365556240082 
Train [9/11] | Epoch [48/160] |	nca: 4.728812895715237, flat: 2.8472645431756973, pod: 47.321369767189026, loss: 54.89744758605957 
Train [9/11] | Epoch [49/160] |	nca: 4.54163084179163, flat: 3.0046879574656487, pod: 50.096051812171936, loss: 57.64237034320831 
Train [9/11] | Epoch [50/160] |	nca: 4.293336920440197, flat: 2.7714224085211754, pod: 47.615118861198425, loss: 54.67987823486328 
Train [9/11] | Epoch [51/160] |	nca: 4.482285030186176, flat: 2.8222054690122604, pod: 47.583078145980835, loss: 54.88756883144379 
Train [9/11] | Epoch [52/160] |	nca: 4.493696331977844, flat: 2.6896062791347504, pod: 45.65357267856598, loss: 52.836875438690186 
Train [9/11] | Epoch [53/160] |	nca: 4.722973175346851, flat: 3.1493897512555122, pod: 49.6525696516037, loss: 57.52493214607239 
Train [9/11] | Epoch [54/160] |	nca: 4.781356744468212, flat: 2.970145493745804, pod: 48.310651540756226, loss: 56.062153458595276 
Train [9/11] | Epoch [55/160] |	nca: 4.192868568003178, flat: 2.7677081301808357, pod: 45.990670800209045, loss: 52.951247453689575 
Train [9/11] | Epoch [56/160] |	nca: 4.254920341074467, flat: 2.633501797914505, pod: 45.64890992641449, loss: 52.53733229637146 
Train [9/11] | Epoch [57/160] |	nca: 4.515877090394497, flat: 2.8637205213308334, pod: 48.62424623966217, loss: 56.003843903541565 
Train [9/11] | Epoch [58/160] |	nca: 4.804301291704178, flat: 2.8951648995280266, pod: 48.273154854774475, loss: 55.97262096405029 
Train [9/11] | Epoch [59/160] |	nca: 4.604490354657173, flat: 2.9030108004808426, pod: 48.29470229148865, loss: 55.80220353603363 
Train [9/11] | Epoch [60/160] |	nca: 4.471008218824863, flat: 2.9549862071871758, pod: 50.10876500606537, loss: 57.534759640693665 
Train [9/11] | Epoch [61/160] |	nca: 4.369344264268875, flat: 2.6571747586131096, pod: 45.57945120334625, loss: 52.60597026348114 
Train [9/11] | Epoch [62/160] |	nca: 4.1142295226454735, flat: 2.5620293095707893, pod: 44.95371651649475, loss: 51.62997543811798 
Train [9/11] | Epoch [63/160] |	nca: 4.31614301353693, flat: 2.6146222352981567, pod: 46.28243827819824, loss: 53.21320354938507 
Train [9/11] | Epoch [64/160] |	nca: 4.447932355105877, flat: 2.77667473256588, pod: 46.92563474178314, loss: 54.15024197101593 
Train [9/11] | Epoch [65/160] |	nca: 4.483663871884346, flat: 3.0315906554460526, pod: 49.17077970504761, loss: 56.686034202575684 
Train [9/11] | Epoch [66/160] |	nca: 4.5040862411260605, flat: 2.603552259504795, pod: 44.76196789741516, loss: 51.869606733322144 
Train [9/11] | Epoch [67/160] |	nca: 4.17831426858902, flat: 2.7220212891697884, pod: 46.23972761631012, loss: 53.140063524246216 
Train [9/11] | Epoch [68/160] |	nca: 4.11596967279911, flat: 2.5407747477293015, pod: 44.501476883888245, loss: 51.1582213640213 
Train [9/11] | Epoch [69/160] |	nca: 3.9381383135914803, flat: 2.2708296068012714, pod: 40.9333781003952, loss: 47.142346024513245 
Train [9/11] | Epoch [70/160] |	nca: 4.1695776134729385, flat: 2.4281679205596447, pod: 44.9058256149292, loss: 51.50357115268707 
Train [9/11] | Epoch [71/160] |	nca: 4.1738069504499435, flat: 2.7037301510572433, pod: 45.92580854892731, loss: 52.803345680236816 
Train [9/11] | Epoch [72/160] |	nca: 4.200433202087879, flat: 2.569442018866539, pod: 45.114928007125854, loss: 51.88480353355408 
Train [9/11] | Epoch [73/160] |	nca: 4.275434270501137, flat: 2.485136829316616, pod: 43.66959083080292, loss: 50.43016171455383 
Train [9/11] | Epoch [74/160] |	nca: 4.111099153757095, flat: 2.3630362264811993, pod: 41.92551672458649, loss: 48.39965236186981 
Train [9/11] | Epoch [75/160] |	nca: 3.927717126905918, flat: 2.35891005769372, pod: 43.046730399131775, loss: 49.33335769176483 
Train [9/11] | Epoch [76/160] |	nca: 4.236118346452713, flat: 2.3776960112154484, pod: 43.7188538312912, loss: 50.33266854286194 
Train [9/11] | Epoch [77/160] |	nca: 3.9910440295934677, flat: 2.33405202627182, pod: 42.507128953933716, loss: 48.83222472667694 
Train [9/11] | Epoch [78/160] |	nca: 3.9374103620648384, flat: 2.266332697123289, pod: 42.08411526679993, loss: 48.28785824775696 
Train [9/11] | Epoch [79/160] |	nca: 4.16017509251833, flat: 2.369500420987606, pod: 43.955347299575806, loss: 50.48502242565155 
Train [9/11] | Epoch [80/160] |	nca: 3.9697085097432137, flat: 2.378304686397314, pod: 43.17208743095398, loss: 49.520100474357605 
Train [9/11] | Epoch [81/160] |	nca: 3.9133217707276344, flat: 2.245874345302582, pod: 41.7024941444397, loss: 47.8616898059845 
Train [9/11] | Epoch [82/160] |	nca: 3.9242002218961716, flat: 2.1091719828546047, pod: 40.111565589904785, loss: 46.14493787288666 
Train [9/11] | Epoch [83/160] |	nca: 3.882271759212017, flat: 2.382701426744461, pod: 43.2481826543808, loss: 49.513155698776245 
Train [9/11] | Epoch [84/160] |	nca: 4.194028049707413, flat: 2.285491582006216, pod: 43.23994708061218, loss: 49.7194664478302 
Train [9/11] | Epoch [85/160] |	nca: 3.8648731037974358, flat: 2.1161078698933125, pod: 40.12388575077057, loss: 46.10486686229706 
Train [9/11] | Epoch [86/160] |	nca: 3.6366314813494682, flat: 1.9393562860786915, pod: 37.84209418296814, loss: 43.41808199882507 
Train [9/11] | Epoch [87/160] |	nca: 3.775717593729496, flat: 2.0292832627892494, pod: 38.3211669921875, loss: 44.12616777420044 
Train [9/11] | Epoch [88/160] |	nca: 3.8042124584317207, flat: 2.1519411765038967, pod: 39.99932587146759, loss: 45.955479860305786 
Train [9/11] | Epoch [89/160] |	nca: 3.7721178010106087, flat: 1.9777669049799442, pod: 38.697041034698486, loss: 44.44692587852478 
Train [9/11] | Epoch [90/160] |	nca: 3.673382416367531, flat: 2.0180757716298103, pod: 39.37682902812958, loss: 45.06828689575195 
Train [9/11] | Epoch [91/160] |	nca: 3.6667144894599915, flat: 2.009132917970419, pod: 40.640531063079834, loss: 46.3163788318634 
Train [9/11] | Epoch [92/160] |	nca: 3.755829058587551, flat: 1.8040338903665543, pod: 36.63970923423767, loss: 42.1995724439621 
Train [9/11] | Epoch [93/160] |	nca: 3.322272878140211, flat: 1.7340592257678509, pod: 35.845294773578644, loss: 40.90162694454193 
Train [9/11] | Epoch [94/160] |	nca: 3.600692167878151, flat: 1.7807584330439568, pod: 36.69430327415466, loss: 42.075753808021545 
Train [9/11] | Epoch [95/160] |	nca: 3.8155464455485344, flat: 1.872618380934, pod: 37.392466962337494, loss: 43.080631732940674 
Train [9/11] | Epoch [96/160] |	nca: 3.878915823996067, flat: 1.8443561643362045, pod: 37.16671967506409, loss: 42.889991879463196 
Train [9/11] | Epoch [97/160] |	nca: 3.7196281626820564, flat: 2.0236851312220097, pod: 39.04240334033966, loss: 44.78571665287018 
Train [9/11] | Epoch [98/160] |	nca: 3.3406003043055534, flat: 1.6036313436925411, pod: 33.64977043867111, loss: 38.59400200843811 
Train [9/11] | Epoch [99/160] |	nca: 3.7629705145955086, flat: 1.7285979464650154, pod: 37.02817404270172, loss: 42.519742369651794 
Train [9/11] | Epoch [100/160] |	nca: 3.5613197833299637, flat: 1.705213502049446, pod: 36.5650709271431, loss: 41.83160388469696 
Train [9/11] | Epoch [101/160] |	nca: 3.4516749009490013, flat: 1.7072272822260857, pod: 36.17517018318176, loss: 41.33407247066498 
Train [9/11] | Epoch [102/160] |	nca: 3.605551280081272, flat: 1.654960509389639, pod: 34.64979165792465, loss: 39.910303592681885 
Train [9/11] | Epoch [103/160] |	nca: 3.713816836476326, flat: 1.690689641982317, pod: 34.72474133968353, loss: 40.12924790382385 
Train [9/11] | Epoch [104/160] |	nca: 3.5180485770106316, flat: 1.661038015037775, pod: 34.97580063343048, loss: 40.154887318611145 
Train [9/11] | Epoch [105/160] |	nca: 3.634044662117958, flat: 1.7572328746318817, pod: 36.15669637918472, loss: 41.54797410964966 
Train [9/11] | Epoch [106/160] |	nca: 3.430445469915867, flat: 1.5911855064332485, pod: 34.05896836519241, loss: 39.080599427223206 
Train [9/11] | Epoch [107/160] |	nca: 3.297506406903267, flat: 1.5034086965024471, pod: 32.852993845939636, loss: 37.6539089679718 
Train [9/11] | Epoch [108/160] |	nca: 3.5480247028172016, flat: 1.5703978054225445, pod: 35.86150860786438, loss: 40.979931354522705 
Train [9/11] | Epoch [109/160] |	nca: 3.571703165769577, flat: 1.6261773332953453, pod: 34.36159133911133, loss: 39.55947148799896 
Train [9/11] | Epoch [110/160] |	nca: 3.418374702334404, flat: 1.5507880188524723, pod: 34.380227744579315, loss: 39.349390506744385 
Train [9/11] | Epoch [111/160] |	nca: 3.441071033477783, flat: 1.4980831369757652, pod: 33.11272007226944, loss: 38.05187427997589 
Train [9/11] | Epoch [112/160] |	nca: 3.4289509877562523, flat: 1.5082799419760704, pod: 33.121993243694305, loss: 38.0592240691185 
Train [9/11] | Epoch [113/160] |	nca: 3.4087091013789177, flat: 1.3422600105404854, pod: 30.316390812397003, loss: 35.067360043525696 
Train [9/11] | Epoch [114/160] |	nca: 3.4072295799851418, flat: 1.401349475607276, pod: 31.47417652606964, loss: 36.28275519609451 
Train [9/11] | Epoch [115/160] |	nca: 3.403914101421833, flat: 1.427929013967514, pod: 32.19782418012619, loss: 37.029667139053345 
Train [9/11] | Epoch [116/160] |	nca: 3.372503936290741, flat: 1.405074167996645, pod: 31.148309230804443, loss: 35.92588746547699 
Train [9/11] | Epoch [117/160] |	nca: 3.3388632014393806, flat: 1.383965115994215, pod: 31.45375168323517, loss: 36.17657995223999 
Train [9/11] | Epoch [118/160] |	nca: 3.3267219811677933, flat: 1.294806532561779, pod: 30.051973402500153, loss: 34.673501908779144 
Train [9/11] | Epoch [119/160] |	nca: 3.2934938818216324, flat: 1.2982717081904411, pod: 30.485461354255676, loss: 35.0772271156311 
Train [9/11] | Epoch [120/160] |	nca: 3.311526872217655, flat: 1.2118942569941282, pod: 28.515975415706635, loss: 33.03939646482468 
Train [9/11] | Epoch [121/160] |	nca: 3.350047565996647, flat: 1.214745182543993, pod: 29.518754184246063, loss: 34.08354687690735 
Train [9/11] | Epoch [122/160] |	nca: 3.45819403976202, flat: 1.2601155079901218, pod: 29.648536384105682, loss: 34.36684602499008 
Train [9/11] | Epoch [123/160] |	nca: 3.3183087706565857, flat: 1.26737947948277, pod: 29.33931601047516, loss: 33.925004065036774 
Train [9/11] | Epoch [124/160] |	nca: 3.43244756013155, flat: 1.3035402931272984, pod: 30.856260061264038, loss: 35.59224796295166 
Train [9/11] | Epoch [125/160] |	nca: 3.373580127954483, flat: 1.2956814672797918, pod: 30.444975554943085, loss: 35.11423712968826 
Train [9/11] | Epoch [126/160] |	nca: 3.2369393333792686, flat: 1.3100958857685328, pod: 30.36698967218399, loss: 34.91402471065521 
Train [9/11] | Epoch [127/160] |	nca: 3.1708667278289795, flat: 1.143405856564641, pod: 28.249560594558716, loss: 32.563833117485046 
Train [9/11] | Epoch [128/160] |	nca: 3.2241735234856606, flat: 1.187965665012598, pod: 28.607034623622894, loss: 33.01917368173599 
Train [9/11] | Epoch [129/160] |	nca: 3.1510954424738884, flat: 1.1365019772201777, pod: 27.37087517976761, loss: 31.658472537994385 
Train [9/11] | Epoch [130/160] |	nca: 3.1373886093497276, flat: 1.130252830684185, pod: 27.67442661523819, loss: 31.94206804037094 
Train [9/11] | Epoch [131/160] |	nca: 3.2477880641818047, flat: 1.1095725893974304, pod: 27.165953516960144, loss: 31.52331405878067 
Train [9/11] | Epoch [132/160] |	nca: 3.0830407813191414, flat: 1.075198182836175, pod: 26.672856509685516, loss: 30.831095814704895 
Train [9/11] | Epoch [133/160] |	nca: 3.2084546983242035, flat: 1.0399539228528738, pod: 26.012023508548737, loss: 30.26043200492859 
Train [9/11] | Epoch [134/160] |	nca: 3.3458527475595474, flat: 1.094290429726243, pod: 26.63141894340515, loss: 31.071562230587006 
Train [9/11] | Epoch [135/160] |	nca: 3.177660435438156, flat: 1.0935647264122963, pod: 26.98208087682724, loss: 31.253306210041046 
Train [9/11] | Epoch [136/160] |	nca: 3.1096637584269047, flat: 1.0671363770961761, pod: 27.299230992794037, loss: 31.47603076696396 
Train [9/11] | Epoch [137/160] |	nca: 3.2937564477324486, flat: 1.0515980254858732, pod: 26.30486673116684, loss: 30.650221467018127 
Train [9/11] | Epoch [138/160] |	nca: 3.1331675052642822, flat: 1.018009427934885, pod: 25.93121427297592, loss: 30.082391142845154 
Train [9/11] | Epoch [139/160] |	nca: 3.1904454305768013, flat: 1.0423081070184708, pod: 26.177645325660706, loss: 30.4103986620903 
Train [9/11] | Epoch [140/160] |	nca: 3.2446825802326202, flat: 1.0020422283560038, pod: 25.521375119686127, loss: 29.76809996366501 
Train [9/11] | Epoch [141/160] |	nca: 3.3342389985919, flat: 0.9936311990022659, pod: 25.34096795320511, loss: 29.668838262557983 
Train [9/11] | Epoch [142/160] |	nca: 3.003831274807453, flat: 1.0182770676910877, pod: 26.00503432750702, loss: 30.027142822742462 
Train [9/11] | Epoch [143/160] |	nca: 3.1479268297553062, flat: 0.9836316518485546, pod: 25.138803601264954, loss: 29.270362079143524 
Train [9/11] | Epoch [144/160] |	nca: 3.1603449285030365, flat: 0.9163128770887852, pod: 23.994456350803375, loss: 28.07111406326294 
Train [9/11] | Epoch [145/160] |	nca: 3.172515980899334, flat: 0.9545156061649323, pod: 24.4794939160347, loss: 28.60652530193329 
Train [9/11] | Epoch [146/160] |	nca: 3.030339539051056, flat: 0.9267837293446064, pod: 23.921984493732452, loss: 27.87910783290863 
Train [9/11] | Epoch [147/160] |	nca: 3.2246051877737045, flat: 0.9160976447165012, pod: 23.951390862464905, loss: 28.092093467712402 
Train [9/11] | Epoch [148/160] |	nca: 3.1608776673674583, flat: 0.9278775434941053, pod: 23.988131642341614, loss: 28.076887130737305 
Train [9/11] | Epoch [149/160] |	nca: 3.167402606457472, flat: 0.9603453353047371, pod: 24.06676560640335, loss: 28.19451355934143 
Train [9/11] | Epoch [150/160] |	nca: 3.1341349855065346, flat: 0.9029264952987432, pod: 23.353731632232666, loss: 27.390792846679688 
Train [9/11] | Epoch [151/160] |	nca: 3.2376173585653305, flat: 0.8922780137509108, pod: 22.79207944869995, loss: 26.92197471857071 
Train [9/11] | Epoch [152/160] |	nca: 3.284239314496517, flat: 0.9312407169491053, pod: 23.635165631771088, loss: 27.850645661354065 
Train [9/11] | Epoch [153/160] |	nca: 3.034431643784046, flat: 0.884053111076355, pod: 22.82659423351288, loss: 26.745079040527344 
Train [9/11] | Epoch [154/160] |	nca: 3.081953313201666, flat: 0.8439551312476397, pod: 22.572679042816162, loss: 26.498587369918823 
Train [9/11] | Epoch [155/160] |	nca: 3.0911043733358383, flat: 0.888840364292264, pod: 22.593189358711243, loss: 26.573134064674377 
Train [9/11] | Epoch [156/160] |	nca: 3.0409392714500427, flat: 0.825941463932395, pod: 21.340256690979004, loss: 25.207137644290924 
Train [9/11] | Epoch [157/160] |	nca: 3.1211791187524796, flat: 0.8237203266471624, pod: 21.438573122024536, loss: 25.383472561836243 
Train [9/11] | Epoch [158/160] |	nca: 3.1253947652876377, flat: 0.8906012661755085, pod: 22.84279888868332, loss: 26.85879498720169 
Train [9/11] | Epoch [159/160] |	nca: 3.0439572036266327, flat: 0.8618115093559027, pod: 22.096904814243317, loss: 26.002673506736755 
Train [9/11] | Epoch [160/160] |	nca: 3.0748964101076126, flat: 0.8512590453028679, pod: 21.975463807582855, loss: 25.9016193151474 
Fine-tuning
Building & updating memory.
Train [9/11] | Epoch [161/180] |	nca: 2.1880007311701775, flat: 1.0786803402006626, pod: 19.502223551273346, loss: 22.768904328346252 
Train [9/11] | Epoch [162/180] |	nca: 2.5286350697278976, flat: 1.1084814369678497, pod: 19.017240047454834, loss: 22.654356598854065 
Train [9/11] | Epoch [163/180] |	nca: 2.340451382100582, flat: 1.093606397509575, pod: 19.265289545059204, loss: 22.699347376823425 
Train [9/11] | Epoch [164/180] |	nca: 2.2798985838890076, flat: 1.1706828214228153, pod: 19.31486201286316, loss: 22.765443325042725 
Train [9/11] | Epoch [165/180] |	nca: 2.7139195427298546, flat: 1.1667084358632565, pod: 19.73947101831436, loss: 23.62009871006012 
Train [9/11] | Epoch [166/180] |	nca: 2.270418107509613, flat: 1.1508439518511295, pod: 19.604420065879822, loss: 23.02568209171295 
Train [9/11] | Epoch [167/180] |	nca: 1.9378295615315437, flat: 1.1702910587191582, pod: 19.46676617860794, loss: 22.574886798858643 
Train [9/11] | Epoch [168/180] |	nca: 2.538592327386141, flat: 1.161719560623169, pod: 19.909555315971375, loss: 23.609867215156555 
Train [9/11] | Epoch [169/180] |	nca: 2.4175021201372147, flat: 1.1650693714618683, pod: 19.593717217445374, loss: 23.176288723945618 
Train [9/11] | Epoch [170/180] |	nca: 2.444862201809883, flat: 1.0822168327867985, pod: 19.77732253074646, loss: 23.304401636123657 
Train [9/11] | Epoch [171/180] |	nca: 3.5453845486044884, flat: 1.1674962751567364, pod: 20.100533962249756, loss: 24.813414931297302 
Train [9/11] | Epoch [172/180] |	nca: 3.189771741628647, flat: 1.097382415086031, pod: 19.570005655288696, loss: 23.857159972190857 
Train [9/11] | Epoch [173/180] |	nca: 2.3711870908737183, flat: 1.0887945964932442, pod: 18.951618909835815, loss: 22.411600828170776 
Train [9/11] | Epoch [174/180] |	nca: 2.091919768601656, flat: 1.1752098836004734, pod: 19.560712099075317, loss: 22.82784152030945 
Train [9/11] | Epoch [175/180] |	nca: 2.0607292130589485, flat: 1.1732965148985386, pod: 19.77553963661194, loss: 23.009565472602844 
Train [9/11] | Epoch [176/180] |	nca: 2.116808220744133, flat: 1.1847539395093918, pod: 19.974024415016174, loss: 23.27558660507202 
Train [9/11] | Epoch [177/180] |	nca: 3.094180129468441, flat: 1.1544554233551025, pod: 19.97652566432953, loss: 24.22516143321991 
Train [9/11] | Epoch [178/180] |	nca: 3.56736621260643, flat: 1.1654436513781548, pod: 19.206649482250214, loss: 23.939459562301636 
Train [9/11] | Epoch [179/180] |	nca: 3.196695774793625, flat: 1.2670075111091137, pod: 20.46187162399292, loss: 24.925574898719788 
Train [9/11] | Epoch [180/180] |	nca: 2.641409456729889, flat: 1.0888999588787556, pod: 18.965047776699066, loss: 22.69535732269287 
after task
Building & updating memory.
after task
Eval on 0->90.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6507777777777778.
Current acc: {'total': 0.555, '00-09': 0.629, '10-19': 0.513, '20-29': 0.447, '30-39': 0.55, '40-49': 0.569, '50-59': 0.546, '60-69': 0.485, '70-79': 0.56, '80-89': 0.692}.
Avg inc acc top5: 0.8888888888888888.
Current acc top5: {'total': 0.837}.
Forgetting: 0.1957.
Cord metric: 0.65.
Old accuracy: 0.54, mean: 0.63.
New accuracy: 0.73, mean: 0.76.
================Task 9 Start!================
Testing on False unseen tasks (max class = 95).
Set memory of size: 1800.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 9 Training!================
The training samples number: 4300
Train on 90->95.
train task
nb 4300.
Train [10/11] | Epoch [1/160] |	nca: 32.99403262138367, flat: 9.634921841323376, pod: 82.31216084957123, loss: 124.9411153793335 
Train [10/11] | Epoch [2/160] |	nca: 28.65943467617035, flat: 12.556078463792801, pod: 99.16575622558594, loss: 140.3812701702118 
Train [10/11] | Epoch [3/160] |	nca: 20.081368058919907, flat: 9.827804982662201, pod: 86.72917437553406, loss: 116.63834714889526 
Train [10/11] | Epoch [4/160] |	nca: 15.714334070682526, flat: 7.900979161262512, pod: 78.52067589759827, loss: 102.13598942756653 
Train [10/11] | Epoch [5/160] |	nca: 12.841747045516968, flat: 7.028749004006386, pod: 73.74008893966675, loss: 93.61058449745178 
Train [10/11] | Epoch [6/160] |	nca: 11.68805930018425, flat: 6.340508803725243, pod: 69.57089006900787, loss: 87.59945821762085 
Train [10/11] | Epoch [7/160] |	nca: 10.876956462860107, flat: 5.940547361969948, pod: 67.77072775363922, loss: 84.58823132514954 
Train [10/11] | Epoch [8/160] |	nca: 10.173347055912018, flat: 5.726185753941536, pod: 66.14451348781586, loss: 82.04404592514038 
Train [10/11] | Epoch [9/160] |	nca: 10.133895501494408, flat: 5.565096914768219, pod: 65.3687025308609, loss: 81.06769514083862 
Train [10/11] | Epoch [10/160] |	nca: 9.830420777201653, flat: 5.889677122235298, pod: 67.36703884601593, loss: 83.08713626861572 
Train [10/11] | Epoch [11/160] |	nca: 9.249352425336838, flat: 5.327989310026169, pod: 65.23004066944122, loss: 79.80738282203674 
Train [10/11] | Epoch [12/160] |	nca: 9.60680666565895, flat: 5.338627472519875, pod: 63.986576318740845, loss: 78.93201065063477 
Train [10/11] | Epoch [13/160] |	nca: 9.883405014872551, flat: 5.48210434615612, pod: 64.86379206180573, loss: 80.22930145263672 
Train [10/11] | Epoch [14/160] |	nca: 9.820784628391266, flat: 5.645063206553459, pod: 63.93842327594757, loss: 79.40427160263062 
Train [10/11] | Epoch [15/160] |	nca: 9.383922979235649, flat: 5.529316544532776, pod: 64.68690121173859, loss: 79.60014009475708 
Train [10/11] | Epoch [16/160] |	nca: 9.042460486292839, flat: 5.500456273555756, pod: 65.62716114521027, loss: 80.17007851600647 
Train [10/11] | Epoch [17/160] |	nca: 8.517967462539673, flat: 5.221994951367378, pod: 63.055949687957764, loss: 76.79591155052185 
Train [10/11] | Epoch [18/160] |	nca: 7.9147613644599915, flat: 5.046263143420219, pod: 62.82584357261658, loss: 75.78686761856079 
Train [10/11] | Epoch [19/160] |	nca: 8.072756066918373, flat: 5.181002855300903, pod: 64.36570692062378, loss: 77.61946558952332 
Train [10/11] | Epoch [20/160] |	nca: 7.216972842812538, flat: 4.617931045591831, pod: 59.45318686962128, loss: 71.28809070587158 
Train [10/11] | Epoch [21/160] |	nca: 7.856808185577393, flat: 4.476894997060299, pod: 57.73923861980438, loss: 70.07294130325317 
Train [10/11] | Epoch [22/160] |	nca: 7.393807902932167, flat: 4.593329168856144, pod: 60.15666592121124, loss: 72.14380252361298 
Train [10/11] | Epoch [23/160] |	nca: 7.41709940135479, flat: 4.4778149127960205, pod: 58.104875326156616, loss: 69.99978971481323 
Train [10/11] | Epoch [24/160] |	nca: 7.544889956712723, flat: 4.60093430429697, pod: 58.713064432144165, loss: 70.85888886451721 
Train [10/11] | Epoch [25/160] |	nca: 7.793227583169937, flat: 4.661728784441948, pod: 59.430479407310486, loss: 71.88543593883514 
Train [10/11] | Epoch [26/160] |	nca: 7.664085671305656, flat: 4.660642132163048, pod: 59.16608452796936, loss: 71.49081230163574 
Train [10/11] | Epoch [27/160] |	nca: 7.480177707970142, flat: 4.593768440186977, pod: 59.90337908267975, loss: 71.97732532024384 
Train [10/11] | Epoch [28/160] |	nca: 7.5008687525987625, flat: 4.4463701993227005, pod: 59.72633492946625, loss: 71.67357420921326 
Train [10/11] | Epoch [29/160] |	nca: 6.9238221645355225, flat: 4.3645999655127525, pod: 57.494470834732056, loss: 68.78289270401001 
Train [10/11] | Epoch [30/160] |	nca: 7.3595703691244125, flat: 4.43067042529583, pod: 58.34673452377319, loss: 70.1369754076004 
Train [10/11] | Epoch [31/160] |	nca: 7.82852029800415, flat: 5.004725396633148, pod: 62.13608372211456, loss: 74.96932888031006 
Train [10/11] | Epoch [32/160] |	nca: 6.764894261956215, flat: 4.3085086196660995, pod: 57.41507911682129, loss: 68.4884819984436 
Train [10/11] | Epoch [33/160] |	nca: 8.050107851624489, flat: 4.777117311954498, pod: 61.989041447639465, loss: 74.81626629829407 
Train [10/11] | Epoch [34/160] |	nca: 6.655311033129692, flat: 4.293442532420158, pod: 57.056694746017456, loss: 68.00544857978821 
Train [10/11] | Epoch [35/160] |	nca: 6.971288651227951, flat: 4.275864690542221, pod: 56.72403335571289, loss: 67.97118639945984 
Train [10/11] | Epoch [36/160] |	nca: 6.7859495878219604, flat: 4.475288115441799, pod: 59.14657247066498, loss: 70.40781044960022 
Train [10/11] | Epoch [37/160] |	nca: 7.045221343636513, flat: 4.1673682034015656, pod: 56.2682466506958, loss: 67.4808360338211 
Train [10/11] | Epoch [38/160] |	nca: 6.835761770606041, flat: 4.245723195374012, pod: 57.020278096199036, loss: 68.10176289081573 
Train [10/11] | Epoch [39/160] |	nca: 6.528748758137226, flat: 4.096911266446114, pod: 55.96382713317871, loss: 66.58948695659637 
Train [10/11] | Epoch [40/160] |	nca: 5.935467593371868, flat: 3.8881338015198708, pod: 55.261494398117065, loss: 65.08509564399719 
Train [10/11] | Epoch [41/160] |	nca: 6.546541526913643, flat: 4.278842955827713, pod: 59.20420777797699, loss: 70.02959263324738 
Train [10/11] | Epoch [42/160] |	nca: 6.607354998588562, flat: 4.107320390641689, pod: 56.55293655395508, loss: 67.26761186122894 
Train [10/11] | Epoch [43/160] |	nca: 6.353712186217308, flat: 3.8999445661902428, pod: 54.45493245124817, loss: 64.70858919620514 
Train [10/11] | Epoch [44/160] |	nca: 6.764427557587624, flat: 4.099645860493183, pod: 55.640352964401245, loss: 66.50442659854889 
Train [10/11] | Epoch [45/160] |	nca: 6.556700222194195, flat: 3.897427909076214, pod: 54.26973259449005, loss: 64.72386121749878 
Train [10/11] | Epoch [46/160] |	nca: 6.279760934412479, flat: 3.664146840572357, pod: 51.8788081407547, loss: 61.8227162361145 
Train [10/11] | Epoch [47/160] |	nca: 5.776851259171963, flat: 3.5718990191817284, pod: 52.845738887786865, loss: 62.19448912143707 
Train [10/11] | Epoch [48/160] |	nca: 6.8264394998550415, flat: 4.079843185842037, pod: 55.757978439331055, loss: 66.66426134109497 
Train [10/11] | Epoch [49/160] |	nca: 6.004643134772778, flat: 3.7275547236204147, pod: 53.04654085636139, loss: 62.77873885631561 
Train [10/11] | Epoch [50/160] |	nca: 6.481629371643066, flat: 3.8658025041222572, pod: 53.19644093513489, loss: 63.54387283325195 
Train [10/11] | Epoch [51/160] |	nca: 6.594671353697777, flat: 3.857235588133335, pod: 54.74273884296417, loss: 65.1946462392807 
Train [10/11] | Epoch [52/160] |	nca: 6.302082024514675, flat: 3.83551699668169, pod: 54.377358078956604, loss: 64.51495671272278 
Train [10/11] | Epoch [53/160] |	nca: 6.252560518682003, flat: 3.733834147453308, pod: 53.12141311168671, loss: 63.107807874679565 
Train [10/11] | Epoch [54/160] |	nca: 6.276838183403015, flat: 3.6590020582079887, pod: 52.688008069992065, loss: 62.62384855747223 
Train [10/11] | Epoch [55/160] |	nca: 5.917723067104816, flat: 3.5502691119909286, pod: 51.35201418399811, loss: 60.82000660896301 
Train [10/11] | Epoch [56/160] |	nca: 5.619017146527767, flat: 3.3464497700333595, pod: 49.402249455451965, loss: 58.36771619319916 
Train [10/11] | Epoch [57/160] |	nca: 5.580479010939598, flat: 3.4608783945441246, pod: 51.21116280555725, loss: 60.2525200843811 
Train [10/11] | Epoch [58/160] |	nca: 6.256655476987362, flat: 3.442595973610878, pod: 49.82636868953705, loss: 59.525620222091675 
Train [10/11] | Epoch [59/160] |	nca: 6.377922400832176, flat: 3.594420075416565, pod: 51.749918818473816, loss: 61.7222615480423 
Train [10/11] | Epoch [60/160] |	nca: 6.262368083000183, flat: 3.7105842754244804, pod: 54.01918399333954, loss: 63.992136120796204 
Train [10/11] | Epoch [61/160] |	nca: 5.958308562636375, flat: 3.6982341706752777, pod: 53.104153871536255, loss: 62.76069676876068 
Train [10/11] | Epoch [62/160] |	nca: 5.7699830532073975, flat: 3.4232700765132904, pod: 50.96104884147644, loss: 60.15430212020874 
Train [10/11] | Epoch [63/160] |	nca: 6.293774165213108, flat: 3.6046261191368103, pod: 51.17953014373779, loss: 61.077930331230164 
Train [10/11] | Epoch [64/160] |	nca: 6.294837258756161, flat: 3.6326686665415764, pod: 51.56715941429138, loss: 61.49466574192047 
Train [10/11] | Epoch [65/160] |	nca: 6.000202834606171, flat: 3.7458640560507774, pod: 52.76466500759125, loss: 62.51073181629181 
Train [10/11] | Epoch [66/160] |	nca: 5.691223703324795, flat: 3.232064999639988, pod: 48.96692097187042, loss: 57.890209436416626 
Train [10/11] | Epoch [67/160] |	nca: 5.312693797051907, flat: 3.119324252009392, pod: 47.59425759315491, loss: 56.026275634765625 
Train [10/11] | Epoch [68/160] |	nca: 5.193716451525688, flat: 2.9929689690470695, pod: 47.344024896621704, loss: 55.530709743499756 
Train [10/11] | Epoch [69/160] |	nca: 5.5237820744514465, flat: 3.2332084476947784, pod: 48.63774871826172, loss: 57.39473915100098 
Train [10/11] | Epoch [70/160] |	nca: 5.796428792178631, flat: 3.0795547366142273, pod: 47.47740972042084, loss: 56.3533935546875 
Train [10/11] | Epoch [71/160] |	nca: 5.2574367970228195, flat: 2.970463328063488, pod: 46.28898847103119, loss: 54.51688873767853 
Train [10/11] | Epoch [72/160] |	nca: 5.120503336191177, flat: 3.0039990916848183, pod: 47.64012837409973, loss: 55.76463043689728 
Train [10/11] | Epoch [73/160] |	nca: 5.361977390944958, flat: 2.9345524832606316, pod: 45.50419044494629, loss: 53.80072033405304 
Train [10/11] | Epoch [74/160] |	nca: 5.878911308944225, flat: 3.308907426893711, pod: 50.410948276519775, loss: 59.598766803741455 
Train [10/11] | Epoch [75/160] |	nca: 5.913996577262878, flat: 3.460784748196602, pod: 52.27324140071869, loss: 61.64802289009094 
Train [10/11] | Epoch [76/160] |	nca: 4.766771666705608, flat: 2.9128235653042793, pod: 46.184266090393066, loss: 53.863861203193665 
Train [10/11] | Epoch [77/160] |	nca: 5.190482899546623, flat: 2.806858479976654, pod: 45.320836186409, loss: 53.318177342414856 
Train [10/11] | Epoch [78/160] |	nca: 5.481266938149929, flat: 2.917545937001705, pod: 47.121182560920715, loss: 55.51999568939209 
Train [10/11] | Epoch [79/160] |	nca: 5.357882425189018, flat: 2.852179117500782, pod: 45.71644723415375, loss: 53.92650854587555 
Train [10/11] | Epoch [80/160] |	nca: 5.001527599990368, flat: 2.823737286031246, pod: 44.86819136142731, loss: 52.693456172943115 
Train [10/11] | Epoch [81/160] |	nca: 5.171912834048271, flat: 2.734377607703209, pod: 44.085163593292236, loss: 51.991454005241394 
Train [10/11] | Epoch [82/160] |	nca: 5.126875452697277, flat: 2.727058820426464, pod: 44.6351934671402, loss: 52.48912763595581 
Train [10/11] | Epoch [83/160] |	nca: 5.1027649119496346, flat: 2.807175487279892, pod: 45.797070264816284, loss: 53.70701086521149 
Train [10/11] | Epoch [84/160] |	nca: 4.806423768401146, flat: 2.699905924499035, pod: 44.96951484680176, loss: 52.47584426403046 
Train [10/11] | Epoch [85/160] |	nca: 5.097943641245365, flat: 2.7580357417464256, pod: 44.35841083526611, loss: 52.21439039707184 
Train [10/11] | Epoch [86/160] |	nca: 4.9025784060359, flat: 2.4797640442848206, pod: 41.70267188549042, loss: 49.08501422405243 
Train [10/11] | Epoch [87/160] |	nca: 5.009598731994629, flat: 2.5415108874440193, pod: 42.8073753118515, loss: 50.3584851026535 
Train [10/11] | Epoch [88/160] |	nca: 5.152352012693882, flat: 2.599814936518669, pod: 42.24052441120148, loss: 49.99269115924835 
Train [10/11] | Epoch [89/160] |	nca: 5.067973352968693, flat: 2.6800672188401222, pod: 43.95243036746979, loss: 51.70047068595886 
Train [10/11] | Epoch [90/160] |	nca: 4.803251996636391, flat: 2.4842249378561974, pod: 42.07961893081665, loss: 49.367096066474915 
Train [10/11] | Epoch [91/160] |	nca: 4.793573319911957, flat: 2.4549834094941616, pod: 41.56960141658783, loss: 48.81815779209137 
Train [10/11] | Epoch [92/160] |	nca: 4.522719331085682, flat: 2.343849863857031, pod: 40.55215227603912, loss: 47.418721318244934 
Train [10/11] | Epoch [93/160] |	nca: 4.890513248741627, flat: 2.279576014727354, pod: 40.16491138935089, loss: 47.33500051498413 
Train [10/11] | Epoch [94/160] |	nca: 4.792105309665203, flat: 2.38653552159667, pod: 40.96640622615814, loss: 48.145047187805176 
Train [10/11] | Epoch [95/160] |	nca: 5.013806372880936, flat: 2.4462442323565483, pod: 41.157665371894836, loss: 48.61771559715271 
Train [10/11] | Epoch [96/160] |	nca: 4.60833727568388, flat: 2.3966809920966625, pod: 41.963775634765625, loss: 48.968793869018555 
Train [10/11] | Epoch [97/160] |	nca: 4.712051376700401, flat: 2.2348075583577156, pod: 39.329129576683044, loss: 46.2759884595871 
Train [10/11] | Epoch [98/160] |	nca: 4.813808292150497, flat: 2.1997298039495945, pod: 39.13334012031555, loss: 46.146878123283386 
Train [10/11] | Epoch [99/160] |	nca: 4.6426519975066185, flat: 2.218919452279806, pod: 38.96279060840607, loss: 45.82436215877533 
Train [10/11] | Epoch [100/160] |	nca: 4.676745682954788, flat: 2.178551521152258, pod: 39.1139771938324, loss: 45.969274282455444 
Train [10/11] | Epoch [101/160] |	nca: 4.6160691902041435, flat: 2.220490638166666, pod: 39.7340202331543, loss: 46.57058000564575 
Train [10/11] | Epoch [102/160] |	nca: 4.696977153420448, flat: 2.208807460963726, pod: 40.03327190876007, loss: 46.939056634902954 
Train [10/11] | Epoch [103/160] |	nca: 4.698247082531452, flat: 2.1644816398620605, pod: 38.41795367002487, loss: 45.28068232536316 
Train [10/11] | Epoch [104/160] |	nca: 4.382115952670574, flat: 2.1334762163460255, pod: 38.258498191833496, loss: 44.77409052848816 
Train [10/11] | Epoch [105/160] |	nca: 4.5524246618151665, flat: 1.9821681417524815, pod: 37.102991342544556, loss: 43.63758409023285 
Train [10/11] | Epoch [106/160] |	nca: 4.680786721408367, flat: 2.0027825981378555, pod: 37.675689458847046, loss: 44.35925889015198 
Train [10/11] | Epoch [107/160] |	nca: 4.592231340706348, flat: 1.9625745452940464, pod: 36.82262349128723, loss: 43.377429246902466 
Train [10/11] | Epoch [108/160] |	nca: 4.571233592927456, flat: 1.9220600351691246, pod: 36.16878294944763, loss: 42.662076354026794 
Train [10/11] | Epoch [109/160] |	nca: 4.43758350610733, flat: 1.935209583491087, pod: 36.19156575202942, loss: 42.564359068870544 
Train [10/11] | Epoch [110/160] |	nca: 4.350607179105282, flat: 1.9036430418491364, pod: 36.13755148649216, loss: 42.391801834106445 
Train [10/11] | Epoch [111/160] |	nca: 4.346537202596664, flat: 1.8769223541021347, pod: 35.071886122226715, loss: 41.29534590244293 
Train [10/11] | Epoch [112/160] |	nca: 4.510183736681938, flat: 1.7481151707470417, pod: 33.60933721065521, loss: 39.86763632297516 
Train [10/11] | Epoch [113/160] |	nca: 4.392853207886219, flat: 1.7700110897421837, pod: 34.35842549800873, loss: 40.52129000425339 
Train [10/11] | Epoch [114/160] |	nca: 4.319636851549149, flat: 1.7650300562381744, pod: 34.071695148944855, loss: 40.15636217594147 
Train [10/11] | Epoch [115/160] |	nca: 4.435656510293484, flat: 1.7715726755559444, pod: 34.66418993473053, loss: 40.871419191360474 
Train [10/11] | Epoch [116/160] |	nca: 4.184135757386684, flat: 1.734786994755268, pod: 34.09880495071411, loss: 40.017727971076965 
Train [10/11] | Epoch [117/160] |	nca: 4.332493558526039, flat: 1.7660005129873753, pod: 35.28823560476303, loss: 41.38672983646393 
Train [10/11] | Epoch [118/160] |	nca: 4.172277614474297, flat: 1.8072401732206345, pod: 35.39705830812454, loss: 41.37657606601715 
Train [10/11] | Epoch [119/160] |	nca: 4.086069971323013, flat: 1.6156031638383865, pod: 32.72820287942886, loss: 38.42987608909607 
Train [10/11] | Epoch [120/160] |	nca: 4.470417462289333, flat: 1.6406910829246044, pod: 32.75619125366211, loss: 38.8672998547554 
Train [10/11] | Epoch [121/160] |	nca: 3.98314867913723, flat: 1.594431083649397, pod: 31.551804423332214, loss: 37.129384100437164 
Train [10/11] | Epoch [122/160] |	nca: 4.442329257726669, flat: 1.5519781187176704, pod: 31.531967401504517, loss: 37.52627468109131 
Train [10/11] | Epoch [123/160] |	nca: 4.324008196592331, flat: 1.6431660763919353, pod: 32.5160653591156, loss: 38.48323965072632 
Train [10/11] | Epoch [124/160] |	nca: 4.5053785517811775, flat: 1.5326417572796345, pod: 31.102295339107513, loss: 37.14031594991684 
Train [10/11] | Epoch [125/160] |	nca: 4.2795074582099915, flat: 1.4957653991878033, pod: 30.733569383621216, loss: 36.50884211063385 
Train [10/11] | Epoch [126/160] |	nca: 4.294381327927113, flat: 1.5509140715003014, pod: 31.12642389535904, loss: 36.97171986103058 
Train [10/11] | Epoch [127/160] |	nca: 4.257728181779385, flat: 1.5160501226782799, pod: 30.80478608608246, loss: 36.57856422662735 
Train [10/11] | Epoch [128/160] |	nca: 3.910052016377449, flat: 1.4856019616127014, pod: 30.800833225250244, loss: 36.196486949920654 
Train [10/11] | Epoch [129/160] |	nca: 4.231753617525101, flat: 1.5441400445997715, pod: 31.002018690109253, loss: 36.77791249752045 
Train [10/11] | Epoch [130/160] |	nca: 4.257561139762402, flat: 1.463634867221117, pod: 29.2222962975502, loss: 34.94349217414856 
Train [10/11] | Epoch [131/160] |	nca: 4.085230462253094, flat: 1.4203972816467285, pod: 29.56956708431244, loss: 35.07519447803497 
Train [10/11] | Epoch [132/160] |	nca: 4.06681602448225, flat: 1.3774199970066547, pod: 28.80087947845459, loss: 34.24511557817459 
Train [10/11] | Epoch [133/160] |	nca: 4.2591512799263, flat: 1.4262815229594707, pod: 29.801335513591766, loss: 35.48676824569702 
Train [10/11] | Epoch [134/160] |	nca: 3.961141213774681, flat: 1.3804222270846367, pod: 28.18688267469406, loss: 33.52844625711441 
Train [10/11] | Epoch [135/160] |	nca: 4.063979409635067, flat: 1.3112995214760303, pod: 28.159953474998474, loss: 33.53523224592209 
Train [10/11] | Epoch [136/160] |	nca: 4.119607426226139, flat: 1.3598754927515984, pod: 28.61296784877777, loss: 34.092450857162476 
Train [10/11] | Epoch [137/160] |	nca: 3.978867456316948, flat: 1.2831311486661434, pod: 27.821058809757233, loss: 33.0830574631691 
Train [10/11] | Epoch [138/160] |	nca: 4.099856726825237, flat: 1.3039282578974962, pod: 27.343441486358643, loss: 32.74722683429718 
Train [10/11] | Epoch [139/160] |	nca: 3.988264314830303, flat: 1.3090457748621702, pod: 27.857143878936768, loss: 33.15445423126221 
Train [10/11] | Epoch [140/160] |	nca: 4.151770807802677, flat: 1.3338017091155052, pod: 27.370963096618652, loss: 32.85653555393219 
Train [10/11] | Epoch [141/160] |	nca: 4.000789679586887, flat: 1.229082079604268, pod: 27.11881560087204, loss: 32.348687291145325 
Train [10/11] | Epoch [142/160] |	nca: 4.003924027085304, flat: 1.215582937002182, pod: 26.006675839424133, loss: 31.2261825799942 
Train [10/11] | Epoch [143/160] |	nca: 4.139224119484425, flat: 1.2754027973860502, pod: 26.681927978992462, loss: 32.096555173397064 
Train [10/11] | Epoch [144/160] |	nca: 3.875546433031559, flat: 1.214088635519147, pod: 26.085638344287872, loss: 31.17527347803116 
Train [10/11] | Epoch [145/160] |	nca: 3.8384964168071747, flat: 1.2053915336728096, pod: 26.78471702337265, loss: 31.828604817390442 
Train [10/11] | Epoch [146/160] |	nca: 4.0304806008934975, flat: 1.2021234836429358, pod: 25.83492624759674, loss: 31.067530274391174 
Train [10/11] | Epoch [147/160] |	nca: 3.973070152103901, flat: 1.1822200249880552, pod: 25.96167927980423, loss: 31.11696946620941 
Train [10/11] | Epoch [148/160] |	nca: 3.9465181082487106, flat: 1.1684514079242945, pod: 25.403505563735962, loss: 30.51847529411316 
Train [10/11] | Epoch [149/160] |	nca: 3.942832939326763, flat: 1.19139308296144, pod: 25.72435188293457, loss: 30.858578145503998 
Train [10/11] | Epoch [150/160] |	nca: 3.797930784523487, flat: 1.134213274344802, pod: 24.68592458963394, loss: 29.61806857585907 
Train [10/11] | Epoch [151/160] |	nca: 4.158968813717365, flat: 1.1279061995446682, pod: 24.607993185520172, loss: 29.894868195056915 
Train [10/11] | Epoch [152/160] |	nca: 3.778000347316265, flat: 1.1697090789675713, pod: 25.126224279403687, loss: 30.073933482170105 
Train [10/11] | Epoch [153/160] |	nca: 3.9276149794459343, flat: 1.1684448700398207, pod: 25.61551284790039, loss: 30.711572468280792 
Train [10/11] | Epoch [154/160] |	nca: 4.02554702013731, flat: 1.1473299618810415, pod: 25.447282314300537, loss: 30.62015926837921 
Train [10/11] | Epoch [155/160] |	nca: 3.953147813677788, flat: 1.1484118532389402, pod: 24.461298525333405, loss: 29.56285810470581 
Train [10/11] | Epoch [156/160] |	nca: 3.922199845314026, flat: 1.1537552066147327, pod: 24.407428860664368, loss: 29.483384132385254 
Train [10/11] | Epoch [157/160] |	nca: 3.7623036727309227, flat: 1.1557292304933071, pod: 24.717538118362427, loss: 29.63557118177414 
Train [10/11] | Epoch [158/160] |	nca: 4.001596763730049, flat: 1.1284895334392786, pod: 24.854690670967102, loss: 29.984776973724365 
Train [10/11] | Epoch [159/160] |	nca: 3.838335633277893, flat: 1.1185572799295187, pod: 24.51283949613571, loss: 29.469732522964478 
Train [10/11] | Epoch [160/160] |	nca: 3.9642049223184586, flat: 1.1585094220936298, pod: 24.96033078432083, loss: 30.083045184612274 
Fine-tuning
Building & updating memory.
Train [10/11] | Epoch [161/180] |	nca: 2.198907032608986, flat: 0.7279869578778744, pod: 12.905058145523071, loss: 15.831952095031738 
Train [10/11] | Epoch [162/180] |	nca: 1.3019543886184692, flat: 0.7244195826351643, pod: 12.753745257854462, loss: 14.78011929988861 
Train [10/11] | Epoch [163/180] |	nca: 1.2037466429173946, flat: 0.7182142212986946, pod: 12.507503151893616, loss: 14.429464101791382 
Train [10/11] | Epoch [164/180] |	nca: 1.0573243014514446, flat: 0.6897519715130329, pod: 12.274499773979187, loss: 14.021576046943665 
Train [10/11] | Epoch [165/180] |	nca: 1.0413225032389164, flat: 0.7364957481622696, pod: 13.31469315290451, loss: 15.092511355876923 
Train [10/11] | Epoch [166/180] |	nca: 0.9266124777495861, flat: 0.6999741122126579, pod: 12.534141302108765, loss: 14.16072803735733 
Train [10/11] | Epoch [167/180] |	nca: 0.8762011714279652, flat: 0.716916099190712, pod: 12.59746140241623, loss: 14.190578758716583 
Train [10/11] | Epoch [168/180] |	nca: 0.8719867505133152, flat: 0.7283789329230785, pod: 12.6625417470932, loss: 14.26290738582611 
Train [10/11] | Epoch [169/180] |	nca: 0.8192085064947605, flat: 0.7156377471983433, pod: 12.498988389968872, loss: 14.033834755420685 
Train [10/11] | Epoch [170/180] |	nca: 0.9557087793946266, flat: 0.7223178297281265, pod: 13.110259234905243, loss: 14.788285911083221 
Train [10/11] | Epoch [171/180] |	nca: 0.7427513115108013, flat: 0.7169261127710342, pod: 12.669103741645813, loss: 14.128781139850616 
Train [10/11] | Epoch [172/180] |	nca: 0.9047840535640717, flat: 0.7009885050356388, pod: 12.80032616853714, loss: 14.406098663806915 
Train [10/11] | Epoch [173/180] |	nca: 0.813213687390089, flat: 0.7291139326989651, pod: 12.907962799072266, loss: 14.450290262699127 
Train [10/11] | Epoch [174/180] |	nca: 0.7724071629345417, flat: 0.6755641363561153, pod: 12.220671892166138, loss: 13.668643116950989 
Train [10/11] | Epoch [175/180] |	nca: 0.7506847903132439, flat: 0.7322729863226414, pod: 12.92284381389618, loss: 14.405801653862 
Train [10/11] | Epoch [176/180] |	nca: 0.748782504349947, flat: 0.7036534212529659, pod: 12.567598104476929, loss: 14.02003401517868 
Train [10/11] | Epoch [177/180] |	nca: 0.770966898649931, flat: 0.7472105324268341, pod: 13.089753687381744, loss: 14.607931137084961 
Train [10/11] | Epoch [178/180] |	nca: 0.7494851425290108, flat: 0.7075006291270256, pod: 12.639163374900818, loss: 14.09614908695221 
Train [10/11] | Epoch [179/180] |	nca: 0.7347353287041187, flat: 0.7062027305364609, pod: 12.645969092845917, loss: 14.086907029151917 
Train [10/11] | Epoch [180/180] |	nca: 0.7246866971254349, flat: 0.7392638511955738, pod: 13.096058785915375, loss: 14.56000930070877 
after task
Building & updating memory.
after task
Eval on 0->95.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6403000000000001.
Current acc: {'total': 0.546, '00-09': 0.608, '10-19': 0.502, '20-29': 0.431, '30-39': 0.51, '40-49': 0.56, '50-59': 0.515, '60-69': 0.456, '70-79': 0.551, '80-89': 0.664, '90-99': 0.772}.
Avg inc acc top5: 0.8829999999999998.
Current acc top5: {'total': 0.83}.
Forgetting: 0.12536363636363637.
Cord metric: 0.64.
Old accuracy: 0.53, mean: 0.62.
New accuracy: 0.77, mean: 0.76.
================Task 10 Start!================
Testing on False unseen tasks (max class = 100).
Set memory of size: 1900.
Before task
Generating imprinted weights
Multi class diff kmeans.
Now 20 examplars per class.
Group: convnet, lr: 0.1.
Group: postprocessing, lr: 0.1.
Group: new_weights, lr: 0.1.
================Task 10 Training!================
The training samples number: 4400
Train on 95->100.
train task
nb 4400.
Train [11/11] | Epoch [1/160] |	nca: 37.54586327075958, flat: 11.193153966218233, pod: 90.91325795650482, loss: 139.6522763967514 
Train [11/11] | Epoch [2/160] |	nca: 28.522400438785553, flat: 12.691536843776703, pod: 103.29032683372498, loss: 144.50426411628723 
Train [11/11] | Epoch [3/160] |	nca: 20.56077688932419, flat: 9.753940224647522, pod: 90.09687042236328, loss: 120.4115879535675 
Train [11/11] | Epoch [4/160] |	nca: 17.03115677833557, flat: 8.53723594546318, pod: 84.23232078552246, loss: 109.80071330070496 
Train [11/11] | Epoch [5/160] |	nca: 14.710795402526855, flat: 7.658961787819862, pod: 80.38478016853333, loss: 102.7545382976532 
Train [11/11] | Epoch [6/160] |	nca: 12.508703500032425, flat: 6.846129685640335, pod: 75.79513549804688, loss: 95.14996838569641 
Train [11/11] | Epoch [7/160] |	nca: 13.160888850688934, flat: 6.780183583498001, pod: 75.3746167421341, loss: 95.31568956375122 
Train [11/11] | Epoch [8/160] |	nca: 11.77481396496296, flat: 6.56887674331665, pod: 72.8931850194931, loss: 91.23687553405762 
Train [11/11] | Epoch [9/160] |	nca: 11.00709544122219, flat: 5.969719901680946, pod: 70.34513735771179, loss: 87.32195258140564 
Train [11/11] | Epoch [10/160] |	nca: 11.28482960164547, flat: 6.064387425780296, pod: 72.02750611305237, loss: 89.37672257423401 
Train [11/11] | Epoch [11/160] |	nca: 10.05894786119461, flat: 5.647490754723549, pod: 67.0065381526947, loss: 82.71297717094421 
Train [11/11] | Epoch [12/160] |	nca: 10.837995186448097, flat: 5.877499282360077, pod: 69.47450089454651, loss: 86.18999552726746 
Train [11/11] | Epoch [13/160] |	nca: 10.17185452580452, flat: 5.885680437088013, pod: 70.22607886791229, loss: 86.28361392021179 
Train [11/11] | Epoch [14/160] |	nca: 9.94279620051384, flat: 5.61826054751873, pod: 66.51920330524445, loss: 82.08026051521301 
Train [11/11] | Epoch [15/160] |	nca: 9.824043735861778, flat: 5.558536157011986, pod: 67.96894264221191, loss: 83.35152196884155 
Train [11/11] | Epoch [16/160] |	nca: 10.461795181035995, flat: 5.78368766605854, pod: 68.14658963680267, loss: 84.39207243919373 
Train [11/11] | Epoch [17/160] |	nca: 9.404166623950005, flat: 5.511496990919113, pod: 67.34479558467865, loss: 82.2604591846466 
Train [11/11] | Epoch [18/160] |	nca: 9.112028911709785, flat: 5.374637320637703, pod: 66.51745986938477, loss: 81.00412583351135 
Train [11/11] | Epoch [19/160] |	nca: 8.333280190825462, flat: 4.944403879344463, pod: 63.435054779052734, loss: 76.71273875236511 
Train [11/11] | Epoch [20/160] |	nca: 9.282540902495384, flat: 5.308151692152023, pod: 65.89050424098969, loss: 80.48119711875916 
Train [11/11] | Epoch [21/160] |	nca: 8.719103276729584, flat: 5.173695579171181, pod: 65.36795496940613, loss: 79.26075387001038 
Train [11/11] | Epoch [22/160] |	nca: 8.158060431480408, flat: 4.744101338088512, pod: 63.89924943447113, loss: 76.80141091346741 
Train [11/11] | Epoch [23/160] |	nca: 8.401639685034752, flat: 5.020477086305618, pod: 63.962377309799194, loss: 77.3844940662384 
Train [11/11] | Epoch [24/160] |	nca: 8.452308997511864, flat: 5.036561146378517, pod: 63.81337797641754, loss: 77.30224895477295 
Train [11/11] | Epoch [25/160] |	nca: 8.767582505941391, flat: 5.034643322229385, pod: 64.07280707359314, loss: 77.87503290176392 
Train [11/11] | Epoch [26/160] |	nca: 8.160855636000633, flat: 4.932018950581551, pod: 63.452433347702026, loss: 76.54530763626099 
Train [11/11] | Epoch [27/160] |	nca: 8.01164796948433, flat: 4.570029377937317, pod: 60.95586013793945, loss: 73.53753769397736 
Train [11/11] | Epoch [28/160] |	nca: 8.169839784502983, flat: 4.72095663100481, pod: 61.72539961338043, loss: 74.6161961555481 
Train [11/11] | Epoch [29/160] |	nca: 8.233696460723877, flat: 4.835491023957729, pod: 63.380980491638184, loss: 76.45016825199127 
Train [11/11] | Epoch [30/160] |	nca: 7.68902213871479, flat: 4.738937459886074, pod: 63.35054647922516, loss: 75.77850568294525 
Train [11/11] | Epoch [31/160] |	nca: 8.21176029741764, flat: 4.991735674440861, pod: 64.24379467964172, loss: 77.4472907781601 
Train [11/11] | Epoch [32/160] |	nca: 8.08910796046257, flat: 4.737347818911076, pod: 63.269734144210815, loss: 76.09618973731995 
Train [11/11] | Epoch [33/160] |	nca: 7.2104538306593895, flat: 4.483089916408062, pod: 61.201117396354675, loss: 72.89466094970703 
Train [11/11] | Epoch [34/160] |	nca: 7.616017863154411, flat: 4.87676727771759, pod: 64.50008809566498, loss: 76.99287331104279 
Train [11/11] | Epoch [35/160] |	nca: 7.431723386049271, flat: 4.566631227731705, pod: 60.22281289100647, loss: 72.2211662530899 
Train [11/11] | Epoch [36/160] |	nca: 7.456527337431908, flat: 4.6477789506316185, pod: 61.10779058933258, loss: 73.21209681034088 
Train [11/11] | Epoch [37/160] |	nca: 7.3655202984809875, flat: 4.492773704230785, pod: 60.78844738006592, loss: 72.64674091339111 
Train [11/11] | Epoch [38/160] |	nca: 6.839146226644516, flat: 4.139439299702644, pod: 58.89336168766022, loss: 69.87194681167603 
Train [11/11] | Epoch [39/160] |	nca: 7.8276359140872955, flat: 4.373010374605656, pod: 60.272217988967896, loss: 72.47286403179169 
Train [11/11] | Epoch [40/160] |	nca: 7.510924860835075, flat: 4.652698747813702, pod: 61.13751149177551, loss: 73.3011349439621 
Train [11/11] | Epoch [41/160] |	nca: 8.42154498398304, flat: 4.741381958127022, pod: 61.01896524429321, loss: 74.18189191818237 
Train [11/11] | Epoch [42/160] |	nca: 7.521024569869041, flat: 4.397133380174637, pod: 59.981226682662964, loss: 71.89938449859619 
Train [11/11] | Epoch [43/160] |	nca: 7.157548621296883, flat: 4.370618432760239, pod: 60.04992175102234, loss: 71.57808911800385 
Train [11/11] | Epoch [44/160] |	nca: 7.55370657145977, flat: 4.598037138581276, pod: 61.07859790325165, loss: 73.23034191131592 
Train [11/11] | Epoch [45/160] |	nca: 7.061756446957588, flat: 4.1625120267271996, pod: 58.84985411167145, loss: 70.07412219047546 
Train [11/11] | Epoch [46/160] |	nca: 6.832258515059948, flat: 4.001365527510643, pod: 56.78076958656311, loss: 67.61439406871796 
Train [11/11] | Epoch [47/160] |	nca: 7.080405525863171, flat: 4.255302578210831, pod: 60.309781432151794, loss: 71.64548993110657 
Train [11/11] | Epoch [48/160] |	nca: 6.092401623725891, flat: 3.5581542178988457, pod: 53.50746238231659, loss: 63.15801823139191 
Train [11/11] | Epoch [49/160] |	nca: 7.213479399681091, flat: 4.153793655335903, pod: 58.472668051719666, loss: 69.83994126319885 
Train [11/11] | Epoch [50/160] |	nca: 6.971141770482063, flat: 4.249616168439388, pod: 58.55628561973572, loss: 69.77704298496246 
Train [11/11] | Epoch [51/160] |	nca: 6.486029110848904, flat: 3.9777400195598602, pod: 57.50467312335968, loss: 67.96844255924225 
Train [11/11] | Epoch [52/160] |	nca: 6.251046635210514, flat: 3.744509756565094, pod: 55.592005014419556, loss: 65.58756160736084 
Train [11/11] | Epoch [53/160] |	nca: 7.204773962497711, flat: 3.9503575265407562, pod: 55.630773305892944, loss: 66.78590476512909 
Train [11/11] | Epoch [54/160] |	nca: 7.071728304028511, flat: 4.15610234439373, pod: 57.32078003883362, loss: 68.54861128330231 
Train [11/11] | Epoch [55/160] |	nca: 6.4322118908166885, flat: 3.99890423566103, pod: 57.49284839630127, loss: 67.92396438121796 
Train [11/11] | Epoch [56/160] |	nca: 6.363739594817162, flat: 3.953609138727188, pod: 57.41741096973419, loss: 67.73475980758667 
Train [11/11] | Epoch [57/160] |	nca: 6.714099690318108, flat: 3.7675769701600075, pod: 54.63123977184296, loss: 65.11291635036469 
Train [11/11] | Epoch [58/160] |	nca: 7.100855231285095, flat: 4.047725275158882, pod: 57.27951741218567, loss: 68.42809820175171 
Train [11/11] | Epoch [59/160] |	nca: 6.327698349952698, flat: 3.6210587918758392, pod: 54.24832570552826, loss: 64.19708275794983 
Train [11/11] | Epoch [60/160] |	nca: 6.120256878435612, flat: 3.495678186416626, pod: 51.77481496334076, loss: 61.39075028896332 
Train [11/11] | Epoch [61/160] |	nca: 6.362562730908394, flat: 3.634452246129513, pod: 53.696863651275635, loss: 63.69387900829315 
Train [11/11] | Epoch [62/160] |	nca: 6.259136840701103, flat: 3.771144710481167, pod: 57.25527548789978, loss: 67.28555691242218 
Train [11/11] | Epoch [63/160] |	nca: 6.348588764667511, flat: 3.5034890919923782, pod: 52.44995379447937, loss: 62.3020316362381 
Train [11/11] | Epoch [64/160] |	nca: 6.230420880019665, flat: 3.545650474727154, pod: 52.66241443157196, loss: 62.438486099243164 
Train [11/11] | Epoch [65/160] |	nca: 6.2748235538601875, flat: 3.5622380524873734, pod: 52.218395709991455, loss: 62.05545723438263 
Train [11/11] | Epoch [66/160] |	nca: 6.32370962947607, flat: 3.4154107198119164, pod: 51.42022740840912, loss: 61.159348130226135 
Train [11/11] | Epoch [67/160] |	nca: 6.527004927396774, flat: 3.704769976437092, pod: 52.82218790054321, loss: 63.0539630651474 
Train [11/11] | Epoch [68/160] |	nca: 5.873056031763554, flat: 3.5330444425344467, pod: 53.01602303981781, loss: 62.42212355136871 
Train [11/11] | Epoch [69/160] |	nca: 5.941067278385162, flat: 3.4364210218191147, pod: 52.379127740859985, loss: 61.75661611557007 
Train [11/11] | Epoch [70/160] |	nca: 6.128055565059185, flat: 3.4030141457915306, pod: 52.91376292705536, loss: 62.44483232498169 
Train [11/11] | Epoch [71/160] |	nca: 5.77024619281292, flat: 3.215308330953121, pod: 50.84014081954956, loss: 59.825695276260376 
Train [11/11] | Epoch [72/160] |	nca: 5.813937179744244, flat: 3.22015218436718, pod: 51.82660734653473, loss: 60.86069691181183 
Train [11/11] | Epoch [73/160] |	nca: 5.635944709181786, flat: 3.2517651468515396, pod: 49.897767543792725, loss: 58.78547716140747 
Train [11/11] | Epoch [74/160] |	nca: 6.039790824055672, flat: 3.230975456535816, pod: 49.119235157966614, loss: 58.39000165462494 
Train [11/11] | Epoch [75/160] |	nca: 5.621150314807892, flat: 3.1794571205973625, pod: 49.228989005088806, loss: 58.02959656715393 
Train [11/11] | Epoch [76/160] |	nca: 5.912827290594578, flat: 3.3656693771481514, pod: 52.15615260601044, loss: 61.43464958667755 
Train [11/11] | Epoch [77/160] |	nca: 5.849259570240974, flat: 3.183042600750923, pod: 50.30154752731323, loss: 59.33384966850281 
Train [11/11] | Epoch [78/160] |	nca: 5.421420581638813, flat: 3.000171035528183, pod: 48.535643339157104, loss: 56.95723497867584 
Train [11/11] | Epoch [79/160] |	nca: 5.672437906265259, flat: 2.885130673646927, pod: 47.235400438308716, loss: 55.79296910762787 
Train [11/11] | Epoch [80/160] |	nca: 5.193946875631809, flat: 2.872799940407276, pod: 49.2669016122818, loss: 57.333648562431335 
Train [11/11] | Epoch [81/160] |	nca: 5.540119983255863, flat: 2.9654305800795555, pod: 48.947399735450745, loss: 57.45295000076294 
Train [11/11] | Epoch [82/160] |	nca: 5.551953449845314, flat: 2.8885364681482315, pod: 47.430338740348816, loss: 55.87082886695862 
Train [11/11] | Epoch [83/160] |	nca: 5.346639417111874, flat: 2.9309778064489365, pod: 49.394946455955505, loss: 57.672563791275024 
Train [11/11] | Epoch [84/160] |	nca: 4.926499009132385, flat: 2.649753011763096, pod: 44.92990243434906, loss: 52.50615441799164 
Train [11/11] | Epoch [85/160] |	nca: 5.328261323273182, flat: 2.766113333404064, pod: 46.19469404220581, loss: 54.289069175720215 
Train [11/11] | Epoch [86/160] |	nca: 5.352714404463768, flat: 2.7290420308709145, pod: 46.40215253829956, loss: 54.483909249305725 
Train [11/11] | Epoch [87/160] |	nca: 5.281316697597504, flat: 2.7096183337271214, pod: 46.26614773273468, loss: 54.25708258152008 
Train [11/11] | Epoch [88/160] |	nca: 5.444181427359581, flat: 2.7165723368525505, pod: 45.889487504959106, loss: 54.050240993499756 
Train [11/11] | Epoch [89/160] |	nca: 5.4453244805336, flat: 2.6959841921925545, pod: 44.859375953674316, loss: 53.0006844997406 
Train [11/11] | Epoch [90/160] |	nca: 5.098192408680916, flat: 2.5577281564474106, pod: 45.28665208816528, loss: 52.942572474479675 
Train [11/11] | Epoch [91/160] |	nca: 4.971517123281956, flat: 2.5627997741103172, pod: 44.945905804634094, loss: 52.480223059654236 
Train [11/11] | Epoch [92/160] |	nca: 4.7133820205926895, flat: 2.4194015003740788, pod: 42.5780645608902, loss: 49.71084809303284 
Train [11/11] | Epoch [93/160] |	nca: 4.95511070638895, flat: 2.363832216709852, pod: 42.144415616989136, loss: 49.463358640670776 
Train [11/11] | Epoch [94/160] |	nca: 5.1239340007305145, flat: 2.4683841802179813, pod: 43.941373229026794, loss: 51.53369164466858 
Train [11/11] | Epoch [95/160] |	nca: 5.090849541127682, flat: 2.473614428192377, pod: 44.012497425079346, loss: 51.576961159706116 
Train [11/11] | Epoch [96/160] |	nca: 4.642545662820339, flat: 2.3717758692801, pod: 42.30757260322571, loss: 49.32189452648163 
Train [11/11] | Epoch [97/160] |	nca: 4.848237462341785, flat: 2.2387450337409973, pod: 40.74549090862274, loss: 47.83247375488281 
Train [11/11] | Epoch [98/160] |	nca: 4.873836249113083, flat: 2.1855986565351486, pod: 41.17404496669769, loss: 48.23348033428192 
Train [11/11] | Epoch [99/160] |	nca: 5.113370299339294, flat: 2.3213559426367283, pod: 41.84021782875061, loss: 49.274943828582764 
Train [11/11] | Epoch [100/160] |	nca: 4.982015810906887, flat: 2.3318623155355453, pod: 42.39647138118744, loss: 49.710349321365356 
Train [11/11] | Epoch [101/160] |	nca: 4.646166600286961, flat: 2.1925581619143486, pod: 40.61857354640961, loss: 47.457298278808594 
Train [11/11] | Epoch [102/160] |	nca: 4.923965141177177, flat: 2.1515787579119205, pod: 40.122061252593994, loss: 47.19760525226593 
Train [11/11] | Epoch [103/160] |	nca: 4.969023644924164, flat: 2.2524853087961674, pod: 40.70160377025604, loss: 47.923113107681274 
Train [11/11] | Epoch [104/160] |	nca: 5.0855559185147285, flat: 2.2651709727942944, pod: 40.929130494594574, loss: 48.27985715866089 
Train [11/11] | Epoch [105/160] |	nca: 4.92050439119339, flat: 2.097822304815054, pod: 39.01147735118866, loss: 46.02980387210846 
Train [11/11] | Epoch [106/160] |	nca: 4.812430217862129, flat: 2.0737551040947437, pod: 39.061375856399536, loss: 45.947561144828796 
Train [11/11] | Epoch [107/160] |	nca: 4.715398162603378, flat: 2.083550203591585, pod: 38.23307639360428, loss: 45.03202486038208 
Train [11/11] | Epoch [108/160] |	nca: 4.729608029127121, flat: 2.1021439619362354, pod: 38.598602414131165, loss: 45.430354952812195 
Train [11/11] | Epoch [109/160] |	nca: 4.503487303853035, flat: 1.9823230281472206, pod: 37.709710478782654, loss: 44.195520877838135 
Train [11/11] | Epoch [110/160] |	nca: 4.437812350690365, flat: 1.8535850495100021, pod: 36.38843482732773, loss: 42.679832339286804 
Train [11/11] | Epoch [111/160] |	nca: 4.353670381009579, flat: 1.8680268600583076, pod: 37.51598799228668, loss: 43.73768508434296 
Train [11/11] | Epoch [112/160] |	nca: 4.581695467233658, flat: 1.8708931766450405, pod: 37.44234657287598, loss: 43.89493525028229 
Train [11/11] | Epoch [113/160] |	nca: 4.459507770836353, flat: 1.859737727791071, pod: 36.36699068546295, loss: 42.68623638153076 
Train [11/11] | Epoch [114/160] |	nca: 4.6661205515265465, flat: 1.9268979281187057, pod: 37.41935449838638, loss: 44.012372851371765 
Train [11/11] | Epoch [115/160] |	nca: 4.718303553760052, flat: 1.9194431751966476, pod: 37.375426054000854, loss: 44.01317322254181 
Train [11/11] | Epoch [116/160] |	nca: 4.2889653369784355, flat: 1.778807371854782, pod: 34.729817628860474, loss: 40.797590494155884 
Train [11/11] | Epoch [117/160] |	nca: 4.633544571697712, flat: 1.819739580154419, pod: 35.63053625822067, loss: 42.08382070064545 
Train [11/11] | Epoch [118/160] |	nca: 4.288910582661629, flat: 1.73662481456995, pod: 35.1015145778656, loss: 41.12705010175705 
Train [11/11] | Epoch [119/160] |	nca: 4.40396162122488, flat: 1.7003593444824219, pod: 35.84250193834305, loss: 41.94682312011719 
Train [11/11] | Epoch [120/160] |	nca: 4.433558702468872, flat: 1.6581491194665432, pod: 33.939673721790314, loss: 40.031381607055664 
Train [11/11] | Epoch [121/160] |	nca: 4.163395240902901, flat: 1.6665809601545334, pod: 35.01214027404785, loss: 40.84211623668671 
Train [11/11] | Epoch [122/160] |	nca: 4.281246453523636, flat: 1.5464101992547512, pod: 33.22648739814758, loss: 39.05414420366287 
Train [11/11] | Epoch [123/160] |	nca: 4.645225487649441, flat: 1.7020494379103184, pod: 35.083820819854736, loss: 41.43109595775604 
Train [11/11] | Epoch [124/160] |	nca: 4.345050483942032, flat: 1.6390775069594383, pod: 33.287325620651245, loss: 39.27145367860794 
Train [11/11] | Epoch [125/160] |	nca: 4.452668838202953, flat: 1.6048667319118977, pod: 33.08760130405426, loss: 39.14513689279556 
Train [11/11] | Epoch [126/160] |	nca: 4.414843611419201, flat: 1.5330020189285278, pod: 32.26899802684784, loss: 38.21684366464615 
Train [11/11] | Epoch [127/160] |	nca: 4.385046303272247, flat: 1.5627499520778656, pod: 32.93382412195206, loss: 38.88162046670914 
Train [11/11] | Epoch [128/160] |	nca: 4.233077719807625, flat: 1.5747475288808346, pod: 33.63801592588425, loss: 39.44584107398987 
Train [11/11] | Epoch [129/160] |	nca: 4.107316799461842, flat: 1.481846746057272, pod: 32.30386984348297, loss: 37.89303356409073 
Train [11/11] | Epoch [130/160] |	nca: 4.412270225584507, flat: 1.4785887636244297, pod: 31.82066059112549, loss: 37.7115193605423 
Train [11/11] | Epoch [131/160] |	nca: 4.370719559490681, flat: 1.4385598935186863, pod: 31.507929503917694, loss: 37.317208886146545 
Train [11/11] | Epoch [132/160] |	nca: 4.257683843374252, flat: 1.4162269346415997, pod: 31.628888964653015, loss: 37.302799582481384 
Train [11/11] | Epoch [133/160] |	nca: 4.438569538295269, flat: 1.4555097222328186, pod: 31.889652371406555, loss: 37.783731520175934 
Train [11/11] | Epoch [134/160] |	nca: 4.080823212862015, flat: 1.3541787769645452, pod: 29.5351459980011, loss: 34.97014772891998 
Train [11/11] | Epoch [135/160] |	nca: 3.91149078309536, flat: 1.3428777940571308, pod: 29.87555092573166, loss: 35.12991976737976 
Train [11/11] | Epoch [136/160] |	nca: 4.373902976512909, flat: 1.3589800335466862, pod: 30.358743846416473, loss: 36.091626942157745 
Train [11/11] | Epoch [137/160] |	nca: 4.304108493030071, flat: 1.284178577363491, pod: 28.20282417535782, loss: 33.79111123085022 
Train [11/11] | Epoch [138/160] |	nca: 4.272355608642101, flat: 1.394934844225645, pod: 30.312616527080536, loss: 35.97990703582764 
Train [11/11] | Epoch [139/160] |	nca: 4.235407263040543, flat: 1.2824161145836115, pod: 29.101259529590607, loss: 34.61908292770386 
Train [11/11] | Epoch [140/160] |	nca: 4.200934253633022, flat: 1.3633644543588161, pod: 29.636021971702576, loss: 35.20032078027725 
Train [11/11] | Epoch [141/160] |	nca: 4.088361904025078, flat: 1.354346038773656, pod: 29.596665620803833, loss: 35.03937357664108 
Train [11/11] | Epoch [142/160] |	nca: 4.204122744500637, flat: 1.2541534211486578, pod: 28.156515538692474, loss: 33.61479192972183 
Train [11/11] | Epoch [143/160] |	nca: 4.162536405026913, flat: 1.2362930718809366, pod: 28.03692889213562, loss: 33.43575841188431 
Train [11/11] | Epoch [144/160] |	nca: 4.099173337221146, flat: 1.2107555847615004, pod: 26.932405173778534, loss: 32.24233418703079 
Train [11/11] | Epoch [145/160] |	nca: 4.003679249435663, flat: 1.2198720909655094, pod: 26.95770937204361, loss: 32.181260764598846 
Train [11/11] | Epoch [146/160] |	nca: 4.0715546905994415, flat: 1.2242849506437778, pod: 27.17593079805374, loss: 32.47177016735077 
Train [11/11] | Epoch [147/160] |	nca: 4.297871835529804, flat: 1.2569430507719517, pod: 28.506775975227356, loss: 34.06159096956253 
Train [11/11] | Epoch [148/160] |	nca: 4.063533321022987, flat: 1.2196716256439686, pod: 27.256074011325836, loss: 32.53927892446518 
Train [11/11] | Epoch [149/160] |	nca: 4.0311396941542625, flat: 1.191280459985137, pod: 26.457424998283386, loss: 31.67984503507614 
Train [11/11] | Epoch [150/160] |	nca: 3.9263864308595657, flat: 1.1580914221704006, pod: 26.04094558954239, loss: 31.12542349100113 
Train [11/11] | Epoch [151/160] |	nca: 4.082765661180019, flat: 1.2125955242663622, pod: 26.3842716217041, loss: 31.67963284254074 
Train [11/11] | Epoch [152/160] |	nca: 4.121293425559998, flat: 1.1996012777090073, pod: 26.718161642551422, loss: 32.03905630111694 
Train [11/11] | Epoch [153/160] |	nca: 3.9536856934428215, flat: 1.149154955521226, pod: 26.249598503112793, loss: 31.35243922472 
Train [11/11] | Epoch [154/160] |	nca: 3.9128970727324486, flat: 1.1775654293596745, pod: 26.343895852565765, loss: 31.43435788154602 
Train [11/11] | Epoch [155/160] |	nca: 3.9902806282043457, flat: 1.1322322357445955, pod: 25.866427063941956, loss: 30.988939940929413 
Train [11/11] | Epoch [156/160] |	nca: 4.323530159890652, flat: 1.149244301021099, pod: 26.594973504543304, loss: 32.06774801015854 
Train [11/11] | Epoch [157/160] |	nca: 4.119642227888107, flat: 1.1720062345266342, pod: 26.183205604553223, loss: 31.47485387325287 
Train [11/11] | Epoch [158/160] |	nca: 4.006330199539661, flat: 1.1414518635720015, pod: 25.54583203792572, loss: 30.693614184856415 
Train [11/11] | Epoch [159/160] |	nca: 3.909452810883522, flat: 1.1320560537278652, pod: 25.708685398101807, loss: 30.750194132328033 
Train [11/11] | Epoch [160/160] |	nca: 3.8701778426766396, flat: 1.1722603384405375, pod: 25.98798394203186, loss: 31.030422270298004 
Fine-tuning
Building & updating memory.
Train [11/11] | Epoch [161/180] |	nca: 2.1472547948360443, flat: 0.7724730670452118, pod: 14.83218377828598, loss: 17.751911520957947 
Train [11/11] | Epoch [162/180] |	nca: 1.3152787238359451, flat: 0.8341077417135239, pod: 15.409873008728027, loss: 17.559259593486786 
Train [11/11] | Epoch [163/180] |	nca: 1.1795290932059288, flat: 0.844539150595665, pod: 15.379494369029999, loss: 17.403562605381012 
Train [11/11] | Epoch [164/180] |	nca: 1.1278821267187595, flat: 0.8360832035541534, pod: 15.500317692756653, loss: 17.46428292989731 
Train [11/11] | Epoch [165/180] |	nca: 1.0482880510389805, flat: 0.8350568450987339, pod: 15.425445199012756, loss: 17.308790147304535 
Train [11/11] | Epoch [166/180] |	nca: 0.9694920033216476, flat: 0.8016746416687965, pod: 15.35183960199356, loss: 17.123006224632263 
Train [11/11] | Epoch [167/180] |	nca: 0.9301845990121365, flat: 0.7976608984172344, pod: 15.040032684803009, loss: 16.767878234386444 
Train [11/11] | Epoch [168/180] |	nca: 0.9526437856256962, flat: 0.8049021624028683, pod: 15.223769307136536, loss: 16.9813152551651 
Train [11/11] | Epoch [169/180] |	nca: 0.9719389155507088, flat: 0.80723812058568, pod: 15.236541867256165, loss: 17.015718698501587 
Train [11/11] | Epoch [170/180] |	nca: 0.8858964964747429, flat: 0.7963205650448799, pod: 15.189800679683685, loss: 16.872017800807953 
Train [11/11] | Epoch [171/180] |	nca: 0.874614454805851, flat: 0.78096828982234, pod: 15.137799978256226, loss: 16.7933828830719 
Train [11/11] | Epoch [172/180] |	nca: 0.8669573962688446, flat: 0.8006621338427067, pod: 15.195391952991486, loss: 16.863011419773102 
Train [11/11] | Epoch [173/180] |	nca: 0.8159186840057373, flat: 0.7855124585330486, pod: 14.8952796459198, loss: 16.49671083688736 
Train [11/11] | Epoch [174/180] |	nca: 0.8223558738827705, flat: 0.8206113800406456, pod: 15.478899776935577, loss: 17.12186712026596 
Train [11/11] | Epoch [175/180] |	nca: 0.8881054371595383, flat: 0.8240005783736706, pod: 15.376372814178467, loss: 17.088478922843933 
Train [11/11] | Epoch [176/180] |	nca: 0.8819329738616943, flat: 0.7903216127306223, pod: 14.718062281608582, loss: 16.390316784381866 
Train [11/11] | Epoch [177/180] |	nca: 0.7720312960445881, flat: 0.7931178882718086, pod: 15.309762954711914, loss: 16.87491238117218 
Train [11/11] | Epoch [178/180] |	nca: 0.8220813348889351, flat: 0.8215630799531937, pod: 15.326841711997986, loss: 16.970486223697662 
Train [11/11] | Epoch [179/180] |	nca: 0.8062225244939327, flat: 0.7596513777971268, pod: 14.726617693901062, loss: 16.292491376399994 
Train [11/11] | Epoch [180/180] |	nca: 0.8367092534899712, flat: 0.8251122198998928, pod: 15.623478710651398, loss: 17.285300254821777 
after task
Building & updating memory.
after task
Saving model at results\dev\podnet\202401\week_1\20240103_podnet_cnn_cifar100_10steps\net_0_task_10.pth.
Saving metadata at results\dev\podnet\202401\week_1\20240103_podnet_cnn_cifar100_10steps\meta_0_task_10.pkl.
Eval on 0->100.
eval task
podnet_cnn_cifar100_10steps
Avg inc acc: 0.6298181818181819.
Current acc: {'total': 0.525, '00-09': 0.595, '10-19': 0.471, '20-29': 0.412, '30-39': 0.499, '40-49': 0.528, '50-59': 0.5, '60-69': 0.434, '70-79': 0.519, '80-89': 0.609, '90-99': 0.679}.
Avg inc acc top5: 0.8767272727272726.
Current acc top5: {'total': 0.814}.
Forgetting: 0.22490909090909092.
Cord metric: 0.63.
Old accuracy: 0.51, mean: 0.60.
New accuracy: 0.74, mean: 0.76.
Average Incremental Accuracy: 0.6298181818181819.
Label was: podnet_cnn_cifar100_10steps
Results done on 1 seeds: avg: 62.98, last: 52.5, forgetting: 22.49
Individual results avg: [62.98]
Individual results last: [52.5]
Individual results forget: [22.49]
Command was C:\Users\Vicco\Desktop\LibContinual\run_trainer.py
Time cost :  4872.235140800476
